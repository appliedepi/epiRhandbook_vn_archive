[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"index.html","id":"dịch-tễ-học-ứng-dụng-và-y-tế-công-cộng-với-r","chapter":"","heading":"Dịch tễ học ứng dụng và y tế công cộng với R","text":"Sổ tay này hướng tới:Là một tài liệu tham khảo R một cách nhanh chóngCung cấp các ví dụ tập trung vào nhiệm vụ giải quyết các vấn đề dịch tễ học phổ biếnHỗ trợ các nhà dịch tễ học chuyển sang sử dụng RCó thể sử dụng trong các tình huống có kết nối internet thấp thông qua phiên bản ngoại tuyến  Được viết bởi các nhà dịch tễ học, dành cho các nhà dịch tễ họcChúng tôi là những nhà dịch tễ học đến từ khắp mọi nơi trên thế giới, viết trong thời gian rảnh của mình để cung cấp tài liệu này tới cộng đồng. Sự động viên và góp ý của bạn luôn được chào đón thông qua:Gửi biểu mẫu phản hồiEmail tới epiRhandbook@gmail.com hoặc tweet @epiRhandbookGửi các vấn đề cho chúng tôi tại Github repository","code":""},{"path":"index.html","id":"sổ-tay-này-được-sử-dụng-như-thế-nào","chapter":"","heading":"Sổ tay này được sử dụng như thế nào","text":"Truy cập các trang trong phần Mục lục, hoặc sử dụng ô tìm kiếmNhấn biểu tượng “copy” để sao chép codeKết hợp theo dõi cùng với các bộ dữ liệu minh họaXem phần “Tài nguyên” trong từng chương để tìm thêm tài liệuPhiên bản ngoại tuyếnXem hướng dẫn tại trang Tải sách và dữ liệu.","code":""},{"path":"index.html","id":"lời-cảm-ơn","chapter":"","heading":"Lời cảm ơn","text":"Sổ tay này được tạo ra bởi sự hợp tác của các nhà dịch tễ học từ khắp nơi trên thế giới, đúc kết kinh nghiệm cùng với các tổ chức khác bao gồm các cơ quan y tế địa phương, tiểu bang, tỉnh và quốc gia, Tổ chức Y tế Thế giới (), Tổ chức Bác sỹ không biên giới (MSF), hệ thống các bệnh viện, và các đơn vị nghiên cứu.Sổ tay này không phải là sản phẩm đã được phê duyệt của bất kỳ tổ chức cụ thể nào. Mặc dù chúng tôi cố gắng đảm bảo tính chính xác, nhưng chúng tôi không chịu trách nhiệm về nội dung trong cuốn sách này.","code":""},{"path":"index.html","id":"những-người-đóng-góp","chapter":"","heading":"Những người đóng góp","text":"Chủ biên: Neale BatraNhóm nòng cốt dự án: Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay CampbellNhóm tác giả: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen LinNhóm dịch giả: Nguyễn Thanh Lương, Nguyễn Thị Khánh Huyền, Võ Hữu Thuận, Nguyễn Trung Thành, Vũ Thu Hà, Hồ Hoàng DungNhóm phản biện: Pat Keating, Annick Lenglet, Margot Charette, Danielly Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao MuiangaHình minh họa: Calder Fong","code":""},{"path":"index.html","id":"tài-trợ-và-hỗ-trợ","chapter":"","heading":"Tài trợ và hỗ trợ","text":"Sổ tay này nhận được tài trợ thông qua kinh phí hỗ trợ trợ xây dựng năng lực khẩn cấp COVID-19 từ TEPHINET, mạng lưới toàn cầu của các Chương trình Đào tạo Dịch tễ học Thực địa (FETPs).Các hỗ trợ hành chính được cung cấp bởi mạng lưới cựu sinh EPIET (EAN), với lời cảm ơn đặc biệt tới Annika Wendland. EPIET là Chương trình đào tạo Dịch tễ học can thiệp tại Châu Âu.Đặc biệt gửi lời cảm ơn tới Trung tâm Điều hành Amsterdam (OCA) của Tổ chức Bác sỹ không biên giới (MSF) cho những sự hỗ trợ của họ trong quá trình phát triển cuốn sổ tay này.Ấn phẩm này được hỗ trợ bởi Hợp đồng Hợp tác số NU2GGH001873, được tài trợ bởi Trung tâm Kiểm soát và Phòng ngừa Dịch bệnh thông qua TEPHINET, một chương trình của Lực lượng đặc nhiệm về sức khỏe toàn cầu. Nội dung của sổ tay hoàn toàn tác giả chịu trách nhiệm và đại diện cho quan điểm chính thức của Trung tâm Kiểm soát và Phòng ngừa Dịch bệnh, Bộ Y tế và Dịch vụ Nhân sinh, Lực lượng Đặc nhiệm về Sức khỏe Toàn cầu, hoặc TEPHINET","code":""},{"path":"index.html","id":"cảm-hứng","chapter":"","heading":"Cảm hứng","text":"Rất nhiều các hướng dẫn và tóm tắt cung cấp kiến thức sử dụng để phát triển nội dung sổ tay này được tham khảo trong các trang nội dung tương ứng.Một cách tổng quát hơn, các nguồn sau đây đã truyền nguồn cảm hứng cho cuốn sổ tay này:“R4Epis” project (một sự hợp tác giữa MSF và RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R MarkdownNetlify để lưu trữ trang web này","code":""},{"path":"index.html","id":"điều-khoản-sử-dụng-và-đóng-góp","chapter":"","heading":"Điều khoản sử dụng và đóng góp","text":"","code":""},{"path":"index.html","id":"giấy-phép","chapter":"","heading":"Giấy phép","text":"Sổ tay này được cấp phép theo Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.Chúng tôi khuyến khích các khóa học và các chương trình đào tạo dịch tễ sử dụng cuốn sổ tay này cho sinh viên của mình. Nếu bạn có thắc mắc về mục đích sử dụng của mình, hãy gửi email tới epiRhandbook@gmail.com.","code":""},{"path":"index.html","id":"trích-dẫn","chapter":"","heading":"Trích dẫn","text":"Neale Batra và cộng sự, Cẩm nang Dịch tễ học với R. ","code":""},{"path":"index.html","id":"đóng-góp","chapter":"","heading":"Đóng góp","text":"Nếu bạn muốn đóng góp nội dung, vui lòng liên hệ với chúng tôi thông qua Github hoặc email. Chúng tôi đang triển khai lịch trình cập nhật cho cuốn sách cũng như xây dựng hướng dẫn dành cho cộng tác viên.Xin lưu ý rằng dự án epiRhandbook được phát hành cùng với bộ Quy tắc ứng xử của cộng tác viên. Bằng cách đóng góp cho dự án này, bạn đồng ý tuân theo các điều khoản của nó.","code":""},{"path":"editorial-style.html","id":"editorial-style","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"1 Biên tập và ghi chú kỹ thuật","text":"Trong chương này, chúng tôi sẽ mô tả triết lý và phong cách viết code, cũng như các quyết định biên tập cụ thể được thực hiện trong việc tạo ra cuốn sổ tay này.","code":""},{"path":"editorial-style.html","id":"cách-tiếp-cận-và-phong-cách","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"1.1 Cách tiếp cận và phong cách","text":"Độc giả tiềm năng của cuốn sách này là rất lớn, bao gồm những người hoàn toàn mới đối với R, và cả những người dùng R có kinh nghiệm đang tìm kiếm cho mình các phương pháp và mẹo hay nhất. Vì vậy, cuốn sách cần phải vừa dễ tiếp cận vừa ngắn gọn. đó, cách tiếp cận của chúng tôi là cung cấp lượng văn bản giải thích vừa đủ để một người mới sử dụng R cũng có thể áp dụng code và hiểu code đang làm gì.Một vài điểm lưu ý:Đây là cuốn sách tham khảo về code đi kèm với những ví dụ tương đối ngắn gọn - không phải một cuốn sách giáo khoa về R hay khoa học dữ liệuĐây là một cuốn sổ tay về R sử dụng trong dịch tễ học ứng dụng - không phải là một hướng dẫn về các phương pháp của dịch tễ học ứng dụngCuốn sách dự kiến sẽ luôn được thay đổi và cập nhập các R packages tối ưu cho một nhiệm vụ luôn được thay đổi thường xuyên, vì vậy chúng tôi hoan nghênh những thảo luận về những điều được nhấn mạnh trong cuốn sách này","code":""},{"path":"editorial-style.html","id":"r-packages","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"R packages","text":"Quá nhiều lựa chọnMột trong những khía cạnh thách thức nhất của việc học R là bạn biết package nào được sử dụng trong trường hợp nào. Việc vật lộn với một công việc mà chỉ sau này bạn nhận ra là có một package R giúp bạn thực hiện tất cả những điều đó trong một dòng lệnh là điều không hề hiếm gặp!Trong sổ tay này, chúng tôi cố gắng cung cấp cho bạn ít nhất hai cách để hoàn thành công việc: một phương pháp đã thử và đúng (có thể là base R hoặc tidyverse) và một R package đặc biệt được thiết kế riêng cho mục đích đó. Chúng tôi muốn bạn có một số tùy chọn trong trường hợp bạn không thể tải xuống một package nhất định hoặc package đó không hoạt động với bạn.Khi lựa chọn package để làm việc, chúng tôi ưu tiên các R package và phương pháp tiếp cận đã được cộng đồng thử nghiệm và hiệu chỉnh, giảm thiểu số lượng package được sử dụng trong một phiên làm việc điển hình, bao gồm sự ổn định (không thay đổi thường xuyên) và giúp hoàn thành nhiệm vụ một cách đơn giản và gọn gàngCuốn sách này ưu tiện các package và câu lệnh từ thư viện tidyverse. Tidyverse là một tuyển tập các R package được thiết kế dành riêng cho khoa học dữ liệu, trong đó các package này chia sẻ nền tảng ngữ pháp và cấu trúc dữ liệu chung. Tất cả các package từ thư viện tidyverse có thể được cài đặt hoặc gọi thông qua thư viện tidyverse. Đọc thêm tại tidyverse website.Khi thích hợp, chúng tôi cũng cung cấp các tùy chọn code sử dụng base R - là các packages và hàm có sẵn của R khi cài đặt. Điều này là chúng tôi nhận thấy rằng một số độc giả của cuốn sách này có thể không có Internet tốt để tải xuống các package bổ sung.Liên kết các hàm và packages một cách rõ ràngTrong các hướng dẫn về R thường rất khó chịu khi một hàm được hiển thị trong code, nhưng bạn không biết hàm đó đến từ package nào! Chúng tôi cố gắng tránh tình trạng này.Trong các đoạn văn bản trần thuật, tên các package được viết đậm (ví dụ: dplyr) và các hàm được viết như sau: mutate(). Chúng tôi cố gắng nói rõ ràng về một hàm đến từ package nào, bằng cách tham chiếu package đó trong đoạn văn bản gần đó hoặc nhấn mạnh package đó một cách rõ ràng trong đoạn code như sau: dplyr::mutate(). Điều này nhìn có vẻ thừa thãi, nhưng chúng tôi làm điều đó là có mục đích.Tham khảo thêm chương R cơ bản để hiểu thêm về package và hàm.","code":""},{"path":"editorial-style.html","id":"phong-cách-viết-code","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"Phong cách viết code","text":"Trong sổ tay này, chúng tôi thường viết theo phong cách “thêm dòng mới”, điều này làm cho code trông có vẻ “dài hơn”. Chúng tôi làm vậy vì một vài lý sau đây:Chúng tôi có thể viết các giải thích bằng # bên cạnh mỗi phần nhỏ của codeNhìn chung, code dài hơn (theo chiều dọc) thì dễ đọc hơnNó cũng dễ đọc hơn trong một diện tích màn hình hẹp (không cần kéo thanh điều hướng trái phải)Từ việc thụt lề, có thể dễ dàng hơn để biết arguments nào thuộc về hàm nàoKết quả là, code lẽ ra sẽ được viết trông như thế này:…bây giờ sẽ được viết như thế này:Code R thường không bị ảnh hưởng bởi thêm các dòng mới hoặc thụt lề. Khi viết code, nếu bạn xuống dòng ngay sau dấu phẩy thì R sẽ tự động thụt lề cho bạn.Chúng tôi cũng sử dụng rất nhiều những khoảng cách (ví dụ n = 1 thay vì n=1) vì nó giúp dễ đọc hơn. Hãy văn minh với những người đang đọc code của bạn!","code":"\nlinelist %>% \n  group_by(hospital) %>%  # group rows by hospital\n  slice_max(date, n = 1, with_ties = F) # if there's a tie (of date), take the first row\nlinelist %>% \n  group_by(hospital) %>% # group rows by hospital\n  slice_max(\n    date,                # keep row per group with maximum date value \n    n = 1,               # keep only the single highest row \n    with_ties = F)       # if there's a tie (of date), take the first row"},{"path":"editorial-style.html","id":"danh-pháp","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"Danh pháp","text":"Trong sổ tay này, chúng tôi thường đề cập đến “cột” và “hàng” thay vì dùng “biến” và “quan sát”. Như đã giải thích trong phần sơ lược về “tidy data”, hầu hết các bộ dữ liệu thống kê dịch tễ học bao gồm các hàng, cột và giá trị theo cấu trúcBiến số chứa các giá trị đo lường của cùng một thuộc tính (như nhóm tuổi, kết cục hoặc ngày khởi phát). Các quan sát bao gồm tất cả các giá trị được đo trên cùng một đơn vị (ví dụ: người, địa điểm hoặc mẫu phòng thí nghiệm). Vì vậy, những khía cạnh này có thể khó được định nghĩa một cách cụ thể.Trong một bộ dữ liệu “tidy”, mỗi cột là một biến số, mỗi hàng là một quan sát và mỗi ô là một giá trị duy nhất. Tuy nhiên, bạn có thể gặp một số bộ dữ liệu không phù hợp với quy luật này - bộ dữ liệu định dạng “ngang” có thể có một biến số được chia thành nhiều cột (xem ví dụ trong chương Pivoting dữ liệu). Tương tự như vậy, các quan sát có thể được trải thành nhiều hàng.Phần lớn cuốn sách này tập trung vào quản lý và biến đổi dữ liệu, vì vậy việc đề cập đến cấu trúc dữ liệu cụ thể của các hàng và cột sẽ liên quan hơn là đề cập tới các khái niệm trừu tượng như các quan sát và biến. Các trường hợp ngoại lệ chủ yếu xảy ra trong các chương về phân tích dữ liệu, ở đó chúng tôi đề cập nhiều hơn đến các biến số và quan sát.","code":""},{"path":"editorial-style.html","id":"lưu-ý","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"Lưu ý","text":"Dưới đây là một vài lưu ý bạn có thể gặp trong cuốn sách:GHI CHÚ: Đây là ghi chúMẸO: Đây là mẹo.CẨN TRỌNG: Đây là ghi chú cẩn trọng.NGUY HIỂM: Đây là một cảnh báo.","code":""},{"path":"editorial-style.html","id":"quyết-định-biên-tập","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"1.2 Quyết định biên tập","text":"Dưới đây, chúng tôi ghi lại các quyết định biên tập quan trọng về việc lựa chọn package và hàm. Nếu bạn không đồng ý hoặc muốn đưa ra một công cụ mới để xem xét, vui lòng tham gia/bắt đầu cuộc thảo luận trên Trang Github của chúng tôi.Bảng các package, hàm, và các quyết định biên tập khác","code":""},{"path":"editorial-style.html","id":"các-bản-sửa-đổi-chính","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"1.3 Các bản sửa đổi chính","text":"","code":""},{"path":"editorial-style.html","id":"thông-tin-phiên-làm-việc-r-rstudio-packages","chapter":"1 Biên tập và ghi chú kỹ thuật","heading":"1.4 Thông tin phiên làm việc (R, RStudio, packages)","text":"Dưới đây là thông tin về các phiên bản của các R package, RStudio và R được sử dụng trong quá trình rendering cuốn sách này.","code":"\nsessioninfo::session_info()## - Session info -------------------------------------------------------------------------\n##  setting  value                       \n##  version  R version 4.1.0 (2021-05-18)\n##  os       Windows 10 x64              \n##  system   x86_64, mingw32             \n##  ui       RStudio                     \n##  language (EN)                        \n##  collate  English_United States.1252  \n##  ctype    English_United States.1252  \n##  tz       Europe/Paris                \n##  date     2021-07-12                  \n## \n## - Packages -----------------------------------------------------------------------------\n##  package     * version    date       lib source                            \n##  assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.1.0)                    \n##  backports     1.2.1      2020-12-09 [1] CRAN (R 4.1.0)                    \n##  bookdown      0.22       2021-04-22 [1] CRAN (R 4.1.0)                    \n##  broom         0.7.6      2021-04-05 [1] CRAN (R 4.2.0)                    \n##  bslib         0.2.5.1    2021-05-18 [1] CRAN (R 4.2.0)                    \n##  cellranger    1.1.0      2016-07-27 [1] CRAN (R 4.1.0)                    \n##  cli           2.5.0      2021-04-26 [1] CRAN (R 4.1.0)                    \n##  colorspace    2.0-1      2021-05-04 [1] CRAN (R 4.2.0)                    \n##  crayon        1.4.1      2021-02-08 [1] CRAN (R 4.2.0)                    \n##  curl          4.3        2019-12-02 [1] CRAN (R 4.0.0)                    \n##  data.table    1.13.0     2020-07-24 [1] CRAN (R 4.1.0)                    \n##  DBI           1.1.1      2021-01-15 [1] CRAN (R 4.2.0)                    \n##  dbplyr        2.0.0      2020-11-03 [1] CRAN (R 4.1.0)                    \n##  digest        0.6.27     2020-10-24 [1] CRAN (R 4.1.0)                    \n##  downlit       0.2.1      2020-11-04 [1] CRAN (R 4.1.0)                    \n##  dplyr       * 1.0.6      2021-05-05 [1] CRAN (R 4.2.0)                    \n##  DT          * 0.16       2020-10-13 [1] CRAN (R 4.1.0)                    \n##  ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)                    \n##  evaluate      0.14       2019-05-28 [1] CRAN (R 4.1.0)                    \n##  fansi         0.5.0      2021-05-25 [1] CRAN (R 4.2.0)                    \n##  forcats     * 0.5.1      2021-01-27 [1] CRAN (R 4.2.0)                    \n##  foreign       0.8-81     2020-12-22 [2] CRAN (R 4.1.0)                    \n##  fs            1.5.0      2020-07-31 [1] CRAN (R 4.0.3)                    \n##  generics      0.1.0      2020-10-31 [1] CRAN (R 4.1.0)                    \n##  ggplot2     * 3.3.3      2020-12-30 [1] CRAN (R 4.2.0)                    \n##  glue          1.4.2      2020-08-27 [1] CRAN (R 4.1.0)                    \n##  gtable        0.3.0      2019-03-25 [1] CRAN (R 4.1.0)                    \n##  haven         2.3.1      2020-06-01 [1] CRAN (R 4.1.0)                    \n##  here        * 1.0.0      2020-11-15 [1] CRAN (R 4.1.0)                    \n##  highr         0.9        2021-04-16 [1] CRAN (R 4.2.0)                    \n##  hms           1.1.0      2021-05-17 [1] CRAN (R 4.2.0)                    \n##  htmltools     0.5.1.1    2021-01-22 [1] CRAN (R 4.2.0)                    \n##  htmlwidgets   1.5.3      2020-12-10 [1] CRAN (R 4.1.0)                    \n##  httr          1.4.2      2020-07-20 [1] CRAN (R 4.1.0)                    \n##  incidence2    1.1        2021-05-29 [1] CRAN (R 4.2.0)                    \n##  jquerylib     0.1.4      2021-04-26 [1] CRAN (R 4.2.0)                    \n##  jsonlite      1.7.2      2020-12-09 [1] CRAN (R 4.1.0)                    \n##  knitr         1.33       2021-04-24 [1] CRAN (R 4.2.0)                    \n##  lifecycle     1.0.0      2021-02-15 [1] CRAN (R 4.2.0)                    \n##  lubridate   * 1.7.10     2021-02-26 [1] CRAN (R 4.2.0)                    \n##  magrittr      2.0.1      2020-11-17 [1] CRAN (R 4.1.0)                    \n##  modelr        0.1.8      2020-05-19 [1] CRAN (R 4.1.0)                    \n##  munsell       0.5.0      2018-06-12 [1] CRAN (R 4.1.0)                    \n##  openxlsx      4.2.3      2020-10-27 [1] CRAN (R 4.1.0)                    \n##  pacman        0.5.1      2019-03-11 [1] CRAN (R 4.1.0)                    \n##  pillar        1.6.1      2021-05-16 [1] CRAN (R 4.2.0)                    \n##  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.1.0)                    \n##  purrr       * 0.3.4      2020-04-17 [1] CRAN (R 4.0.0)                    \n##  R6            2.5.0      2020-10-28 [1] CRAN (R 4.1.0)                    \n##  Rcpp          1.0.6      2021-01-15 [1] CRAN (R 4.1.0)                    \n##  readr       * 1.3.1      2018-12-21 [1] CRAN (R 4.0.0)                    \n##  readxl        1.3.1      2019-03-13 [1] CRAN (R 4.0.0)                    \n##  reprex        0.3.0      2019-05-16 [1] CRAN (R 4.1.0)                    \n##  rio         * 0.5.16     2018-11-26 [1] CRAN (R 4.1.0)                    \n##  rlang         0.4.11     2021-04-30 [1] CRAN (R 4.2.0)                    \n##  rmarkdown     2.6.4      2021-01-17 [1] Github (rstudio/rmarkdown@0a2a3ca)\n##  rprojroot     2.0.2      2020-11-15 [1] CRAN (R 4.1.0)                    \n##  rstudioapi    0.13       2020-11-12 [1] CRAN (R 4.1.0)                    \n##  rvest         0.3.6      2020-07-25 [1] CRAN (R 4.1.0)                    \n##  sass          0.4.0      2021-05-12 [1] CRAN (R 4.2.0)                    \n##  scales        1.1.1      2020-05-11 [1] CRAN (R 4.1.0)                    \n##  sessioninfo   1.1.1      2018-11-05 [1] CRAN (R 4.1.0)                    \n##  stringi       1.6.2      2021-05-17 [1] CRAN (R 4.2.0)                    \n##  stringr     * 1.4.0      2019-02-10 [1] CRAN (R 4.0.0)                    \n##  tibble      * 3.1.2      2021-05-16 [1] CRAN (R 4.2.0)                    \n##  tidyr       * 1.1.3      2021-03-03 [1] CRAN (R 4.2.0)                    \n##  tidyselect    1.1.1      2021-04-30 [1] CRAN (R 4.2.0)                    \n##  tidyverse   * 1.3.0      2019-11-21 [1] CRAN (R 4.0.0)                    \n##  utf8          1.2.1.9000 2021-04-21 [1] Github (patperry/r-utf8@15e56f0)  \n##  vctrs         0.3.8      2021-04-29 [1] CRAN (R 4.2.0)                    \n##  withr         2.4.2      2021-04-18 [1] CRAN (R 4.1.0)                    \n##  xfun          0.23       2021-05-15 [1] CRAN (R 4.2.0)                    \n##  xml2          1.3.2      2020-04-23 [1] CRAN (R 4.0.0)                    \n##  yaml          2.2.1      2020-02-01 [1] CRAN (R 4.0.0)                    \n##  zip           2.1.1      2020-08-27 [1] CRAN (R 4.1.0)                    \n## \n## [1] D:/Rlibrary\n## [2] C:/Program Files/R/R-4.1.0/library"},{"path":"data-used.html","id":"data-used","chapter":"2 Tải sách và dữ liệu","heading":"2 Tải sách và dữ liệu","text":"","code":""},{"path":"data-used.html","id":"tải-sách-ngoại-tuyến","chapter":"2 Tải sách và dữ liệu","heading":"2.1 Tải sách ngoại tuyến","text":"Bạn có thể tải xuống phiên bản ngoại tuyến của sổ tay này dưới dạng tệp HTML để có thể xem trong trình duyệt web của mình ngay cả khi bạn không có kết nối internet. Nếu bạn đang cân nhắc việc sử dụng ngoại tuyến Sổ tay Epi R, dưới đây là một số điều bạn cần cân nhắc:Khi bạn mở tệp, có thể mất một đến hai phút để tải các hình ảnh và mục lụcPhiên bản ngoại tuyến có bố cục hơi khác với phiên bản trực tuyến - là một trang rất dài với Mục lục ở phía bên trái. Để tìm kiếm các cụm từ cụ thể, hãy sử dụng Ctrl + F (Cmd-f)Xem chương Package đề xuất để hỗ trợ bạn cài đặt các R package thích hợp trước khi bạn mất kết nối internetCài đặt package epirhandbook của chúng tôi trong đó chứa tất cả các dữ liệu minh họa (quy trình cài đặt được mô tả bên dưới)Có hai cách bạn có thể tải xuống sổ tay:","code":""},{"path":"data-used.html","id":"sử-dụng-link-download","chapter":"2 Tải sách và dữ liệu","heading":"Sử dụng link download","text":"Để truy cập nhanh, nháy phải chuột vào link này và lựa chọn “Save link ”.Nếu trên máy Mac, hãy sử dụng Cmd + Nhấp chuột. Nếu trên điện thoại di động, hãy bấm và giữ liên kết và chọn “Save link”. Sổ tay sẽ tải xuống thiết bị của bạn. Nếu trên màn hình xuất hiện mã HTML gốc, hãy đảm bảo bạn đã làm đúng theo các hướng dẫn bên trên hoặc thử Phương án 2.","code":""},{"path":"data-used.html","id":"sử-dụng-package-của-chúng-tôi","chapter":"2 Tải sách và dữ liệu","heading":"Sử dụng package của chúng tôi","text":"Chúng tôi cung cấp một R package có tên là epirhandbook. Nó bao gồm một hàm có tên download_book() giúp bạn tải xuống sổ tay này từ kho Github của chúng tôi vào máy tính của bạn.Package này cũng chứa hàm get_data() giúp tải xuống toàn bộ các dữ liệu minh họa vào máy tính của bạn.Chạy dòng code sau để cài đặt package epirhandbook từ Github repository appliedepi. Đây không phải là package thuộc CRAN, đó cần sử dụng hàm đặc biệt p_install_gh() để cài đặt nó từ Github.Bây giờ, bạn gọi package để sử dụng cho phiên làm việc R hiện tại:Tiếp theo, bạn chạy hàm download_book() (phần trong ngoặc bỏ trống) để tải sổ tay vào máy tính của bạn. Nếu bạn sử dụng RStudio, một cửa sổ sẽ xuất hiện cho phép bạn lựa chọn thư mục lưu trữ.","code":"\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n# load the package for use\npacman::p_load(epirhandbook)\n# download the offline handbook to your computer\ndownload_book()"},{"path":"data-used.html","id":"tải-dữ-liệu-xuống-để-tiện-theo-dõi","chapter":"2 Tải sách và dữ liệu","heading":"2.2 Tải dữ liệu xuống để tiện theo dõi","text":"Để “tiện theo dõi” cùng với sổ tay này, bạn có thể tải xuống các bộ dữ liệu minh họa và các kết quả.","code":""},{"path":"data-used.html","id":"sử-dụng-package-của-chúng-tôi-1","chapter":"2 Tải sách và dữ liệu","heading":"Sử dụng package của chúng tôi","text":"Cách dễ nhất để tải xuống tất cả dữ liệu là cài đặt package epirhandbook của chúng tôi. Nó chứa hàm get_data() giúp lưu toàn bộ dữ liệu minh họa vào một thư mục bạn chọn trên máy tính của mình.Để cài đặt package epirhandbook, bạn chạy theo code dưới đây. Lưu ý là package này không từ CRAN, đó cần sử dụng hàm p_install_gh() để cài đặt. Thông tin đầu vào sẽ được chuyển tới trang Github của chúng tôi (“appliedepi”) và package epirhandbook.Bây giờ, bạn gọi package để sử dụng cho phiên làm việc hiện tại:Tiếp theo, sử dụng hàm get_data() trong package để tải dữ liệu minh họa và máy tính của bạn. Chạy hàm get_data(\"\") để tải toàn bộ dữ liệu minh họa, hoặc bạn có thể nêu tên một tệp cụ thể và phần mở rộng bên trong dấu ngoặc kép để tải một tệp duy nhất.Dữ liệu sẽ được tải xuống cùng với package và bạn đơn giản chỉ cần lưu nó vào một thư mục trên máy tính của bạn. Một cửa sổ sẽ xuất hiện, cho phép bạn chọn vị trí lưu thư mục. Chúng tôi khuyên bạn nên tạo một thư mục mới tên là “data” vì có khoảng 30 tệp (bao gồm các bộ dữ liệu minh họa và kết quả).Khi bạn dùng hàm get_data() để lưu tệp dữ liệu vào máy tính của mình, bạn sẽ vẫn cần nhập dữ liệu vào R. Xem chương Nhập xuất dữ liệu để biết thêm chi tiết.Nếu bạn muốn, bạn có thể xem toàn bộ dữ liệu sử dụng trong cuốn sách này ở thư mục “dữ liệu” trong kho Github của chúng tôi.","code":"\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n# load the package for use\npacman::p_load(epirhandbook)\n# download all the example data into a folder on your computer\nget_data(\"all\")\n\n# download only the linelist example data into a folder on your computer\nget_data(file = \"linelist_cleaned.rds\")\n# download a specific file into a folder on your computer\nget_data(\"linelist_cleaned.rds\")"},{"path":"data-used.html","id":"tải-từng-thứ-một","chapter":"2 Tải sách và dữ liệu","heading":"Tải từng thứ một","text":"Tùy chọn này liên quan đến việc tải xuống từng tệp dữ liệu từ kho lưu trữ Github của chúng tôi thông qua liên kết hoặc lệnh R dành riêng cho từng tệp. Một số loại tệp cho phép nút tải xuống, trong khi những loại khác có thể được tải xuống thông qua lệnh R.","code":""},{"path":"data-used.html","id":"dữ-liệu-linelist","chapter":"2 Tải sách và dữ liệu","heading":"Dữ liệu linelist","text":"Đây là số liệu bùng phát Ebola giả định, được nhóm tác giả cẩm nang mở rộng từ bộ dữ liệu thực hành ebola_sim trong package outbreaks.Bấm để tải xuống dữ liệu “thô” linelist (.xlsx). Bộ dữ liệu “thô” là một trang tính Excel với dữ liệu lộn xộn. Sử dụng số liệu này trong chương Làm sạch số liệu và các hàm quan trọng.Bấm để tải xuống dữ liệu “thô” linelist (.xlsx). Bộ dữ liệu “thô” là một trang tính Excel với dữ liệu lộn xộn. Sử dụng số liệu này trong chương Làm sạch số liệu và các hàm quan trọng.Bấm để tải xuống dữ liệu “đã làm sạch” linelist (.rds). Sử dụng tệp này cho tất cả các chương khác trong sổ tay có sử dụng bộ dữ liệu linelist. Tệp mở rộng .rds là một kiểu file của R có khả năng lưu trữ các thông tin cột. Điều này đảm bảo bạn sẽ có ít việc phải làm khi làm sạch số liệu sau khi nhập số liệu vào R.Bấm để tải xuống dữ liệu “đã làm sạch” linelist (.rds). Sử dụng tệp này cho tất cả các chương khác trong sổ tay có sử dụng bộ dữ liệu linelist. Tệp mở rộng .rds là một kiểu file của R có khả năng lưu trữ các thông tin cột. Điều này đảm bảo bạn sẽ có ít việc phải làm khi làm sạch số liệu sau khi nhập số liệu vào R.Các tệp liên quan khác:Bấm để tải xuống dữ liệu “đã làm sạch” linelist dưới dạng tệp ExcelBấm để tải xuống dữ liệu “đã làm sạch” linelist dưới dạng tệp ExcelMột phần của chương làm sạch sử dụng “từ điển làm sạch” (tệp .csv). Bạn có thể tải nó trực tiếp vào R bằng cách chạy các lệnh sau:Một phần của chương làm sạch sử dụng “từ điển làm sạch” (tệp .csv). Bạn có thể tải nó trực tiếp vào R bằng cách chạy các lệnh sau:","code":"\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\ncleaning_dict <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/case_linelists/cleaning_dict.csv\")"},{"path":"data-used.html","id":"data_malaria","chapter":"2 Tải sách và dữ liệu","heading":"Dữ liệu số trường hợp sốt rét","text":"Đây là số liệu giả định về số lượng trường hợp sốt rét theo nhóm tuổi, cơ sở điều trị và ngày. Tệp mở rộng .rds là một kiểu file của R có khả năng lưu trữ các thông tin cột. Điều này đảm bảo bạn sẽ có ít việc phải làm khi làm sạch số liệu sau khi nhập số liệu vào R. Bấm để tải file dữ liệu sốt rét (.rds file) ","code":""},{"path":"data-used.html","id":"dữ-liệu-thang-đo-likert","chapter":"2 Tải sách và dữ liệu","heading":"Dữ liệu thang đo Likert","text":"Đây là dữ liệu giả định từ một cuộc khảo sát sử dụng thang đo Likert, được sử dụng trong chương Tháp dân số và thang đo Likert. Bạn có thể tải những dữ liệu này trực tiếp vào R bằng cách chạy các lệnh sau:","code":"\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\nlikert_data <- import(\"https://raw.githubusercontent.com/nsbatra/Epi_R_handbook/master/data/likert_data.csv\")"},{"path":"data-used.html","id":"flexdashboard","chapter":"2 Tải sách và dữ liệu","heading":"Flexdashboard","text":"Dưới đây là các liên kết đến tệp được dùng trong chương Dashboards với R Markdown:Để tải xuống R Markdown dashboard về một đợt bùng phát dịch, bấm phải chuột vào link này (Cmd+click đối với Mac) và chọn “Save link ”.Để tải xuống HTML dashboard, bấm phải chuột vào link này (Cmd+click đối với Mac) và chọn “Save link ”.","code":""},{"path":"data-used.html","id":"truy-vết-tiếp-xúc","chapter":"2 Tải sách và dữ liệu","heading":"Truy vết tiếp xúc","text":"Chương Truy vết tiếp xúc trình bày phân tích dữ liệu truy vết tiếp xúc, sử dụng dữ liệu minh họa từ Go.Data. Dữ liệu được sử dụng trong chương này có thể được tải xuống dưới dạng tệp .rds bằng cách bấm vào các liên kết sau: Bấm để tải xuống dữ liệu điều tra trường hợp (.rds file)  Bấm để tải xuống dữ liệu ghi nhận tiếp xúc (.rds file)  Bấm để tải xuống dữ liệu theo dõi liên hệ (.rds file) LƯU Ý: Dữ liệu truy vết tiếp xýc có cấu trúc từ phần mềm khác (ví dụ: KoBo, DHIS2 Tracker, CommCare) có thể sẽ khác. Nếu bạn muốn đóng góp dữ liệu hoặc nội dung mẫu thay thế cho trang này, vui lòng liên hệ chúng tôi.MẸO: Nếu bạn đang triển khai Go.Data và muốn kết nối với API phiên bản của bạn, vui lòng xem chương Nhập xuất dữ liệu (mục API) và Go.Data Cộng đồng thực hành.","code":""},{"path":"data-used.html","id":"gis","chapter":"2 Tải sách và dữ liệu","heading":"GIS","text":"Shapefiles có nhiều tệp thành phần phụ, mỗi tệp có một phần mở rộng tệp khác nhau. Một tệp sẽ có phần mở rộng “.shp”, nhưng những tệp khác có thể là “.dbf”, “.prj”, v.v.Chương GIS cơ bản cung cấp các liên kết đến trang web Humanitarian Data Exchange, nơi bạn có thể tải xuống trực tiếp các shapefiles dưới dạng tệp nén.Ví dụ, dữ liệu phân bố của các cơ sở y tế có thể được tải xuống tại đây. Bạn tải tệp “hotosm_sierra_leone_health_facilities_points_shp.zip”. Sau khi được lưu vào máy tính của bạn, hãy “giải nén” thư mục. Bạn sẽ thấy một số tệp có các phần mở rộng khác nhau (ví dụ: “.shp”, “.prj”, “.shx”) - tất cả những tệp này phải được lưu vào cùng một thư mục trên máy tính của bạn. Sau đó, để nhập vào R, hãy cung cấp đường dẫn đến tệp và tên của tệp “.shp” bằng hàm st_read() từ package sf (đã được mô tả trong chương GIS cơ bản).Nếu bạn làm theo Cách 1 để tải xuống tất cả dữ liệu minh họa (thông qua package epirhandbook của chúng tôi), tất cả các shapefiles đã được bao gồm.Ngoài ra, bạn có thể tải xuống các shapefiles từ thư mục “data” trên trang R Handbook Github (xem thư mục con “gis”). Tuy nhiên, cần lưu ý rằng bạn sẽ phải tải từng tệp con xuống máy tính của mình. Trong Github, nhấp vào từng tệp riêng lẻ và tải chúng xuống bằng cách nhấp vào nút “Download”. Xem hình minh họa dưới đây, bạn có thể thấy shapefile “sl_adm3” bao gồm nhiều tệp con như thế nào - và mỗi tệp đều cần được tải xuống từ Github.","code":""},{"path":"data-used.html","id":"cây-phả-hệ","chapter":"2 Tải sách và dữ liệu","heading":"Cây phả hệ","text":"Xem chương Cây phả hệ. Tệp có tên Newick về cây phả hệ được xây dựng từ việc giải trình tự toàn bộ bộ gen của 299 mẫu Shigella sonnei và dữ liệu mẫu tương ứng (được chuyển đổi thành tệp văn bản). Các mẫu và kết quả từ nước Bỉ được cung cấp thông qua Trung tâm tham khảo quốc gia về Salmonella và Shigella (NRC Bỉ) trong phạm vi dự án EUPHEM Fellow của ECDC thực hiện, và cũng sẽ được xuất bản dưới dạng bản thảo. Dữ liệu quốc tế được cung cấp công khai trên cơ sở dữ liệu công cộng (ncbi) và đã được xuất bản trước đó.Để tải xuống file cây phả hệ “Shigella_tree.txt”, nhấn chuột phải vào link này (Cmd+click đối với Mac) và chọn “Save link ”.Để tải xuống file “sample_data_Shigella_tree.csv” với thông tin bổ sung cho từng mẫu, nhấn chuột phải vào link này (Cmd+click đối với Mac) và chọn “Save link ”.Để xem subset-tree mới được tạo, nhấn chuột phải vào link này (Cmd+click đối với Mac) và chọn “Save link ”. Tệp .txt sẽ được tải xuống máy tính của bạn.Sau đó bạn có thể nhập tệp .txt files bằng hàm read.tree() từ ape package, như đã được trình bày trong chương này.","code":"\nape::read.tree(\"Shigella_tree.txt\")"},{"path":"data-used.html","id":"chuẩn-hóa","chapter":"2 Tải sách và dữ liệu","heading":"Chuẩn hóa","text":"Xem trong chương Tỷ lệ chuẩn hóa. Bạn có thể tải dữ liệu trực tiếp từ kho lưu trữ Github của chúng tôi trên internet vào phiên làm việc R của bạn bằng các lệnh sau :","code":"\n# install/load the rio package\npacman::p_load(rio) \n\n##############\n# Country A\n##############\n# import demographics for country A directly from Github\nA_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryA.csv\")\n\n##############\n# Country B\n##############\n# import demographics for country B directly from Github\nB_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryB.csv\")\n\n\n###############\n# Reference Pop\n###############\n# import demographics for country B directly from Github\nstandard_pop_data <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/world_standard_population_by_sex.csv\")"},{"path":"data-used.html","id":"data_outbreak","chapter":"2 Tải sách và dữ liệu","heading":"Chuỗi thời gian và phát hiện ổ dịch","text":"Xem trong chương Chuỗi thời gian và phát hiện ổ dịch. Chúng tôi sử dụng các trường hợp campylobacter được báo cáo ở Đức từ 2002-2011, có sẵn từ package surveillance của R. (lưu ý. tập dữ liệu này đã được điều chỉnh từ bản gốc, trong đó 3 tháng dữ liệu cuối năm 2011 đã bị xóa để dùng với mục đích minh họa) Bấm để tải xuống dữ liệu Campylobacter ở Đức (.xlsx) Chúng tôi cũng sử dụng dữ liệu khí hậu ở Đức từ 2002-2011 (nhiệt độ tính bằng độ C và lượng mưa tính bằng milimet). Dữ liệu được tải xuống từ tập dữ liệu phân tích vệ tinh Copernicus của EU bằng cách sử dụng package ecmwfr . Bạn sẽ cần tải xuống tất cả những thứ này và nhập chúng vào R bằng hàm stars::read_stars() như đã được giải thích trong chương chuỗi thời gian. Bấm để tải dữ liệu thời tiết ở Đức 2002 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2003 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2004 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2005 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2006 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2007 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2008 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2009 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2010 (.nc file)  Bấm để tải dữ liệu thời tiết ở Đức 2011 (.nc file) ","code":""},{"path":"data-used.html","id":"data_survey","chapter":"2 Tải sách và dữ liệu","heading":"Phân tích sống còn","text":"Đối với chương phân tích sống còn, chúng tôi sử dụng dữ liệu khảo sát tử vong giả định dựa trên mẫu khảo sát của MSF OCA. Dữ liệu giả định này là một phần của Dự án “R4Epis”. Bấm để tài xuống dữ liệu khảo sát giả định (.xlsx)  Bấm để tài xuống từ điển dữ liệu khảo sát giả định (.xlsx)  Bấm để tài xuống dữ liệu khảo sát quần thể giả định (.xlsx) ","code":""},{"path":"data-used.html","id":"data_shiny","chapter":"2 Tải sách và dữ liệu","heading":"Shiny","text":"Chương Dashboards với Shiny trình diễn việc xây dựng một ứng dụng đơn giản để hiển thị dữ liệu bệnh sốt rét.Để tải xuống các tệp R dùng để tạo thành ứng dụng Shiny:Bạn có thể  bấm vào đây để tải xuống tệp app.R trong đó chứa code của cả UI và Server của ứng dụng Shiny.Bạn có thể  bấm vào đây để tải tệp facility_count_data.rds có chứa dữ liệu sốt rét cho ứng dụng Shiny. Lưu ý rằng bạn có thể cần phải lưu trữ nó trong thư mục “data” để các đường dẫn tệp () hoạt động chính xác.Bạn có thể  bấm vào đây để tải tệp global.R mà sẽ được chạy trước khi mở ứng dụng, như đã được giải thích trong chương.Bạn có thể  bấm vào đây để tải tệp plot_epicurve.R có nguồn từ tệp global.R. Lưu ý rằng bạn có thể cần phải lưu trữ nó trong thư mục “funcs” để các đường dẫn tệp () hoạt động chính xác.","code":""},{"path":"basics.html","id":"basics","chapter":"3 R Cơ bản","heading":"3 R Cơ bản","text":"Chào mừng bạn!Chương này sẽ mô tả những kỹ thuật cơ bản của R. Đây không phải là hướng dẫn sử dụng toàn diện, nhưng sẽ cung cấp những kiến thức cơ bản và có thể hữu ích trong việc làm mới hiểu biết của bạn. Phần Tài nguyên học liệu sẽ liên kết đến những hướng dẫn sử dụng R bao quát hơn.Các phần của chương này đã được điều chỉnh dưới sự cho phép của Dự án R4Epis.Xem chương Chuyển đổi sang R để biết các mẹo khi chuyển đổi từ STATA, SAS hoặc Excel sang R.","code":""},{"path":"basics.html","id":"tại-sao-sử-dụng-r","chapter":"3 R Cơ bản","heading":"3.1 Tại sao sử dụng R?","text":"Như đã được công bố trên trang web dự án R, R là một ngôn ngữ và môi trường lập trình cho tính toán và đồ họa thống kê. Nó rất linh hoạt, có khả năng mở rộng và hướng tới cộng đồng.Chi phíR được sử dụng miễn phí! Có sự tồn tại mạnh mẽ về đạo đức trong cộng đồng người sử dụng nguồn tài nguyên mở và miễn phí.Khả năng tái lậpThực hiện quản lý và phân tích dữ liệu của bạn thông qua một ngôn ngữ lập trình (sánh với Excel hoặc công cụ khác mà thao tác chính là nhấp chuột/thao tác thủ công) giúp nâng cao khả năng tái lập, giúp phát hiện lỗi dễ dàng hơn và giảm bớt khối lượng công việc của bạn.Cộng đồngR có cộng đồng người dùng khổng lồ và có tính hợp tác. Các package và công cụ mới nhằm giải quyết các vấn đề thực tế được phát triển hàng ngày và được kiểm tra bởi cộng đồng người dùng. Ví dụ, R-Ladies là một tổ chức toàn cầu có sứ mệnh thúc đẩy sự đa dạng giới trong cộng đồng R và là một trong những tổ chức người dùng R lớn nhất. Thậm chí có thể có một phần của nhóm này đang ở gần bạn!","code":""},{"path":"basics.html","id":"các-thuật-ngữ-chính","chapter":"3 R Cơ bản","heading":"3.2 Các thuật ngữ chính","text":"RStudio - RStudio là Giao diện đồ họa người dùng (GUI) giúp sử dụng R dễ dàng hơn. Đọc thêm trong mục RStudio.Đối tượng - Bao gồm mọi thứ bạn lưu trữ trong R - bộ dữ liệu, biến, danh sách tên làng, quy mô dân số, thậm chí cả các kết quả đầu ra như đồ thị - là các đối tượng được gán tên và có thể được tham chiếu trong các lệnh sau này. Đọc thêm trong mục Đối tượng.Hàm - Mỗi hàm là một code hoạt động mà chấp nhận dữ liệu đầu vào và trả về kết quả đầu ra đã được biến đổi. Đọc thêm trong mục Các hàm.Packages - Mỗi package R là một gói câu lệnh có khả năng chia sẻ. Đọc thêm trong mục Packages.Scripts - Mỗi script là một tệp tài liệu chứa các lệnh của bạn. Đọc thêm trong mục Scripts","code":""},{"path":"basics.html","id":"learning","chapter":"3 R Cơ bản","heading":"3.3 Tài nguyên học liệu","text":"","code":""},{"path":"basics.html","id":"tài-nguyên-trong-rstudio","chapter":"3 R Cơ bản","heading":"Tài nguyên trong RStudio","text":"Tài liệu trợ giúpTìm kiếm tab “Help” của RStudio về tài liệu liên quan đến package R và các hàm cụ thể. Tab này nằm trong cửa sổ chứa các tab Files, Plots và Packages (thường ở cửa sổ phía dưới bên phải). Như một lối tắt, bạn cũng có thể nhập tên của một package hoặc câu lệnh vào R Console sau dấu hỏi chấm và không bao gồm dấu ngoặc đơn để mở trang trợ giúp liên quan.Ví dụ: ?filter hoặc ?diagrammeR.Các hướng dẫn có sự tương tácR có thể được học thông qua một số tương tác trong RStudio.RStudio cung cấp một cửa sổ Tutorial được hỗ trợ bởi package learnr. Chỉ cần cài đặt package này và mở hướng dẫn qua tab “Tutorial” trong cửa sổ RStudio phía trên bên phải (cũng chứa các tab Environment và History).Package swirl cung cấp các nội dung học tương tác trong R Console. Cài đặt và tải package này, rồi chạy lệnh swirl() (dấu ngoặc đơn trống) trong R Console. Bạn sẽ thấy các thông báo xuất hiện trong cửa sổ Console. Phản hồi bằng cách nhập vào Console. Nó sẽ hướng dẫn bạn qua một nội dung học bạn lựa chọn.","code":""},{"path":"basics.html","id":"cheatsheets","chapter":"3 R Cơ bản","heading":"Cheatsheets","text":"Có rất nhiều “cheatsheets” PDF có sẵn trên trang web của RStudio, ví dụ như:Factors với package forcatsNgày và thời gian với package lubridateChuỗi với package stringrCác vòng lặp với package purrrNhập dữ liệuCheatsheet biến đổi dữ liệu với package dplyrR Markdown (để tạo các tài liệu như PDF, Word, Powerpoint…)Shiny (để xây dựng các ứng dụng web tương tác)Trực quan hóa dữ liệu với package ggplot2Bản đồ học (GIS)Package leaflet (bản đồ tương tác)Python với R (package reticulate)Đây là tài nguyên R trực tuyến dành riêng cho Người dùng Excel","code":""},{"path":"basics.html","id":"twitter","chapter":"3 R Cơ bản","heading":"Twitter","text":"R có một cộng đồng twitter sôi động, nơi bạn có thể tìm hiểu các mẹo, lối tắt và tin tức - hãy theo dõi các tài khoản sau:Theo dõi chúng tôi: @epiRhandbookR Function Day @rfuntionaday là một nguồn tài nguyên tuyệt vờiR Data Science @rstats4dsRStudio @RStudioRStudio Tips @rstudiotipsR-Bloggers @RbloggersR-ladies @RLadiesGlobalHadley Wickham @hadleywickhamCũng như:#epitwitter và #rstats","code":""},{"path":"basics.html","id":"nguồn-tài-nguyên-trực-tuyến-miễn-phí","chapter":"3 R Cơ bản","heading":"Nguồn tài nguyên trực tuyến miễn phí","text":"Cuốn sách R Data Science (R dành cho Khoa học Dữ liệu) của Garrett Grolemund và Hadley WickhamTrang web của dự án R4Epis nhằm mục đích “phát triển các công cụ làm sạch, phân tích và báo cáo dữ liệu được chuẩn hóa dùng trong các trường hợp bùng phát dịch phổ biến và các cuộc điều tra dựa trên dân số mà sẽ được tiến hành trong các ứng phó khẩn cấp của Tổ chức Bác sỹ không biên giới” Bạn có thể tìm thấy tài liệu đào tạo cơ bản về R, các mẫu báo cáo RMarkdown và khảo sát về các đợt bùng phát dịch, cũng như các hướng dẫn để giúp bạn thiết lập chúng.","code":""},{"path":"basics.html","id":"các-ngôn-ngữ-khác-ngoài-tiếng-anh","chapter":"3 R Cơ bản","heading":"Các ngôn ngữ khác ngoài Tiếng Anh","text":"Tài liệu RStudio bằng tiếng Tây Ban NhaGiới thiệu cơ bản về R (tiếng Pháp)","code":""},{"path":"basics.html","id":"cài-đặt","chapter":"3 R Cơ bản","heading":"3.4 Cài đặt","text":"","code":""},{"path":"basics.html","id":"r-và-rstudio","chapter":"3 R Cơ bản","heading":"R và RStudio","text":"Làm thế nào để cài đặt RTruy cập vào trang web https://www.r-project.org/ và tải phiên bản mới nhất của R phù hợp với máy tính của bạn.Làm thế nào để cài đặt RStudioTruy cập vào trang web https://rstudio.com/products/rstudio/download/ và tải phiên bản Desktop mới nhất của RStudio phù hợp với máy tính của bạn.Quyền truy cập\nLưu ý rằng bạn nên cài đặt R và RStudio vào một ổ đĩa mà bạn có quyền đọc và ghi lại. Nếu không, khả năng cài đặt các package R (thường xuyên xảy ra) của bạn sẽ bị ảnh hưởng. Nếu bạn gặp sự cố, hãy thử mở RStudio bằng cách nhấp chuột phải vào biểu tượng và chọn “Run administrator”. Các mẹo khác có thể được tìm thấy trong chương R trên ổ cứng mạng.Làm thế nào để cập nhật R và RStudioPhiên bản R của bạn được ra R Console khi khởi động. Bạn cũng có thể chạy lệnh sessionInfo().Để cập nhật R, truy cập đến trang web được nhắc đến ở trên và cài đặt lại R. Ngoài ra, bạn có thể sử dụng package installr (trên Windows) bằng cách chạy câu lệnh installr::updateR(). Thao tác này sẽ mở ra các hộp thoại giúp bạn tải xuống phiên bản R mới nhất và cập nhật các package của bạn lên phiên bản R mới. Có thể tìm thấy thêm chi tiết trong tài liệu installr .Lưu ý rằng phiên bản R cũ sẽ vẫn tồn tại trong máy tính của bạn. Bạn có thể tạm thời chạy phiên bản cũ hơn (“installation” cũ hơn) của R bằng cách nhấp vào “Tools” -> “Global Options” trong RStudio và chọn một phiên bản R. Điều này có thể hữu ích nếu bạn muốn sử dụng một package chưa được cập nhật để hoạt động trên phiên bản R mới nhất.Để cập nhật RStudio, truy cập đến trang web được nhắc đến ở trên và cài đặt lại RStudio. Một tùy chọn khác là nhấp vào “Help” -> “Check Updates” trong RStudio, nhưng điều này có thể dẫn đến việc không hiển thị các bản cập nhật mới nhất.Để xem phiên bản R, RStudio hoặc package nào đã được sử dụng khi viết Sổ tay này, hãy xem chương Biên tập và ghi chú kỹ thuật.","code":""},{"path":"basics.html","id":"những-phần-mềm-khác-bạn-có-thể-cần-cài-đặt","chapter":"3 R Cơ bản","heading":"Những phần mềm khác bạn có thể cần cài đặt","text":"TinyTeX (để biên dịch tài liệu RMarkdown sang PDF)Pandoc (để biên dịch tài liệu RMarkdown)RTools (để xây dựng các package cho R)phantomjs (để lưu ảnh tĩnh của mạng động, chẳng hạn như chuỗi lây truyền)","code":""},{"path":"basics.html","id":"tinytex","chapter":"3 R Cơ bản","heading":"TinyTex","text":"TinyTex là một bản phân phối LaTeX tùy chỉnh, hữu ích khi tạo các tệp PDF từ R.\nTruy cập https://yihui.org/tinytex/ để tìm hiểu thêm thông tin.Để cài đặt TinyTex từ R:","code":"\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n# to uninstall TinyTeX, run tinytex::uninstall_tinytex()"},{"path":"basics.html","id":"pandoc","chapter":"3 R Cơ bản","heading":"Pandoc","text":"Pandoc là một công cụ chuyển đổi văn bản, một phần mềm tách biệt với R. Nó đi kèm với RStudio và không cần phải tải xuống. Nó hỗ trợ quá trình chuyển đổi văn bản từ Rmarkdown sang các định dạng như .pdf và có bổ sung thêm một số tính năng phức tạp.","code":""},{"path":"basics.html","id":"rtools","chapter":"3 R Cơ bản","heading":"RTools","text":"RTools là một phần mềm được sử dụng để xây dựng package cho RCài đặt từ trang web: https://cran.r-project.org/bin/windows/Rtools/","code":""},{"path":"basics.html","id":"phantomjs","chapter":"3 R Cơ bản","heading":"phantomjs","text":"Phần mềm này thường được sử dụng để chụp “chụp ảnh màn hình” trang web. Ví dụ khi bạn tạo một chuỗi lây truyền với package epicontacts, một tệp HTML có thể tương tác và chuyển động được tạo ra. Nếu bạn muốn có hình ảnh tĩnh, sử dụng package webshot để tự động hóa quá trình này. Việc này sẽ yêu cầu chương trình bên ngoài “phantomjs”. Bạn có thể cài đặt phantomjs thông qua package webshot bằng lệnh webshot::install_phantomjs().","code":""},{"path":"basics.html","id":"rstudio","chapter":"3 R Cơ bản","heading":"3.5 RStudio","text":"","code":""},{"path":"basics.html","id":"làm-quen","chapter":"3 R Cơ bản","heading":"Làm quen","text":"Đầu tiên, mở RStudio. Biểu tượng của chúng có sự tương đồng, hãy chắc chắn bạn đang mở RStudio chứ không phải R.Để RStudio hoạt động bạn cũng cần phải cài đặt R trên máy tính (xem hướng dẫn cài đặt ở bên trên).RStudio là một giao diện người dùng (GUI) giúp sử dụng R dễ dàng hơn. YBạn có thể coi R như một động cơ đang đảm đương công việc chính của một phương tiện và RStudio là phần thân của phương tiện (với ghế ngồi, các phụ kiện,…) giúp bạn sử dụng động cơ tiến về phía trước. Bạn có thể xem toàn bộ cheatsheet giao diện người dùng của RStudio (PDF) tại đâyRStudio mặc định hiển thị bốn cửa sổ hình chữ nhật.MẸO: Nếu RStudio của bạn chỉ hiển thị một cửa sổ bên trái thì đó là bạn chưa mở scripts nào.Cửa sổ mã nguồn\nCửa sổ này, mặc định hiển thị phía trên bên trái, là một khoảng trống để chỉnh sửa, chạy và lưu các scripts của bạn. Script chứa các lệnh mà bạn muốn chạy. Cửa sổ này cũng có thể hiển thị thông tin dữ liệu (data frames).Đối với người dùng Stata, cửa sổ này tương tự với các cửa sổ -file và Data Editor.Cửa sổ R ConsoleR Console, mặc định ở cửa sổ bên trái hoặc phía dưới bên trái của RStudio, là ngôi nhà của “động cơ” R. Đây là nơi các lệnh thực sự được chạy, các kết quả đầu ra không phải là đồ họa và các thông báo lỗi/cảnh báo sẽ xuất hiện. Bạn có thể nhập và chạy các lệnh trực tiếp trong R Console, nhưng sẽ sớm nhận ra các lệnh này không được lưu như khi chạy lệnh từ một script.Nếu bạn đã quen thuộc với Stata, R Console giống như cửa sổ Command Window và Results Window.Cửa sổ Environment\nCửa sổ này, mặc định ở phía trên bên phải, thường được sử dụng để xem tóm tắt ngắn gọn về các đối tượng itrong R Environment ở phiên hiện tại. Các đối tượng này có thể bao gồm các tập dữ liệu đã được nhập, chỉnh sửa hoặc tạo mới, các tham số bạn đã xác định (ví dụ: một tuần dịch tễ cụ thể để phân tích), vectơ hoặc các danh sách bạn đã xác định trong quá trình phân tích (ví dụ: tên các vùng). Bạn có thể nhấp vào mũi tên bên cạnh tên của data frames để xem các biến số của nó.Cửa sổ này gần giống với cửa sổ Variables Manager trong Stata.Cửa sổ này cũng chứa History - nơi mà bạn có thể xem các lệnh đã làm trước đó. Nó cũng có một tab “Tutorial” - là nơi mà bạn có thể hoàn thành các hướng dẫn tương tác với R nếu bạn đã cài đặt package learnr. Nó cũng chứa một tab “Connections” cho phép các kết nối bên ngoài và có thể có cửa sổ “Git” nếu bạn chọn giao diện với Github.Cửa sổ Plots, Viewer, Packages, và Help\nCửa sổ phía dưới bên phải bao gồm một số tab quan trọng. Các đồ họa chính điển hình bao gồm bản đồ sẽ được hiển thị trong Cửa sổ Plot. Các kết quả đầu ra tương tác hoặc HTML sẽ được hiển thị trong cửa sổ Viewer. Cửa sổ File là một trình duyệt có thể được sử dụng để mở hoặc xóa tệp. Cửa sổ Packages cho phép bạn xem, cài đặt, cập nhật, xóa, tải/dỡ các package R và xem bạn có phiên bản package nào. Để tìm hiểu thêm về các package hãy xem mục packages bên dưới.Cửa sổ này chứa các nội dung tương đương với các cửa sổ Plots Manager và Project Manager trong Stata.","code":""},{"path":"basics.html","id":"các-cài-đặt-của-rstudio","chapter":"3 R Cơ bản","heading":"Các cài đặt của RStudio","text":"Thay đổi các cài đặt và giao diện của RStudio trong thanh menu thả xuống Tools, bằng cách chọn Global Options. Ở đó, bạn có thể thay đổi cài đặt mặc định, bao gồm cả màu giao diện/nền.Khởi động lạiNếu R của bạn bị treo, bạn có thể khởi động lại R bằng cách di chuột đến menu Session và nhấp vào “Restart R”. Thao tác này giúp tránh rắc rối khi đóng và mở RStudio. Mọi thứ trong môi trường R của bạn sẽ bị xóa khi thực hiện thao tác này.","code":""},{"path":"basics.html","id":"các-phím-tắt","chapter":"3 R Cơ bản","heading":"Các phím tắt","text":"Dưới đây là một vài phím tắt rất hữu dụng. Tất cả các phím tắt cho Windows, Max và Linux nằm ở chương 2 cheatsheet giao diện người dùng của RStudio.MẸO: Sử dụng phím Tab của bạn khi nhập để sử dụng chức năng tự động hoàn thành của RStudio. Điều này có thể giúp ngăn ngừa các lỗi chính tả. Nhấn Tab trong khi nhập để hiện ra menu thả xuống gồm các hàm và đối tượng có thể có, dựa trên những gì bạn đã nhập.","code":""},{"path":"basics.html","id":"functions","chapter":"3 R Cơ bản","heading":"3.6 Hàm","text":"Các hàm là phần cốt lõi của việc sử dụng R. Hàm là cách bạn thực hiện các tác vụ và hoạt động. Nhiều hàm được cài đặt sẵn với R, nhiều hàm khác sẵn sàng để tải xuống trong các packages (giải thích trong phần packages), và bạn thậm chí có thể viết các hàm tùy chỉnh của riêng mình!Phần khái niệm cơ bản của hàm giải thích:Thế nào là một hàm và cách mà chúng hoạt độngThế nào là đối số của hàmLàm cách nào để nhận được sự trợ giúp khi tìm hiểu một hàmLưu ý nhanh về cú pháp: Trong cuốn sổ tay này, các hàm được viết dưới dạng code văn bản với dấu mở ngoặc đơn như sau: filter(). Như đã giải thích trong phần packages, các hàm được tải xuống có sẵn trong các packages. Trong sổ tay này, tên các package được đậm, ví dụ như dplyr. Đôi khi trong code ví dụ, bạn có thể thấy tên hàm được liên kết rõ ràng với tên package của chính hàm đó bằng hai dấu hai chấm (::) như thế này: dplyr::filter(). Mục đích của việc liên kết này sẽ được giải thích trong phần package.","code":""},{"path":"basics.html","id":"các-hàm-cơ-bản","chapter":"3 R Cơ bản","heading":"Các hàm cơ bản","text":"Một hàm giống như một cỗ máy nhận các dữ liệu đầu vào, thực hiện một số thao tác với dữ liệu đó và sản xuất kết quả đầu ra. Kết quả đầu ra như thế nào phụ thuộc vào hàm mà bạn sử dụng.Các hàm thường hoạt động dựa trên các đối tượng được đặt trong dấu ngoặc đơn của hàm. Ví dụ, hàm sqrt() tính căn bậc hai của một số:Đối tượng được dùng cho một hàm cũng có thể là một cột trong tập dữ liệu (xem phần Đối tượng để biết chi tiết về tất cả các loại đối tượng). Vì R có thể lưu trữ nhiều tập dữ liệu, bạn sẽ cần xác định cả tập dữ liệu và cột. Một cách để làm điều này là sử dụng ký hiệu $ để liên kết tên của tập dữ liệu và tên của cột (dataset$column). Trong ví dụ dưới đây, hàm summary() được áp dụng cho cột age trong tập dữ liệu linelist, và kết quả đầu ra là bản tóm tắt các giá trị số và giá trị missing của cột.LƯU Ý: Đằng sau một hàm là hệ thống code bổ sung phức tạp đã được gói gọn cho người dùng thành một lệnh đơn giản.","code":"\nsqrt(49)## [1] 7\n# Print summary statistics of column 'age' in the dataset 'linelist'\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.07   23.00   84.00      86"},{"path":"basics.html","id":"hàm-với-nhiều-đối-số","chapter":"3 R Cơ bản","heading":"Hàm với nhiều đối số","text":"Các hàm thường yêu cầu một số dữ liệu đầu vào, được gọi là đối số, đặt trong dấu ngoặc đơn của hàm, thường được phân tách bằng dấu phẩy.Một vài đối số là bắt buộc để hàm hoạt động chính xác, những đối số khác là tùy chọnNhững đối số tùy chọn có thiết lập mặc địnhCác đối số có thể nhận ký tự, số, logic (TRUE / FALSE) và các dữ liệu đầu vào khácDưới đây là một hàm giả định thú vị, được gọi là oven_bake(), là ví dụ về một hàm điển hình. Hàm này nhận một đối tượng đầu vào (ví dụ: một tập dữ liệu, hoặc trong ví dụ này là “bột”) và thực hiện các hoạt động được xác định bởi các đối số bổ sung (minutes = temperature =). Kết quả đầu ra có thể được ra cửa sổ console hoặc được lưu dưới dạng một đối tượng bằng cách sử dụng toán tử gán <-.Trong một ví dụ thực tế hơn, hàm age_pyramid() dưới đây tạo một biểu đồ tháp tuổi dựa trên nhóm tuổi đã xác định và cột phân tách nhị phân, ví dụ như giới tính. Hàm được cung cấp bởi ba đối số trong dấu ngoặc đơn và được phân tách nhau bằng dấu phẩy. Các giá trị được cung cấp cho các đối số thiết lập linelist là dataframe được sử dụng, age_cat5 là cột để đếm và giới tính là cột nhị phân để sử dụng chia kim tự tháp theo màu.Lệnh trên có thể được viết tương tự như bên dưới, theo cách dài hơn với một dòng mới cho mỗi đối số. Phong cách này có thể dễ đọc và dễ viết “bình luận” hơn với # để giải thích từng phần (bình luận mở rộng là một thực hành tốt!). Để chạy lệnh dài hơn này, bạn có thể bôi đen toàn bộ lệnh và nhấp vào “Run” hoặc chỉ cần đặt con trỏ vào dòng đầu tiên rồi nhấn đồng thời phím Ctrl và phím Enter.Không cần xác định nửa đầu của phép gán đối số (ví dụ: data =) nếu các đối số được viết theo một thứ tự cụ thể (được chỉ định trong tài liệu của hàm). Đoạn code dưới đây tạo ra cùng một kim tự tháp như ở trên, bởi vì hàm kì vọng thứ tự đối số là: data frame, biến age_group, biến split_by.Một lệnh age_pyramid() phức tạp hơn có thể bao gồm các đối số tùy chọn để:Hiển thị tỷ lệ thay vì số lượng (đặt proportional = TRUE khi giá trị mặc định là FALSE)Chỉ định hai màu để sử dụng (pal = là viết tắt của “bảng màu” và được cung cấp với một vectơ gồm hai tên màu. Xem chương đối tượng để biết cách hàm c() tạo ra một vectơ)LƯU Ý: Đối với các đối số mà bạn xác định với cả hai phần của đối số (ví dụ: proportional = TRUE), thứ tự của chúng trong tất cả các đối số không quan trọng.","code":"\n# Create an age pyramid\nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n# Create an age pyramid\nage_pyramid(\n  data = linelist,        # use case linelist\n  age_group = \"age_cat5\", # provide age group column\n  split_by = \"gender\"     # use gender column for two sides of pyramid\n  )\n# This command will produce the exact same graphic as above\nage_pyramid(linelist, \"age_cat5\", \"gender\")\nage_pyramid(\n  linelist,                    # use case linelist\n  \"age_cat5\",                  # age group column\n  \"gender\",                    # split by gender\n  proportional = TRUE,         # percents instead of counts\n  pal = c(\"orange\", \"purple\")  # colors\n  )"},{"path":"basics.html","id":"viết-hàm","chapter":"3 R Cơ bản","heading":"Viết hàm","text":"R là một ngôn ngữ được định hướng xung quanh hàm, vì thế bạn nên cảm thấy được trao quyền để tự viết các hàm của riêng mình. Việc tạo ra hàm mang đến một vài lợi thế:Tạo điều kiện thuận lợi cho lập trình mô-đun - tách code thành các phần độc lập và có thể quản lýThay thế việc copy--paste lặp đi lặp lại, điều mà có thể dễ xảy ra lỗiĐặt tên dễ nhớ cho các đoạn codeCách viết một hàm được trình bày cụ thể trong chương Viết hàm.","code":""},{"path":"basics.html","id":"packages","chapter":"3 R Cơ bản","heading":"3.7 Packages","text":"Packages chứa các hàm.Một package trong phần mềm R là một gói code và các tài liệu hướng dẫn có thể chia sẻ được chứa các hàm được định nghĩa trước. Cộng đồng người dùng phần mềm R luôn phát triển những package giúp giải quyết các vấn đề cụ thể, điều này có thể sẽ giúp bạn trong công việc của mình! Bạn sẽ có thể cần cài đặt và sử dụng hàng trăm package trong quá trình sử dụng phần mềm R.Khi cài đặt, R đã có sẵn các package và hàm “cơ bản” giúp thực hiện các nhiệm vụ đơn giản. Nhưng nhiều người dùng R tạo ra các hàm chuyên biệt, được cộng đồng R kiểm chứng và bạn có thể tải xuống dưới dạng package để sử dụng theo cách của riêng mình. Trong sách này, tên package được viết đậm. Một trong những khía cạnh thách thức hơn cả của R đó là thường có nhiều hàm hoặc package để lựa chọn nhằm hoàn thành một nhiệm vụ nhất định.","code":""},{"path":"basics.html","id":"cài-đặt-và-gọi","chapter":"3 R Cơ bản","heading":"Cài đặt và Gọi","text":"Các hàm được chứa trong packages có thể được tải (“cài đặt”) về máy tính của bạn từ internet. Khi một package được tải xuống, package đó sẽ được lưu trữ trong “thư viện” của bạn. Sau đó, bạn có thể truy cập các hàm mà nó chứa trong phiên làm việc hiện tại trên R của bạn bằng cách “Gọi” package.Hãy coi R là thư viện cá nhân của bạn: Khi bạn tải xuống một package, thư viện của bạn nhận được một cuốn sách mới gồm các hàm, nhưng mỗi lần bạn muốn sử dụng một hàm trong cuốn sách đó, bạn phải mượn (“gọi”) cuốn sách đó từ thư viện của mình.Tóm lại: để sử dụng các hàm có sẵn trong package R, phải thực hiện 2 bước:Package phải được cài đặt (một lần), vàPackage phải được gọi (trong mỗi phiên làm việc của R)","code":""},{"path":"basics.html","id":"thư-viện-của-bạn","chapter":"3 R Cơ bản","heading":"Thư viện của bạn","text":"“Thư viện” của bạn thực ra là một thư mục trên máy tính của bạn, bao gồm các thư mục chứa các package đã được cài đặt. Hãy tìm nơi R được cài đặt trong máy tính của bạn và tìm kiếm một thư mục có tên “win-library”. Ví dụ: R\\win-library\\4.0 (4.0 là phiên bản R - bạn sẽ có các thư viện khác nhau tùy theo phiên bản R mà bạn đã tải xuống).Bạn có thể ra đường dẫn tệp đến thư viện của mình bằng cách gõ lệnh .libPaths() (dấu ngoặc bỏ trống). Điều này trở nên đặc biệt quan trọng nếu làm việc với R trên ổ cứng mạng.","code":""},{"path":"basics.html","id":"cài-đặt-từ-cran","chapter":"3 R Cơ bản","heading":"Cài đặt từ CRAN","text":"Thông thường, người dùng R tải các package xuống từ CRAN. CRAN (Comprehensive R Archive Network - Mạng lưu trữ R toàn diện) là một kho công cộng trực tuyến gồm các package R đã được xuất bản bởi các thành viên cộng đồng R.Bạn có cần lo lắng về vi-rút và bảo mật khi tải xuống một package từ CRAN? Đọc bài viết sau để hiểm thêm về chủ đề này.","code":""},{"path":"basics.html","id":"làm-thế-nào-để-cài-đặt-và-gọi","chapter":"3 R Cơ bản","heading":"Làm thế nào để cài đặt và gọi","text":"Trong sách này, chúng tôi khuyên bạn nên sử dụng package pacman (viết tắt của “package manager”). Nó cung cấp một hàm thuận tiện p_load() mà sẽ cài đặt một package nếu cần và gọi nó để sử dụng trong phiên làm việc hiện tại.Cú pháp khá đơn giản. Chỉ cần liệt kê tên của các package trong dấu ngoặc đơn của hàm p_load() và phân tách chúng bằng dấu phẩy. Lệnh dưới đây sẽ cài đặt các package sau rio, tidyverse, và nếu chúng chưa được cài đặt và sẽ gọi chúng ra để sử dụng. Điều này làm cho cách tiếp cận p_load() trở nên thuận tiện và ngắn gọn nếu chia sẻ scripts với người khác. Lưu ý rằng tên package có phân biệt chữ hoa chữ thường.Lưu ý rằng chúng ta đã sử dụng cú pháp pacman::p_load() để viết rõ ràng tên package (pacman) trước tên hàm (p_load()), được nối với nhau bằng hai dấu hai chấm ::. Cú pháp này tiện dụng vì nó cũng gọi package pacman (giả sử package này đã được cài đặt).Ngoài ra còn có các hàm base R thay thế mà bạn sẽ gặp thường xuyên. Hàm base R để cài đặt một package là install.packages(). Tên của package muốn cài đặt phải được đặt trong dấu ngoặc đơn bên trong dấu ngoặc kép. Nếu bạn muốn cài đặt nhiều package trong một lệnh, chúng phải được liệt kê trong một vectơ dạng ký tự c().Lưu ý: lệnh này cài đặt một package, nhưng không gọi nó ra để sử dụng trong phiên làm việc hiện tại.Việc cài đặt cũng có thể được thực hiện bằng cách chọn và nhấp chuột vào cửa sổ RStudio “Package” và chọn “Install”, sau đó tìm kiếm tên package mong muốn cài đặt.Hàm base R để gọi một package ra sử dụng (sau khi nó đã được cài đặt) là library(). Hàm này chỉ có thể gọi một package tại một thời điểm (cách khác của lệnh p_load()). Bạn có thể nhập tên package có hoặc không có dấu ngoặc kép.Để kiểm tra xem một package đã được cài đặt và/hoặc đã được gọi hay chưa, bạn có thể xem Cửa số Package trong RStudio. Nếu package được cài đặt, nó sẽ hiển thị ở đó với số phiên bản. Nếu checkbox của nó được đánh dấu nghĩa là nó đã được gọi cho phiên làm việc hiện tại.Cài đặt từ GithubĐôi khi, bạn cần cài đặt một package chưa có sẵn từ CRAN. Hoặc có lẽ package đã có sẵn trên CRAN nhưng bạn muốn phiên bản mới hơn với các tính năng mới chưa được cung cấp trong phiên bản cũ. Chúng thường được lưu trữ trên trang web github.com trong một “kho lưu trữ (repository)” code công khai và miễn phí. Đọc thêm về Github trong chương Version control với Git và Github.Để download packages R từ Github, bạn có thể dụng hàm p_load_gh() từ pacman, hàm này sẽ cài đặt package nếu cần và gọi nó để sử dụng cho phiên làm việc R hiện tại. Cách khác để cài đặt bao gồm sử dụng package remotes hoặc devtools. Đọc thêm về các hàm của pacman tại Tài liệu về package.Để cài đặt từ Github, bạn phải cung cấp thêm các thông tin sau:Github ID của chủ sở hữuTên của repository chứa package(Tùy chọn) Tên của “nhánh” (phiên bản phát triển cụ thể) mà bạn muốn tải xuốngTrong các ví dụ dưới đây, từ đầu tiên trong dấu ngoặc kép là Github ID của chủ sở hữu kho lưu trữ, sau dấu gạch chéo là tên của kho lưu trữ (tên của package).Nếu bạn muốn cài đặt từ một “nhánh” (phiên bản) khác với nhánh chính, hãy thêm tên nhánh sau dấu “@”, được đặt phía sau tên kho lưu trữ.Nếu không có sự khác biệt giữa phiên bản Github và phiên bản trên máy tính của bạn, bạn không cần thực hiện thao tác này. Thay vào đó, bạn có thể “buộc” phải cài đặt lại bằng cách sử dụng p_load_current_gh() với đối số update = TRUE. Đọc thêm về pacman tại Minh họa trực tuyếnCài đặt từ ZIP hoặc TARBạn có thể cài đặt package từ một URL:Hoặc, tải xuống máy tính của bạn dưới dạng tệp nén:Cách 1: sử dụng lệnh install_local() từ package remotesCách 2: sử dụng lệnh install.packages() của base R, cung cấp đường dẫn tệp đến tệp ZIP và thiết lập type = \"source và repos = NULL.","code":"\n# Install (if necessary) and load packages for use\npacman::p_load(rio, tidyverse, here)\n# install a single package with base R\ninstall.packages(\"tidyverse\")\n\n# install multiple packages with base R\ninstall.packages(c(\"tidyverse\", \"rio\", \"here\"))\n# load packages for use, with base R\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\n# install/load the epicontacts package from its Github repository\np_load_gh(\"reconhub/epicontacts\")\n# install the \"timeline\" branch of the epicontacts package from Github\np_load_gh(\"reconhub/epicontacts@timeline\")\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\ninstall.packages(\"~/Downloads/dplyr-master.zip\", repos=NULL, type=\"source\")"},{"path":"basics.html","id":"cú-pháp-code","chapter":"3 R Cơ bản","heading":"Cú pháp code","text":"Để tăng sự tường minh trong cuốn sách này, các hàm đôi khi sẽ được đặt sau tên package của chúng bằng cách sử dụng ký hiệu :: theo cách sau: package_name::function_name()Khi một package được gọi cho một phiên làm việc, việc làm này là không cần thiết. Bạn chỉ cần sử dụng function_name(). Tuy nhiên, việc viết tên package sẽ hữu ích khi một tên hàm phổ biến và có thể tồn tại trong nhiều package (ví dụ: plot()). Việc viết tên package sẽ giúp gọi package trong trường hợp nó chưa được gọi ra.","code":"\n# This command uses the package \"rio\" and its function \"import()\" to import a dataset\nlinelist <- rio::import(\"linelist.xlsx\", which = \"Sheet1\")"},{"path":"basics.html","id":"trợ-giúp-về-hàm","chapter":"3 R Cơ bản","heading":"Trợ giúp về hàm","text":"Để đọc thêm thông tin về một hàm, bạn có thể tìm kiếm hàm đó trong cửa sổ Help của RStudio nằm ở góc dưới bên phải. Hoặc bạn cũng có thể chạy một lệnh chẳng hạn như ?thefunctionname (đặt tên của hàm sau dấu chấm hỏi) và trang Trợ giúp sẽ xuất hiện trong cửa sổ Help. Cuối cùng, hãy thử tìm kiếm trên internet.","code":""},{"path":"basics.html","id":"cập-nhật-packages","chapter":"3 R Cơ bản","heading":"Cập nhật packages","text":"Bạn có thể cập nhật các packages bằng cách cài đặt lại chúng. Bạn cũng có thể bấm vào nút “Update” màu xanh lá cây trong cửa sổ packages của RStudio để xem packages nào có phiên bản mới để cài đặt. Lưu ý rằng code cũ của bạn có thể cần được cập nhật nếu có một bản sửa đổi lớn về cách hoạt động của một hàm!","code":""},{"path":"basics.html","id":"xóa-packages","chapter":"3 R Cơ bản","heading":"Xóa packages","text":"Sử dụng p_delete() từ pacman, hoặc remove.packages() từ base R. Ngoài ra, hãy tìm thư mục chứa thư viện của bạn và xóa thư mục theo cách thủ công.","code":""},{"path":"basics.html","id":"sự-phụ-thuộc","chapter":"3 R Cơ bản","heading":"Sự phụ thuộc","text":"Các packages thường phụ thuộc vào các packages khác để hoạt động. Chúng được gọi là sự phụ thuộc. Nếu một package không cài đặt được, thì package phụ thuộc vào nó có khả năng cũng không thể cài đặt được.Xem sự phụ thuộc của một package với lệnh p_depends(), và xem package nào phụ thuộc vào nó với p_depends_reverse()","code":""},{"path":"basics.html","id":"hàm-bị-che-giấu","chapter":"3 R Cơ bản","heading":"Hàm bị che giấu","text":"Không có gì lạ nếu hai hoặc nhiều packages chứa cùng một tên hàm. Ví dụ: packages dplyr có hàm filter(), nhưng package stats cũng vậy. Hàm filter() mặc định phụ thuộc vào thứ tự các package này được gọi lên trong phiên làm việc R - packages được gọi ra sau sẽ là mặc định cho hàm filter().Bạn có thể kiểm tra thứ tự của chúng trong cửa sổ Environment của R Studio - nhấp vào menu thả xuống “Global Environment” và xem thứ tự của các packages. Các hàm thuộc các packages ở vị trí thấp hơn trong danh sách thả xuống đó sẽ che giấu các hàm cùng tên trong các packages xuất hiện ở vị trí bên trên trong danh sách thả xuống. Khi bạn vừa gọi một package, R sẽ cảnh báo bạn trong bảng điều khiển nếu xảy ra hiện tượng này, nhưng điều này rất hay bị bỏ quên.Dưới đây là những cách bạn có thể sửa lỗi hàm bị che giấu:Ghi rõ tên package trong lệnh. Ví dụ, sử dụng dplyr::filter()Sắp xếp lại thứ tự mà các package được tải (ví dụ trong p_load()), và bắt đầu một phiên làm việc R mới","code":""},{"path":"basics.html","id":"gỡ-package","chapter":"3 R Cơ bản","heading":"Gỡ package","text":"Để gỡ (detach) một package, hãy sử dụng lệnh dưới đây, với tên package chính xác và chỉ có một dấu hai chấm. Lưu ý rằng điều này có thể không giải quyết được việc hàm bị che giấu.","code":"\ndetach(package:PACKAGE_NAME_HERE, unload=TRUE)"},{"path":"basics.html","id":"cài-đặt-phiên-bản-cũ-hơn","chapter":"3 R Cơ bản","heading":"Cài đặt phiên bản cũ hơn","text":"Xem hướng dẫn này để cài đặt phiên bản cũ hơn của một package cụ thể.","code":""},{"path":"basics.html","id":"packages-đề-xuất","chapter":"3 R Cơ bản","heading":"Packages đề xuất","text":"Xem chương Package đề xuất để biết danh sách các packages thường được sử dụng trong dịch tễ học.","code":""},{"path":"basics.html","id":"scripts","chapter":"3 R Cơ bản","heading":"3.8 Scripts","text":"Scripts là một phần cơ bản của lập trình. Chúng là các tài liệu chứa các câu lệnh của bạn (ví dụ: các hàm để tạo và chỉnh sửa bộ số liệu, các hàm để các biểu đồ trực quan hóa số liệu, v.v.). Bạn có thể lưu một scripts và chạy lại sau này. Có nhiều lợi ích để lưu trữ và chạy các lệnh của bạn từ một scripts (với nhập “từng lệnh” vào R console):Tiện dụng - bạn có thể chia sẻ công việc của mình với người khác bằng cách gửi cho họ các tập lệnh của bạnKhả năng tái lập - để bạn và những người khác biết chính xác những gì bạn đã làmKiểm soát phiên bản - để bạn có thể theo dõi các thay đổi chính bạn hoặc đồng nghiệp thực hiệnDễ dàng nhận xét/chú thích - để giải thích cho đồng nghiệp của bạn những gì bạn đã làm","code":""},{"path":"basics.html","id":"bình-luận","chapter":"3 R Cơ bản","heading":"Bình luận","text":"Khi viết script, bạn có thể thêm các chú thích (“bình luận”) xung quanh code R của bạn. Bình luận là cần thiết để giải thích cho chính bạn và những người đọc khác hiểu những gì bạn đang làm. Bạn có thể thêm bình luận bằng cách nhập dấu thăng (#) và viết bình luận của bạn sau đó. Nội dung bình luận sẽ xuất hiện với màu khác với code R.Bất kỳ code nào được viết sau dấu # sẽ không được chạy. đó, đặt dấu # trước dòng code cũng là một cách hữu ích để tạm thời vô hiệu hóa một dòng code (“comment ”) nếu bạn không muốn xóa nó). Bạn có thể comment /nhiều dòng cùng một lúc bằng cách bôi đen chúng và nhấn Ctrl + Shift + c (Cmd + Shift + c trong Mac).Bình luận những gì bạn đang làm và tại sao bạn làm như vậy.Chia code của bạn thành các phần hợp lýKèm theo code của bạn với mô tả từng bước về những gì đang được thực hiện (ví dụ: các bước được đánh số)","code":"\n# A comment can be on a line by itself\n# import data\nlinelist <- import(\"linelist_raw.xlsx\") %>%   # a comment can also come after code\n# filter(age > 50)                          # It can also be used to deactivate / remove a line of code\n  count()"},{"path":"basics.html","id":"phong-cách-viết-code-1","chapter":"3 R Cơ bản","heading":"Phong cách viết code","text":"Phong cách viết code của bạn rất quan trọng - đặc biệt là khi làm việc theo nhóm. Chúng tôi khuyên bạn nên tuân theo hướng dẫn phong cách viết code tidyverse . Bên cạnh đó còn có các packages khác như styler và lintr để giúp bạn tuân theo phong cách này.Một vài điểm rất cơ bản để làm cho code của bạn dễ dàng đọc được đối với người khác:\n* Khi đặt tên cho các đối tượng, chỉ sử dụng các chữ cái viết thường, số và dấu gạch dưới _, ví dụ: my_data\n* Thường xuyên sử dụng dấu cách, bao gồm cả xung quanh các toán tử, ví dụ: n = 1 và age_new <- age_old + 3","code":""},{"path":"basics.html","id":"ví-dụ-về-script","chapter":"3 R Cơ bản","heading":"Ví dụ về Script","text":"Dưới đây là một ví dụ về một đoạn ngắn R script. Hãy nhớ rằng, bạn càng giải thích ngắn gọn lệnh code của mình trong phần bình luận, thì đồng nghiệp của bạn sẽ càng thích bạn!","code":""},{"path":"basics.html","id":"r-markdown","chapter":"3 R Cơ bản","heading":"R markdown","text":"R markdown là một dạng của R script và có khả năng xuất thành các tệp đầu ra (PDF, Word, HTML, Powerpoint, v.v.). Đây là những công cụ vô cùng hữu ích và linh hoạt thường được sử dụng để tạo các báo cáo tự động. Ngay cả trang web và cuốn sách này cũng được viết bằng R markdown!Bạn cần biết rằng những người mới bắt đầu dùng R cũng có thể sử dụng R Markdown - đó đừng sợ! Để tìm hiểu thêm, hãy xem chương Báo cáo với R Markdown trong cuốn sách này.","code":""},{"path":"basics.html","id":"r-notebooks","chapter":"3 R Cơ bản","heading":"R notebooks","text":"Không có sự khác biệt trong cách viết giữa R markdown và R notebook. Tuy nhiên, việc thực thi của hai loại file này hơi khác nhau một chút. Xem trang Web này để biết thêm chi tiết.","code":""},{"path":"basics.html","id":"shiny","chapter":"3 R Cơ bản","heading":"Shiny","text":"Shiny apps/websites được chứa trong một script có tên app.R. Tệp này có ba thành phần:Giao diện người dùng (ui)Một hàm máy chúMột lệng gọi hàm shinyAppXem thêm trong cuốn sách này tại chương Dashboards với Shiny, hoặc hướng dẫn trực tuyến này: Shiny tutorialTrước đây, tệp bên trên được chia thành 2 tệp con (ui.R và server.R)","code":""},{"path":"basics.html","id":"thu-gọn-code","chapter":"3 R Cơ bản","heading":"Thu gọn Code","text":"Bạn có thể thu gọn các đoạn code để làm cho script của bạn dễ đọc hơn.Để làm điều này, hãy tạo tiêu đề văn bản bằng dấu thăng #, viết tiêu đề của bạn và thêm vào phía sau nó ít nhất hoặc là 4 dấu gạch ngang (-), dấu thăng (#) hoặc dấu bằng (=). Ngay sau đó, một mũi tên nhỏ sẽ xuất bên cạnh ở bên phải số thự tự của dòng lệnh. Bạn có thể nhấp vào mũi tên này và phần code bên dưới sẽ được thu gọn cho đến trước tiêu đề tiếp theo và một mũi tên hai chiều xuất hiện ở đây.Để mở rộng lại đoạn code đã thu gọn, hãy nhấp lại vào mũi tên hoặc biểu tượng mũi tên hai chiều. Ngoài ra còn có thể sử dụng thêm các phím tắt như đã được giải thích trong mục RStudio của chương này.Bằng cách tạo tiêu đề bằng #, bạn cũng sẽ kích hoạt Mục lục ở cuối tập lệnh của mình (xem bên dưới) mà bạn có thể sử dụng để điều hướng tập lệnh của mình. Bạn có thể tạo tiêu đề phụ bằng cách thêm các ký hiệu #, ví dụ: # # cho tiêu đề chính, ## fcho tiêu đề thứ hai, và ### cho tiêu đề thứ ba.Dưới đây là hai phiên bản của một ví dụ cho script. Ở bên trái là bản gốc với các tiêu đề được chú thích. Ở bên phải, bốn dấu gạch ngang đã được viết sau mỗi tiêu đề, làm cho chúng có thể thu gọn được. Hai trong số chúng đã được thu gọn và bạn có thể thấy Mục lục ở dưới cùng hiện hiển thị từng phần.Các phần code khác mặc định đủ điều kiện để thu gọn bao gồm các phần “nằm giữa” hai dấu ngoặc nhọn { }, chẳng hạn như định nghĩa hàm hoặc các khối điều kiện (câu lệnh else). Bạn có thể đọc thêm về cách thu gọn code tại trang của Rstudio.","code":""},{"path":"basics.html","id":"thư-mục-làm-việc","chapter":"3 R Cơ bản","heading":"3.9 Thư mục làm việc","text":"Thư mục làm việc là vị trí thư mục gốc được R sử dụng cho công việc của bạn - nơi R tìm kiếm và lưu các tệp theo mặc định. Mặc định là, R sẽ lưu các tệp mới và xuất tệp vào vị trí này, đồng thời sẽ tìm kiếm các tệp để nhập dữ liệu (ví dụ: bộ dữ liệu) tại đây.Thư mục làm việc xuất hiện bằng dòng chữ màu xám ở phía trên cửa sổ Rstudio Console. Bạn cũng có thể thư mục làm việc hiện tại bằng cách chạy lệnh getwd() (để trống dấu ngoặc đơn).","code":""},{"path":"basics.html","id":"gợi-ý-cách-tiếp-cận","chapter":"3 R Cơ bản","heading":"Gợi ý cách tiếp cận","text":"Xem thêm tại chương Dự án R để biết chi tiết về gợi ý các cách tiếp cận của chúng tôi trong việc quản lý thư mục làm việc của bạn.\nMột cách phổ biến, hiệu quả và không gặp sự cố khi quản lý thư mục làm việc và đường dẫn tệp là kết hợp 3 yếu tố này trong một quy trình làm việc với [Dự án R][R projects] có định hướng :Một dự án R để lưu trữ tất cả tệp của bạn (xem tại chương Dự án R)Package để định vị tệp (xem tại [Import export])rio package import/export files (see page Nhập xuất dữ liệu)","code":""},{"path":"basics.html","id":"thiết-lập-bằng-lệnh","chapter":"3 R Cơ bản","heading":"Thiết lập bằng lệnh","text":"Cho tới gần đây, nhiều người học R đã được dạy để bắt đầu script của họ bằng lệnh setwd(). Hãy thay đổi thói quen đó bằng cách sử dụng [Dự án R][R projects] và đọc thêm tài liệu sau để hiểu lý không nên sử dụng setwd(). Một cách ngắn gọn là, công việc của bạn chỉ thực hiện được trên máy tính của bạn, các đường dẫn tệp được sử dụng để nhập và xuất tệp trở nên “dễ lỗi” và điều này cản trở nghiêm trọng đến việc cộng tác và sử dụng code của bạn trên bất kỳ máy tính nào khác. Bạn có những lựa chọn khác dễ dàng hơn!Như đã nói ở trên, mặc dù chúng tôi không khuyến nghị phương pháp này trong hầu hết các trường hợp, bạn vẫn có thể sử dụng lệnh setwd() với đường dẫn tệp thư mục mong muốn trong dấu ngoặc kép, ví dụ:NGUY HIỂM: thiết lập một thư mục làm việc với setwd() có thể dẫn đến “lỗi” nếu đường dẫn tệp dành riêng cho một máy tính. Thay vào đó, hãy sử dụng đường dẫn tệp liên quan đến thư mục gốc Dự án R (với package ).","code":"\nsetwd(\"C:/Documents/R Files/My analysis\")"},{"path":"basics.html","id":"thiết-lập-thủ-công","chapter":"3 R Cơ bản","heading":"Thiết lập thủ công","text":"Để thiết lập thư mục làm việc một cách thủ công (trỏ và nhấp tương đương với setwd()), hãy chọn mục Session trên thanh công cụ và chọn “Set Working Directory”, sau đó chọn “Choose Directory”. Chú ý: nếu sử dụng phương pháp này, bạn sẽ phải thực hiện việc này theo cách thủ công mỗi khi mở RStudio.","code":""},{"path":"basics.html","id":"thiết-lập-bên-trong-một-dự-án-r","chapter":"3 R Cơ bản","heading":"Thiết lập bên trong một dự án R","text":"Nếu bạn đang mở một dự án R, thư mục làm việc sẽ mặc định là thư mục gốc của dự án R có chứa tệp “.rproj”. Điều này sẽ áp dụng nếu bạn mở RStudio bằng cách nhấp vào mở R Project (tệp có phần mở rộng “.rproj”).","code":""},{"path":"basics.html","id":"thư-mục-làm-việc-với-r-markdown","chapter":"3 R Cơ bản","heading":"Thư mục làm việc với R markdown","text":"Trong script ở R markdown, thư mục làm việc mặc định là thư mục chứa tệp R markdown (.Rmd). Nếu sử dụng dự án R và package , điều này sẽ không được áp dụng. Để biết thư mục làm việc là gì, sử dụng lệnh () như đã được giải thích tại chương Dự án R.Nếu bạn muốn thay đổi thư mục làm việc của một tệp độc lập ở R markdown (không phải ở dự án R), nếu bạn sử dụng setwd() điều này sẽ chỉ áp dụng chỉ cho đoạn code đó. Để thực hiện thay đổi cho tất cả các đoạn code trong R markdown, hãy điều chỉnh ở bước thiết lập để thêm tham số root.dir =, như bên dưới:Cách này dễ hơn nhiều với chỉ sử dụng R markdown bên trong một dự án R và sử dụng package .","code":"\nknitr::opts_knit$set(root.dir = 'desired/directorypath')"},{"path":"basics.html","id":"cung-cấp-đường-dẫn-tệp","chapter":"3 R Cơ bản","heading":"Cung cấp đường dẫn tệp","text":"Có lẽ điều khiến những người mới bắt đầu với R cảm thấy nản nhất (ít nhất là với người dùng máy tính Windows) đó là gõ đường dẫn tệp để nhập xuất dữ liệu. Chúng tôi có giải thích cặn kẽ về cách tạo đường dẫn tệp đầu vào tốt nhất trong chương Nhập xuất dữ liệu, nhưng dưới đây là một số điểm chính:Đường dẫn tệp bị lỗiDưới đây là ví dụ về đường dẫn tệp “tuyệt đối” hoặc “địa chỉ đầy đủ”. Chúng có thể bị lỗi nếu được sử dụng bởi một máy tính khác. Một ngoại lệ là nếu bạn đang sử dụng ổ đĩa chia sẻ/mạng.Đường dẫn với dấu gạch chéoNếu nhập đường dẫn tệp, hãy lưu ý hướng của các dấu gạch chéo. Sử dụng dấu gạch chéo xuôi (/) để tách các thành phần (“data/provincial.csv”). Đối với người dùng Windows, cách mặc định mà đường dẫn tệp được hiển thị là dấu gạch chéo ngược (\\) - vì vậy bạn sẽ cần phải thay đổi hướng của mỗi dấu gạch chéo. Nếu bạn sử dụng package được miêu tả ở Dự án R thì dấu gạch chéo không còn là vấn đề với bạn nữa.Đường dẫn tệp tương đốiNói chung, chúng tôi khuyên bạn nên cung cấp các đường dẫn tệp theo cách “tương đối” - nghĩa là, đường dẫn liên quan đến thư mục gốc Dự án R của bạn. Bạn có thể thực hiện việc này bằng cách sử dụng package như được giải thích trong chương Dự án R. Một đường dẫn tệp tương đối sẽ trông như thế này:Ngay cả khi sử dụng đường dẫn tệp tương đối trong dự án R, bạn vẫn có thể sử dụng đường dẫn tuyệt đối để nhập/xuất dữ liệu ở bên ngoài dự án R của bạn.","code":"C:/Users/Name/Document/Analytic Software/R/Projects/Analysis2019/data/March2019.csv  \n# Import csv linelist from the data/linelist/clean/ sub-folders of an R project\nlinelist <- import(here(\"data\", \"clean\", \"linelists\", \"marin_country.csv\"))"},{"path":"basics.html","id":"objects","chapter":"3 R Cơ bản","heading":"3.10 Đối tượng","text":"Mọi thứ trong R đều là một đối tượng, và R là một ngôn ngữ “lập trình hướng đối tượng”. Các phần dưới đây sẽ giải thích:Cách tạo ra các đối tượng (<-)Các loại đối tượng (ví dụ: data frames, vectors..)Cách truy cập các tập con của đối tượng (ví dụ: các biến số trong một bộ dữ liệu)Các loại đối tượng (ví dụ: numeric, logical, integer, double, character, factor)","code":""},{"path":"basics.html","id":"mọi-thứ-đều-là-một-đối-tượng","chapter":"3 R Cơ bản","heading":"Mọi thứ đều là một đối tượng","text":"Phần này được dựa theo sách R4Epis project.\nMọi thứ bạn lưu trữ trong R - bao gồm bộ dữ liệu, biến số, danh sách tên làng, tổng số dân, thậm chí cả kết quả đầu ra như biểu đồ - đều là các đối tượng, được gán tên và có thể được tham chiếu trong các lệnh sau đó.Một đối tượng tồn tại khi bạn đã gán giá trị cho nó (xem phần gán bên dưới). Khi nó được gán một giá trị, đối tượng sẽ xuất hiện trong cửa sổ Environment (xem cửa sổ phía trên bên phải của RStudio). Sau đó, nó có thể được sử dụng, thao tác, thay đổi và định nghĩa lại.","code":""},{"path":"basics.html","id":"định-nghĩa-một-đối-tượng--","chapter":"3 R Cơ bản","heading":"Định nghĩa một đối tượng (<-)","text":"Tạo ra một đối tượng bằng cách gán cho chúng một giá trị bằng toán tử <-.\nBạn có thể nghĩ về toán tử gán <- tương đương với từ “được định nghĩa là”. Các lệnh gán thường tuân theo một trật tự quy định:tên đối tượng <- giá trị của đối tượng (hoặc quy trình / tính toán tạo ra giá trị)Ví dụ: bạn muốn ghi nhận một báo cáo tuần dịch tễ học hiện tại dưới dạng một đối tượng để tham chiếu tới code của bạn sau này. Trong ví dụ này, đối tượng current_week được tạo khi nó được gán giá trị \"2018-W10\" (dấu ngoặc kép sẽ quy định đây là giá trị dạng chữ). Đối tượng current_week sẽ xuất hiện trong cửa sổ RStudio Environment (phía trên bên phải) và có thể được tham chiếu tới các lệnh sau này.Xem các lệnh R và kết quả của chúng như dưới đây.CHÚ Ý: Lưu ý rằng số [1] trong kết quả ở R console đơn giản là chỉ ra rằng bạn đang xem mục đầu tiên của đầu raTHẬN TRỌNG: Giá trị của một đối tượng có thể bị ghi đè bất kỳ lúc nào bằng cách chạy lệnh gán để định nghĩa lại giá trị của nó. đó, thứ tự của các lệnh được chạy rất quan trọng.Lệnh sau sẽ định nghĩa lại giá trị của đối tượng current_week:Dấu bằng =Bạn cũng sẽ thấy các dấu bằng trong R code:Hai dấu bằng == giữa hai đối tượng hoặc giá trị dùng để đặt một câu hỏi logic: “cái này có bằng cái kia không?”.Bạn cũng sẽ thấy các dấu bằng trong các hàm được sử dụng để xác định giá trị của các đối số của hàm (đọc thêm ở các phần bên dưới), ví dụ: max(age, na.rm = TRUE).Bạn có thể sử dụng một dấu bằng = thay cho dấu <- để tạo và định nghĩa các đối tượng, nhưng điều này không được khuyến khích. Bạn có thể đọc về lý tại sao điều này không được khuyến khích ở đây.Bộ dữ liệuBộ dữ liệu (datasets) cũng là một đối tượng (thường là một “dataframes”) và phải được gán tên khi chúng được nhập. Trong đoạn mã dưới đây, đối tượng linelist được tạo và gán giá trị từ tệp CSV, tệp này được nhập bằng package rio và hàm import() của package này.Bạn có thể đọc thêm về nhập và xuất dữ liệu trong chương Nhập xuất dữ liệu.THẬN TRỌNG: Lưu ý nhanh về cách đặt tên đối tượng:Tên đối tượng không được chứa dấu cách, nhưng bạn nên sử dụng dấu gạch dưới (_) hoặc dấu chấm (.) thay vì dấu cách.Tên đối tượng phân biệt chữ hoa và chữ thường (nghĩa là Dataset_A khác với dataset_A).Tên đối tượng phải bắt đầu bằng chữ cái (không được bắt đầu bằng số như 1, 2 hoặc 3).Kết quả đầu raCác kết quả đầu ra như bảng và biểu đồ cung cấp một ví dụ về cách các kết quả đầu ra có thể được lưu dưới dạng đối tượng hoặc chỉ được ra mà không cần lưu. Ví dụ, một bảng chéo giữa giới tính và biến kết cục được tạo ra bởi hàm table() trong base R, có thể được trực tiếp vào R console (mà không cần lưu).Nhưng bảng này cũng có thể được lưu dưới dạng một đối tượng được đặt tên. Sau đó, bạn có thể nó ra.CộtCác cột trong tập dữ liệu cũng là các đối tượng và có thể được định nghĩa, ghi đè và tạo như được mô tả bên dưới trong phần Cột.Bạn có thể sử dụng toán tử gán từ base R để tạo một cột mới. Dưới đây, cột mới bmi (Body Mass Index) được tạo, và giá trị mới ứng với mỗi hàng là kết quả của một phép toán trên giá trị của các hàng trong cột wt_kg và cột ht_cm.Tuy nhiên, trong cuốn sách này, chúng tôi tập trung vào một cách tiếp cận khác để định nghĩa cột, sử dụng hàm mutate() trong package dplyr và piping với toán tử pipe (%>%). Cú pháp dễ đọc hơn và có những ưu điểm khác đã được giải thích trong cuốn sách này ở chương Làm sạch số liệu và các hàm quan trọng. Bạn có thể đọc thêm về piping trong phần Piping phía bên dưới.","code":"\ncurrent_week <- \"2018-W10\"   # this command creates the object current_week by assigning it a value\ncurrent_week                 # this command prints the current value of current_week object in the console## [1] \"2018-W10\"\ncurrent_week <- \"2018-W51\"   # assigns a NEW value to the object current_week\ncurrent_week                 # prints the current value of current_week in the console## [1] \"2018-W51\"\n# linelist is created and assigned the value of the imported CSV file\nlinelist <- import(\"my_linelist.csv\")\n# printed to R console only\ntable(linelist$gender, linelist$outcome)##    \n##     Death Recover\n##   f  1227     953\n##   m  1228     950\n# save\ngen_out_table <- table(linelist$gender, linelist$outcome)\n\n# print\ngen_out_table##    \n##     Death Recover\n##   f  1227     953\n##   m  1228     950\n# create new \"bmi\" column using base R syntax\nlinelist$bmi <- linelist$wt_kg / (linelist$ht_cm/100)^2\n# create new \"bmi\" column using dplyr syntax\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)"},{"path":"basics.html","id":"objectstructure","chapter":"3 R Cơ bản","heading":"3.10.1 Cấu trúc đối tượng","text":"Các đối tượng có thể là một phần dữ liệu đơn lẻ (ví dụ: my_number <- 24), hoặc chúng có thể bao gồm dữ liệu có cấu trúc.Hình ảnh dưới đây được tham khảo từ hướng dẫn R trực tuyến này. Nó cho thấy một số cấu trúc dữ liệu phổ biến và tên của chúng. Hình ảnh này không bao gồm dữ liệu không gian. Bạn có thể xem thêm về dữ liệu không gian tại chương GIS cơ bản.Trong dịch tễ học (và đặc biệt là dịch tễ học thực địa), bạn sẽ thường xuyên phải tiếp xúc với data frames và vectors:Lưu ý rằng để tạo một vectơ “độc lập” (mà không phải là một phần của data frame), hàm c() được sử dụng để kết hợp các phần tử khác nhau. Ví dụ: nếu tạo một vectơ màu sắc thang màu của biểu đồ: vector_of_colors <- c(\"blue\", \"red2\", \"orange\", \"grey\")","code":""},{"path":"basics.html","id":"kiểu-đối-tượng","chapter":"3 R Cơ bản","heading":"Kiểu đối tượng","text":"Tất cả các đối tượng được lưu trữ trong R đều có một kiểu dữ liệu cho biết cách nó được xử lý. Có nhiều kiểu đối tượng, nhưng những kiểu phổ biến bao gồm:Bạn có thể kiểm tra kiểu của một đối tượng bằng cách cung cấp tên của nó tới hàm class(). Lưu ý: bạn có thể tham chiếu một cột cụ thể trong tập dữ liệu bằng cách sử dụng ký hiệu $ để phân tách tên của tập dữ liệu và tên của cột.Đôi khi, một cột sẽ được tự động chuyển đổi thành một kiểu khác bởi R. Hãy coi chừng điều này! Ví dụ: nếu bạn có một vectơ hoặc cột kiểu số, nhưng một giá trị ký tự được chèn vào … thì toàn bộ cột sẽ thay đổi thành kiểu ký tự.Một ví dụ phổ biến của điều này là khi thao tác với một data frame để bảng - nếu bạn tạo một hàng tính tổng và cố gắng dán /gắn phần trăm với số trong cùng một ô (ví dụ: 23 (40%)), toàn bộ cột dạng số ở trên sẽ chuyển đổi thành ký tự và không còn có thể được sử dụng cho các phép tính toán học nữa.Đôi khi, bạn sẽ cần chuyển đổi các đối tượng hoặc cột sang một loại khác.Tương tự như vậy, một số hàm base R có thể kiểm tra xem một đối tượng CÓ thuộc của một kiểu dữ liệu cụ thể nào hay không, chẳng hạn như .numeric(), .character(), .double(), .factor(), .integer()Bạn có thể tham khảo một tài liệu trực tuyến về các kiểu và cấu trúc dữ liệu trong R tại đây.","code":"\nclass(linelist)         # class should be a data frame or tibble## [1] \"data.frame\"\nclass(linelist$age)     # class should be numeric## [1] \"numeric\"\nclass(linelist$gender)  # class should be character## [1] \"character\"\nnum_vector <- c(1,2,3,4,5) # define vector as all numbers\nclass(num_vector)          # vector is numeric class## [1] \"numeric\"\nnum_vector[3] <- \"three\"   # convert the third element to a character\nclass(num_vector)          # vector is now character class## [1] \"character\""},{"path":"basics.html","id":"cột-biến-số","chapter":"3 R Cơ bản","heading":"Cột / Biến số ($)","text":"Một cột trong data frame về mặt kỹ thuật là một “vector” (xem bảng ở trên) - bao gồm một chuỗi các giá trị cùng loại (ký tự, số, lôgic, v.v.).Một vectơ có thể tồn tại độc lập với một data frame, ví dụ: vectơ tên cột mà bạn muốn đưa vào làm biến giải thích trong mô hình. Để tạo một vectơ “độc lập”, hãy sử dụng hàm c() như dưới đây:Các cột trong data frame cũng là vectơ và có thể được gọi, tham chiếu, trích xuất hoặc tạo bằng ký hiệu $. Ký hiệu $ kết nối tên của cột với tên của data frame tương ứng. Trong cuốn sách này, chúng tôi cố gắng sử dụng từ “cột” thay vì “biến số”.Bằng cách nhập tên của một dataframe, theo sau bởi ký tự $, bạn sẽ thấy menu gợi ý của tất cả các tên cột trong dataframe. Bạn có thể di chuyển giữa các cột bằng phím mũi tên, chọn cột bằng phím Enter để tránh lỗi chính tả!MẸO NÂNG CAO: Một số đối tượng phức tạp hơn (ví dụ: một danh sách hoặc đối tượng epicontacts) có thể có nhiều cấp độ có thể được truy cập thông qua nhiều ký tự đô la. Ví dụ: epicontacts$linelist$date_onset","code":"\n# define the stand-alone vector of character values\nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# print the values in this named vector\nexplanatory_vars## [1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\"\n# Retrieve the length of the vector age_years\nlength(linelist$age) # (age is a column in the linelist data frame)"},{"path":"basics.html","id":"truy-cập-indexing-đối-tượng-bằng-dấu-ngoặc-vuông","chapter":"3 R Cơ bản","heading":"Truy cập / indexing đối tượng bằng dấu ngoặc vuông ([ ])","text":"Khi cần xem một phần của đối tượng, còn được gọi là “indexing”, bạn có thể sử dụng dấu ngoặc vuông [ ]. Sử dụng $ trên dataframe để truy cập một cột cũng là một kiểu indexing.Dấu ngoặc vuông cũng hoạt động để xem các phần cụ thể trong kết quả đầu ra, chẳng hạn như đầu ra của hàm summary():Dấu ngoặc vuông cũng hoạt động trên data frames để xem các hàng và cột cụ thể. Bạn có thể thực hiện việc này bằng cú pháp dataframe[rows, columns]:Lưu ý rằng bạn cũng có thể indexing hàng / cột trong một data frames và tibbles bằng cách sử dụng cú pháp của package dplyr (hàm filter() đối với hàng, và select() đối với cột). Đọc thêm về các hàm quan trọng này trong chương Làm sạch số liệu và các hàm quan trọng.Để lọc dựa trên “số thứ tự hàng”, bạn có thể sử dụng hàm row_number()trong package dplyr với dấu ngoặc đơn mở như một phần của biểu thức lọc logic. Thường thì bạn sẽ sử dụng toán tử %% và một khoảng giá trị số như một phần của câu lệnh logic đó, như được trình bày dưới đây. Để xem N hàng đầu tiên, bạn cũng có thể sử dụng hàm head() của package dplyr.Khi indexing một đối tượng chứa một danh sách bằng một dấu ngoặc vuông sẽ luôn trả về kiểu danh sách, ngay cả khi chỉ một đối tượng được trả về . Tuy nhiên, hai dấu ngoặc vuông có thể được sử dụng để truy cập một phần tử đơn lẻ đối và trả về một kiểu không phải là một danh sách.\nDấu ngoặc vuông cũng có thể được viết sau nhau, như được minh họa bên dưới.Bạn có thể xem một giải thích trực quan về việc indexing với ví dụ về hộp lắc hạt tiêu tại đây, rất hài hước và hữu ích.Đây là cách mà một danh sách được trong R console. Có hai phần tử được đặt tên:hospitals, một vector chứa ký tựaddresses, một data frame chứa các địa chỉDưới đây là các phương pháp indexing mà bạn có thể sử dụng:","code":"\nmy_vector <- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")  # define the vector\nmy_vector[5]                                  # print the 5th element## [1] \"e\"\n# All of the summary\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.07   23.00   84.00      86\n# Just the second element of the summary, with name (using only single brackets)\nsummary(linelist$age)[2]## 1st Qu. \n##       6\n# Just the second element, without name (using double brackets)\nsummary(linelist$age)[[2]]## [1] 6\n# Extract an element by name, without showing the name\nsummary(linelist$age)[[\"Median\"]]## [1] 13\n# View a specific row (2) from dataset, with all columns (don't forget the comma!)\nlinelist[2,]\n\n# View all rows, but just one column\nlinelist[, \"date_onset\"]\n\n# View values from row 2 and columns 5 through 10\nlinelist[2, 5:10] \n\n# View values from row 2 and columns 5 through 10 and 18\nlinelist[2, c(5:10, 18)] \n\n# View rows 2 through 20, and specific columns\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# View rows and columns based on criteria\n# *** Note the dataframe must still be named in the criteria!\nlinelist[linelist$age > 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# Use View() to see the outputs in the RStudio Viewer pane (easier to read) \n# *** Note the capital \"V\" in View() function\nView(linelist[2:20, \"date_onset\"])\n\n# Save as a new object\nnew_table <- linelist[2:20, c(\"date_onset\")] \n# View first 100 rows\nlinelist %>% head(100)\n\n# Show row 5 only\nlinelist %>% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns (note no quotes necessary on column names)\nlinelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)\n# define demo list\nmy_list <- list(\n  # First element in the list is a character vector\n  hospitals = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n  # second element in the list is a data frame of addresses\n  addresses   = data.frame(\n    street = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n    city   = c(\"Andover\", \"Hamilton\", \"El Paso\")\n    )\n  )\nmy_list## $hospitals\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\n## \n## $addresses\n##            street     city\n## 1 145 Medical Way  Andover\n## 2  1048 Brown Ave Hamilton\n## 3   999 El Camino  El Paso\nmy_list[1] # this returns the element in class \"list\" - the element name is still displayed## $hospitals\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[1]] # this returns only the (unnamed) character vector## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[\"hospitals\"]] # you can also index by name of the list element## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[1]][3] # this returns the third element of the \"hospitals\" character vector## [1] \"Santa Anna\"\nmy_list[[2]][1] # This returns the first column (\"street\") of the address data frame##            street\n## 1 145 Medical Way\n## 2  1048 Brown Ave\n## 3   999 El Camino"},{"path":"basics.html","id":"xóa-đối-tượng","chapter":"3 R Cơ bản","heading":"Xóa đối tượng","text":"Bạn có thể xóa từng đối tượng riêng lẻ khỏi cửa sổ R environment bằng cách để tên của đối tượng cần xóa vào trong hàm rm() (không có dấu ngoặc kép):Bạn có thể xóa tất cả các đối tượng (xóa không gian làm việc của bạn) bằng cách chạy:","code":"\nrm(object_name)\nrm(list = ls(all = TRUE))"},{"path":"basics.html","id":"piping","chapter":"3 R Cơ bản","heading":"3.11 Piping (%>%)","text":"Hai cách tiếp cận chung để làm việc với các đối tượng là:Pipes/tidyverse - pipes chuyển một đối tượng từ hàm này sang hàm khác - tập trung vào hành động chứ không phải đối tượngXác định đối tượng trung gian - một đối tượng được xác định lại nhiều lần - tập trung vào đối tượng","code":""},{"path":"basics.html","id":"pipes","chapter":"3 R Cơ bản","heading":"Pipes","text":"Giải thích một cách đơn giản, toán tử pipe (%>%) chuyển một đầu ra trung gian từ hàm này sang hàm tiếp theo.\nHiểu đơn giản pipe nghĩa là “sau đó”. Nhiều hàm có thể được liên kết với nhau bằng toán tử %>%.Piping nhấn mạnh một chuỗi các hành động, không phải đối tượng mà các hành động đang áp dụngPipes được áp dụng tốt nhất khi một chuỗi hành động phải được thực hiện trên một đối tượngPipes đến từ package magrittr, và đã tự động được thêm vào packages dplyr và tidyversePipes làm cho code sạch hơn, dễ đọc hơn và trực quan hơnĐọc thêm về cách tiếp cận này trong package tidyverse tại đây Hướng dẫnĐây là một ví dụ mô phỏng dùng để sánh, sử dụng các hàm hư cấu để “nướng bánh”. Đầu tiên, phương pháp pipe:Đây là một link khác mô tả công dụng của pipe.Piping không phải là một hàm trong base R. Để sử dụng piping, package magrittr phải được cài đặt và gọi ra trong phiên làm việc hiện tại (điều này thường được thực hiện bằng cách gọi package tidyverse hoặc dplyr). Bạn có thể đọc thêm về piping trong tài liệu magrittr.Lưu ý rằng cũng giống như các lệnh R khác, các pipes có thể được sử dụng để hiển thị kết quả hoặc lưu/lưu lại một đối tượng, tùy thuộc vào toán tử <- được code như thế nào. Xem hai ví dụ dưới đây:%<>%Đây là một “assignment pipe (pipe dùng để gán” từ package magrittr, package này sẽ pipe một đối tượng theo chiều tiến lên và cũng tái định nghĩa lại đối tượng. Đối tượng cần đứng đầu trong chuỗi pipe. Nó nhanh hơn sử dụng pipe thông thường. Hai lệnh dưới đây là tương đương với nhau:","code":"\n# A fake example of how to bake a cake using piping syntax\n\ncake <- flour %>%       # to define cake, start with flour, and then...\n  add(eggs) %>%   # add eggs\n  add(oil) %>%    # add oil\n  add(water) %>%  # add water\n  mix_together(         # mix together\n    utensil = spoon,\n    minutes = 2) %>%    \n  bake(degrees = 350,   # bake\n       system = \"fahrenheit\",\n       minutes = 35) %>%  \n  let_cool()            # let it cool down\n# Create or overwrite object, defining as aggregate counts by age category (not printed)\nlinelist_summary <- linelist %>% \n  count(age_cat)\n# Print the table of counts in the console, but don't save it\nlinelist %>% \n  count(age_cat)##   age_cat    n\n## 1     0-4 1095\n## 2     5-9 1095\n## 3   10-14  941\n## 4   15-19  743\n## 5   20-29 1073\n## 6   30-49  754\n## 7   50-69   95\n## 8     70+    6\n## 9    <NA>   86\nlinelist <- linelist %>%\n  filter(age > 50)\n\nlinelist %<>% filter(age > 50)"},{"path":"basics.html","id":"định-nghĩa-đối-tượng-trung-gian","chapter":"3 R Cơ bản","heading":"Định nghĩa đối tượng trung gian","text":"Cách tiếp cận này dùng để thay đổi đối tượng/dataframes sẽ phát huy hiệu quả nếu:Bạn cần thao tác trên nhiều đối tượngCác bước trung gian có ý nghĩa cụ thể và xứng đáng tạo các tên đối tượng riêng biệtCác nguy cơ:Tạo đối tượng mới cho mỗi bước có nghĩa là bạn sẽ tạo thêm rất nhiều đối tượng. Nếu bạn sử dụng không cẩn thận, bạn có thể dễ dàng bị nhầm lẫn!Đặt thêm nhiều tên cho nhiều đối tượng có thể gây nhầm lẫnNếu có lỗi thì không dễ để phát hiệnĐặt tên cho từng đối tượng trung gian hoặc ghi đè lên đối tượng gốc hoặc kết hợp tất cả hàm với nhau đều đi kèm với những rủi ro.Dưới đây vẫn là ví dụ mô phỏng quy trình làm “bánh” tương tự như trên, nhưng sử dụng phong cách này:Kết hợp tất cả các hàm với nhau - câu lệnh rất khó đọc:","code":"\n# a fake example of how to bake a cake using this method (defining intermediate objects)\nbatter_1 <- left_join(flour, eggs)\nbatter_2 <- left_join(batter_1, oil)\nbatter_3 <- left_join(batter_2, water)\n\nbatter_4 <- mix_together(object = batter_3, utensil = spoon, minutes = 2)\n\ncake <- bake(batter_4, degrees = 350, system = \"fahrenheit\", minutes = 35)\n\ncake <- let_cool(cake)\n# an example of combining/nesting mutliple functions together - difficult to read\ncake <- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = \"fahrenheit\", minutes = 35))"},{"path":"basics.html","id":"operators","chapter":"3 R Cơ bản","heading":"3.12 Các toán tử và hàm chính","text":"Mục này sẽ trình bày chi tiết các toán tử trong R, chẳng hạn như :Toán tử định nghĩaToán tử quan hệ (nhỏ hơn, bằng nhau..)Toán tử logic (và, hoặc..)Xử lý missingCác toán tử và hàm toán học (+/-, >, sum(), median(), …)Toán tử %%","code":""},{"path":"basics.html","id":"toán-tử-gán","chapter":"3 R Cơ bản","heading":"Toán tử gán","text":"<-Toán tử gán cơ bản trong R là <-. Chẳng hạn như object_name <- value.\nToán tử gán này cũng có thể được viết là =. Chúng tôi khuyên bạn nên sử dụng <-.\nBạn nên sử dụng dấu cách trong khi viết code với toán tử gán để dễ đọc hơn.<<-Khi Viết hàm, hoặc khi sử dụng R với scipt nguồn, thì bạn có thể cần sử dụng toán tử gán này <<- (từ base R). Toán tử này được sử dụng để định nghĩa một đối tượng trong một hàm lồng trong một hàm khác. Xem thêm tại nguồn tham khảo online này.%<>%Đây là một “pipe gán” từ package magrittr, package này sẽ gán một đối tượng theo chiều tiến lên và cũng định nghĩa lại đối tượng. Pipe gán phải là toán tử đầu tiên trong chuỗi pipe code. Đây là cách viết ngắn gọn, như được trình bày dưới đây là hai ví dụ tương đương với nhau:Đoạn code bên trên tương đương với code dưới đây:%<+%Toán tử này được sử dụng dể thêm dữ liệu vào Cây phả hệ với package ggtree. Xem thêm chương Cây phả hệ hoặc Sách online này.","code":"\nlinelist <- linelist %>% \n  mutate(age_months = age_years * 12)\nlinelist %<>% mutate(age_months = age_years * 12)"},{"path":"basics.html","id":"toán-tử-quan-hệ-và-logic","chapter":"3 R Cơ bản","heading":"Toán tử quan hệ và logic","text":"Toán tử quan hệ sánh các giá trị và thường được sử dụng khi định nghĩa các biến mới và tập con của bộ dữ liệu. Dưới đây là các toán tử quan hệ phổ biến trong R:Các toán tử logic, chẳng hạn như và , thường được sử dụng để kết nối các quan hệ và tạo ra các điều kiện phức tạp hơn. Các biểu thức phức tạp có thể yêu cầu dấu ngoặc đơn () để phân nhóm và thứ tự áp dụng.Ví dụ: chúng ta có một số liệu có tên linelist với hai biến mà chúng tôi muốn sử dụng để minh họa, hep_e_rdt: kết quả xét nghiệm và other_cases_in_hh: những trường hợp khác trong gia đình. Lệnh dưới đây sử dụng hàm case_when() để tạo biến mới case_def như sau:Lưu ý rằng R có phân biệt chữ hoa chữ thường, vì vậy “Positive” khác với “positive”…","code":"\nlinelist_cleaned <- linelist %>%\n  mutate(case_def = case_when(\n    is.na(rdt_result) & is.na(other_case_in_home)            ~ NA_character_,\n    rdt_result == \"Positive\"                                 ~ \"Confirmed\",\n    rdt_result != \"Positive\" & other_cases_in_home == \"Yes\"  ~ \"Probable\",\n    TRUE                                                     ~ \"Suspected\"\n  ))"},{"path":"basics.html","id":"giá-trị-missing","chapter":"3 R Cơ bản","heading":"Giá trị Missing","text":"Trong R, giá trị missing được biểu diễn bằng giá trị đặc biệt NA (giá trị “dành riêng cho missing”) (chữ N và viết hoa - không nằm trong dấu ngoặc kép). Nếu dữ liệu bạn nhập vào R bị missing theo cách khác (ví dụ: 99, “Missing”, .), bạn có thể sẽ cần phải mã hóa lại các giá trị đó thành NA. Cách thực hiện việc này được đề cập trong chương Nhập xuất dữ liệu.Để kiểm tra xem một giá trị có phải là NA hay không, sử dụng hàm đặc biệt .na(), kết quả sẽ trả về TRUE hoặc FALSE.Đọc thêm về missing, vô hạn, NULL, và các giá trị không thể trong chương Dữ liệu Missing. Tìm hiểu thêm cách chuyển đổi các giá trị bị missing khi nhập dữ liệu trong chương Nhập xuất dữ liệu.","code":"\nrdt_result <- c(\"Positive\", \"Suspected\", \"Positive\", NA)   # two positive cases, one suspected, and one unknown\nis.na(rdt_result)  # Tests whether the value of rdt_result is NA## [1] FALSE FALSE FALSE  TRUE"},{"path":"basics.html","id":"toán-học-và-thống-kê","chapter":"3 R Cơ bản","heading":"3.12.1 Toán học và thống kê","text":"{.unnumbered}Tất cả các toán tử và hàm trong chương này đều có sẵn bằng cách sử dụng base R.","code":""},{"path":"basics.html","id":"toán-tử-toán-học","chapter":"3 R Cơ bản","heading":"Toán tử toán học","text":"Chúng thường được sử dụng để thực hiện phép cộng, phép chia, để tạo cột mới, v.v. Dưới đây là các toán tử toán học phổ biến trong R. Việc bạn có đặt dấu cách xung quanh các toán tử hay không là không quan trọng.","code":""},{"path":"basics.html","id":"các-hàm-toán-học","chapter":"3 R Cơ bản","heading":"Các hàm toán học","text":"lưu ý: sử dụng hàm round() và digits = để xác định số chữ số thập phân được hiển thị. Sử dụng hàm signif() để làm tròn đến số chữ số nhất định.","code":""},{"path":"basics.html","id":"ký-hiệu-khoa-học","chapter":"3 R Cơ bản","heading":"Ký hiệu khoa học","text":"Khả năng ký hiệu khoa học được sử dụng phụ thuộc vào giá trị của scipen.Từ tài liệu hướng dẫn của ?options: scipen được áp dụng khi quyết định các giá trị số theo ký hiệu cố định hoặc hàm mũ. Giá trị dương thuộc về ký hiệu cố định còn giá trị âm thuộc về ký hiệu khoa học: ký hiệu cố định sẽ luôn được ưu tiên trừ khi có nhiều chữ số ‘scipen’.Nếu như có rất nhiều số bé cần hiển thị (vd: số 0), mặc định tính năng này sẽ “được bật”. Để “tắt” tính năng ký hiệu khoa học trong phiên làm việc của bạn, hãy thiết lập nó với một số rất lớn, ví dụ:","code":"\n# turn off scientific notation\noptions(scipen=999)"},{"path":"basics.html","id":"làm-tròn","chapter":"3 R Cơ bản","heading":"Làm tròn","text":"NGUY HIỂM: Hàm round() sử dụng “cách làm tròn của ngân hàng” nghĩa là chỉ làm tròn với số .5 nếu số được làm tròn lên là số chẵn. Sử dụng hàm round_half_up() từ package janitor để thống nhất cách làm tròn với giá trị .5. Xem thêm giải thích sau đây","code":"\n# use the appropriate rounding function for your work\nround(c(2.5, 3.5))## [1] 2 4\njanitor::round_half_up(c(2.5, 3.5))## [1] 3 4"},{"path":"basics.html","id":"các-hàm-thống-kê","chapter":"3 R Cơ bản","heading":"Các hàm thống kê","text":"CẨN TRỌNG: Các hàm sau đây sẽ mặc định bao gồm cả giá trị missing khi tính toán. Giá trị missing sẽ trả về kết quả đầu ra chứa NA, trừ khi đối số na.rm = TRUE được xác định khi viết hàm. Nó cũng có thể viết ngắn gọn thành na.rm = T.Notes:*quantile(): x là vectơ số cần khảo sát, và probs = là một vectơ số với các xác suất nằm giữa 0 và 1.0, ví dụ c(0.5, 0.8, 0.85)**summary(): trả về tóm tắt một vectơ số bao gồm giá trị trung bình, trung vị, và các khoảng phân vị thường gặpNGUY HIỂM: Nếu cung cấp một vectơ số cho một trong các hàm trên, hãy đảm bảo các số được đặt trong hàm c() .","code":"\n# If supplying raw numbers to a function, wrap them in c()\nmean(1, 6, 12, 10, 5, 0)    # !!! INCORRECT !!!  ## [1] 1\nmean(c(1, 6, 12, 10, 5, 0)) # CORRECT## [1] 5.666667"},{"path":"basics.html","id":"một-số-hàm-hữu-ích-khác","chapter":"3 R Cơ bản","heading":"Một số hàm hữu ích khác","text":"","code":""},{"path":"basics.html","id":"in","chapter":"3 R Cơ bản","heading":"%in%","text":"Một toán tử rất hữu ích để nhanh chóng đánh giá xem một giá trị có nằm trong một vectơ hoặc một dataframe hay không.Để truy vấn một giá trị không %% một vectơ, hãy đặt dấu chấm (!) phía trước biểu thức logic:%% sẽ rất hữu dụng khi dùng hàm case_when() của package dplyr. Bạn có thể định nghĩa một vectơ trước đó, sau đó tham chiếu đến nó. ví dụ:Lưu ý: Nếu bạn muốn phát hiện một phần của chuỗi, có lẽ việc sử dụng hàm str_detect() từ package stringr, sẽ không chấp nhận một vectơ ký tự kiểu như c(\"1\", \"Yes\", \"yes\", \"y\"). Thay vào đó, nó cần được cung cấp dưới dạng một biểu thức chính quy - một chuối cô đọng với thanh dọc cho phép sánh , chẳng hạn như “1|Yes|yes|y”. Ví dụ, str_detect(hospitalized, \"1|Yes|yes|y\"). Xem thêm chương Ký tự và chuỗi để biết thêm chi tiết.Bạn có thể chuyển đổi một vectơ ký tự thành một biểu thức chính quy được đặt tên bằng lệnh này:","code":"\nmy_vector <- c(\"a\", \"b\", \"c\", \"d\")\n\"a\" %in% my_vector## [1] TRUE\n\"h\" %in% my_vector## [1] FALSE\n# to negate, put an exclamation in front\n!\"a\" %in% my_vector## [1] FALSE\n!\"h\" %in% my_vector## [1] TRUE\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist <- linelist %>% \n  mutate(child_hospitaled = case_when(\n    hospitalized %in% affirmative & age < 18 ~ \"Hospitalized Child\",\n    TRUE                                      ~ \"Not\"))\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative## [1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\"\n# condense to \naffirmative_str_search <- paste0(affirmative, collapse = \"|\")  # option with base R\naffirmative_str_search <- str_c(affirmative, collapse = \"|\")   # option with stringr package\n\naffirmative_str_search## [1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\""},{"path":"basics.html","id":"lỗi-và-cảnh-báo","chapter":"3 R Cơ bản","heading":"3.13 Lỗi và cảnh báo","text":"Phần này giải thích:Sự khác biệt giữa lỗi và cảnh báoMẹo cú pháp chung để viết code RTrợ giúp viết codeCác lỗi thường gặp và cảnh báo cũng như mẹo khắc phục sự cố có thể được tìm thấy trong chương Các lỗi thường gặp.","code":""},{"path":"basics.html","id":"lỗi-và-cảnh-báo-1","chapter":"3 R Cơ bản","heading":"Lỗi và Cảnh báo","text":"Khi một lệnh được thực thi, cửa sổ R Console có thể hiển thị cho bạn cảnh báo hoặc thông báo lỗi bằng văn bản màu đỏ.Một cảnh báo nghĩa là R đã hoàn thành lệnh của bạn, nhưng phải thực hiện các bước bổ sung hoặc tạo ra kết quả bất thường mà bạn cần lưu ý.Một cảnh báo nghĩa là R đã hoàn thành lệnh của bạn, nhưng phải thực hiện các bước bổ sung hoặc tạo ra kết quả bất thường mà bạn cần lưu ý.Một lỗi nghĩa là R không thể hoàn thành lệnh của bạn.Một lỗi nghĩa là R không thể hoàn thành lệnh của bạn.Tìm manh mối:Thông báo lỗi/cảnh báo thường sẽ bao gồm số dòng xảy ra sự cố.Thông báo lỗi/cảnh báo thường sẽ bao gồm số dòng xảy ra sự cố.Nếu một đối tượng “không xác định được (unknown)” hoặc “không tìm thấy (found)”, có lẽ bạn đã viết sai chính tả, quên gọi một package bằng hàm library(), hoặc quên chạy lại tập lệnh của bạn sau khi thực hiện các thay đổi.Nếu một đối tượng “không xác định được (unknown)” hoặc “không tìm thấy (found)”, có lẽ bạn đã viết sai chính tả, quên gọi một package bằng hàm library(), hoặc quên chạy lại tập lệnh của bạn sau khi thực hiện các thay đổi.Nếu vẫn thất bại, hãy sao chép thông báo lỗi vào Google cùng với một số từ khóa chính - rất có thể ai đó cũng đã gặp lỗi này rồi!","code":""},{"path":"basics.html","id":"mẹo-cú-pháp-chung","chapter":"3 R Cơ bản","heading":"Mẹo cú pháp chung","text":"Một số điều cần nhớ khi viết lệnh trong R, để tránh lỗi và cảnh báo:Luôn đóng dấu ngoặc đơn - mẹo: đếm số lần mở dấu ngoặc đơn “(” và đóng dấu ngoặc đơn “)” cho mỗi đoạn mãTránh để khoảng trắng trong tên cột và đối tượng. Thay vào đó, hãy sử dụng dấu gạch dưới (_) hoặc dấu chấm (.)Theo dõi và nhớ tách các đối số của hàm bằng dấu phẩyR phân biệt chữ hoa và chữ thường, nghĩa là Variable_A khác với variable_A","code":""},{"path":"basics.html","id":"trợ-giúp-viết-code","chapter":"3 R Cơ bản","heading":"Trợ giúp viết code","text":"Bất kỳ tập lệnh nào (RMarkdown hoặc những cái khác) sẽ cung cấp manh mối khi bạn mắc lỗi. Ví dụ: nếu bạn quên viết dấu phẩy ở vị trí cần thiết hoặc quên đóng dấu ngoặc đơn, RStudio sẽ treo cờ trên dòng đó, ở phía bên trái của script, để cảnh báo bạn.","code":""},{"path":"transition-to-R.html","id":"transition-to-R","chapter":"4 Chuyển đổi sang R","heading":"4 Chuyển đổi sang R","text":"Dưới đây, chúng tôi cung cấp một số lời khuyên và tài nguyên nếu bạn đang chuyển đổi sang R.R được giới thiệu vào cuối những năm 1990 và kể từ đó đã phát triển quy mô mạnh mẽ. Khả năng của nó rộng đến mức các lựa chọn thương mại thay thế đã phản ứng với sự phát triển của R để duy trì tính cạnh tranh! (đọc bài viết sánh R, SPSS, SAS, STATA và Python).Hơn thế nữa, R đã dễ học hơn nhiều với 10 năm trước. Trước đây, R nổi tiếng là khó sử dụng cho những người mới bắt đầu. Giờ đây việc này trở nên dễ dàng hơn nhiều với giao diện người dùng thân thiện như RStudio, code trực quan như tidyverse và có nhiều tài nguyên hướng dẫn.Đừng ngần ngại - hãy đến khám phá thế giới của R!","code":""},{"path":"transition-to-R.html","id":"từ-excel","chapter":"4 Chuyển đổi sang R","heading":"4.1 Từ Excel","text":"Chuyển đổi từ Excel trực tiếp sang R hoàn toàn là mục tiêu có thể đạt được. Nó dường như có vẻ khó khăn, nhưng bạn có thể làm được!Sự thật là một người có kỹ năng Excel tốt có thể thực hiện các thao tác nâng cao chỉ trong Excel - ngay cả khi sử dụng các công cụ tạo script như VBA. Excel được sử dụng trên toàn thế giới và là một công cụ cần thiết cho một nhà dịch tễ học. Tuy nhiên, kết hợp nó với R có thể cải thiện và mở rộng đáng kể quy trình công việc của bạn.","code":""},{"path":"transition-to-R.html","id":"lợi-ích","chapter":"4 Chuyển đổi sang R","heading":"Lợi ích","text":"Bạn sẽ thấy rằng việc sử dụng R mang lại những lợi ích lớn trong việc tiết kiệm thời gian, giúp phân tích nhất quán và chính xác hơn, có khả năng tái lập, khả năng chia sẻ và sửa lỗi nhanh hơn. Giống như bất kỳ phần mềm mới nào, bạn phải đầu tư một “đường cong” thời gian học tập để trở nên quen thuộc. Bạn sẽ được mở ra những kĩ năng mới trên một phạm vi rộng đáng kể với R.Excel là một phần mềm phổ biến mà người dùng mới bắt đầu có thể dễ dàng sử dụng để tạo ra các phân tích và sơ đồ hóa đơn giản với các thao tác “trỏ và nhấp”. Trong khi đó, có thể mất vài tuần để trở nên quen thuộc với các chức năng và giao diện của R. Tuy nhiên, R đã phát triển trong những năm gần đây để trở nên thân thiện hơn với người mới bắt đầu.Nhiều quy trình làm việc của Excel phụ thuộc vào trí nhớ và sự lặp lại - đó, có nhiều khả năng xảy ra lỗi. Hơn nữa, nhìn chung, việc làm sạch dữ liệu, phương pháp phân tích và các phương trình được sử dụng đều bị ẩn đi trong trang tính. Có thể cần đến một khoảng thời gian đáng kể để những người mới bắt đầu hiểu trang tính Excel đang làm gì và cách khắc phục sự cố. Với R, tất cả các bước được viết rõ ràng trong script và có thể dễ dàng xem, chỉnh sửa, sửa lỗi và áp dụng cho các bộ dữ liệu khác.Để bắt đầu chuyển đổi từ Excel sang R, bạn phải điều chỉnh tư duy của mình theo một số hướng quan trọng:","code":""},{"path":"transition-to-R.html","id":"tidy-data","chapter":"4 Chuyển đổi sang R","heading":"Tidy data","text":"Sử dụng “tidy” data để máy có thể đọc được thay vì dữ liệu lộn xộn “con người có thể đọc được”. Dưới đây là ba yêu cầu chính đối với “tidy” data\", đã được giải thích trong hướng dẫn này về “tidy” data trong R:Mỗi biến số nằm trên một cộtMỗi quan sát phải nằm trên một hàngMỗi giá trị phải có ô riêngĐối với người dùng Excel - hãy nghĩ đến vai trò của “bảng” Excel trong việc chuẩn hóa dữ liệu và làm cho định dạng trở nên dễ đoán hơn.Một ví dụ về “tidy” data là trường hợp bộ dữ liệu linelist được sử dụng trong cuốn sổ tay này - mỗi biến được chứa trong một cột, mỗi quan sát (mỗi trường hợp) có hàng riêng và mọi giá trị chỉ nằm trong một ô. Dưới đây, bạn có thể xem 50 hàng đầu tiên của bộ dữ liệu linelist:Nguyên nhân chính khiến người dùng gặp phải tình trạng non-tidy data là nhiều bảng tính Excel được thiết kế để ưu tiên con người dễ đọc chứ không phải máy móc/phần mềm dễ đọc.Để giúp bạn thấy sự khác biệt, dưới đây là một số ví dụ mô phỏng về non-tidy data mà ưu tiên khả năng đọc của con người hơn khả năng đọc của máy:Vấn đề: Trong bảng tính ở trên, một số ô đã được ghép với nhau - khiến chúng trở nên khó đọc bởi R. Hàng nào nên được coi là “tiêu đề” không rõ ràng. Từ điển dựa trên màu sắc nằm ở phía bên phải và các giá trị ô được biểu thị bằng màu sắc - điều này cũng không dễ dàng được giải thích bởi R (cũng như những người bị mù màu!). Hơn nữa, các phần thông tin khác nhau được kết hợp thành một ô (nhiều tổ chức đối tác hoạt động trong cùng một khu hoặc trạng thái “TBC” trong cùng ô với “Partner D”).Vấn đề: Trong bảng tính ở trên, có rất nhiều hàng và cột trống trong bộ dữ liệu - điều này sẽ gây phiền toái khi làm sạch trong R. Hơn nữa, tọa độ GPS được trải rộng trên hai hàng cho một trung tâm điều trị nhất định. Một lưu ý nhỏ - tọa độ GPS có hai định dạng khác nhau!Các bộ dữ liệu “tidy” có thể không đọc được bằng mắt người, nhưng chúng giúp việc làm sạch và phân tích dữ liệu dễ dàng hơn rất nhiều! Tidy data có thể được lưu trữ ở nhiều định dạng khác nhau, chẳng hạn như dạng “dọc” hoặc “ngang”\"(xem chương về Xoay trục dữ liệu), tuy nhiên các nguyên tắc trên vẫn được tuân thủ.","code":""},{"path":"transition-to-R.html","id":"hàm","chapter":"4 Chuyển đổi sang R","heading":"Hàm","text":"Từ “hàm (function)” trong R có thể mới, nhưng khái niệm này cũng tồn tại trong Excel dưới dạng công thức (formulas). Công thức trong Excel cũng yêu cầu cú pháp chính xác (ví dụ: vị trí của dấu chấm phẩy và dấu ngoặc đơn). Tất cả những gì bạn cần làm là tìm hiểu một vài hàm mới và cách chúng hoạt động cùng nhau trong R.","code":""},{"path":"transition-to-R.html","id":"script","chapter":"4 Chuyển đổi sang R","heading":"Script","text":"Thay vì nhấp vào các biểu tượng và kéo các ô, bạn sẽ viết mọi bước và quy trình thành một “script”. Người dùng Excel có thể quen thuộc với “VBA macros”, thứ mà cũng sử dụng cách tiếp cận script.R script bao gồm các hướng dẫn từng bước. Điều này cho phép bất kỳ đồng nghiệp nào cũng có thể đọc script và dễ dàng xem các bước bạn đã thực hiện. Điều này cũng giúp loại bỏ lỗi hoặc các tính toán không chính xác. Xem phần R cơ bản về script để có thêm các ví dụ.Dưới đây là một ví dụ của một R script:","code":""},{"path":"transition-to-R.html","id":"tài-liệu-liên-quan-đến-chuyển-đổi-từ-excel-sang-r","chapter":"4 Chuyển đổi sang R","heading":"Tài liệu liên quan đến chuyển đổi từ Excel-sang-R","text":"Dưới đây là một vài đường link hướng dẫn giúp bạn chuyển đổi sang R từ Excel:R vs. ExcelCác khóa RStudio trong R cho người dùng Excel","code":""},{"path":"transition-to-R.html","id":"tương-tác-giữa-r-và-excel","chapter":"4 Chuyển đổi sang R","heading":"Tương tác giữa R và Excel","text":"R có khả năng mạnh trong việc nhập các Excel workbook, làm việc với dữ liệu, xuất/lưu tệp Excel và làm việc với các sắc thái của các trang tính Excel.Đúng là một số định dạng Excel có tính thẩm mỹ hơn có thể bị mất trong quá trình chuyển đổi (ví dụ: chữ nghiêng, chữ nằm ngang, v.v.). Nếu quy trình công việc của bạn yêu cầu chuyển tài liệu qua lại giữa R và Excel trong khi vẫn giữ nguyên định dạng Excel ban đầu, hãy thử các package như openxlsx.","code":""},{"path":"transition-to-R.html","id":"từ-stata","chapter":"4 Chuyển đổi sang R","heading":"4.2 Từ Stata","text":"Chuyển đến R từ StataNhiều nhà dịch tễ học được dạy cách sử dụng Stata ngay từ đầu, và có vẻ khó khăn khi chuyển sang R. Tuy nhiên, nếu bạn là một người dùng quen Stata thì việc chuyển sang R chắc chắn sẽ dễ quản lý hơn bạn nghĩ. Mặc dù có một số khác biệt chính giữa Stata và R về cách tạo và sửa đổi dữ liệu, cũng như cách triển khai các chức năng phân tích – sau khi tìm hiểu những khác biệt chính này, bạn sẽ có thể chuyển đổi các kỹ năng của mình.Dưới đây là một số cách chuyển đổi chính giữa Stata và R, điều mà có thể hữu ích khi bạn xem lại hướng dẫn này.Những lưu ý chungThư mục làm việcNhập và xem dữ liệuThao tác dữ liệu cơ bảnPhân tích mô tảMặc dù danh sách này cung cấp một cái nhìn tổng quan về những điều cơ bản trong việc chuyển các lệnh Stata sang R, nhưng nó vẫn chưa đầy đủ. Bạn có thể quan tâm tới nhiều nguồn tài nguyên tuyệt vời khác dành cho người dùng Stata chuyển sang R:https://dss.princeton.edu/training/RStata.pdfhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.htmlhttp://r4stats.com/books/r4stata/","code":""},{"path":"transition-to-R.html","id":"từ-sas","chapter":"4 Chuyển đổi sang R","heading":"4.3 Từ SAS","text":"Chuyển từ SAS sang RSAS thường được sử dụng tại các cơ quan y tế công cộng và các lĩnh vực nghiên cứu học thuật. Mặc dù chuyển đổi sang một ngôn ngữ mới hiếm khi là một quá trình đơn giản, nhưng hiểu được những điểm khác biệt chính giữa SAS và R có thể giúp bạn bắt đầu chuyển hướng ngôn ngữ mới bằng ngôn ngữ mẹ đẻ của mình. Dưới đây là phác thảo các bước chuyển đổi chính trong quản lý dữ liệu và phân tích mô tả giữa SAS và R.Những lưu ý chungThư mục làm việcNhập và xem dữ liệuThao tác dữ liệu cơ bảnPhân tích mô tảMột số tài nguyên hữu ích:R SAS SPSS Users (2011)SAS R, Second Edition (2014)","code":""},{"path":"transition-to-R.html","id":"khả-năng-tương-tác-dữ-liệu","chapter":"4 Chuyển đổi sang R","heading":"4.4 Khả năng tương tác dữ liệu","text":"Xem chương Nhập xuất dữ liệu để biết chi tiết về cách R package rio có thể nhập và xuất các file như file STATA .dta, file SAS .xpt và .sas7bdat, file SPSS .por và .sav và nhiều file khác.","code":""},{"path":"packages-suggested.html","id":"packages-suggested","chapter":"5 Package đề xuất","heading":"5 Package đề xuất","text":"Dưới đây là danh sách các package được đề xuất dành cho các công việc dịch tễ học phổ biến trong R. Bạn có thể sao chép code này, chạy nó và tất cả các package này sẽ cài đặt từ CRAN và tải để sử dụng trong phiên làm việc hiện tại. Nếu một package đã được cài đặt, nó sẽ chỉ được gọi ra để sử dụng.Bạn có thể sửa đổi code với ký hiệu # để loại bỏ bất kỳ packages nào bạn không muốn.Chú ý:Đầu tiên, cần cài đặt package pacman trước khi chạy đoạn code dưới đây. Bạn có thể thực hiện việc này với lệnh install.packages(\"pacman\"). Trong sổ tay này, chúng tôi nhấn mạnh đến hàm p_load() từ package pacman, sẽ có thể vừa cài đặt package nếu cần và gọi chúng ra để sử dụng trong phiên làm việc. Bạn cũng có thể gọi package đã được cài đặt với lệnh library() từ base R.Trong đoạn code dưới đây, các packages được bao gồm khi cài đặt/gọi thông qua một package khác được trình bày bằng cách thụt lề và dấu thăng. Ví dụ: ggplot2 được liệt kê bên dưới tidyverse.Nếu nhiều package có các hàm cùng tên, việc đè lên nhau đè lên nhau có thể xảy ra khi hàm từ package được gọi ra sau sẽ được ưu tiên hơn. Đọc thêm trong chương R cơ bản. Cân nhắc sử dụng package conflicted để quản lý các xung đột tương tự.Xem chương R cơ bản mục packages để biết thêm về pacman và ghi đè.Để xem các phiên bản của R, RStudio và R packages được sử dụng trong quá trình viết cuốn sổ tay này, xem chương Biên tập và ghi chú kỹ thuật.","code":""},{"path":"packages-suggested.html","id":"packages-từ-cran","chapter":"5 Package đề xuất","heading":"5.1 Packages từ CRAN","text":"","code":"\n##########################################\n# List of useful epidemiology R packages #\n##########################################\n\n# This script uses the p_load() function from pacman R package, \n# which installs if package is absent, and loads for use if already installed\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n# Packages available from CRAN\n##############################\npacman::p_load(\n     \n     # learning R\n     ############\n     learnr,   # interactive tutorials in RStudio Tutorial pane\n     swirl,    # interactive tutorials in R console\n        \n     # project and file management\n     #############################\n     here,     # file paths relative to R project root folder\n     rio,      # import/export of many types of data\n     openxlsx, # import/export of multi-sheet Excel workbooks \n     \n     # package install and management\n     ################################\n     pacman,   # package install/load\n     renv,     # managing versions of packages when working in collaborative groups\n     remotes,  # install from github\n     \n     # General data management\n     #########################\n     tidyverse,    # includes many packages for tidy data wrangling and presentation\n          #dplyr,      # data management\n          #tidyr,      # data management\n          #ggplot2,    # data visualization\n          #stringr,    # work with strings and characters\n          #forcats,    # work with factors \n          #lubridate,  # work with dates\n          #purrr       # iteration and working with lists\n     linelist,     # cleaning linelists\n     naniar,       # assessing missing data\n     \n     # statistics  \n     ############\n     janitor,      # tables and data cleaning\n     gtsummary,    # making descriptive and statistical tables\n     rstatix,      # quickly run statistical tests and summaries\n     broom,        # tidy up results from regressions\n     lmtest,       # likelihood-ratio tests\n     easystats,\n          # parameters, # alternative to tidy up results from regressions\n          # see,        # alternative to visualise forest plots \n     \n     # epidemic modeling\n     ###################\n     epicontacts,  # Analysing transmission networks\n     EpiNow2,      # Rt estimation\n     EpiEstim,     # Rt estimation\n     projections,  # Incidence projections\n     incidence2,   # Make epicurves and handle incidence data\n     i2extras,     # Extra functions for the incidence2 package\n     epitrix,      # Useful epi functions\n     distcrete,    # Discrete delay distributions\n     \n     \n     # plots - general\n     #################\n     #ggplot2,         # included in tidyverse\n     cowplot,          # combining plots  \n     # patchwork,      # combining plots (alternative)     \n     RColorBrewer,     # color scales\n     ggnewscale,       # to add additional layers of color schemes\n\n     \n     # plots - specific types\n     ########################\n     DiagrammeR,       # diagrams using DOT language\n     incidence2,       # epidemic curves\n     gghighlight,      # highlight a subset\n     ggrepel,          # smart labels\n     plotly,           # interactive graphics\n     gganimate,        # animated graphics \n\n     \n     # gis\n     ######\n     sf,               # to manage spatial data using a Simple Feature format\n     tmap,             # to produce simple maps, works for both interactive and static maps\n     OpenStreetMap,    # to add OSM basemap in ggplot map\n     spdep,            # spatial statistics \n     \n     # routine reports\n     #################\n     rmarkdown,        # produce PDFs, Word Documents, Powerpoints, and HTML files\n     reportfactory,    # auto-organization of R Markdown outputs\n     officer,          # powerpoints\n     \n     # dashboards\n     ############\n     flexdashboard,    # convert an R Markdown script into a dashboard\n     shiny,            # interactive web apps\n     \n     # tables for presentation\n     #########################\n     knitr,            # R Markdown report generation and html tables\n     flextable,        # HTML tables\n     #DT,              # HTML tables (alternative)\n     #gt,              # HTML tables (alternative)\n     #huxtable,        # HTML tables (alternative) \n     \n     # phylogenetics\n     ###############\n     ggtree,           # visualization and annotation of trees\n     ape,              # analysis of phylogenetics and evolution\n     treeio            # to visualize phylogenetic files\n \n)"},{"path":"packages-suggested.html","id":"packages-từ-github","chapter":"5 Package đề xuất","heading":"5.2 Packages từ Github","text":"Dưới đây là các lệnh giúp cài đặt trực tiếp packages từ kho lưu trữ trên Github.Phiên bản phát triển của epicontacts có khả năng tạo cây lây nhiễm với trục x tạm thờiPackage epirhandbook chứa tất cả các dữ liệu minh họa cho sổ tay này và có thể được sử dụng để tải xuống phiên bản ngoại tuyến của sổ tay.","code":"\n# Packages to download from Github (not available on CRAN)\n##########################################################\n\n# Development version of epicontacts (for transmission chains with a time x-axis)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# The package for this handbook, which includes all the example data  \npacman::p_install_gh(\"appliedepi/epirhandbook\")"},{"path":"r-projects.html","id":"r-projects","chapter":"6 Dự án R","heading":"6 Dự án R","text":"Một dự án R cho phép công việc của bạn được đóng gói trong một thư mục khép kín. Trong dự án, tất cả các tập lệnh, tệp dữ liệu, biểu đồ/kết quả đầu ra và lịch sử có liên quan được lưu trữ trong các thư mục con và quan trọng là - thư mục làm việc là thư mục gốc của dự án.","code":""},{"path":"r-projects.html","id":"gợi-ý-sử-dụng","chapter":"6 Dự án R","heading":"6.1 Gợi ý sử dụng","text":"Một cách phổ biến, hiệu quả và ít rắc rối để sử dụng R là sự kết hợp của 3 thành tố này. Mỗi dự án công việc cụ thể sẽ được lưu trữ trong một dự án R. Từng thành tố được mô tả như dưới đây.Một Dự án R\nMột môi trường làm việc khép kín với các thư mục bao gồm dữ liệu, tập lệnh, các kết quả đầu ra, v.v.\nMột môi trường làm việc khép kín với các thư mục bao gồm dữ liệu, tập lệnh, các kết quả đầu ra, v.v.Package dành cho các đường dẫn tương đối\nĐường dẫn tệp được ghi một cách tương đối dẫn đến thư mục gốc của dự án R - xem chương Nhập xuất dữ liệu để biết thêm chi tiết\nĐường dẫn tệp được ghi một cách tương đối dẫn đến thư mục gốc của dự án R - xem chương Nhập xuất dữ liệu để biết thêm chi tiếtPackage rio để nhập/xuất\nimport() và export() giúp giải quyết tất cả các tệp với phần mở rộng khác nhau (ví dụ: .csv, .xlsx, .png)\nimport() và export() giúp giải quyết tất cả các tệp với phần mở rộng khác nhau (ví dụ: .csv, .xlsx, .png)","code":""},{"path":"r-projects.html","id":"tạo-một-dự-án-r","chapter":"6 Dự án R","heading":"6.2 Tạo một dự án R","text":"Để tạo một dự án R, hãy chọn “New Project” từ menu File.Nếu bạn muốn tạo một thư mục mới cho dự án, hãy chọn “New directory” và cho biết nơi bạn muốn nó được tạo.Nếu bạn muốn tạo dự án trong một thư mục có sẵn, hãy chọn “Existing directory” và trỏ tới đường dẫn thư mục đó.Nếu bạn muốn tạo một bản sao từ kho lưu trữ Github, hãy chọn tùy chọn thứ ba “Version Control” và sau đó chọn “Git”. Xem chương Version control với Git và Github để biết thêm chi tiết.Dự án R bạn tạo ra sẽ có dạng một thư mục chứa tệp .Rproj. Tệp này có thể đóng vai trò là một lối tắt mà bạn sẽ mở dự án của mình. Bạn cũng có thể mở một dự án bằng cách chọn “Open Project” từ menu File. Ngoài ra, ở phía trên bên phải trên của RStudio, bạn sẽ thấy biểu tượng dự án R và menu thả xuống gồm các dự án R có sẵn.Để thoát khỏi một dự án R, hãy mở một dự án mới hoặc đóng dự án (File - Close Project).","code":""},{"path":"r-projects.html","id":"di-chuyển-giữa-các-dự-án","chapter":"6 Dự án R","heading":"Di chuyển giữa các dự án","text":"Để di chuyển giữa các dự án, hãy bấm vào biểu tượng dự án R và menu thả xuống ở phía trên cùng bên phải của RStudio. Bạn sẽ thấy các tùy chọn Close Project, Open Project và danh sách các dự án gần đây.","code":""},{"path":"r-projects.html","id":"thiết-lập","chapter":"6 Dự án R","heading":"Thiết lập","text":"Thông thường, mỗi khi bạn khởi động RStudio nên là một “clean slate - khởi đầu mới” - nghĩa là với không gian làm việc hiện tại không được giữ nguyên với phiên làm việc trước đó. Điều này có nghĩa là các đối tượng và kết quả của bạn sẽ không tồn tại giữa các phiên làm việc (bạn phải tạo lại chúng bằng cách chạy lại scripts của mình). Điều này là tốt, vì nó sẽ buộc bạn phải viết các đoạn code tốt hơn và tránh được lỗi về lâu dài.Để thiết lập RStudio có một “khởi đầu mới” mỗi khi khởi động:Chọn “Project Options” từ menu Tools.Trong tab “General”, thiết lập RStudio không khôi phục .RData vào môi trường làm việc của bạn mỗi khi khởi động, và cũng không lưu môi trường làm việc vào tệp .RData khi kết thúc.","code":""},{"path":"r-projects.html","id":"tổ-chức","chapter":"6 Dự án R","heading":"Tổ chức","text":"Thông thường sẽ có các thư mục con trong dự án của bạn. Hãy cân nhắc đặt tên các thư mục như “data”, “scripts”, “figures”, “presentations”. Bạn có thể thêm các thư mục theo cách thông thường mà bạn sẽ thêm một thư mục mới cho máy tính của mình. Ngoài ra, hãy xem chương Tương tác với thư mục làm việc để tìm hiểu cách tạo thư mục mới bằng lệnh R.","code":""},{"path":"r-projects.html","id":"kiểm-soát-phiên-bản","chapter":"6 Dự án R","heading":"Kiểm soát phiên bản","text":"Hãy cân nhắc sử dụng một hệ thống kiểm soát phiên bản. Nó có thể là một cái gì đó đơn giản như có ngày tháng trên tên của các scripts (ví dụ: “transmission_analysis_2020-10-03.R”) và một thư mục “lưu trữ”. Bạn cũng có thể thêm các đoạn văn bản tiêu đề nhận xét ở đầu mỗi scripts bao gồm các thông tin như mô tả, thẻ, tác giả và nhật ký thay đổi.Một phương pháp phức tạp hơn đó là việc sử dụng Github hoặc một nền tảng tương tự để kiểm soát phiên bản. Xem chương Version control với Git và Github.Một mẹo là bạn có thể tìm kiếm trong toàn bộ dự án hoặc thư mục bằng cách sử dụng công cụ “Find Files” (Edit menu)). Công cụ này có thể tìm kiếm và thậm chí thay thế các chuỗi trên nhiều tệp.","code":""},{"path":"r-projects.html","id":"các-ví-dụ","chapter":"6 Dự án R","heading":"6.3 Các ví dụ","text":"Dưới đây là một vài ví dụ về cách nhập/xuất/lưu trữ sử dụng lệnh () within R projct. bên trong một dự án R. Đọc thêm về package trong chương Nhập xuất dữ liệu.Nhập linelist_raw.xlsx từ thư mục “data” trong dự án R của bạnXuất đối tượng linelist thành tệp “my_linelist.rds” vào thư mục “clean” nằm trong thư mục “data” trong dự án R của bạn.Lưu biểu đồ được gần đây nhất thành tệp “epicurve_2021-02-15.png” nằm trong thư mục “epicurves” của thư mục “outputs” trong dự án R của bạn.","code":"\nlinelist <- import(here(\"data\", \"linelist_raw.xlsx\"))\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))"},{"path":"r-projects.html","id":"nguồn","chapter":"6 Dự án R","heading":"6.4 Nguồn","text":"Trang web của RStudio về việc sử dụng các dự án R","code":""},{"path":"importing.html","id":"importing","chapter":"7 Nhập xuất dữ liệu","heading":"7 Nhập xuất dữ liệu","text":"Trong chương này, chúng tôi mô tả các cách để định vị, nhập và xuất tệp:Sử dụng package rio để import() và export() linh hoạt nhiều loại tệpSử dụng package rio để import() và export() linh hoạt nhiều loại tệpSử dụng package để định vị tệp liên quan đến dự án R gốc - để ngăn ngừa sự phức tạp nhiều đường dẫn tệp chỉ dành riêng cho một máy tínhSử dụng package để định vị tệp liên quan đến dự án R gốc - để ngăn ngừa sự phức tạp nhiều đường dẫn tệp chỉ dành riêng cho một máy tínhCác trường hợp nhập cụ thể:\nExcel sheet cụ thể\nTiêu đề sắp xếp lộn xộn và bỏ qua một số hàng\nTừ Google sheet\nTừ dữ liệu được đăng lên các trang web\nVới APIs\nNhập tệp gần đây nhất\nCác trường hợp nhập cụ thể:Excel sheet cụ thểTiêu đề sắp xếp lộn xộn và bỏ qua một số hàngTừ Google sheetTừ dữ liệu được đăng lên các trang webVới APIsNhập tệp gần đây nhấtNhập dữ liệu thủ côngNhập dữ liệu thủ côngCác loại tệp R cụ thể ví dụ như RDS và RDataCác loại tệp R cụ thể ví dụ như RDS và RDataXuất/lưu tệp và biểu đồXuất/lưu tệp và biểu đồ","code":""},{"path":"importing.html","id":"tổng-quan","chapter":"7 Nhập xuất dữ liệu","heading":"7.1 Tổng quan","text":"Khi bạn nhập một “dataset” vào R, bạn thường tạo ra một đối tượng data frame mới trong môi trường R của mình và định nghĩa nó là tệp được nhập (ví dụ: Excel, CSV, TSV, RDS), từ trong các thư mục của bạn tại một đường dẫn/địa chỉ tệp nhất định.Bạn có thể nhập/xuất nhiều loại tệp, bao gồm cả những tệp được tạo bởi các chương trình thống kê khác (SAS, STATA, SPSS). Bạn cũng có thể kết nối với các cơ sở dữ liệu liên quan.R thậm chí còn có các định dạng dữ liệu riêng:Một tệp RDS (.rds) lưu trữ một đối tượng R đơn lẻ chẳng hạn như một data frame. Chúng hữu ích trong việc lưu trữ dữ liệu đã được làm sạch, vì chúng giữ lại kiểu dữ liệu cho các cột R. Đọc thêm trong mục này.Một tệp RData (.Rdata) có thể được sử dụng để lưu trữ nhiều đối tượng hoặc thậm chí là một không gian làm việc trong R hoàn chỉnh. Đọc thêm trong mục này.","code":""},{"path":"importing.html","id":"package-rio","chapter":"7 Nhập xuất dữ liệu","heading":"7.2 Package rio","text":"Package R chúng tôi gợi ý là: rio. Tên “rio” là chữ viết tắt của “R /O” (dữ liệu đầu vào (input)/kết quả đầu ra (output)).Hàm import() và export() có thể xử lý nhiều loại tệp khác nhau (ví dụ: .xlsx, .csv, .rds, .tsv). Khi bạn cung cấp đường dẫn tệp đến một trong các hàm này (bao gồm cả đuôi file mở rộng như “.csv”), rio sẽ đọc phần mở rộng và sử dụng đúng công cụ để nhập hoặc xuất tệp.Giải pháp thay thế cho việc sử dụng rio là sử dụng các hàm từ nhiều package khác, mỗi gói cụ thể cho một loại tệp. Ví dụ như, read.csv() (base R), read.xlsx() (package openxlsx) và write_csv() (package readr), v.v… Những lựa chọn thay thế này có thể khó nhớ, trong khi sử dụng import() và export() từ rio rất dễ dàng.Các hàm import() và export() của rio sử dụng package và lệnh phù hợp cho một tệp nhất định, dựa trên phần mở rộng của tệp đó. Xem phần cuối của chương này để thấy bảng đầy đủ về các package/hàm rio có thể xử lý được. Hàm này cũng có thể được sử dụng để nhập các tệp STATA, SAS và SPSS trong hàng tá các loại tệp khác.Nhập/xuất shapefiles đòi hỏi các package khác, được mô tả cụ thể trong chương GIS cơ bản.","code":""},{"path":"importing.html","id":"here","chapter":"7 Nhập xuất dữ liệu","heading":"7.3 Package here","text":"Package và hàm () của nó giúp R dễ dàng biết nơi tìm và lưu tệp của bạn - về bản chất, nó xây dựng đường dẫn tệp.Được sử dụng cùng với dự án R, cho phép bạn mô tả vị trí các tệp trong dự án R của bạn trong thư mục gốc (root directory) của dự án R (thư mục cấp cao nhất). Điều này hữu ích khi dự án R có thể được chia sẻ hoặc truy cập bởi nhiều người dùng/máy tính. Package này ngăn ngừa sự phức tạp các đường dẫn tệp là duy nhất trên các máy tính khác nhau (ví dụ: \"C:/Users/Laura/Documents...\") bằng cách “khởi động (starting)” đường dẫn tệp ở thư mục chung cho tất cả người dùng (dự án R gốc).Đây là cách () làm việc trong một dự án R:Khi package được tải lần đầu tiên trong dự án R, nó đặt một tệp nhỏ có tên là “.” trong thư mục gốc dự án R của bạn như là một “điểm chuẩn” hoặc “mỏ neo”Trong script của bạn, để tham chiếu một tệp trong các thư mục con của dự án R, bạn sử dụng hàm () để tạo đường dẫn tệp liên quan đến thư mục gốc (anchor)Để tạo đường dẫn tệp, viết tên các thư mục bên ngoài thư mục gốc, trong dấu ngoặc kép, được phân tách bằng dấu phẩy, cuối cùng kết thúc bằng tên và phần mở rộng của tệp như được trình bày dưới đâyCác đường dẫn tệp () có thể được sử dụng cả để nhập và xuất dữ liệuVí dụ, dưới đây, một đường dẫn tệp được tạo bởi () đang cung cấp cho hàm import()Lệnh (\"data\", \"linelists\", \"ebola_linelist.xlsx\") đang cung cấp đường dẫn tệp đầy đủ mà duy nhất cho máy tính của người dùng:Ưu điểm là lệnh () được R sử dụng có thể chạy thành công trên bất kỳ máy tính nào truy cập dự án R.MẸO: Nếu bạn không chắc gốc “.” được đặt ở đâu, hãy chạy lệnh () với dấu ngoặc đơn trống.Đọc thêm về package tại đường dẫn này.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\""},{"path":"importing.html","id":"đường-dẫn-tệp","chapter":"7 Nhập xuất dữ liệu","heading":"7.4 Đường dẫn tệp","text":"Khi nhập hoặc xuất dữ liệu, bạn phải cung cấp một đường dẫn tệp. Bạn có thể thực hiện thao tác này bằng một trong ba cách sau:Khuyên dùng: cung cấp một đường dẫn tệp “tương đối” bằng package hereCung cấp đường dẫn tệp “đầy đủ” / “tuyệt đối”Chọn tệp theo cách thủ công","code":""},{"path":"importing.html","id":"đường-dẫn-tệp-tương-đối","chapter":"7 Nhập xuất dữ liệu","heading":"Đường dẫn tệp “tương đối”","text":"Trong R, đường dẫn tệp “tương đối” bao gồm đường dẫn tệp mà liên quan đến phần gốc của dự án R. Chúng cho phép nhiều đường dẫn tệp đơn giản hơn có thể làm việc trên nhiều máy tính khác nhau (ví dụ: nếu dự án R nằm trên bộ nhớ dùng chung hoặc được gửi qua thư điện tử). Như đã được mô tả ở trên, đường dẫn tệp tương đối được tạo ra dễ dàng bằng cách sử dụng package .Dưới đây là một ví dụ về đường dẫn tệp tương đối được tạo bằng package (). Chúng tôi giả sử công việc nằm trong một dự án R có chứa một thư mục con “data” và bên trong thư mục con “linelists”, trong đó có tệp .xlsx được quan tâm.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))"},{"path":"importing.html","id":"đường-dẫn-tệp-tuyệt-đối","chapter":"7 Nhập xuất dữ liệu","heading":"Đường dẫn tệp “tuyệt đối”","text":"Đường dẫn tệp tuyệt đối hay “đầy đủ” có thể được cung cấp cho các hàm như import() nhưng chúng “dễ vỡ” vì chúng là duy nhất cho cho các máy tính khác nhau của người dùng và đó không được khuyến khích sử dụng.Dưới đây là một ví dụ về đường dẫn tệp tuyệt đối, trong máy tính của Laura có một thư mục “analysis”, một thư mục con “data” và bên trong là thư mục con “linelists”, trong đó có tệp .xlsx được quan tâm.Một vài điều cần lưu ý về đường dẫn tệp tuyệt đối:Tránh sử dụng đường dẫn tệp tuyệt đối vì chúng sẽ bị vỡ nếu script được chạy trên một máy tính khácSử dụng dấu gạch chéo lên (/), như trong ví dụ trên (lưu ý: đây KHÔNG phải là mặc định đối với đường dẫn tệp trong Windows)Đường dẫn tệp bắt đầu với hai dấu gạch chéo (ví dụ: “//…”) sẽ có khả năng không được R nhận ra và tạo ra lỗi. Cân nhắc chuyển công việc của bạn sang ổ đĩa “có tên” hoặc “có chữ” bắt đầu bằng một chữ cái (ví dụ: “J:” hoặc “C:”). Xem trang về Tương tác với thư mục làm việc để biết thêm chi tiết về vấn đề này.Một tình huống mà đường dẫn tệp tuyệt đối có thể phù hợp là khi bạn muốn nhập một tệp từ bộ nhớ dùng chung có cùng đường dẫn tệp đầy đủ cho tất cả người dùng.MẸO: Để nhanh chóng chuyển đổi tất cả \\ thành /, đánh dấu code được quan tâm, sử dụng Ctrl + f (trong Windows), kiểm tra hộp tùy chọn cho “selection”, sau đó sử dụng chức năng thay thế (replace) để chuyển đổi chúng.","code":"\nlinelist <- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")"},{"path":"importing.html","id":"chọn-tệp-theo-cách-thủ-công","chapter":"7 Nhập xuất dữ liệu","heading":"Chọn tệp theo cách thủ công","text":"Bạn có thể nhập dữ liệu theo cách thủ công thông qua một trong các phương pháp sau:Từ cửa sổ Environment trong RStudio, nhấp vào “Import Dataset” và chọn loại dữ liệuNhấp vào File / Import Dataset / (chọn loại dữ liệu)Để lựa chọn thủ công bằng hard-code, hãy sử dụng lệnh base R file.choose() (để trống dấu ngoặc đơn) để kích hoạt sự xuất hiện của cửa sổ pop-cho phép người dùng chọn tệp theo cách thủ công từ máy tính của họ. Ví dụ:MẸO: Cửa sổ pop-có thể xuất hiện SAU cửa sổ RStudio của bạn.","code":"\n# Manual selection of a file. When this command is run, a POP-UP window will appear. \n# The file path selected will be supplied to the import() command.\n\nmy_data <- import(file.choose())"},{"path":"importing.html","id":"nhập-dữ-liệu","chapter":"7 Nhập xuất dữ liệu","heading":"7.5 Nhập dữ liệu","text":"Sử dụng lệnh import() để nhập một bộ dữ liệu khá đơn giản. Chỉ cần cung cấp đường dẫn đến tệp (bao gồm tên và phần mở rộng của tệp) trong dấu ngoặc kép. Nếu sử dụng () để xây dựng đường dẫn tệp, hãy làm theo hướng dẫn ở trên. Dưới đây là một vài ví dụ:Nhập tệp csv nằm trong “thư mục làm việc (working directory)” của bạn hoặc trong thư mục gốc của dự án R:Nhập sheet đầu tiên Excel workbook nằm trong thư mục con “data” và “linelists” của dự án R (đường dẫn tệp được tạo bằng ()):Nhập một data frame (một tệp .rds ) sử dụng đường dẫn tệp tuyệt đối:","code":"\nlinelist <- import(\"linelist_cleaned.csv\")\nlinelist <- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\nlinelist <- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")"},{"path":"importing.html","id":"trang-tính-excel-cụ-thể","chapter":"7 Nhập xuất dữ liệu","heading":"Trang tính Excel cụ thể","text":"Theo mặc định, nếu bạn cung cấp một Excel workbook (.xlsx) để import(), trang tính đầu tiên của workbook sẽ được nhập. Nếu bạn muốn nhập một trang tính cụ thể, hãy nhập tên trang tính vào đối số =. Ví dụ:Nếu sử dụng hàm () để cung cấp một đường dẫn tương đối đến import(), bạn vẫn có thể chỉ ra một trang tính cụ thể bằng cách thêm đối số = sau dấu đóng ngoặc của hàm ().Để xuất một data frame từ R sang một trang tính Excel sheet và phần còn lại của Excel workbook không thay đổi, bạn sẽ phải nhập, chỉnh sửa và xuất với một package thay thế phục vụ cho mục đích này, chẳng hạn như openxlsx. Xem thêm thông tin trong chương về Tương tác với thư mục làm việc hoặc tại trang github này.Nếu Excel workbook của bạn là .xlsb (định dạng nhị phân của Excel workbook) bạn có thể không nhập được bằng rio. Cân nhắc lưu lại nó dưới dạng .xlsx hoặc sử dụng một package như readxlsb, là package được xây dựng cho mục đích này.","code":"\nmy_data <- import(\"my_excel_file.xlsx\", which = \"Sheetname\")# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\nlinelist_raw <- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  "},{"path":"importing.html","id":"import_missing","chapter":"7 Nhập xuất dữ liệu","heading":"Giá trị missing","text":"Bạn có thể muốn xác định (các) giá trị nào trong bộ dữ liệu của mình nên được coi là missing. Như đã giải thích trong chương về Dữ liệu missing, giá trị trong R cho dữ liệu missing là NA, nhưng có thể bộ dữ liệu bạn muốn nhập sử dụng giá trị 99, “Missing” hoặc chỉ là khoảng trống ký tự \"\".Sử dụng đối số na = để import() và cung cấp (các) giá trị trong dấu ngoặc kép (ngay cả khi chúng là các số). Bạn có thể chỉ định nhiều giá trị bằng cách gộp chúng trong một vectơ, sử dụng c() như được thể hiện dưới đây.Tại đây, giá trị “99” trong bộ dữ liệu đã nhập được coi là missing và được chuyển đổi thành NA trong R.Tại đây, bất kỳ giá trị “Missing”, \"\" (ô trống) hoặc \"\" (khoảng trắng) nào trong bộ dữ liệu đã nhập đều được chuyển đổi thành NA trong R.","code":"\nlinelist <- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\nlinelist <- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))"},{"path":"importing.html","id":"bỏ-qua-một-số-hàng","chapter":"7 Nhập xuất dữ liệu","heading":"Bỏ qua một số hàng","text":"Đôi khi, bạn có thể không muốn nhập một hàng dữ liệu. Bạn có thể thực hiện thao tác này với đối số skip = nếu sử dụng import() từ rio trên tệp .xlsx hoặc .csv. Cung cấp số hàng bạn muốn bỏ qua.Không may skip = chỉ chấp nhận một giá trị số nguyên, không chấp nhận một khoảng (ví dụ: “2:10” sẽ không hoạt động). Để bỏ qua việc nhập các hàng cụ thể không liên tiếp từ trên cùng, hãy cân nhắc nhập nhiều lần và sử dụng bind_rows() từ dplyr. Hãy xem ví dụ dưới đây về việc chỉ bỏ qua hàng thứ 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row"},{"path":"importing.html","id":"quản-lý-hàng-tiêu-đề-thứ-hai","chapter":"7 Nhập xuất dữ liệu","heading":"Quản lý hàng tiêu đề thứ hai","text":"Đôi khi, dữ liệu của bạn có thể có hàng thứ hai, với chức năng như là “từ điển dữ liệu” như hình dưới đây. Trường hợp này có thể xảy ra vấn đề vì nó có thể dẫn đến việc tất cả các cột được nhập vào dưới dạng nhóm “ký tự (character)”.Dưới đây là một ví dụ về loại bộ dữ liệu này (với hàng đầu tiên là từ điển dữ liệu).","code":""},{"path":"importing.html","id":"xóa-hàng-tiêu-đề-thứ-hai","chapter":"7 Nhập xuất dữ liệu","heading":"Xóa hàng tiêu đề thứ hai","text":"Để bỏ hàng tiêu đề thứ hai, bạn có thể sẽ cần nhập dữ liệu hai lần.Nhập dữ liệu vào để lấy tên các cột một cách chính xácNhập lại dữ liệu, bỏ qua hai hàng đầu tiên (hàng tiêu đề và hàng thứ hai)Liên kết dataframe đã xóa bỏ 2 hàng đầu tiên với tên cột ở bước 1Đối số chính xác được sử dụng để liên kết các tên cột tùy thuộc vào loại tệp dữ liệu (.csv, .tsv, .xlsx, v.v.). Điều này là rio sử dụng các hàm khác nhau cho các loại tệp khác nhau (xem bảng ở trên).Đối với tệp Excel: (col_names =)Đối với tệp CSV: (col.names =)Tùy chọn sao lưu - thay đổi tên cột dưới dạng một lệnh riêng biệt","code":"\n# import first time; store the column names\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # save true column names\n\n# import second time; skip row 2, and assign column names to argument col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n# import first time; sotre column names\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# note argument for csv files is 'col.names = '\nlinelist_raw <- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) <- linelist_raw_names"},{"path":"importing.html","id":"tạo-từ-điển-dữ-liệu","chapter":"7 Nhập xuất dữ liệu","heading":"Tạo từ điển dữ liệu","text":"Thông tin thêm! Nếu bạn có hàng thứ hai là từ điển dữ liệu, bạn có thể dễ dàng tạo từ điển dữ liệu thích hợp từ nó. Mẹo này được điều chỉnh từ bài đăng này.","code":"\ndict <- linelist_2headers %>%             # begin: linelist with dictionary as first row\n  head(1) %>%                             # keep only column names and first dictionary row                \n  pivot_longer(cols = everything(),       # pivot all columns to long format\n               names_to = \"Column\",       # assign new column names\n               values_to = \"Description\")"},{"path":"importing.html","id":"kết-hợp-hai-hàng-tiêu-đề","chapter":"7 Nhập xuất dữ liệu","heading":"Kết hợp hai hàng tiêu đề","text":"Trong một số trường hợp khi bộ dữ liệu thô của bạn có hai hàng tiêu đề (hoặc cụ thể hơn, hàng dữ liệu thứ 2 là tiêu đề phụ), bạn có thể muốn “kết hợp” chúng hoặc thêm các giá trị trong hàng tiêu đề thứ hai vào hàng tiêu đề đầu tiên.Lệnh dưới đây sẽ xác định tên cột của data frame là sự kết hợp (dán với nhau) của các tiêu đề (đúng) đầu tiên với giá trị ngay bên dưới (trong hàng đầu tiên).","code":"\nnames(my_data) <- paste(names(my_data), my_data[1, ], sep = \"_\")"},{"path":"importing.html","id":"trang-tính-google","chapter":"7 Nhập xuất dữ liệu","heading":"Trang tính Google","text":"Bạn có thể nhập dữ liệu từ một trang tính Google trực tuyến với package googlesheet4 và bằng cách xác thực quyền truy cập của bạn vào trang tính.Dưới đây là một trang tính Google minh họa được nhập và lưu. Lệnh này có thể yêu cầu xác thực tài khoản Google của bạn. Làm theo lời nhắc và cửa sổ bật lên trong trình duyệt Internet của bạn để cấp cho các package Tidyverse API quyền chỉnh sửa, tạo và xóa trang tính của bạn trong Google Drive.Trang tính dưới đây “có thể được xem bởi bất kỳ ai có liên kết” và bạn có thể thử nhập trang tính đó.Trang tính cũng có thể được nhập chỉ bằng ID của sheet, một phần ngắn hơn của URL:Một package khác, googledrive cung cấp các hàm hữu ích để viết, chỉnh sửa và xóa các trang tính Google. Ví dụ: các hàm được sử dụng gs4_create() và sheet_write() đều được tìm thấy trong package này.Dưới đây là một số hướng dẫn trực tuyến hữu ích khác:hướng dẫn nhập Google sheet cơ bảnhướng dẫn chi tiết hơntương tác giữa googlesheets4 và tidyverse","code":"\npacman::p_load(\"googlesheets4\")\nGsheets_demo <- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\nGsheets_demo <- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")"},{"path":"importing.html","id":"nhập-xuất-tách-kết-hợp---nhiều-tệp","chapter":"7 Nhập xuất dữ liệu","heading":"7.6 Nhập, xuất, tách, kết hợp - nhiều tệp","text":"Xem chương về [Lặp, vòng lặp và danh sách] để biết ví dụ về cách nhập và kết hợp nhiều tệp hoặc nhiều Excel workbook. Chương này cũng có các ví dụ về cách chia một data frame thành các phần và xuất từng phần riêng biệt hoặc dưới dạng các sheet được đặt tên trong một Excel workbook.","code":""},{"path":"importing.html","id":"import_github","chapter":"7 Nhập xuất dữ liệu","heading":"7.7 Nhập từ Github","text":"Nhập dữ liệu trực tiếp từ Github vào R có thể rất dễ dàng hoặc có thể yêu cầu một vài bước - tùy thuộc vào loại tệp. Dưới đây là một số cách tiếp cận:","code":""},{"path":"importing.html","id":"tệp-csv","chapter":"7 Nhập xuất dữ liệu","heading":"Tệp CSV","text":"Có thể dễ dàng nhập tệp .csv trực tiếp từ Github vào R bằng lệnh R.Đi tới repo Github, tìm tệp quan tâm và nhấp vào tệp đóNhấp vào nút “Raw” (sau đó bạn sẽ thấy dữ liệu csv “thô”, như được hiển thị bên dưới)Sao chép URL (địa chỉ web)Đặt URL trong dấu ngoặc kép trong lệnh R import()","code":""},{"path":"importing.html","id":"tệp-xlsx","chapter":"7 Nhập xuất dữ liệu","heading":"Tệp XLSX","text":"Bạn có thể không xem được dữ liệu “Thô” cho một số tệp (ví dụ: .xlsx, .rds, .nwk, .shp)Đi tới repo Github, tìm tệp quan tâm và nhấp vào tệp đóNhấp vào nút “Download”, như được hiển thị bên dướiLưu tệp trên máy tính của bạn và nhập tệp đó vào R","code":""},{"path":"importing.html","id":"shapefiles","chapter":"7 Nhập xuất dữ liệu","heading":"Shapefiles","text":"Các Shapefiles có nhiều tệp thành phần phụ, mỗi tệp có một phần mở rộng khác nhau. Một tệp sẽ có phần mở rộng “.shp”, nhưng những tệp khác có thể là “.dbf”, “.prj”, v.v. Để tải xuống shapefiles từ Github, bạn sẽ cần tải xuống từng tệp thành phần phụ riêng lẻ và lưu chúng trong cùng một thư mục trên máy tính của bạn. Trong Github, nhấp vào từng tệp riêng lẻ và tải chúng xuống bằng cách nhấp vào nút “Download”.Một khi được lưu vào máy tính, bạn có thể nhập định dạng tệp như được trình bày trong chương GIS cơ bản bằng cách sử dụng hàm st_read() từ package sf. Bạn chỉ cần cung cấp đường dẫn tệp và tên của tệp “.shp” - miễn là các tệp liên quan khác nằm trong cùng một thư mục trên máy tính của bạn.Dưới đây, bạn có thể thấy shapefiles tên “sl_adm3” bao gồm nhiều tệp như thế nào - mỗi tệp phải được tải xuống từ Github.","code":""},{"path":"importing.html","id":"nhập-dữ-liệu-thủ-công","chapter":"7 Nhập xuất dữ liệu","heading":"7.8 Nhập dữ liệu thủ công","text":"","code":""},{"path":"importing.html","id":"nhập-theo-hàng","chapter":"7 Nhập xuất dữ liệu","heading":"Nhập theo hàng","text":"Sử dụng hàm tribble của package tibble từ tidyverse (tài liệu tham khảo trực tuyến).Lưu ý cách tiêu đề cột bắt đầu bằng dấu ngã (~). Cũng lưu ý rằng mỗi cột chỉ được chứa một nhóm dữ liệu (ký tự, số, v.v.). Bạn có thể sử dụng các tab, khoảng cách và hàng mới để làm cho việc nhập dữ liệu trực quan và dễ đọc hơn. Khoảng trắng không quan trọng giữa các giá trị, nhưng mỗi hàng được biểu thị bằng một dòng code mới. Ví dụ:Và giờ chúng ta hiển thị bộ dữ liệu mới:","code":"\n# create the dataset manually by row\nmanual_entry_rows <- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )"},{"path":"importing.html","id":"nhập-theo-cột","chapter":"7 Nhập xuất dữ liệu","heading":"Nhập theo cột","text":"Vì data frame bao gồm các vectơ (cột dọc), cách tiếp cận cơ bản để tạo data frame thủ công trong R muốn bạn xác định từng cột và sau đó liên kết chúng lại với nhau. Điều này có thể phản trực quan trong dịch tễ học, vì chúng ta thường nghĩ về dữ liệu của mình theo hàng (như trên).CHÚ Ý: Tất cả các vectơ phải có cùng độ dài (cùng số giá trị).Các vectơ sau đó có thể được liên kết với nhau bằng cách sử dụng lệnh data.frame():Và giờ chúng ta hiển thị bộ dữ liệu mới:","code":"\n# define each vector (vertical column) separately, each with its own name\nPatientID <- c(235, 452, 778, 111)\nTreatment <- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     <- c(1, 0, 1, 0)\n# combine the columns into a data frame, by referencing the vector names\nmanual_entry_cols <- data.frame(PatientID, Treatment, Death)"},{"path":"importing.html","id":"dán-từ-bộ-nhớ-tạm","chapter":"7 Nhập xuất dữ liệu","heading":"Dán từ bộ nhớ tạm","text":"Nếu bạn sao chép dữ liệu từ nơi khác và có nó trong bộ nhớ tạm, bạn có thể thử một trong hai cách dưới đây:Từ package clipr, bạn có thể sử dụng hàm read_clip_tbl() để nhập dưới dạng data frame hoặc chỉ cần hàm read_clip() để nhập dưới dạng một vectơ ký tự. Trong cả hai trường hợp, hãy để trống dấu ngoặc đơn.Bạn cũng có thể dễ dàng xuất sang clipboard của hệ thống bằng clipr. Xem mục bên dưới về Xuất dữ liệu.Ngoài ra, bạn có thể sử dụng lệnh read.table() từ base R với file = \"clipboard\") để nhập dưới dạng data frame:","code":"\nlinelist <- clipr::read_clip_tbl()  # imports current clipboard as data frame\nlinelist <- clipr::read_clip()      # imports as character vector\ndf_from_clipboard <- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row"},{"path":"importing.html","id":"nhập-tệp-gần-đây-nhất","chapter":"7 Nhập xuất dữ liệu","heading":"7.9 Nhập tệp gần đây nhất","text":"Thường thì bạn có thể nhận được các bản cập nhật hàng ngày cho bộ dữ liệu của mình. Trong trường hợp này, bạn sẽ muốn viết code mà nhập tệp gần đây nhất. Dưới đây, chúng tôi trình bày hai cách để tiếp cận điều này:Chọn tệp dựa trên ngày trong tên tệpChọn tệp dựa trên siêu dữ liệu (metadata) của tệp (lần sửa đổi cuối cùng)","code":""},{"path":"importing.html","id":"ngày-trong-tên-tệp","chapter":"7 Nhập xuất dữ liệu","heading":"Ngày trong tên tệp","text":"Cách tiếp cận này dựa trên ba cơ sở:Bạn tin tưởng ngày tháng trong tên tệpNgày tháng ở dạng số và thường xuất hiện ở cùng một định dạng (ví dụ: năm rồi tháng rồi ngày)Không có số nào khác trong tên tệpChúng tôi sẽ giải thích từng bước và sau đó cho bạn thấy cách chúng được kết hợp ở phần cuối.Đầu tiên, sử dụng dir() từ base R để chỉ trích xuất tên tệp cho mỗi tệp trong thư mục quan tâm. Xem chương về Tương tác với thư mục làm việc để biết thêm chi tiết về dir(). Trong ví dụ này, thư mục quan tâm là thư mục “linelists” trong thư mục “example” chứa trong thư mục “data” của dự án R.Một khi bạn có vectơ chứa các tên này, bạn có thể trích xuất ngày với chúng bằng cách áp dụng hàm str_extract() từ stringr với việc sử dụng biểu thức chính quy sau đây. Nó giúp trích xuất bất kỳ số nào trong tên tệp (bao gồm bất kỳ ký tự nào khác ở giữa như dấu gạch ngang hoặc dấu gạch chéo). Bạn có thể đọc thêm về stringr trong chương Ký tự và chuỗi.Giả sử ngày thường được viết theo cùng một định dạng ngày (ví dụ: Năm rồi Tháng rồi Ngày) và năm có 4 chữ số, bạn có thể sử dụng các hàm chuyển đổi linh hoạt của lubridate (ymd(), dmy(), mdy()) để chuyển đổi chúng thành ngày. Đối với các hàm này, dấu gạch ngang, dấu cách hoặc dấu gạch chéo không quan trọng, quan trọng chỉ là thứ tự của các số. Đọc thêm trong chương Làm việc với ngày tháng.Sau đó, hàm base R .max() có thể được sử dụng để trả về vị trí chỉ mục (ví dụ: 1, 2, 3,…) của giá trị ngày lớn nhất. Tệp mới nhất được xác định chính xác là tệp thứ 6 - “case_linelist_2020-10-08.xlsx”.Nếu chúng ta tổng hợp tất cả các lệnh này, code hoàn chỉnh có thể trông giống như bên dưới. Lưu ý rằng dấu . ở dòng cuối cùng thay thế cho thành phần được piping vào hàm đó. Tại thời điểm đó, giá trị chỉ đơn giản là số 6. Giá trị này được đặt trong dấu ngoặc kép để trích xuất phần tử thứ 6 của vectơ tên tệp được tạo bởi dir().Bây giờ bạn có thể sử dụng tên này để kết thúc đường dẫn tệp tương đối, với ():Và bây giờ bạn có thể nhập tệp mới nhất:","code":"\nlinelist_filenames <- dir(here(\"data\", \"example\", \"linelists\")) # get file names from folder\nlinelist_filenames                                              # print## [1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\" \n## [3] \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \n## [5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n## [7] \"case_linelist20201006.csv\"\nlinelist_dates_raw <- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print## [1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\"\n## [7] \"20201006\"\nlinelist_dates_clean <- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean## [1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\"\n## [7] \"2020-10-06\"\nindex_latest_file <- which.max(linelist_dates_clean)\nindex_latest_file## [1] 6\n# load packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extract the file name of latest file\nlatest_file <- dir(here(\"data\", \"example\", \"linelists\")) %>%  # file names from \"linelists\" sub-folder          \n  str_extract(\"[0-9].*[0-9]\") %>%                  # pull out dates (numbers)\n  ymd() %>%                                        # convert numbers to dates (assuming year-month-day format)\n  which.max() %>%                                  # get index of max date (latest file)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # return the filename of latest linelist\n\nlatest_file  # print name of latest file## [1] \"case_linelist_2020-10-08.xlsx\"\nhere(\"data\", \"example\", \"linelists\", latest_file) \n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # import "},{"path":"importing.html","id":"sử-dụng-thông-tin-tệp","chapter":"7 Nhập xuất dữ liệu","heading":"Sử dụng thông tin tệp","text":"Nếu tệp của bạn không có ngày trong tên của chúng (hoặc bạn không tin tưởng vào những ngày đó), bạn có thể thử trích xuất ngày sửa đổi cuối cùng từ siêu dữ liệu tệp. Sử dụng các hàm từ package fs để kiểm tra thông tin siêu dữ liệu cho từng tệp, bao gồm thời gian sửa đổi cuối cùng và đường dẫn tệp.Dưới đây, chúng tôi cung cấp thư mục quan tâm tới dir_info() của fs. Trong trường hợp này, thư mục quan tâm nằm trong dự án R trong thư mục “data”, thư mục con “example” và thư mục con thư mục này “linelists”. Kết quả là một data frame với một dòng cho mỗi tệp và các cột cho modification_time, path, v.v. Bạn có thể xem ví dụ trực quan về điều này trong chương về Tương tác với thư mục làm việc.Chúng ta có thể sắp xếp data frame này của các tệp theo cột với modification_time, và sau đó chỉ giữ lại hàng trên cùng/mới nhất (tệp) với head()của base R. Sau đó, chúng ta có thể trích xuất đường dẫn tệp của tệp mới nhất này chỉ với hàm pull() của dplyr trên path cột. Cuối cùng, chúng ta có thể chuyển đường dẫn tệp này đến import(). Tệp đã nhập được lưu dưới dạng latest_file.","code":"\nlatest_file <- dir_info(here(\"data\", \"example\", \"linelists\")) %>%  # collect file info on all files in directory\n  arrange(desc(modification_time)) %>%      # sort by modification time\n  head(1) %>%                               # keep only the top (latest) file\n  pull(path) %>%                            # extract only the file path\n  import()                                  # import the file"},{"path":"importing.html","id":"import_api","chapter":"7 Nhập xuất dữ liệu","heading":"7.10 API","text":"Một “Giao diện lập trình tự động (Automated Programming Interface)” (API) có thể được sử dụng để yêu cầu trực tiếp dữ liệu từ một trang web. API là một tập hợp các quy tắc cho phép một ứng dụng phần mềm tương tác với một ứng dụng phần mềm khác. Khách hàng (bạn) gửi một “yêu cầu (request)” và nhận được một “phản hồi (response)” có chứa nội dung. Các package R httr và jsonlite có thể hỗ trợ quá trình này.Mỗi trang web hỗ trợ API sẽ có tài liệu và chi tiết cụ thể riêng để làm quen. Một số trang web công khai API và cho phép có thể được truy cập bởi bất kỳ ai. Những nền tảng khác, chẳng hạn như nền tảng có ID người dùng và thông tin đăng nhập, yêu cầu xác thực để truy cập dữ liệu của họ.Không cần phải nói, để nhập dữ liệu qua API thì cần phải có kết nối internet. Chúng tôi sẽ đưa ra các ví dụ ngắn gọn về việc sử dụng API để nhập dữ liệu và liên kết bạn với các tài nguyên khác.Lưu ý: Hãy nhớ lại rằng dữ liệu có thể được đăng trên một trang web không có API, điều này có thể dễ dàng truy xuất hơn. Ví dụ: một tệp CSV đã đăng có thể được truy cập chỉ bằng cách cung cấp URL của trang web để import() như được mô tả trong mục nhập từ Github.","code":""},{"path":"importing.html","id":"yêu-cầu-http-http-request","chapter":"7 Nhập xuất dữ liệu","heading":"Yêu cầu HTTP (HTTP request)","text":"Trao đổi API thường được thực hiện thông qua một HTTP request. HTTP là Giao thức truyền siêu văn bản (Hypertext Transfer Protocol) và là định dạng cơ bản của giao thức yêu cầu (request)/phản hồi (response) giữa máy khách và máy chủ. Đầu vào và đầu ra chính xác có thể khác nhau tùy thuộc vào loại API nhưng quy trình là giống nhau - “Request” (thường là HTTP request) từ người dùng, thường chứa một truy vấn, theo sau là “Response”, chứa thông tin trạng thái về request và có thể là nội dung được yêu cầu.Dưới đây là một số thành phần của một HTTP request:URL của điểm cuối API“Method (Phương thức)” (hoặc “Verb (Động từ)”)Các tiêu đềPhần thânHTTP request “method” là hành động bạn muốn thực hiện. Hai phương thức HTTP phổ biến nhất là GET và POST nhưng những phương thức khác có thể bao gồm PUT, DELETE, PATCH, v.v. Khi nhập dữ liệu vào R, rất có thể bạn sẽ sử dụng GET.Sau request của bạn, máy tính của bạn sẽ nhận được “phản hồi” ở định dạng tương tự như những gì bạn đã gửi, bao gồm URL, trạng thái HTTP (Trạng thái 200 là thứ bạn muốn!), loại tệp, kích thước và nội dung mong muốn. Sau đó, bạn sẽ cần phân tích cú pháp phản hồi này và biến nó thành một data frame khả thi trong môi trường R của bạn.","code":""},{"path":"importing.html","id":"package","chapter":"7 Nhập xuất dữ liệu","heading":"Package","text":"Package httr hoạt động tốt để xử lý các yêu cầu HTTP trong R. Nó đòi hỏi ít kiến thức về API Web và có thể được sử dụng bởi những người ít quen thuộc với thuật ngữ phát triển phần mềm. Ngoài ra, nếu phản hồi HTTP là .json, bạn có thể sử dụng jsonlite để phân tích cú pháp phản hồi.","code":"\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)"},{"path":"importing.html","id":"dữ-liệu-công-khai","chapter":"7 Nhập xuất dữ liệu","heading":"Dữ liệu công khai","text":"Dưới đây là một ví dụ về một HTTP request, được mượn từ một hướng dẫn từ Phòng thí nghiệm Dữ liệu Trafford. Trang web này chứa một số tài nguyên khác để tìm hiểu và các bài tập về API.Tình huống: Chúng ta muốn nhập một danh sách các cửa hàng thức ăn nhanh ở thành phố Trafford, Vương quốc Anh. Dữ liệu có thể được truy cập từ API của Cơ quan Tiêu chuẩn Thực phẩm, cơ quan cung cấp dữ liệu xếp hạng vệ sinh thực phẩm cho Vương quốc Anh.Dưới đây là các thông số cho yêu cầu của chúng tôi:Phương thức HTTP: GETURL của điểm cuối API: http://api.ratings.food.gov.uk/EstablishmentsCác thông số đã chọn: tên, địa chỉ, kinh độ, vĩ độ, businessTypeId, ratingKey, localAuthorityIdCác tiêu đề: “x-api-version”, 2(Các) Định dạng dữ liệu: JSON, XMLTài liệu: http://api.ratings.food.gov.uk/helpR code sẽ như sau:Bây giờ bạn có thể làm sạch và sử dụng data frame có tên response, với mỗi hàng là một cơ sở thức ăn nhanh.","code":"\n# prepare the request\npath <- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest <- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# check for any server error (\"200\" is good!)\nrequest$status_code\n\n# submit the request, parse the response, and convert to a data frame\nresponse <- content(request, as = \"text\", encoding = \"UTF-8\") %>%\n  fromJSON(flatten = TRUE) %>%\n  pluck(\"establishments\") %>%\n  as_tibble()"},{"path":"importing.html","id":"yêu-cầu-xác-thực","chapter":"7 Nhập xuất dữ liệu","heading":"Yêu cầu xác thực","text":"Một số API yêu cầu xác thực - để bạn chứng minh mình là ai và có thể truy cập vào dữ liệu bị hạn chế. Để nhập những dữ liệu này, trước tiên bạn có thể cần sử dụng phương thức POST để cung cấp tên người dùng, mật khẩu hoặc code. Điều này sẽ trả về một mã thông báo truy cập, có thể được sử dụng cho các yêu cầu phương thức GET tiếp theo để truy xuất dữ liệu mong muốn.Dưới đây là một ví dụ về truy vấn dữ liệu từ Go.Data, một công cụ điều tra ổ dịch. Go.Data sử dụng một API cho tất cả các tương tác giữa giao diện người dùng web và các ứng dụng điện thoại thông minh được sử dụng để thu thập dữ liệu. Go.Data được sử dụng trên khắp thế giới. Bởi vì dữ liệu các vụ dịch là nhạy cảm và bạn nên là người duy nhất có thể truy cập vào dữ liệu vụ dịch của mình, nên việc xác thực là bắt buộc.Dưới đây là một số code R mẫu sử dụng httr và jsonlite để kết nối với API Go.Data để nhập dữ liệu liên hệ truy vết từ vụ dịch của bạn.CẨN TRỌNG: Nếu bạn đang nhập một lượng lớn dữ liệu từ một API yêu cầu xác thực, nó có thể hết thời gian chờ. Để tránh điều này, hãy truy xuất lại access_token trước mỗi yêu cầu API GET và thử sử dụng các bộ lọc hoặc giới hạn trong truy vấn.MẸO: Lệnh fromJSON() từ package jsonlite không hoàn toàn không - lồng ghép vào lần đầu tiên nó được chạy, vì vậy bạn vẫn có thể có danh sách các hàng trong phần kết quả của mình. Bạn sẽ cần phải bỏ lồng ghép thêm cho một số biến nhất định; tùy thuộc vào cách .json của bạn được lồng ghép vào nhau. Để xem thêm thông tin về điều này, hãy xem tài liệu về package jsonlite, chẳng hạn như flatten() function.Để biết thêm chi tiết, hãy xem tài liệu trên LoopBack Explorer, chương Truy vết tiếp xúc hoặc các mẹo API trên Go.Data Github repositoryBạn có thể đọc thêm về httr trong package herePhần này cũng đã được trình bày trong hướng dẫn nàyvà hướng dẫn này hướng dẫn này.","code":"\n# set credentials for authorization\nurl <- \"https://godatasampleURL.int/\"           # valid Go.Data instance url\nusername <- \"username\"                          # valid Go.Data username \npassword <- \"password\"                          # valid Go,Data password \noutbreak_id <- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # valid Go.Data outbreak ID\n\n# get access token\nurl_request <- paste0(url,\"api/oauth/token?access_token=123\") # define base URL request\n\n# prepare request\nresponse <- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # use saved username/password from above to authorize                               \n    password = password),                                       \n    encode = \"json\")\n\n# execute request and parse response\ncontent <-\n  content(response, as = \"text\") %>%\n  fromJSON(flatten = TRUE) %>%          # flatten nested JSON\n  glimpse()\n\n# Save access token from response\naccess_token <- content$access_token    # save access token to allow subsequent API calls below\n\n# import outbreak contacts\n# Use the access token \nresponse_contacts <- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # GET request\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts <- content(response_contacts, as = \"text\")         # convert to text JSON\n\ncontacts <- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # flatten JSON to tibble"},{"path":"importing.html","id":"xuất-dữ-liệu","chapter":"7 Nhập xuất dữ liệu","heading":"7.11 Xuất dữ liệu","text":"","code":""},{"path":"importing.html","id":"với-package-rio","chapter":"7 Nhập xuất dữ liệu","heading":"Với package rio","text":"Với rio, bạn có thể sử dụng lệnh export() theo cách tương tự với import(). Đầu tiên, cung cấp tên của đối tượng R bạn muốn lưu (ví dụ: linelist), sau đó trong dấu ngoặc kép đặt đường dẫn tệp nơi bạn muốn lưu tệp, bao gồm tên tệp mong muốn và phần mở rộng tệp. Ví dụ:Thao tác này lưu data frame linelist dưới dạng một Excel workbook vào thư mục làm việc/thư mục gốc của dự án R:Bạn có thể lưu cùng một data frame dưới dạng tệp csv bằng cách thay đổi phần mở rộng. Ví dụ, chúng tôi cũng lưu nó vào một đường dẫn tệp được tạo bằng ():","code":"\nexport(linelist, \"my_linelist.xlsx\") # will save to working directory\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))"},{"path":"importing.html","id":"tới-bộ-nhớ-tạm","chapter":"7 Nhập xuất dữ liệu","heading":"Tới bộ nhớ tạm","text":"Để xuất khung dữ liệu sang “bộ nhớ tạm” của máy tính (để sau đó dán vào một phần mềm khác như Excel, Google Spreadsheets, v.v.), bạn có thể sử dụng write_clip() từ package clipr.","code":"\n# export the linelist data frame to your system's clipboard\nclipr::write_clip(linelist)"},{"path":"importing.html","id":"import_rds","chapter":"7 Nhập xuất dữ liệu","heading":"7.12 Tệp RDS","text":"Giống như .csv, .xlsx, v.v., bạn cũng có thể xuất/lưu các R data frame dưới dạng tệp .rds. Đây là định dạng tệp dành riêng cho R và rất hữu ích nếu bạn biết mình sẽ làm việc lại với dữ liệu đã xuất trong R.Các nhóm của cột được lưu trữ, vì vậy bạn không cần phải làm sạch lại khi chúng được nhập (với Excel hoặc thậm chí là tệp CSV, điều này có thể khiến bạn đau đầu!). Nó cũng là một tệp nhỏ hơn, hữu ích cho việc xuất và nhập nếu bộ dữ liệu của bạn lớn.Ví dụ: nếu bạn làm việc trong nhóm Dịch tễ học và cần gửi tệp cho nhóm GIS để lập bản đồ và họ cũng sử dụng R, chỉ cần gửi tệp .rds cho họ! Sau đó, tất cả các nhóm cột được giữ lại và có ít việc phải xử lý hơn.","code":"\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))"},{"path":"importing.html","id":"import_rdata","chapter":"7 Nhập xuất dữ liệu","heading":"7.13 Tệp và danh sách Rdata","text":"Tệp .Rdata có thể lưu trữ nhiều đối tượng R - ví dụ: nhiều data frame, kết quả mô hình, danh sách, v.v. Điều này có thể rất hữu ích để hợp nhất hoặc chia sẻ nhiều dữ liệu của bạn cho một dự án nhất định.Trong ví dụ dưới đây, nhiều đối tượng R được lưu trữ trong tệp “my_objects.Rdata” đã xuất:Lưu ý: nếu bạn đang thử nhập một danh sách, hãy sử dụng import_list() từ rio để nhập nó với cấu trúc và nội dung gốc hoàn chỉnh.","code":"\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\nrio::import_list(\"my_list.Rdata\")"},{"path":"importing.html","id":"lưu-biểu-đồ","chapter":"7 Nhập xuất dữ liệu","heading":"7.14 Lưu biểu đồ","text":"Hướng dẫn về cách lưu các biểu đồ, chẳng hạn như các biểu đồ được tạo bởi ggplot(), được thảo luận sâu trong chương ggplot cơ bản.Tóm lại, chạy lệnh ggsave(\"my_plot_filepath_and_name.png\") sau khi biểu đồ của bạn. Bạn có thể cung cấp một đối tượng biểu đồ đã lưu cho đối số plot = hoặc chỉ cần xác định đường dẫn tệp đích (với phần mở rộng tệp) để lưu biểu đồ được hiển thị gần đây nhất. Bạn cũng có thể kiểm soát width =, height =, units = và dpi =.Cách để lưu đồ thị mạng lưới (network graph), chẳng hạn như cây lây nhiễm, được đề cập trong chương Chuỗi lây nhiễm.","code":""},{"path":"importing.html","id":"tài-nguyên-học-liệu","chapter":"7 Nhập xuất dữ liệu","heading":"7.15 Tài nguyên học liệu","text":"R Data Import/Export ManualR 4 Data Science chapter data importggsave() documentationDưới đây là một bảng, lấy từ rio vignette trực tuyến. Đối với mỗi loại dữ liệu, nó hiển thị: phần mở rộng tệp dự kiến, package rio sử dụng để nhập hoặc xuất dữ liệu và trả lời chức năng này có được bao gồm trong phiên bản rio được cài đặt mặc định hay không.","code":""},{"path":"cleaning.html","id":"cleaning","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8 Làm sạch số liệu và các hàm quan trọng","text":"page demonstrates common steps used process “cleaning” dataset, also explains use many essential R data management functions.demonstrate data cleaning, page begins importing raw case linelist dataset, proceeds step--step cleaning process. R code, manifests “pipe” chain, references “pipe” operator %>% passes dataset one operation next.","code":""},{"path":"cleaning.html","id":"core-functions","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Core functions","text":"handbook emphasizes use functions tidyverse family R packages. essential R functions demonstrated page listed .Many functions belong dplyr R package, provides “verb” functions solve data manipulation challenges (name reference \"data frame-plier. dplyr part tidyverse family R packages (also includes ggplot2, tidyr, stringr, tibble, purrr, magrittr, forcats among others).want see functions compare Stata SAS commands, see page [Transition R].may encounter alternative data management framework data.table R package operators like := frequent use brackets [ ]. approach syntax briefly explained Data Table page.","code":""},{"path":"cleaning.html","id":"nomenclature","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Nomenclature","text":"handbook, generally reference “columns” “rows” instead “variables” “observations”. explained primer “tidy data”, epidemiological statistical datasets consist structurally rows, columns, values.Variables contain values measure underlying attribute (like age group, outcome, date onset). Observations contain values measured unit (e.g. person, site, lab sample). aspects can difficult tangibly define.“tidy” datasets, column variable, row observation, cell single value. However datasets encounter fit mold - “wide” format dataset may variable split across several columns (see example [Pivoting data] page). Likewise, observations split across several rows.handbook managing transforming data, referring concrete data structures rows columns relevant abstract observations variables. Exceptions occur primarily pages data analysis, see references variables observations.","code":""},{"path":"cleaning.html","id":"cleaning-pipeline","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.1 Cleaning pipeline","text":"page proceeds typical cleaning steps, adding sequentially cleaning pipe chain.epidemiological analysis data processing, cleaning steps often performed sequentially, linked together. R, often manifests cleaning “pipeline”, raw dataset passed “piped” one cleaning step another.chains utilize dplyr “verb” functions magrittr pipe operator %>%. pipe begins “raw” data (“linelist_raw.xlsx”) ends “clean” R data frame (linelist) can used, saved, exported, etc.cleaning pipeline order steps important. Cleaning steps might include:Importing dataColumn names cleaned changedDe-duplicationColumn creation transformation (e.g. re-coding standardising values)Rows filtered added","code":""},{"path":"cleaning.html","id":"load-packages","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.2 Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  tidyverse   # data management and visualization\n)"},{"path":"cleaning.html","id":"import-data","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.3 Import data","text":"","code":""},{"path":"cleaning.html","id":"import","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Import","text":"import “raw” case linelist Excel file using import() function package rio. rio package flexibly handles many types files (e.g. .xlsx, .csv, .tsv, .rds. See page [Import export] information tips unusual situations (e.g. skipping rows, setting missing values, importing Google sheets, etc).want follow along, click download “raw” linelist (.xlsx file).dataset large takes long time import, can useful import command separate pipe chain “raw” saved distinct file. also allows easy comparison original cleaned versions.import raw Excel file save data frame linelist_raw. assume file located working directory R project root, sub-folders specified file path.can view first 50 rows data frame . Note: base R function head(n) allow view just first n rows R console.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\")"},{"path":"cleaning.html","id":"review","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Review","text":"can use function skim() package skimr get overview entire dataframe (see page [Descriptive tables] info). Columns summarised class/type character, numeric. Note: “POSIXct” type raw date class (see Working dates.Table 8.1: Data summaryVariable type: characterVariable type: numericVariable type: POSIXct","code":"\nskimr::skim(linelist_raw)"},{"path":"cleaning.html","id":"column-names","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.4 Column names","text":"R, column names “header” “top” value column. used refer columns code, serve default label figures.statistical software SAS STATA use “labels” co-exist longer printed versions shorter column names. R offer possibility adding column labels data, emphasized practice. make column names “printer-friendly” figures, one typically adjusts display within plotting commands create outputs (e.g. axis legend titles plot, column headers printed table - see scales section ggplot tips page [Tables presentation] pages). want assign column labels data, read online .R column names used often, must “clean” syntax. suggest following:Short namesNo spaces (replace underscores _ )unusual characters (&, #, <, >, …)Similar style nomenclature (e.g. date columns named like date_onset, date_report, date_death…)columns names linelist_raw printed using names() base R. can see initially:names contain spaces (e.g. infection date)Different naming patterns used dates (date onset vs. infection date)must merged header across two last columns .xlsx. know name two merged columns (“merged_header”) assigned R first column, second column assigned placeholder name “…28” (empty 28th column).NOTE: reference column name includes spaces, surround name back-ticks, example: linelist$` '\\x60infection date\\x60'`. note keyboard, back-tick (`) different single quotation mark (’).","code":"\nnames(linelist_raw)##  [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"     \n##  [5] \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n## [13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n## [21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\""},{"path":"cleaning.html","id":"labels","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Labels","text":"statistical software SAS variable labels","code":""},{"path":"cleaning.html","id":"automatic-cleaning","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Automatic cleaning","text":"function clean_names() package janitor standardizes column names makes unique following:Converts names consist underscores, numbers, lettersAccented characters transliterated ASCII (e.g. german o umlaut becomes “o”, spanish “enye” becomes “n”)Capitalization preference new column names can specified using case = argument (“snake” default, alternatives include “sentence”, “title”, “small_camel”…)can specify specific name replacements providing vector replace = argument (e.g. replace = c(onset = \"date_of_onset\"))online vignetteBelow, cleaning pipeline begins using clean_names() raw linelist.NOTE: last column name “…28” changed “x28”.","code":"\n# pipe the raw dataset through the function clean_names(), assign result as \"linelist\"  \nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# see the new column names\nnames(linelist)##  [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"     \n##  [5] \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n## [13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n## [21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\""},{"path":"cleaning.html","id":"manual-name-cleaning","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Manual name cleaning","text":"Re-naming columns manually often necessary, even standardization step . , re-naming performed using rename() function dplyr package, part pipe chain. rename() uses style NEW = OLD - new column name given old column name., re-naming command added cleaning pipeline. Spaces added strategically align code easier reading.Now can see columns names changed:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"case_id\"              \"generation\"           \"date_infection\"      \n##  [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"            \n## [10] \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"              \n## [22] \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [28] \"x28\""},{"path":"cleaning.html","id":"rename-by-column-position","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Rename by column position","text":"can also rename column position, instead column name, example:","code":"\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)"},{"path":"cleaning.html","id":"rename-via-select-and-summarise","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Rename via select() and summarise()","text":"shortcut, can also rename columns within dplyr select() summarise() functions. select() used keep certain columns (covered later page). summarise() covered [Grouping data] [Descriptive tables] pages. functions also uses format new_name = old_name. example:","code":"\nlinelist_raw %>% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning.html","id":"other-challenges","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Other challenges","text":"","code":""},{"path":"cleaning.html","id":"empty-excel-column-names","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Empty Excel column names","text":"R dataset columns column names (headers). , import Excel dataset data column headers, R fill-headers names like “…1” “…2”. number represents column number (e.g. 4th column dataset header, R name “…4”).can clean names manually referencing position number (see example ), assigned name (linelist_raw$...1).","code":""},{"path":"cleaning.html","id":"merged-excel-column-names-and-cells","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Merged Excel column names and cells","text":"Merged cells Excel file common occurrence receiving data. explained [Transition R], merged cells can nice human reading data, “tidy data” cause many problems machine reading data. R accommodate merged cells.Remind people data entry human-readable data machine-readable data. Strive train users principles tidy data. possible, try change procedures data arrive tidy format without merged cells.variable must column.observation must row.value must cell.using rio’s import() function, value merged cell assigned first cell subsequent cells empty.One solution deal merged cells import data function readWorkbook() package openxlsx. Set argument fillMergedCells = TRUE. gives value merged cell cells within merge range.DANGER: column names merged readWorkbook(), end duplicate column names, need fix manually - R work well duplicate column names! can re-name referencing position (e.g. column 5), explained section manual column name cleaning.","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning.html","id":"select-or-re-order-columns","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.5 Select or re-order columns","text":"Use select() dplyr select columns want retain, specify order data frame.CAUTION: examples , linelist data frame modified select() displayed, saved. demonstration purposes. modified column names printed piping data frame names().column names linelist point cleaning pipe chain:","code":"\nnames(linelist)##  [1] \"case_id\"              \"generation\"           \"date_infection\"      \n##  [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"            \n## [10] \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"              \n## [22] \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [28] \"x28\""},{"path":"cleaning.html","id":"keep-columns","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Keep columns","text":"Select columns want remainPut names select() command, quotation marks. appear data frame order provide. Note include column exist, R return error (see use any_of() want error situation).","code":"\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names()  # display the column names## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\"\n## [4] \"fever\""},{"path":"cleaning.html","id":"clean_tidyselect","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"“tidyselect” helper functions","text":"helper functions exist make easy specify columns keep, discard, transform. package tidyselect, included tidyverse underlies columns selected dplyr functions.example, want re-order columns, everything() useful function signify “columns yet mentioned”. command moves columns date_onset date_hospitalisation beginning (left) dataset, keeps columns afterward. Note everything() written empty parentheses:“tidyselect” helper functions also work within dplyr functions like select(), across(), summarise():everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEcontains() - columns containing character string\nexample: select(contains(\"time\"))\nexample: select(contains(\"time\"))starts_with() - matches specified prefix\nexample: select(starts_with(\"date_\"))\nexample: select(starts_with(\"date_\"))ends_with() - matches specified suffix\nexample: select(ends_with(\"_post\"))\nexample: select(ends_with(\"_post\"))matches() - apply regular expression (regex)\nexample: select(matches(\"[pt]al\"))\nexample: select(matches(\"[pt]al\"))num_range() - numerical range like x01, x02, x03any_of() - matches column exists returns error found\nexample: select(any_of(date_onset, date_death, cardiac_arrest))\nexample: select(any_of(date_onset, date_death, cardiac_arrest))addition, use normal operators c() list several columns, : consecutive columns, ! opposite, & , | .Use () specify logical criteria columns. providing function inside (), include function’s empty parentheses. command selects columns class Numeric.Use contains() select columns column name contains specified character string. ends_with() starts_with() provide nuance.function matches() works similarly contains() can provided regular expression (see page [Characters strings]), multiple strings separated bars within parentheses:CAUTION: column name specifically provide exist data, can return error stop code. Consider using any_of() cite columns may may exist, especially useful negative (remove) selections.one columns exists, error produced code continues without stopping cleaning chain.","code":"\n# move date_onset and date_hospitalisation to beginning\nlinelist %>% \n  select(date_onset, date_hospitalisation, everything()) %>% \n  names()##  [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"             \n##  [4] \"generation\"           \"date_infection\"       \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"            \n## [10] \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"              \n## [22] \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [28] \"x28\"\n# select columns that are class Numeric\nlinelist %>% \n  select(where(is.numeric)) %>% \n  names()## [1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"      \"ht_cm\"     \n## [7] \"ct_blood\"   \"temp\"\n# select columns containing certain characters\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n## [4] \"date_outcome\"\n# searched for multiple character matches\nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # note the OR symbol \"|\"\n  names()## [1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"            \n## [4] \"fever\"\nlinelist %>% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %>% \n  names()## [1] \"date_onset\""},{"path":"cleaning.html","id":"remove-columns","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Remove columns","text":"Indicate columns remove placing minus symbol “-” front column name (e.g. select(-outcome)), vector column names (). columns retained.can also remove column using base R syntax, defining NULL. example:","code":"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% # remove date_onset and all columns from fever to vomit\n  names()##  [1] \"case_id\"              \"generation\"           \"date_infection\"      \n##  [4] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n##  [7] \"gender\"               \"hospital\"             \"lon\"                 \n## [10] \"lat\"                  \"infector\"             \"source\"              \n## [13] \"age\"                  \"age_unit\"             \"row_num\"             \n## [16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n## [19] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [22] \"x28\"\nlinelist$date_onset <- NULL   # deletes column with base R syntax "},{"path":"cleaning.html","id":"standalone","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Standalone","text":"select() can also used independent command (pipe chain). case, first argument original dataframe operated upon.","code":"\n# Create a new linelist with id and age-related columns\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\""},{"path":"cleaning.html","id":"add-to-the-pipe-chain","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Add to the pipe chain","text":"linelist_raw, columns need: row_num, merged_header, x28. remove select() command cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning.html","id":"deduplication","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.6 Deduplication","text":"See handbook page [De-duplication] extensive options de-duplicate data. simple row de-duplication example presented .package dplyr offers distinct() function. function examines every row reduce data frame unique rows. , removes rows 100% duplicates.evaluating duplicate rows, takes account range columns - default considers columns. shown de-duplication page, can adjust column range uniqueness rows evaluated regards certain columns.simple example, just add empty command distinct() pipe chain. ensures rows 100% duplicates rows (evaluated across columns).begin nrow(linelist) rows linelist.de-duplication nrow(linelist) rows. removed rows 100% duplicates rows., distinct() command added cleaning pipe chain:","code":"\nlinelist <- linelist %>% \n  distinct()\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()"},{"path":"cleaning.html","id":"column-creation-and-transformation","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.7 Column creation and transformation","text":"recommend using dplyr function mutate() add new column, modify existing one.example creating new column mutate(). syntax : mutate(new_column_name = value transformation)Stata, similar command generate, R’s mutate() can also used modify existing column.","code":""},{"path":"cleaning.html","id":"new-columns","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"New columns","text":"basic mutate() command create new column might look like . creates new column new_col value every row 10.can also reference values columns, perform calculations. , new column bmi created hold Body Mass Index (BMI) case - calculated using formula BMI = kg/m^2, using column ht_cm column wt_kg.creating multiple new columns, separate comma new line. examples new columns, including ones consist values columns combined using str_glue() stringr package (see page [Characters strings].Review new columns. demonstration purposes, new columns columns used create shown:TIP: variation mutate() function transmute(). function adds new column just like mutate(), also drops/removes columns mention within parentheses.","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nnew_col_demo <- linelist %>%                       \n  mutate(\n    new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n    new_var_static = 7,                   # new column = all values the same\n    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n    ) %>% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        # show only new columns, for demonstration purposes\n# HIDDEN FROM READER\n# removes new demo columns created above\n# linelist <- linelist %>% \n#   select(-contains(\"new_var\"))"},{"path":"cleaning.html","id":"convert-column-class","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Convert column class","text":"Columns containing values dates, numbers, logical values (TRUE/FALSE) behave expected correctly classified. difference “2” class character 2 class numeric!ways set column class import commands, often cumbersome. See [R Basics] section object classes learn converting class objects columns.First, let’s run checks important columns see correct class. also saw beginning ran skim().Currently, class age column character. perform quantitative analyses, need numbers recognized numeric!class date_onset column also character! perform analyses, dates must recognized dates!resolve , use ability mutate() re-define column transformation. define column , converted different class. basic example, converting ensuring column age class Numeric:similar way, can use .character() .logical(). convert class Factor, can use factor() base R as_factor() forcats. Read [Factors] page.must careful converting class Date. Several methods explained page Working dates. Typically, raw date values must format conversion work correctly (e.g “MM/DD/YYYY”, “DD MM YYYY”). converting class Date, check data confirm value converted correctly.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))"},{"path":"cleaning.html","id":"grouped-data","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Grouped data","text":"data frame already grouped (see page [Grouping data]), mutate() may behave differently data frame grouped. summarizing functions, like mean(), median(), max(), etc. calculate group, rows.Read using mutate () grouped dataframes tidyverse mutate documentation.","code":"\n# age normalized to mean of ALL rows\nlinelist %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning.html","id":"clean_across","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Transform multiple columns","text":"Often write concise code want apply transformation multiple columns . transformation can applied multiple columns using across() function package dplyr (also contained within tidyverse package). across() can used dplyr function, commonly used within select(), mutate(), filter(), summarise(). See applied summarise() page [Descriptive tables].Specify columns argument .cols = function(s) apply .fns =. additional arguments provide .fns function can included comma, still within across().","code":""},{"path":"cleaning.html","id":"across-column-selection","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"across() column selection","text":"Specify columns argument .cols =. can name individually, use “tidyselect” helper functions. Specify function .fns =. Note using function mode demonstrated , function written without parentheses ( ).transformation .character() applied specific columns named within across().“tidyselect” helper functions available assist specifying columns. detailed section Selecting re-ordering columns, include: everything(), last_col(), (), starts_with(), ends_with(), contains(), matches(), num_range() any_of().example one change columns character class:Convert character columns name contains string “date” (note placement commas parentheses):, example mutating columns currently class POSIXct (raw datetime class shows timestamps) - words, function .POSIXct() evaluates TRUE. want apply function .Date() columns convert normal class Date.Note within across() also use function () .POSIXct evaluating either TRUE FALSE.Note .POSIXct() package lubridate. similar “” functions like .character(), .numeric(), .logical() base R","code":"\nlinelist <- linelist %>% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = everything(), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\nlinelist <- linelist %>% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))"},{"path":"cleaning.html","id":"across-functions","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"across() functions","text":"can read documentation ?across details provide functions across(). summary points: several ways specify function(s) perform column can even define functions:can provide function name alone (e.g. mean .character)can provide function purrr-style (e.g. ~ mean(.x, na.rm = TRUE)) (see [page][Iteration, loops, lists])can specify multiple functions providing list (e.g. list(mean = mean, n_miss = ~ sum(.na(.x))).\nprovide multiple functions, multiple transformed columns returned per input column, unique names format col_fn. can adjust new columns named .names = argument using glue syntax (see page [Characters strings]) {.col} {.fn} shorthand input column function.\nprovide multiple functions, multiple transformed columns returned per input column, unique names format col_fn. can adjust new columns named .names = argument using glue syntax (see page [Characters strings]) {.col} {.fn} shorthand input column function.online resources using across(): creator Hadley Wickham’s thoughts/rationale","code":""},{"path":"cleaning.html","id":"coalesce","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"coalesce()","text":"dplyr function finds first non-missing value position. “fills-” missing values first available value order specify.example outside context data frame: Let us say two vectors, one containing patient’s village detection another containing patient’s village residence. can use coalesce pick first non-missing value index:works provide data frame columns: row, function assign new column value first non-missing value columns provided (order provided).example “row-wise” operation. complicated row-wise calculations, see section Row-wise calculations.","code":"\nvillage_detection <- c(\"a\", \"b\", NA,  NA)\nvillage_residence <- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage <- coalesce(village_detection, village_residence)\nvillage    # print## [1] \"a\" \"b\" \"a\" \"d\"\nlinelist <- linelist %>% \n  mutate(village = coalesce(village_detection, village_residence))"},{"path":"cleaning.html","id":"cumulative-math","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Cumulative math","text":"want column reflect cumulative sum/mean/min/max etc assessed rows dataframe point, use following functions:cumsum() returns cumulative sum, shown :can used dataframe making new column. example, calculate cumulative number cases per day outbreak, consider code like :first 10 rows:See page [Epidemic curves] plot cumulative incidence epicurve.See also:cumsum(), cummean(), cummin(), cummax(), cumany(), cumall()","code":"\nsum(c(2,4,15,10))     # returns only one number## [1] 31\ncumsum(c(2,4,15,10))  # returns the cumulative sum at each step## [1]  2  6 21 31\ncumulative_case_counts <- linelist %>%  # begin with case linelist\n  count(date_onset) %>%                 # count of rows per day, as column 'n'   \n  mutate(cumulative_cases = cumsum(n))  # new column, of the cumulative sum at each row\nhead(cumulative_case_counts, 10)##    date_onset n cumulative_cases\n## 1  2012-04-15 1                1\n## 2  2012-05-05 1                2\n## 3  2012-05-08 1                3\n## 4  2012-05-31 1                4\n## 5  2012-06-02 1                5\n## 6  2012-06-07 1                6\n## 7  2012-06-14 1                7\n## 8  2012-06-21 1                8\n## 9  2012-06-24 1                9\n## 10 2012-06-25 1               10"},{"path":"cleaning.html","id":"using-base-r","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Using base R","text":"define new column (re-define column) using base R, write name data frame, connected $, new column (column modified). Use assignment operator <- define new value(s). Remember using base R must specify data frame name column name every time (e.g. dataframe$column). example creating bmi column using base R:","code":"linelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)"},{"path":"cleaning.html","id":"add-to-pipe-chain","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Add to pipe chain","text":", new column added pipe chain classes converted.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>% \n  \n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) "},{"path":"cleaning.html","id":"re-code-values","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.8 Re-code values","text":"scenarios need re-code (change) values:edit one specific value (e.g. one date incorrect year format)reconcile values spelled sameto create new column categorical valuesto create new column numeric categories (e.g. age categories)","code":""},{"path":"cleaning.html","id":"specific-values","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Specific values","text":"change values manually can use recode() function within mutate() function.Imagine nonsensical date data (e.g. “2014-14-15”): fix date manually raw source data, , write change cleaning pipeline via mutate() recode(). latter transparent reproducible anyone else seeking understand repeat analysis.mutate() line can read : “mutate column date_onset equal column date_onset re-coded OLD VALUE changed NEW VALUE”. Note pattern (OLD = NEW) recode() opposite R patterns (new = old). R development community working revising .another example re-coding multiple values within one column.linelist values column “hospital” must cleaned. several different spellings many missing values.recode() command re-defines column “hospital” current column “hospital”, specified recode changes. Don’t forget commas !Now see spellings hospital column corrected consolidated:TIP: number spaces equals sign matter. Make code easier read aligning = rows. Also, consider adding hashed comment row clarify future readers side OLD side NEW. TIP: Sometimes blank character value exists dataset (recognized R’s value missing - NA). can reference value two quotation marks space inbetween (\"\").","code":"\n# fix incorrect values                   # old value       # new value\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")  # print table of all unique values, including missing  ## \n##                      Central Hopital                     Central Hospital \n##                                   11                                  457 \n##                           Hospital A                           Hospital B \n##                                  290                                  289 \n##                     Military Hopital                    Military Hospital \n##                                   32                                  798 \n##                     Mitylira Hopital                    Mitylira Hospital \n##                                    1                                   79 \n##                                Other                         Port Hopital \n##                                  907                                   48 \n##                        Port Hospital St. Mark's Maternity Hospital (SMMH) \n##                                 1756                                  417 \n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \n##                                   11                                 1512\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                     # for reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \n##                     Central Hospital                           Hospital A \n##                                  468                                  290 \n##                           Hospital B                    Military Hospital \n##                                  289                                  910 \n##                                Other                        Port Hospital \n##                                  907                                 1804 \n## St. Mark's Maternity Hospital (SMMH)                                 <NA> \n##                                  428                                 1512"},{"path":"cleaning.html","id":"by-logic","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"By logic","text":"demonstrate re-code values column using logic conditions:Using replace(), ifelse() if_else() simple logicUsing case_when() complex logic","code":""},{"path":"cleaning.html","id":"simple-logic","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Simple logic","text":"","code":""},{"path":"cleaning.html","id":"replace","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"replace()","text":"re-code simple logical criteria, can use replace() within mutate(). replace() function base R. Use logic condition specify rows change . general syntax :mutate(col_to_change = replace(col_to_change, criteria rows, new value)).One common situation use replace() changing just one value one row, using unique row identifier. , gender changed “Female” row column case_id “2195”.equivalent command using base R syntax indexing brackets [ ] . reads “Change value dataframe linelist‘s column gender (rows linelist’s column case_id value ’2195’) ‘Female’”.","code":"\n# Example: change gender of one specific observation to \"Female\" \nlinelist <- linelist %>% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning.html","id":"ifelse-and-if_else","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"ifelse() and if_else()","text":"Another tool simple logic ifelse() partner if_else(). However, cases re-coding clear use case_when() (detailed ). “else” commands simplified versions else programming statement. general syntax :ifelse(condition, value return condition evaluates TRUE, value return condition evaluates FALSE), column source_known defined. value given row set “known” row’s value column source missing. value source missing, value source_known set “unknown”.if_else() special version dplyr handles dates. Note ‘true’ value date, ‘false’ value must also qualify date, hence using special value NA_real_ instead just NA.Avoid stringing together many ifelse commands… use case_when() instead! case_when() much easier read ’ll make fewer errors.Outside context data frame, want object used code switch value, consider using switch() base R.","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n# Create a date of death column, which is NA if patient has not died.\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning.html","id":"clean_case_when","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Complex logic","text":"Use dplyr’s case_when() re-coding many new groups, need use complex logic statements re-code values. function evaluates every row data frame, assess whether rows meets specified criteria, assigns correct new value.case_when() commands consist statements Right-Hand Side (RHS) Left-Hand Side (LHS) separated “tilde” ~. logic criteria left side pursuant values right side statement. Statements separated commas.example, utilize columns age age_unit create column age_years:row data evaluated, criteria applied/evaluated order case_when() statements written - top--bottom. top criteria evaluates TRUE given row, RHS value assigned, remaining criteria even tested row. Thus, best write specific criteria first, general last.Along lines, final statement, place TRUE left-side, capture row meet previous criteria. right-side statement assigned value like “check !” missing.DANGER: Vvalues right-side must class - either numeric, character, date, logical, etc. assign missing (NA), may need use special variations NA NA_character_, NA_real_ (numeric POSIX), .Date(NA). Read Working dates.","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # if age is given in years\n            age_unit == \"months\" ~ age/12,    # if age is given in months\n            is.na(age_unit)      ~ age,       # if age unit is missing, assume years\n            TRUE                 ~ NA_real_)) # any other circumstance, assign missing"},{"path":"cleaning.html","id":"missing-values","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Missing values","text":"special functions handling missing values context data cleaning.See page [Missing data] detailed tips identifying handling missing values. example, .na() function logically tests missingness.replace_na()change missing values (NA) specific value, “Missing”, use dplyr function replace_na() within mutate(). Note used manner recode - name variable must repeated within replace_na().fct_explicit_na()function forcats package. forcats package handles columns class Factor. Factors R’s way handle ordered values c(\"First\", \"Second\", \"Third\") set order values (e.g. hospitals) appear tables plots. See page [Factors].data class Factor try convert NA “Missing” using replace_na(), get error: invalid factor level, NA generated. tried add “Missing” value, defined possible level factor, rejected.easiest way solve use forcats function fct_explicit_na() converts column class factor, converts NA values character “(Missing)”.slower alternative add factor level using fct_expand() convert missing values.na_if()convert specific value NA, use dplyr’s na_if(). command performs opposite operation replace_na(). example , values “Missing” column hospital converted NA.Note: na_if() used logic criteria (e.g. “values > 99”) - use replace() case_when() :","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist %>% \n  mutate(hospital = fct_explicit_na(hospital))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# Convert temperatures above 40 to NA \nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\nlinelist <- linelist %>% \n  mutate(date_onset = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning.html","id":"cleaning-dictionary","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Cleaning dictionary","text":"Use R package linelist ’s function clean_variable_spelling() clean data frame cleaning dictionary. linelist package developed RECON - R Epidemics Consortium.Create cleaning dictionary 3 columns:\n“” column (incorrect value)\n“” column (correct value)\ncolumn specifying column changes applied (“.global” apply columns)\n“” column (incorrect value)“” column (correct value)column specifying column changes applied (“.global” apply columns)Note: .global dictionary entries overridden column-specific dictionary entries.Import dictionary file R. example can downloaded via instructions [Download handbook data] page.Pass raw linelist clean_variable_spelling(), specifying wordlists = cleaning dictionary data frame. spelling_vars = argument can used specify column dictionary refers columns (3rd default), can set NULL dictionary apply character factor columns. Note function can take long time run.Now scroll right see values changed - particularly gender (lowercase uppercase), symptoms columns transformed yes/1/0.Note column names cleaning dictionary must correspond names point cleaning script. See online reference linelist package details.","code":"\ncleaning_dict <- import(\"cleaning_dict.csv\")\nlinelist <- linelist %>% \n  linelist::clean_variable_spelling(\n    wordlists = cleaning_dict,\n    spelling_vars = \"col\",        # dict column containing column names, defaults to 3rd column in dict\n  )"},{"path":"cleaning.html","id":"add-to-pipe-chain-1","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Add to pipe chain","text":", new columns column transformations added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n   # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n   ###################################################\n\n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))"},{"path":"cleaning.html","id":"num_cats","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.9 Numeric categories","text":"describe special approaches creating categories numerical columns. Common examples include age categories, groups lab values, etc. discuss:age_categories(), epikit packagecut(), base Rcase_when()quantile breaks quantile() ntile()","code":""},{"path":"cleaning.html","id":"review-distribution","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Review distribution","text":"example create age_cat column using age_years column.First, examine distribution data, make appropriate cut-points. See page [ggplot basics].CAUTION: Sometimes, numeric variables import class “character”. occurs non-numeric characters values, example entry “2 months” age, (depending R locale settings) comma used decimals place (e.g. “4,5” mean four one half years)..","code":"\n#check the class of the linelist variable age\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.04   23.00   84.00     107"},{"path":"cleaning.html","id":"age_categories","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"age_categories()","text":"epikit package, can use age_categories() function easily categorize label numeric columns (note: function can applied non-age numeric variables ). bonum, output column automatically ordered factor.required inputs:numeric vector (column)breakers = argument - provide numeric vector break points new groupsFirst, simplest example:break values specify default lower bounds - , included “higher” group / groups “open” lower/left side. shown , can add 1 break value achieve groups open top/right.can adjust labels displayed separator =. default “-”can adjust top numbers handled, ceiling = arguemnt. set upper cut-set ceiling = TRUE. use, highest break value provided “ceiling” category “XX+” created. values highest break value (upper =, defined) categorized NA. example ceiling = TRUE, category XX+ values 70 (highest break value) assigned NA.Alternatively, instead breakers =, can provide lower =, upper =, =:lower = lowest number want considered - default 0upper = highest number want consideredby = number years groupsSee function’s Help page details (enter ?age_categories R console).","code":"\n# Simple example\n################\npacman::p_load(epikit)                    # load package\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(             # create new column\n      age_years,                            # numeric column to make groups from\n      breakers = c(0, 5, 10, 15, 20,        # break points\n                   30, 40, 50, 60, 70)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \n##  1227  1223  1048   827  1216   597   251    78    27     7   107\n# Include upper ends for the same categories\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \n##  1469  1195  1040   770  1149   547   231    70    24     6   107\n# With ceiling set to TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \n##  1227  1223  1048   827  1216   597   251    78    28   113\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  <NA> \n##  2450  1875  1216   597   251    78    27     6     1     0     0   107"},{"path":"cleaning.html","id":"cut","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"cut()","text":"cut() base R alternative age_categories(), think see age_categories() developed simplify process. notable differences age_categories() :need install/load another packageYou can specify whether groups open/closed right/leftYou must provide accurate labels yourselfIf want 0 included lowest group must specify thisThe basic syntax within cut() first provide numeric column cut (age_years), breaks argument, numeric vector c() break points. Using cut(), resulting column ordered factor.default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). opposite behavior age_categories() function. default labels use notation “(, B]”, means included B . Reverse behavior providing right = TRUE argument.Thus, default, “0” values excluded lowest group, categorized NA! “0” values infants coded age 0 careful! change , add argument include.lowest = TRUE “0” values included lowest group. automatically-generated label lowest category “[],B]”. Note include include.lowest = TRUE argument right = TRUE, extreme inclusion now apply highest break point value category, lowest.can provide vector customized labels using labels = argument. manually written, careful ensure accurate! Check work using cross-tabulation, described .example cut() applied age_years make new variable age_cat :Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 16-20).Re-labeling NA valuesYou may want assign NA values label “Missing”. new column class Factor (restricted values), simply mutate replace_na(), value rejected. Instead, use fct_explicit_na() forcats explained [Factors] page.Quickly make breaks labelsFor fast way make breaks label vectors, use something like . See [R basics] page references seq() rep().Read cut() Help page entering ?cut R console.","code":"\n# Create new variable, by cutting the numeric age variable\n# lower break is excluded but upper break is included in each category\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")## \n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \n##     1469     1195     1040      770     1149      778       94        6      107\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values##                     Categories\n## Numeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\n##   0                    136      0       0       0       0       0       0        0    0\n##   0.0833333333333333     1      0       0       0       0       0       0        0    0\n##   0.25                   2      0       0       0       0       0       0        0    0\n##   0.333333333333333      6      0       0       0       0       0       0        0    0\n##   0.416666666666667      1      0       0       0       0       0       0        0    0\n##   0.5                    6      0       0       0       0       0       0        0    0\n##   0.583333333333333      3      0       0       0       0       0       0        0    0\n##   0.666666666666667      3      0       0       0       0       0       0        0    0\n##   0.75                   3      0       0       0       0       0       0        0    0\n##   0.833333333333333      1      0       0       0       0       0       0        0    0\n##   0.916666666666667      1      0       0       0       0       0       0        0    0\n##   1                    275      0       0       0       0       0       0        0    0\n##   1.5                    2      0       0       0       0       0       0        0    0\n##   2                    308      0       0       0       0       0       0        0    0\n##   3                    246      0       0       0       0       0       0        0    0\n##   4                    233      0       0       0       0       0       0        0    0\n##   5                    242      0       0       0       0       0       0        0    0\n##   6                      0    241       0       0       0       0       0        0    0\n##   7                      0    256       0       0       0       0       0        0    0\n##   8                      0    239       0       0       0       0       0        0    0\n##   9                      0    245       0       0       0       0       0        0    0\n##   10                     0    214       0       0       0       0       0        0    0\n##   11                     0      0     220       0       0       0       0        0    0\n##   12                     0      0     224       0       0       0       0        0    0\n##   13                     0      0     191       0       0       0       0        0    0\n##   14                     0      0     199       0       0       0       0        0    0\n##   15                     0      0     206       0       0       0       0        0    0\n##   16                     0      0       0     186       0       0       0        0    0\n##   17                     0      0       0     164       0       0       0        0    0\n##   18                     0      0       0     141       0       0       0        0    0\n##   19                     0      0       0     130       0       0       0        0    0\n##   20                     0      0       0     149       0       0       0        0    0\n##   21                     0      0       0       0     158       0       0        0    0\n##   22                     0      0       0       0     149       0       0        0    0\n##   23                     0      0       0       0     125       0       0        0    0\n##   24                     0      0       0       0     144       0       0        0    0\n##   25                     0      0       0       0     107       0       0        0    0\n##   26                     0      0       0       0     100       0       0        0    0\n##   27                     0      0       0       0     117       0       0        0    0\n##   28                     0      0       0       0      85       0       0        0    0\n##   29                     0      0       0       0      82       0       0        0    0\n##   30                     0      0       0       0      82       0       0        0    0\n##   31                     0      0       0       0       0      68       0        0    0\n##   32                     0      0       0       0       0      84       0        0    0\n##   33                     0      0       0       0       0      78       0        0    0\n##   34                     0      0       0       0       0      58       0        0    0\n##   35                     0      0       0       0       0      58       0        0    0\n##   36                     0      0       0       0       0      33       0        0    0\n##   37                     0      0       0       0       0      46       0        0    0\n##   38                     0      0       0       0       0      45       0        0    0\n##   39                     0      0       0       0       0      45       0        0    0\n##   40                     0      0       0       0       0      32       0        0    0\n##   41                     0      0       0       0       0      34       0        0    0\n##   42                     0      0       0       0       0      26       0        0    0\n##   43                     0      0       0       0       0      31       0        0    0\n##   44                     0      0       0       0       0      24       0        0    0\n##   45                     0      0       0       0       0      27       0        0    0\n##   46                     0      0       0       0       0      25       0        0    0\n##   47                     0      0       0       0       0      16       0        0    0\n##   48                     0      0       0       0       0      21       0        0    0\n##   49                     0      0       0       0       0      15       0        0    0\n##   50                     0      0       0       0       0      12       0        0    0\n##   51                     0      0       0       0       0       0      13        0    0\n##   52                     0      0       0       0       0       0       7        0    0\n##   53                     0      0       0       0       0       0       4        0    0\n##   54                     0      0       0       0       0       0       6        0    0\n##   55                     0      0       0       0       0       0       9        0    0\n##   56                     0      0       0       0       0       0       7        0    0\n##   57                     0      0       0       0       0       0       9        0    0\n##   58                     0      0       0       0       0       0       6        0    0\n##   59                     0      0       0       0       0       0       5        0    0\n##   60                     0      0       0       0       0       0       4        0    0\n##   61                     0      0       0       0       0       0       2        0    0\n##   62                     0      0       0       0       0       0       1        0    0\n##   63                     0      0       0       0       0       0       5        0    0\n##   64                     0      0       0       0       0       0       1        0    0\n##   65                     0      0       0       0       0       0       5        0    0\n##   66                     0      0       0       0       0       0       3        0    0\n##   67                     0      0       0       0       0       0       2        0    0\n##   68                     0      0       0       0       0       0       1        0    0\n##   69                     0      0       0       0       0       0       3        0    0\n##   70                     0      0       0       0       0       0       1        0    0\n##   72                     0      0       0       0       0       0       0        1    0\n##   73                     0      0       0       0       0       0       0        3    0\n##   76                     0      0       0       0       0       0       0        1    0\n##   84                     0      0       0       0       0       0       0        1    0\n##   <NA>                   0      0       0       0       0       0       0        0  107\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # make missing values explicit\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n  )    \n\n# table to view counts\ntable(linelist$age_cat, useNA = \"always\")## \n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69 \n##        1227        1223        1048         827        1216         848         105 \n##      70-100 Missing age        <NA> \n##           7         107           0\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)"},{"path":"cleaning.html","id":"quantile-breaks","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Quantile breaks","text":"common understanding, “quantiles” “percentiles” typically refer value proportion values fall. example, 95th percentile ages linelist age 95% age fall.However common speech, “quartiles” “deciles” can also refer groups data equally divided 4, 10 groups (note one break point group).get quantile break points, can use quantile() stats package base R. provide numeric vector (e.g. column dataset) vector numeric probability values ranging 0 1.0. break points returned numeric vector. Explore details statistical methodologies entering ?quantile.input numeric vector missing values best set na.rm = TRUESet names = FALSE get un-named numeric vectorYou can use results quantile() break points age_categories() cut(). create new column deciles using cut() breaks defined using quantiles() age_years. , display results using tabyl() janitor can see percentages (see [Descriptive tables] page). Note exactly 10% group.","code":"\nquantile(linelist$age_years,               # specify numeric vector to work on\n  probs = c(0, .25, .50, .75, .90, .95),   # specify the percentiles you want\n  na.rm = TRUE)                            # ignore missing values ##  0% 25% 50% 75% 90% 95% \n##   0   6  13  23  33  41\nlinelist %>%                                # begin with linelist\n  mutate(deciles = cut(age_years,           # create new column decile as cut() on column age_years\n    breaks = quantile(                      # define cut breaks using quantile()\n      age_years,                               # operate on age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 to 1.0 by 0.1\n      na.rm = TRUE),                           # ignore missing values\n    include.lowest = TRUE)) %>%             # for cut() include age 0\n  janitor::tabyl(deciles)                   # pipe to table to display##  deciles   n    percent valid_percent\n##    [0,2] 748 0.11319613    0.11505922\n##    (2,5] 721 0.10911017    0.11090601\n##    (5,7] 497 0.07521186    0.07644978\n##   (7,10] 698 0.10562954    0.10736810\n##  (10,13] 635 0.09609564    0.09767728\n##  (13,17] 755 0.11425545    0.11613598\n##  (17,21] 578 0.08746973    0.08890940\n##  (21,26] 625 0.09458232    0.09613906\n##  (26,33] 596 0.09019370    0.09167820\n##  (33,84] 648 0.09806295    0.09967697\n##     <NA> 107 0.01619249            NA"},{"path":"cleaning.html","id":"evenly-sized-groups","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Evenly-sized groups","text":"Another tool make numeric groups dplyr function ntile(), attempts break data n evenly-sized groups - aware unlike quantile() value appear one group. Provide numeric vector number groups. values new column created just group “numbers” (e.g. 1 10), range values using cut().","code":"\n# make groups with ntile()\nntile_data <- linelist %>% \n  mutate(even_groups = ntile(age_years, 10))\n\n# make table of counts and proportions by group\nntile_table <- ntile_data %>% \n  janitor::tabyl(even_groups)\n  \n# attach min/max values to demonstrate ranges\nntile_ranges <- ntile_data %>% \n  group_by(even_groups) %>% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )## Warning in min(age_years, na.rm = T): no non-missing arguments to min; returning Inf## Warning in max(age_years, na.rm = T): no non-missing arguments to max; returning -Inf\n# combine and print - note that values are present in multiple groups\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")##  even_groups   n    percent valid_percent min  max\n##            1 651 0.09851695    0.10013844   0    2\n##            2 650 0.09836562    0.09998462   2    5\n##            3 650 0.09836562    0.09998462   5    7\n##            4 650 0.09836562    0.09998462   7   10\n##            5 650 0.09836562    0.09998462  10   13\n##            6 650 0.09836562    0.09998462  13   17\n##            7 650 0.09836562    0.09998462  17   21\n##            8 650 0.09836562    0.09998462  21   26\n##            9 650 0.09836562    0.09998462  26   33\n##           10 650 0.09836562    0.09998462  33   84\n##           NA 107 0.01619249            NA Inf -Inf"},{"path":"cleaning.html","id":"case_when","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"case_when()","text":"possible use dplyr function case_when() create categories numeric column, easier use age_categories() epikit cut() create ordered factor automatically.using case_when(), please review proper use described earlier Re-code values section page. Also aware right-hand side values must class. Thus, want NA right-side either write “Missing” use special NA value NA_character_.","code":""},{"path":"cleaning.html","id":"add-to-pipe-chain-2","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Add to pipe chain","text":", code create two categorical age columns added cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning.html","id":"add-rows","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.10 Add rows","text":"","code":""},{"path":"cleaning.html","id":"one-by-one","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"One-by-one","text":"Adding rows one--one manually tedious can done add_row() dplyr. Remember column must contain values one class (either character, numeric, logical, etc.). adding row requires nuance maintain .Use ... specify placement row want add. .= 3 put new row current 3rd row. default behavior add row end. Columns specified left empty (NA).new row number may look strange (“…23”) row numbers pre-existing rows changed. using command twice, examine/test insertion carefully.class provide see error like :(inserting row date value, remember wrap date function .Date() like .Date(\"2020-10-10\")).","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)Error: Can't combine ..1$infection date <date> and ..2$infection date <character>."},{"path":"cleaning.html","id":"bind-rows","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Bind rows","text":"combine datasets together binding rows one dataframe bottom another data frame, can use bind_rows() dplyr. explained detail page [Joining data].","code":""},{"path":"cleaning.html","id":"filter-rows","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.11 Filter rows","text":"typical cleaning step cleaned columns re-coded values filter data frame specific rows using dplyr verb filter().Within filter(), specify logic must TRUE row dataset kept. show filter rows based simple complex logical conditions.","code":""},{"path":"cleaning.html","id":"simple-filter","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Simple filter","text":"simple example re-defines dataframe linelist , filtered rows meet logical condition. rows logical statement within parentheses evaluates TRUE kept.example, logical statement gender == \"f\", asking whether value column gender equal “f” (case sensitive).filter applied, number rows linelist nrow(linelist).filter applied, number rows linelist linelist %>% filter(gender == \"f\") %>% nrow().","code":"\nlinelist <- linelist %>% \n  filter(gender == \"f\")   # keep only rows where gender is equal to \"f\""},{"path":"cleaning.html","id":"filter-out-missing-values","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Filter out missing values","text":"fairly common want filter rows missing values. Resist urge write filter(!.na(column) & !.na(column)) instead use tidyr function custom-built purpose: drop_na(). run empty parentheses, removes rows missing values. Alternatively, can provide names specific columns evaluated missingness, use “tidyselect” helper functions described .See page [Missing data] many techniques analyse manage missingness data.","code":"\nlinelist %>% \n  drop_na(case_id, age_years)  # drop rows with missing values for case_id or age_years"},{"path":"cleaning.html","id":"filter-by-row-number","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Filter by row number","text":"data frame tibble, row usually “row number” (seen R Viewer) appears left first column. true column data, can used filter() statement.filter based “row number”, can use dplyr function row_number() open parentheses part logical filtering statement. Often use %% operator range numbers part logical statement, shown . see first N rows, can also use special dplyr function head().can also convert row numbers true column piping data frame tibble function rownames_to_column() (put anything parentheses).","code":"\n# View first 100 rows\nlinelist %>% head(100)     # or use tail() to see the n last rows\n\n# Show row 5 only\nlinelist %>% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns\nlinelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)"},{"path":"cleaning.html","id":"complex-filter","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Complex filter","text":"complex logical statements can constructed using parentheses ( ), |, negate !, %%, & operators. example :Note: can use ! operator front logical criteria negate . example, !.na(column) evaluates true column value missing. Likewise !column %% c(\"\", \"b\", \"c\") evaluates true column value vector.","code":""},{"path":"cleaning.html","id":"examine-the-data","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Examine the data","text":"simple one-line command create histogram onset dates. See second smaller outbreak 2012-2013 also included raw dataset. analyses, want remove entries earlier outbreak.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning.html","id":"how-filters-handle-missing-numeric-and-date-values","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"How filters handle missing numeric and date values","text":"Can just filter date_onset rows June 2013? Caution! Applying code filter(date_onset > .Date(\"2013-06-01\"))) remove rows later epidemic missing date onset!DANGER: Filtering greater (>) less (<) date number can remove rows missing values (NA)! NA treated infinitely large small.(See page Working dates information working dates package lubridate)","code":""},{"path":"cleaning.html","id":"design-the-filter","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Design the filter","text":"Examine cross-tabulation make sure exclude correct rows:criteria can filter remove first outbreak (2012 & 2013) dataset? see :first epidemic 2012 & 2013 occurred Hospital , Hospital B, also 10 cases Port Hospital.Hospitals & B cases second epidemic, Port Hospital .want exclude:nrow(linelist %>% filter(hospital %% c(\"Hospital \", \"Hospital B\") | date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013 either hospital , B, Port:\nExclude nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013\nExclude nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows Hospitals & B missing onset dates\nexclude nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows missing onset dates.\nExclude nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) rows onset 2012 2013Exclude nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows Hospitals & B missing onset datesDo exclude nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) rows missing onset dates.start linelist nrow(linelist)`. filter statement:re-make cross-tabulation, see Hospitals & B removed completely, 10 Port Hospital cases 2012 & 2013 removed, values - just wanted.Multiple statements can included within one filter command (separated commas), can always pipe separate filter() command clarity.Note: readers may notice easier just filter date_hospitalisation 100% complete missing values. true. date_onset used purposes demonstrating complex filter.","code":"\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2012 2013 2014 2015 <NA>\n##   Central Hospital                        0    0  351   99   18\n##   Hospital A                            229   46    0    0   15\n##   Hospital B                            227   47    0    0   15\n##   Military Hospital                       0    0  676  200   34\n##   Missing                                 0    0 1117  318   77\n##   Other                                   0    0  684  177   46\n##   Port Hospital                           9    1 1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 6019\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2014 2015 <NA>\n##   Central Hospital                      351   99   18\n##   Military Hospital                     676  200   34\n##   Missing                              1117  318   77\n##   Other                                 684  177   46\n##   Port Hospital                        1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)  322   93   13\n##   <NA>                                    0    0    0"},{"path":"cleaning.html","id":"standalone-1","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Standalone","text":"Filtering can also done stand-alone command (part pipe chain). Like dplyr verbs, case first argument must dataset .can also use base R subset using square brackets reflect [rows, columns] want retain.","code":"\n# dataframe <- filter(dataframe, condition(s) for rows to keep)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning.html","id":"quickly-review-records","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Quickly review records","text":"Often want quickly review records, columns. base R function View() print data frame viewing RStudio.View linelist RStudio:two examples viewing specific cells (specific rows, specific columns):dplyr functions filter() select():Within View(), pipe dataset filter() keep certain rows, select() keep certain columns. example, review onset hospitalization dates 3 specific cases:can achieve base R syntax, using brackets [ ] subset want see.","code":"\nView(linelist)\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])"},{"path":"cleaning.html","id":"add-to-pipe-chain-3","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"Add to pipe chain","text":"","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning.html","id":"row-wise-calculations","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.12 Row-wise calculations","text":"want perform calculation within row, can use rowwise() dplyr. See online vignette row-wise calculations.\nexample, code applies rowwise() creates new column sums number specified symptom columns value “yes”, row linelist. columns specified within sum() name within vector c(). rowwise() essentially special kind group_by(), best use ungroup() done (page [Grouping data]).specify column evaluate, may want use “tidyselect” helper functions described select() section page. just make one adjustment (using within dplyr function like select() summarise()).Put column-specification criteria within dplyr function c_across(). c_across (documentation) designed work rowwise() specifically. example, following code:Applies rowwise() following operation (sum()) applied within row (summing entire columns)Creates new column num_NA_dates, defined row number columns (name containing “date”) .na() evaluated TRUE (missing data).ungroup() remove effects rowwise() subsequent stepsYou also provide functions, max() get latest recent date row:","code":"\nlinelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %>% \n  ungroup() %>% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # for display## # A tibble: 5,888 x 6\n##    fever chills cough aches vomit num_symptoms\n##    <chr> <chr>  <chr> <chr> <chr>        <int>\n##  1 no    no     yes   no    yes              2\n##  2 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  3 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  4 no    no     no    no    no               0\n##  5 no    no     yes   no    yes              2\n##  6 no    no     yes   no    yes              2\n##  7 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  8 no    no     yes   no    yes              2\n##  9 no    no     yes   no    yes              2\n## 10 no    no     yes   no    no               1\n## # ... with 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %>% \n  ungroup() %>% \n  select(num_NA_dates, contains(\"date\")) # for display## # A tibble: 5,888 x 5\n##    num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n##           <int> <date>         <date>     <date>               <date>      \n##  1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n##  2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n##  3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n##  4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n##  5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n## 10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n## # ... with 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %>% \n  ungroup() %>% \n  select(latest_date, contains(\"date\"))  # for display## # A tibble: 5,888 x 5\n##    latest_date date_infection date_onset date_hospitalisation date_outcome\n##    <date>      <date>         <date>     <date>               <date>      \n##  1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n##  2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n##  3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n##  4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n##  5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n## 10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n## # ... with 5,878 more rows"},{"path":"cleaning.html","id":"arrange-and-sort","chapter":"8 Làm sạch số liệu và các hàm quan trọng","heading":"8.13 Arrange and sort","text":"Use dplyr function arrange() sort order rows column values.Simple list columns order sorted . Specify .by_group = TRUE want sorting first occur groupings applied data (see page [Grouping data]).default, column sorted “ascending” order (applies numeric also character columns). can sort variable “descending” order wrapping desc().Sorting data arrange() particularly useful making [Tables presentation], using slice() take “top” rows per group, setting factor level order order appearance.example, sort linelist rows hospital, date_onset descending order, use:","code":"\nlinelist %>% \n   arrange(hospital, desc(date_onset))"},{"path":"dates.html","id":"dates","chapter":"9 Làm việc với ngày tháng","heading":"9 Làm việc với ngày tháng","text":"Working dates R requires attention working object classes. , offer tools example make process less painful. Luckily, dates can wrangled easily practice, set helpful packages lubridate.Upon import raw data, R often interprets dates character objects - means used general date operations making time series calculating time intervals. make matters difficult, many ways date can formatted must help R know part date represents (month, day, hour, etc.).Dates R class object - Date class. noted also class stores objects date time. Date time objects formally referred POSIXt, POSIXct, /POSIXlt classes (difference isn’t important). objects informally referred datetime classes.important make R recognize column contains dates.Dates object class can tricky work .present several ways convert date columns Date class.","code":""},{"path":"dates.html","id":"preparation","chapter":"9 Làm việc với ngày tháng","heading":"9.1 Preparation","text":"","code":""},{"path":"dates.html","id":"load-packages-1","chapter":"9 Làm việc với ngày tháng","heading":"Load packages","text":"code chunk shows loading packages required page. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\n# Checks if package is installed, installs if necessary, and loads package for current session\n\npacman::p_load(\n  lubridate,  # general package for handling and converting dates  \n  linelist,   # has function to \"guess\" messy dates\n  aweek,      # another option for converting dates to weeks, and weeks to dates\n  zoo,        # additional date/time functions\n  tidyverse,  # data management and visualization  \n  rio)        # data import/export"},{"path":"dates.html","id":"import-data-1","chapter":"9 Làm việc với ngày tháng","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow along step--step, see instruction [Download handbook data] page. assume file working directory sub-folders specified file path.","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"dates.html","id":"current-date","chapter":"9 Làm việc với ngày tháng","heading":"9.2 Current date","text":"can get current “system” date system datetime computer following base R.lubridate package can also returned today() now(), respectively. date() returns current date time weekday month names.","code":"\n# get the system date - this is a DATE class\nSys.Date()## [1] \"2021-07-12\"\n# get the system time - this is a DATETIME class\nSys.time()## [1] \"2021-07-12 21:35:28 CEST\""},{"path":"dates.html","id":"convert-to-date","chapter":"9 Làm việc với ngày tháng","heading":"9.3 Convert to Date","text":"importing dataset R, date column values may look like “1989/12/30”, “05/06/2014”, “13 Jan 2020”. cases, R likely still treating values Character values. R must told values dates… format date (part Day, Month, Year, etc).told, R converts values class Date. background, R store dates numbers (number days “origin” date 1 Jan 1970). interface date number often, allows R treat dates continuous variables allow special operations calculating distance dates.default, values class Date R displayed YYYY-MM-DD. Later section discuss change display date values.present two approaches converting column character values class Date.TIP: can check current class column base R function class(), like class(linelist$date_onset).","code":""},{"path":"dates.html","id":"base-r","chapter":"9 Làm việc với ngày tháng","heading":"base R","text":".Date() standard, base R function convert object column class Date (note capitalization “D”).Use .Date() requires :specify existing format raw character date origin date supplying dates numbers (see section Excel dates)used character column, date values must exact format (case, try guess_dates() linelist package)First, check class column class() base R. unsure confused class data (e.g. see “POSIXct”, etc.) can easiest first convert column class Character .character(), convert class Date.Second, within .Date() function, use format = argument tell R current format character date components - characters refer month, day, year, separated. values already one R’s standard date formats (“YYYY-MM-DD” “YYYY/MM/DD”) format = argument necessary.format =, provide character string (quotes) represents current date format using special “strptime” abbreviations . example, character dates currently format “DD/MM/YYYY”, like “24/04/1968”, use format = \"%d/%m/%Y\" convert values dates. Putting format quotation marks necessary. don’t forget slashes dashes!strptime abbreviations listed . can see complete list running ?strptime.%d = Day number month (5, 17, 28, etc.)\n%j = Day number year (Julian day 001-366)\n%= Abbreviated weekday (Mon, Tue, Wed, etc.)\n%= Full weekday (Monday, Tuesday, etc.)\n%w = Weekday number (0-6, Sunday 0)\n%u = Weekday number (1-7, Monday 1)\n%W = Week number (00-53, Monday week start)\n%U = Week number (01-53, Sunday week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds\n%z = offset GMT\n%Z = Time zone (character)TIP: format = argument .Date() telling R format want dates , rather identify date parts run command.TIP: sure format = argument use date-part separator (e.g. /, -, space) present dates.values class Date, R default display standard format, YYYY-MM-DD.","code":"\n# Convert to class date\nlinelist <- linelist %>% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))"},{"path":"dates.html","id":"lubridate","chapter":"9 Làm việc với ngày tháng","heading":"lubridate","text":"Converting character objects dates can made easier using lubridate package. tidyverse package designed make working dates times simple consistent base R. reasons, lubridate often considered gold-standard package dates time, recommended whenever working .lubridate package provides several different helper functions designed convert character objects dates intuitive, lenient way specifying format .Date(). functions specific rough date format, allow variety separators, synonyms dates (e.g. 01 vs Jan vs January) - named abbreviations date formats.ymd() function flexibly converts date values supplied year, month, day.mdy() function flexibly converts date values supplied month, day, year.dmy() function flexibly converts date values supplied day, month, year.using piping, conversion character column dates lubridate might look like :complete, can run class() verify class columnOnce values class Date, R default display standard format, YYYY-MM-DD.Note functions work best 4-digit years. 2-digit years can produce unexpected results, lubridate attempts guess century.convert 2-digit year 4-digit year (century) can convert class character combine existing digits pre-fix using str_glue() stringr package (see [Characters strings]). convert date.","code":"\n# install/load lubridate \npacman::p_load(lubridate)\n# read date in year-month-day format\nymd(\"2020-10-11\")## [1] \"2020-10-11\"\nymd(\"20201011\")## [1] \"2020-10-11\"\n# read date in month-day-year format\nmdy(\"10/11/2020\")## [1] \"2020-10-11\"\nmdy(\"Oct 11 20\")## [1] \"2020-10-11\"\n# read date in day-month-year format\ndmy(\"11 10 2020\")## [1] \"2020-10-11\"\ndmy(\"11 October 2020\")## [1] \"2020-10-11\"\nlinelist <- linelist %>%\n  mutate(date_onset = lubridate::dmy(date_onset))\n# Check the class of the column\nclass(linelist$date_onset)  \ntwo_digit_years <- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")## 2015\n## 2015\n## 2016\n## 2017"},{"path":"dates.html","id":"combine-columns","chapter":"9 Làm việc với ngày tháng","heading":"Combine columns","text":"can use lubridate functions make_date() make_datetime() combine multiple numeric columns one date column. example numeric columns onset_day, onset_month, onset_year data frame linelist:","code":"\nlinelist <- linelist %>% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))"},{"path":"dates.html","id":"excel-dates","chapter":"9 Làm việc với ngày tháng","heading":"9.4 Excel dates","text":"background, software store dates numbers. R stores dates origin 1st January, 1970. Thus, run .numeric(.Date(\"1970-01-01)) get 0.Microsoft Excel stores dates origin either December 30, 1899 (Windows) January 1, 1904 (Mac), depending operating system. See Microsoft guidance information.Excel dates often import R numeric values instead characters. dataset imported Excel shows dates numbers characters like “41369”… use .Date() (lubridate’s as_date() function) convert, instead supplying “format” , supply Excel origin date argument origin =.work Excel date stored R character type, sure ensure number class Numeric!NOTE: provide origin date R’s default date format (“YYYY-MM-DD”).","code":"\n# An example of providing the Excel 'origin date' when converting Excel number dates\ndata_cleaned <- data %>% \n  mutate(date_onset = as.numeric(date_onset)) %>%   # ensure class is numeric\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # convert to date using Excel origin"},{"path":"dates.html","id":"messy-dates","chapter":"9 Làm việc với ngày tháng","heading":"9.5 Messy dates","text":"function guess_dates() linelist package attempts read “messy” date column containing dates many different formats convert dates standard format. can read online guess_dates(). guess_dates() yet available CRAN R 4.0.2, try install via pacman::p_load_gh(\"reconhub/linelist\").example guess_dates see vector following character dates “03 Jan 2018”, “07/03/1982”, “08/20/85” convert class Date : 2018-01-03, 1982-03-07, 1985-08-20.optional arguments guess_dates() might include :error_tolerance - proportion entries identified dates tolerated (defaults 0.1 10%)last_date - last valid date (defaults current date)first_date - first valid date. Defaults fifty years last_date.","code":"\nlinelist::guess_dates(c(\"03 Jan 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))## [1] \"2018-01-03\" \"1982-03-07\" \"1985-08-20\"# An example using guess_dates on the column dater_onset\nlinelist <- linelist %>%                 # the dataset is called linelist\n  mutate(\n    date_onset = linelist::guess_dates(  # the guess_dates() from package \"linelist\"\n      date_onset,\n      error_tolerance = 0.1,\n      first_date = \"2016-01-01\"\n    )"},{"path":"dates.html","id":"working-with-date-time-class","chapter":"9 Làm việc với ngày tháng","heading":"9.6 Working with date-time class","text":"previously mentioned, R also supports datetime class - column contains date time information. Date class, often need converted character objects datetime objects.","code":""},{"path":"dates.html","id":"convert-dates-with-times","chapter":"9 Làm việc với ngày tháng","heading":"Convert dates with times","text":"standard datetime object formatted date first, followed time component - example 01 Jan 2020, 16:30. dates, many ways can formatted, numerous levels precision (hours, minutes, seconds) can supplied.Luckily, lubridate helper functions also exist help convert strings datetime objects. functions extensions date helper functions, _h (hours supplied), _hm (hours minutes supplied), _hms (hours, minutes, seconds supplied) appended end (e.g. dmy_hms()). can used shown:Convert datetime hours datetime objectConvert datetime hours minutes datetime objectConvert datetime hours, minutes, seconds datetime objectYou can supply time zone ignored. See section later page time zones.working data frame, time date columns can combined create datetime column using str_glue() stringr package appropriate lubridate function. See page [Characters strings] details stringr.example, linelist data frame column format “hours:minutes”. convert datetime follow steps:Create “clean” time admission column missing values filled-column median. lubridate won’t operate missing values. Combine column date_hospitalisation, use function ymd_hm() convert.","code":"\nymd_h(\"2020-01-01 16hrs\")## [1] \"2020-01-01 16:00:00 UTC\"\nymd_h(\"2020-01-01 4PM\")## [1] \"2020-01-01 16:00:00 UTC\"\ndmy_hm(\"01 January 2020 16:20\")## [1] \"2020-01-01 16:20:00 UTC\"\nmdy_hms(\"01 January 2020, 16:20:40\")## [1] \"2020-01-20 16:20:40 UTC\"\nmdy_hms(\"01 January 2020, 16:20:40 PST\")## [1] \"2020-01-20 16:20:40 UTC\"# packages\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission is a column in hours:minutes\nlinelist <- linelist %>%\n  \n  # when time of admission is not given, assign the median admission time\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # if time is missing\n      median(time_admission),        # assign the median\n      time_admission                 # if not missing keep as is\n  ) %>%\n  \n    # use str_glue() to combine date and time columns to create one character column\n    # and then use ymd_hm() to convert it to datetime\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %>% \n      ymd_hm()\n  )"},{"path":"dates.html","id":"convert-times-alone","chapter":"9 Làm việc với ngày tháng","heading":"Convert times alone","text":"data contain character time (hours minutes), can convert manipulate times using strptime() base R. example, get difference two times:Note however without date value provided, assumes date today. combine string date string time together see use stringr section just . Read strptime() .convert single-digit numbers double-digits (e.g. “pad” hours minutes leading zeros achieve 2 digits), see “Pad length” section Characters strings page.","code":"\n# raw character times\ntime1 <- \"13:45\" \ntime2 <- \"15:20\"\n\n# Times converted to a datetime class\ntime1_clean <- strptime(time1, format = \"%H:%M\")\ntime2_clean <- strptime(time2, format = \"%H:%M\")\n\n# Difference is of class \"difftime\" by default, here converted to numeric hours \nas.numeric(time2_clean - time1_clean)   # difference in hours## [1] 1.583333"},{"path":"dates.html","id":"extract-time","chapter":"9 Làm việc với ngày tháng","heading":"Extract time","text":"can extract elements time hour(), minute(), second() lubridate.example extracting hour, classifing part day. begin column time_admission, class Character format “HH:MM”. First, strptime() used described convert characters datetime class. , hour extracted hour(), returning number 0-24. Finally, column time_period created using logic case_when() classify rows Morning/Afternoon/Evening/Night based hour admission.learn case_when() see page [Cleaning data core functions].","code":"\nlinelist <- linelist %>%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %>%\n  mutate(time_period = case_when(\n    hour_admit > 06 & hour_admit < 12 ~ \"Morning\",\n    hour_admit >= 12 & hour_admit < 17 ~ \"Afternoon\",\n    hour_admit >= 17 & hour_admit < 21 ~ \"Evening\",\n    hour_admit >=21 | hour_admit <= 6 ~ \"Night\"))"},{"path":"dates.html","id":"working-with-dates","chapter":"9 Làm việc với ngày tháng","heading":"9.7 Working with dates","text":"lubridate can also used variety functions, extracting aspects date/datetime, performing date arithmetic, calculating date intervalsHere define date use examples:","code":"\n# create object of class Date\nexample_date <- ymd(\"2020-03-01\")"},{"path":"dates.html","id":"extract-date-components","chapter":"9 Làm việc với ngày tháng","heading":"Extract date components","text":"can extract common aspects month, day, weekday:can also extract time components datetime object column. can useful want view distribution admission times.several options retrieve weeks. See section Epidemiological weeks .Note seeking display date certain way (e.g. “Jan 2020” “Thursday 20 March” “Week 20, 1977”) can flexibly described section Date display.","code":"\nmonth(example_date)  # month number## [1] 3\nday(example_date)    # day (number) of the month## [1] 1\nwday(example_date)   # day number of the week (1-7)## [1] 1\nexample_datetime <- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime)     # extract hour\nminute(example_datetime)   # extract minute\nsecond(example_datetime)   # extract second"},{"path":"dates.html","id":"date-math","chapter":"9 Làm việc với ngày tháng","heading":"Date math","text":"can add certain numbers days weeks using respective function lubridate.","code":"\n# add 3 days to this date\nexample_date + days(3)## [1] \"2020-03-04\"\n# add 7 weeks and subtract two days from this date\nexample_date + weeks(7) - days(2)## [1] \"2020-04-17\""},{"path":"dates.html","id":"date-intervals","chapter":"9 Làm việc với ngày tháng","heading":"Date intervals","text":"difference dates can calculated :Ensure dates class dateUse subtraction return “difftime” difference two datesIf necessary, convert result numeric class perform subsequent mathematical calculationsBelow interval two dates calculated displayed. can find intervals using subtraction “minus” symbol values class Date. Note, however class returned value “difftime” displayed , must converted numeric.subsequent operations “difftime”, convert numeric .numeric().can brought together work data - example:data frame context, either dates missing, operation fail row. result NA instead numeric value. using column calculations, sure set na.rm = argument TRUE. example:","code":"\n# find the interval between this date and Feb 20 2020 \noutput <- example_date - ymd(\"2020-02-20\")\noutput    # print## Time difference of 10 days\nclass(output)## [1] \"difftime\"\npacman::p_load(lubridate, tidyverse)   # load packages\n\nlinelist <- linelist %>%\n  \n  # convert date of onset from character to date objects by specifying dmy format\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %>%\n  \n  # filter out all cases without onset in march\n  filter(month(date_onset) == 3) %>%\n    \n  # find the difference in days between onset and hospitalisation\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n# calculate the median number of days to hospitalisation for all cases where data are available\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)"},{"path":"dates.html","id":"date-display","chapter":"9 Làm việc với ngày tháng","heading":"9.8 Date display","text":"dates correct class, often want display differently, example display “Monday 05 January” instead “2018-01-05”. may also want adjust display order group rows date elements displayed - example group month-year.","code":""},{"path":"dates.html","id":"format","chapter":"9 Làm việc với ngày tháng","heading":"format()","text":"Adjust date display base R function format(). function accepts character string (quotes) specifying desired output format “%” strptime abbreviations (syntax used .Date()). common abbreviations.Note: using format() convert values class Character, generally used towards end analysis display purposes ! can see complete list running ?strptime.%d = Day number month (5, 17, 28, etc.)\n%j = Day number year (Julian day 001-366)\n%= Abbreviated weekday (Mon, Tue, Wed, etc.)\n%= Full weekday (Monday, Tuesday, etc.)\n%w = Weekday number (0-6, Sunday 0)\n%u = Weekday number (1-7, Monday 1)\n%W = Week number (00-53, Monday week start)\n%U = Week number (01-53, Sunday week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds\n%z = offset GMT\n%Z = Time zone (character)example formatting today’s date:Note using str_glue(), aware within expected double quotes \" use single quotes ().","code":"\n# today's date, with formatting\nformat(Sys.Date(), format = \"%d %B %Y\")## [1] \"12 July 2021\"\n# easy way to get full date and time (default formatting)\ndate()## [1] \"Mon Jul 12 21:35:30 2021\"\n# formatted combined date, time, and time zone using str_glue() function\nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z  %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")## Monday, July 12 2021, +0000  UTC, 21:35:30\n# Using format to display weeks\nformat(Sys.Date(), \"%Y Week %W\")## [1] \"2021 Week 28\""},{"path":"dates.html","id":"month-year","chapter":"9 Làm việc với ngày tháng","heading":"Month-Year","text":"convert Date column Month-year format, suggest use function .yearmon() zoo package. converts date class “yearmon” retains proper ordering. contrast, using format(column, \"%Y %B\") convert class Character order values alphabetically (incorrectly)., new column yearmonth created column date_onset, using .yearmon() function. default (correct) ordering resulting values shown table.contrast, can see using format() achieve desired display format, correct ordering.Note: working within ggplot() want adjust dates displayed , may sufficient provide strptime format date_labels = argument scale_x_date() - can use \"%b %Y\" \"%Y %b\". See [ggplot tips] page.zoo also offers function .yearqtr(), can use scale_x_yearmon() using ggplot().","code":"\n# create new column \ntest_zoo <- linelist %>% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# print table\ntable(test_zoo$yearmon)## \n## Apr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 Dec 2014 Jan 2015 \n##        7       64      100      226      528     1070     1112      763      562      431 \n## Feb 2015 Mar 2015 Apr 2015 \n##      306      277      186\n# create new column\ntest_format <- linelist %>% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# print table\ntable(test_format$yearmon)## \n## Apr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 Mar 2015 May 2014 \n##        7      186      528      562      306      431      226      100      277       64 \n## Nov 2014 Oct 2014 Sep 2014 \n##      763     1112     1070"},{"path":"dates.html","id":"dates_epi_wks","chapter":"9 Làm việc với ngày tháng","heading":"9.9 Epidemiological weeks","text":"","code":""},{"path":"dates.html","id":"lubridate-1","chapter":"9 Làm việc với ngày tháng","heading":"lubridate","text":"See page [Grouping data] extensive examples grouping data date. briefly describe grouping data weeks.generally recommend using floor_date() function lubridate, argument unit = \"week\". rounds date “start” week, defined argument week_start =. default week start 1 (Mondays) can specify day week start (e.g. 7 Sundays). floor_date() versitile can used round time units setting unit = “second”, “minute”, “hour”, “day”, “month”, “year”.returned value start date week, Date class. Date class useful plotting data, easily recognized ordered correctly ggplot().interested adjusting dates display week plot, see section page Date display. example plotting epicurve can format date display providing desired strptime “%” nomenclature. example, use “%Y-%W” “%Y-%U” return year week number (given Monday Sunday week start, respectively).","code":""},{"path":"dates.html","id":"weekly-counts","chapter":"9 Làm việc với ngày tháng","heading":"Weekly counts","text":"See page [Grouping data] thorough explanation grouping data count(), group_by(), summarise(). brief example .Create new ‘week’ column mutate(), using floor_date() unit = \"week\"Get counts rows (cases) per week count(); filter cases missing dateFinish complete() tidyr ensure weeks appear data - even rows/cases. default count values “new” rows NA, can make 0 fill = argument, expects named list (, n name counts column).first rows resulting data frame:","code":"\n# Make aggregated dataset of weekly case counts\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%             # remove cases missing onset date\n  mutate(weekly_cases = floor_date(   # make new column, week of onset\n    date_onset,\n    unit = \"week\")) %>%            \n  count(weekly_cases) %>%           # group data by week and count rows per group (creates column 'n')\n  tidyr::complete(                  # ensure all weeks are present, even those with no cases reported\n    weekly_cases = seq.Date(          # re-define the \"weekly_cases\" column as a complete sequence,\n      from = min(weekly_cases),       # from the minimum date\n      to = max(weekly_cases),         # to the maxiumum date\n      by = \"week\"),                   # by weeks\n    fill = list(n = 0))             # fill-in NAs in the n counts column with 0"},{"path":"dates.html","id":"epiweek-alternatives","chapter":"9 Làm việc với ngày tháng","heading":"Epiweek alternatives","text":"Note lubridate also functions week(), epiweek(), isoweek(), slightly different start dates nuances. Generally speaking though, floor_date() need. Read details functions entering ?week console reading documentation .might consider using package aweek set epidemiological weeks. can read RECON website. functions date2week() week2date() can set week start day week_start = \"Monday\". package easiest want “week”-style outputs (e.g. “2020-W12”). Another advantage aweek date2week() applied date column, returned column (week format) automatically class Factor includes levels weeks time span (avoids extra step complete() described ). However, aweek functionality round dates time units months, years, etc.Another alternative time series also works well show “week” format (“2020 W12”) yearweek() package tsibble, demonstrated page [Time series outbreak detection].","code":""},{"path":"dates.html","id":"converting-datestime-zones","chapter":"9 Làm việc với ngày tháng","heading":"9.10 Converting dates/time zones","text":"data present different time time zones, can often important standardise data unified time zone. can present challenge, time zone component data must coded manually cases.R, datetime object timezone component. default, datetime objects carry local time zone computer used - generally specific location rather named timezone, time zones often change locations due daylight savings time. possible accurately compensate time zones without time component date, event date column represents attributed specific time, therefore time shifts measured hours reasonably accounted .deal time zones, number helper functions lubridate can used change time zone datetime object local time zone different time zone. Time zones set attributing valid tz database time zone datetime object. list can found - location using data list, nearby large cities time zone available serve purpose.https://en.wikipedia.org/wiki/List_of_tz_database_time_zonesThis may seem largely abstract, often needed user isn’t working across time zones.","code":"\n# assign the current time to a column\ntime_now <- Sys.time()\ntime_now## [1] \"2021-07-12 21:35:31 CEST\"\n# use with_tz() to assign a new timezone to the column, while CHANGING the clock time\ntime_london_real <- with_tz(time_now, \"Europe/London\")\n\n# use force_tz() to assign a new timezone to the column, while KEEPING the clock time\ntime_london_local <- force_tz(time_now, \"Europe/London\")\n\n\n# note that as long as the computer that was used to run this code is NOT set to London time,\n# there will be a difference in the times \n# (the number of hours difference from the computers time zone to london)\ntime_london_real - time_london_local## Time difference of -1 hours"},{"path":"dates.html","id":"lagging-and-leading-calculations","chapter":"9 Làm việc với ngày tháng","heading":"9.11 Lagging and leading calculations","text":"lead() lag() functions dplyr package help find previous (lagged) subsequent (leading) values vector - typically numeric date vector. useful calculations change/difference time units.Let’s say want calculate difference cases current week previous one. data initially provided weekly counts shown .using lag() lead() order rows dataframe important! - pay attention whether dates/numbers ascending descendingFirst, create new column containing value previous (lagged) week.Control number units back/forward n = (must non-negative integer)Use default = define value placed non-existing rows (e.g. first row lagged value). default NA.Use order_by = TRUE rows ordered reference columnNext, create new column difference two cases columns:can read lead() lag() documentation entering ?lag console.","code":"\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)"},{"path":"dates.html","id":"resources","chapter":"9 Làm việc với ngày tháng","heading":"9.12 Resources","text":"lubridate tidyverse pagelubridate RStudio cheatsheet\nR Data Science page dates timesOnline tutorial\nDate formats","code":""},{"path":"characters-strings.html","id":"characters-strings","chapter":"10 Ký tự và chuỗi","heading":"10 Ký tự và chuỗi","text":"page demonstrates use stringr package evaluate handle character values (“strings”).Combine, order, split, arrange - str_c(), str_glue(), str_order(), str_split()Clean standardise\nAdjust length - str_pad(), str_trunc(), str_wrap()\nChange case - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()\nAdjust length - str_pad(), str_trunc(), str_wrap()Change case - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()Evaluate extract position - str_length(), str_sub(), word()Patterns\nDetect locate - str_detect(), str_subset(), str_match(), str_extract()\nModify replace - str_sub(), str_replace_all()\nDetect locate - str_detect(), str_subset(), str_match(), str_extract()Modify replace - str_sub(), str_replace_all()Regular expressions (“regex”)ease display examples shown acting short defined character vector, however can easily adapted column within data frame.stringr vignette provided much inspiration page.","code":""},{"path":"characters-strings.html","id":"preparation-1","chapter":"10 Ký tự và chuỗi","heading":"10.1 Preparation","text":"","code":""},{"path":"characters-strings.html","id":"load-packages-2","chapter":"10 Ký tự và chuỗi","heading":"Load packages","text":"Install load stringr tidyverse packages.","code":"\n# install/load packages\npacman::p_load(\n  stringr,    # many functions for handling strings\n  tidyverse,  # for optional data manipulation\n  tools)      # alternative for converting to title case"},{"path":"characters-strings.html","id":"import-data-2","chapter":"10 Ký tự và chuỗi","heading":"Import data","text":"page occassionally reference cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"characters-strings.html","id":"unite-split-and-arrange","chapter":"10 Ký tự và chuỗi","heading":"10.2 Unite, split, and arrange","text":"section covers:Using str_c(), str_glue(), unite() combine stringsUsing str_order() arrange stringsUsing str_split() separate() split strings","code":""},{"path":"characters-strings.html","id":"combine-strings","chapter":"10 Ký tự và chuỗi","heading":"Combine strings","text":"combine concatenate multiple strings one string, suggest using str_c stringr. distinct character values combine, simply provide unique arguments, separated commas.argument sep = inserts character value arguments provided (e.g. inserting comma, space, newline \"\\n\")argument collapse = relevant inputting multiple vectors arguments str_c(). used separate elements output vector, output vector one long character element.example shows combination two vectors one (first names last names). Another similar example might jurisdictions case counts. example:sep = value appears first last nameThe collapse = value appears personNote: Depending desired display context, printing combined string newlines, may need wrap whole phrase cat() newlines print properly:","code":"\nstr_c(\"String1\", \"String2\", \"String3\")## [1] \"String1String2String3\"\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")## [1] \"String1, String2, String3\"\nfirst_names <- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  <- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep displays between the respective input strings, while collapse displays between the elements produced\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")## [1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n# For newlines to print correctly, the phrase may need to be wrapped in cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))## abdul hussein;\n## fahruk akinleye;\n## janice okeke"},{"path":"characters-strings.html","id":"dynamic-strings","chapter":"10 Ký tự và chuỗi","heading":"Dynamic strings","text":"Use str_glue() insert dynamic R code string. useful function creating dynamic plot captions, demonstrated .content goes double quotation marks str_glue(\"\")dynamic code references pre-defined values placed within curly brackets {} within double quotation marks. can many curly brackets str_glue() command.display character quotes ’’, use single quotes within surrounding double quotes (e.g. providing date format - see example )Tip: can use \\n force new lineTip: use format() adjust date display, use Sys.Date() display current dateA simple example, dynamic plot caption:alternative format use placeholders within brackets define code separate arguments end str_glue() function, . can improve code readability text long.Pulling data frameSometimes, useful pull data data frame pasted together sequence. example data frame. use make summary statement jurisdictions new total case counts.Use str_glue_data(), specially made taking data data frame rows:Combine strings across rowsIf trying “roll-” values data frame column, e.g. combine values multiple rows just one row pasting together separator, see section [De-duplication] page “rolling-” values.Data frame one lineYou can make statement appear one line using str_c() (specifying data frame column names), providing sep = collapse = arguments.add pre-fix text “New Cases:” beginning statement wrapping separate str_c() (“New Cases:” within original str_c() appear multiple times).","code":"\nstr_glue(\"Data include {nrow(linelist)} cases and are current to {format(Sys.Date(), '%d %b %Y')}.\")## Data include 5888 cases and are current to 12 Jul 2021.\nstr_glue(\"Linelist as of {current_date}.\\nLast case hospitalized on {last_hospital}.\\n{n_missing_onset} cases are missing date of onset and not shown\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %>% filter(is.na(date_onset)))\n         )## Linelist as of 12 Jul 2021.\n## Last case hospitalized on 30 Apr 2015.\n## 256 cases are missing date of onset and not shown\n# make case data frame\ncase_table <- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\ncase_table %>% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")## Zone 1: 3 (40 total cases)\n## Zone 2: 0 (4 total cases)\n## Zone 3: 7 (25 total cases)\n## Zone 4: 0 (10 total cases)\n## Zone 5: 15 (103 total cases)\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")## [1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))## [1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\""},{"path":"characters-strings.html","id":"str_unite","chapter":"10 Ký tự và chuỗi","heading":"Unite columns","text":"Within data frame, bringing together character values multiple columns can achieved unite() tidyr. opposite separate().Provide name new united column. provide names columns wish unite.default, separator used united column underscore _, can changed sep = argument.remove = removes input columns data frame (TRUE default)na.rm = removes missing values uniting (FALSE default), define mini-data frame demonstrate :example data frame:, unite three symptom columns:","code":"\ndf <- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # patient 1\n                \"chills, aches, pains\",        # patient 2 \n                \"fever\",                       # patient 3\n                \"vomiting, diarrhoea\",         # patient 4\n                \"bleeding from gums, fever\",   # patient 5\n                \"rapid pulse, headache\"),      # patient 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\ndf_split <- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")## Warning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\ndf_split %>% \n  unite(\n    col = \"all_symptoms\",         # name of the new united column\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # columns to unite\n    sep = \", \",                   # separator to use in united column\n    remove = TRUE,                # if TRUE, removes input cols from the data frame\n    na.rm = TRUE                  # if TRUE, missing values are removed before uniting\n  )##   case_ID                all_symptoms outcome\n## 1       1     jaundice, fever, chills Recover\n## 2       2        chills, aches, pains   Death\n## 3       3                       fever   Death\n## 4       4         vomiting, diarrhoea Recover\n## 5       5 bleeding, from, gums, fever Recover\n## 6       6      rapid, pulse, headache Recover"},{"path":"characters-strings.html","id":"split","chapter":"10 Ký tự và chuỗi","heading":"Split","text":"split string based pattern, use str_split(). evaluates string(s) returns list character vectors consisting newly-split values.simple example evaluates one string splits three. default returns object class list one element (character vector) string initially provided. simplify = TRUE returns character matrix.example, one string provided, function returns list one element - character vector three values.output saved, can access nth split value bracket syntax. access specific value can use syntax like : the_returned_object[[1]][2], access second value first evaluated string (“fever”). See [R basics] page detail accessing elements.multiple strings provided str_split(), one element returned list.return “character matrix” instead, may useful creating data frame columns, set argument simplify = TRUE shown :can also adjust number splits create n = argument. example, restricts number splits 2. commas remain within second values.Note - outputs can achieved str_split_fixed(), give simplify argument, must instead designate number columns (n).","code":"\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\"\npt1_symptoms <- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extracts 2nd value from 1st (and only) element of the list## [1] \" fever\"\nsymptoms <- c(\"jaundice, fever, chills\",     # patient 1\n              \"chills, aches, pains\",        # patient 2 \n              \"fever\",                       # patient 3\n              \"vomiting, diarrhoea\",         # patient 4\n              \"bleeding from gums, fever\",   # patient 5\n              \"rapid pulse, headache\")       # patient 6\n\nstr_split(symptoms, \",\")                     # split each patient's symptoms## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\" \n## \n## [[2]]\n## [1] \"chills\" \" aches\" \" pains\"\n## \n## [[3]]\n## [1] \"fever\"\n## \n## [[4]]\n## [1] \"vomiting\"   \" diarrhoea\"\n## \n## [[5]]\n## [1] \"bleeding from gums\" \" fever\"            \n## \n## [[6]]\n## [1] \"rapid pulse\" \" headache\"\nstr_split(symptoms, \",\", simplify = TRUE)##      [,1]                 [,2]         [,3]     \n## [1,] \"jaundice\"           \" fever\"     \" chills\"\n## [2,] \"chills\"             \" aches\"     \" pains\" \n## [3,] \"fever\"              \"\"           \"\"       \n## [4,] \"vomiting\"           \" diarrhoea\" \"\"       \n## [5,] \"bleeding from gums\" \" fever\"     \"\"       \n## [6,] \"rapid pulse\"        \" headache\"  \"\"\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)##      [,1]                 [,2]            \n## [1,] \"jaundice\"           \" fever, chills\"\n## [2,] \"chills\"             \" aches, pains\" \n## [3,] \"fever\"              \"\"              \n## [4,] \"vomiting\"           \" diarrhoea\"    \n## [5,] \"bleeding from gums\" \" fever\"        \n## [6,] \"rapid pulse\"        \" headache\"\nstr_split_fixed(symptoms, \",\", n = 2)"},{"path":"characters-strings.html","id":"split-columns","chapter":"10 Ký tự và chuỗi","heading":"Split columns","text":"trying split data frame column, best use separate() function dplyr. used split one character column columns.Let’s say simple data frame df (defined united unite section) containing case_ID column, one character column many symptoms, one outcome column. goal separate symptoms column many columns - one containing one symptom.Assuming data piped separate(), first provide column separated. provide = vector c( ) containing new columns names, shown .sep = separator, can character, number (interpreted character position split )remove = FALSE default, removes input columnconvert = FALSE default, cause string “NA”s become NAextra = controls happens values created separation new columns named.\nextra = \"warn\" means see warning drop excess values (default)\nextra = \"drop\" means excess values dropped warning\nextra = \"merge\" split number new columns listed - setting preserve data\nextra = \"warn\" means see warning drop excess values (default)extra = \"drop\" means excess values dropped warningextra = \"merge\" split number new columns listed - setting preserve dataAn example extra = \"merge\" - data lost. Two new columns defined third symptoms left second new column:default extra = \"drop\" used , warning given third symptoms lost:CAUTION: provide enough values new columns, data may truncated.","code":"\n# third symptoms combined into second new column\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1          sym_2 outcome\n## 1       1           jaundice  fever, chills Recover\n## 2       2             chills   aches, pains   Death\n## 3       3              fever           <NA>   Death\n## 4       4           vomiting      diarrhoea Recover\n## 5       5 bleeding from gums          fever Recover\n## 6       6        rapid pulse       headache Recover\n# third symptoms are lost\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")## Warning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1      sym_2 outcome\n## 1       1           jaundice      fever Recover\n## 2       2             chills      aches   Death\n## 3       3              fever       <NA>   Death\n## 4       4           vomiting  diarrhoea Recover\n## 5       5 bleeding from gums      fever Recover\n## 6       6        rapid pulse   headache Recover"},{"path":"characters-strings.html","id":"arrange-alphabetically","chapter":"10 Ký tự và chuỗi","heading":"Arrange alphabetically","text":"Several strings can sorted alphabetical order. str_order() returns order, str_sort() returns strings order.use different alphabet, add argument locale =. See full list locales entering stringi::stri_locale_list() R console.","code":"\n# strings\nhealth_zones <- c(\"Alba\", \"Takota\", \"Delta\")\n\n# return the alphabetical order\nstr_order(health_zones)## [1] 1 3 2\n# return the strings in alphabetical order\nstr_sort(health_zones)## [1] \"Alba\"   \"Delta\"  \"Takota\""},{"path":"characters-strings.html","id":"base-r-functions","chapter":"10 Ký tự và chuỗi","heading":"base R functions","text":"common see base R functions paste() paste0(), concatenate vectors converting parts character. act similarly str_c() syntax arguably complicated - parentheses part separated comma. parts either character text (quotes) pre-defined code objects (quotes). example:sep = collapse = arguments can specified. paste() simply paste0() default sep = \" \" (one space).","code":"\nn_beds <- 10\nn_masks <- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")## [1] \"Regional hospital needs 10 beds and 20 masks.\""},{"path":"characters-strings.html","id":"clean-and-standardise","chapter":"10 Ký tự và chuỗi","heading":"10.3 Clean and standardise","text":"","code":""},{"path":"characters-strings.html","id":"change-case","chapter":"10 Ký tự và chuỗi","heading":"Change case","text":"Often one must alter case/capitalization string value, example names jursidictions. Use str_to_upper(), str_to_lower(), str_to_title(), stringr, shown :Using *base** R, can also achieved toupper(), tolower().Title caseTransforming string word capitalized can achieved str_to_title():Use toTitleCase() tools package achieve nuanced capitalization (words like “”, “”, “” capitalized).can also use str_to_sentence(), capitalizes first letter string.","code":"\nstr_to_upper(\"California\")## [1] \"CALIFORNIA\"\nstr_to_lower(\"California\")## [1] \"california\"\nstr_to_title(\"go to the US state of california \")## [1] \"Go To The Us State Of California \"\ntools::toTitleCase(\"This is the US state of california\")## [1] \"This is the US State of California\"\nstr_to_sentence(\"the patient must be transported\")## [1] \"The patient must be transported\""},{"path":"characters-strings.html","id":"str_pad","chapter":"10 Ký tự và chuỗi","heading":"Pad length","text":"Use str_pad() add characters string, minimum length. default spaces added, can also pad characters using pad = argument.example, pad numbers leading zeros (hours minutes), can pad number minimum length 2 pad = \"0\".","code":"\n# ICD codes of differing length\nICD_codes <- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# ICD codes padded to 7 characters on the right side\nstr_pad(ICD_codes, 7, \"right\")## [1] \"R10.13 \" \"R10.819\" \"R17    \"\n# Pad with periods instead of spaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")## [1] \"R10.13.\" \"R10.819\" \"R17....\"\n# Add leading zeros to two digits (e.g. for times minutes/hours)\nstr_pad(\"4\", 2, pad = \"0\") ## [1] \"04\"\n# example using a numeric column named \"hours\"\n# hours <- str_pad(hours, 2, pad = \"0\")"},{"path":"characters-strings.html","id":"truncate","chapter":"10 Ký tự và chuỗi","heading":"Truncate","text":"str_trunc() sets maximum length string. string exceeds length, truncated (shortened) ellipsis (…) included indicate string previously longer. Note ellipsis counted length. ellipsis characters can changed argument ellipsis =. optional side = argument specifies ellipsis appear within truncated string (“left”, “right”, “center”).","code":"\noriginal <- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")## [1] \"Symp...ing\""},{"path":"characters-strings.html","id":"standardize-length","chapter":"10 Ký tự và chuỗi","heading":"Standardize length","text":"Use str_trunc() set maximum length, use str_pad() expand short strings truncated length. example , 6 set maximum length (one value truncated), one short value padded achieve length 6.","code":"\n# ICD codes of differing length\nICD_codes   <- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# truncate to maximum length of 6\nICD_codes_2 <- str_trunc(ICD_codes, 6)\nICD_codes_2## [1] \"R10.13\" \"R10...\" \"R17\"\n# expand to minimum length of 6\nICD_codes_3 <- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3## [1] \"R10.13\" \"R10...\" \"R17   \""},{"path":"characters-strings.html","id":"remove-leadingtrailing-whitespace","chapter":"10 Ký tự và chuỗi","heading":"Remove leading/trailing whitespace","text":"Use str_trim() remove spaces, newlines (\\n) tabs (\\t) sides string input. Add \"right\" \"left\", \"\" command specify side trim (e.g. str_trim(x, \"right\").","code":"\n# ID numbers with excess spaces on right\nIDs <- c(\"provA_1852  \", # two excess spaces\n         \"provA_2345\",   # zero excess spaces\n         \"provA_9460 \")  # one excess space\n\n# IDs trimmed to remove excess spaces on right side only\nstr_trim(IDs)## [1] \"provA_1852\" \"provA_2345\" \"provA_9460\""},{"path":"characters-strings.html","id":"remove-repeated-whitespace-within","chapter":"10 Ký tự và chuỗi","heading":"Remove repeated whitespace within","text":"Use str_squish() remove repeated spaces appear inside string. example, convert double spaces single spaces. also removes spaces, newlines, tabs outside string like str_trim().Enter ?str_trim, ?str_pad R console see details.","code":"\n# original contains excess spaces within string\nstr_squish(\"  Pt requires   IV saline\\n\") ## [1] \"Pt requires IV saline\""},{"path":"characters-strings.html","id":"wrap-into-paragraphs","chapter":"10 Ký tự và chuỗi","heading":"Wrap into paragraphs","text":"Use str_wrap() wrap long unstructured text structured paragraph fixed line length. Provide ideal character length line, applies algorithm insert newlines (\\n) within paragraph, seen example .base function cat() can wrapped around command order print output, displaying new lines added.","code":"\npt_course <- \"Symptom onset 1/4/2020 vomiting chills fever. Pt saw traditional healer in home village on 2/4/2020. On 5/4/2020 pt symptoms worsened and was admitted to Lumta clinic. Sample was taken and pt was transported to regional hospital on 6/4/2020. Pt died at regional hospital on 7/4/2020.\"\n\nstr_wrap(pt_course, 40)## [1] \"Symptom onset 1/4/2020 vomiting chills\\nfever. Pt saw traditional healer in\\nhome village on 2/4/2020. On 5/4/2020\\npt symptoms worsened and was admitted\\nto Lumta clinic. Sample was taken and pt\\nwas transported to regional hospital on\\n6/4/2020. Pt died at regional hospital\\non 7/4/2020.\"\ncat(str_wrap(pt_course, 40))## Symptom onset 1/4/2020 vomiting chills\n## fever. Pt saw traditional healer in\n## home village on 2/4/2020. On 5/4/2020\n## pt symptoms worsened and was admitted\n## to Lumta clinic. Sample was taken and pt\n## was transported to regional hospital on\n## 6/4/2020. Pt died at regional hospital\n## on 7/4/2020."},{"path":"characters-strings.html","id":"handle-by-position","chapter":"10 Ký tự và chuỗi","heading":"10.4 Handle by position","text":"","code":""},{"path":"characters-strings.html","id":"extract-by-character-position","chapter":"10 Ký tự và chuỗi","heading":"Extract by character position","text":"Use str_sub() return part string. function takes three main arguments:character vector(s)start positionend positionA notes position numbers:position number positive, position counted starting left end string.position number negative, counted starting right end string.Position numbers inclusive.Positions extending beyond string truncated (removed).examples applied string “pneumonia”:","code":"\n# start and end third from left (3rd letter from left)\nstr_sub(\"pneumonia\", 3, 3)## [1] \"e\"\n# 0 is not present\nstr_sub(\"pneumonia\", 0, 0)## [1] \"\"\n# 6th from left, to the 1st from right\nstr_sub(\"pneumonia\", 6, -1)## [1] \"onia\"\n# 5th from right, to the 2nd from right\nstr_sub(\"pneumonia\", -5, -2)## [1] \"moni\"\n# 4th from left to a position outside the string\nstr_sub(\"pneumonia\", 4, 15)## [1] \"umonia\""},{"path":"characters-strings.html","id":"extract-by-word-position","chapter":"10 Ký tự và chuỗi","heading":"Extract by word position","text":"extract nth ‘word’, use word(), also stringr. Provide string(s), first word position extract, last word position extract.default, separator ‘words’ assumed space, unless otherwise indicated sep = (e.g. sep = \"_\" words separated underscores.","code":"\n# strings to evaluate\nchief_complaints <- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extract 1st to 3rd words of each string\nword(chief_complaints, start = 1, end = 3, sep = \" \")## [1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\""},{"path":"characters-strings.html","id":"replace-by-character-position","chapter":"10 Ký tự và chuỗi","heading":"Replace by character position","text":"str_sub() paired assignment operator (<-) can used modify part string:example applied multiple strings (e.g. column). Note expansion length “HIV”.","code":"\nword <- \"pneumonia\"\n\n# convert the third and fourth characters to X \nstr_sub(word, 3, 4) <- \"XX\"\n\n# print\nword## [1] \"pnXXmonia\"\nwords <- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convert the third and fourth characters to X \nstr_sub(words, 3, 4) <- \"XX\"\n\nwords## [1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\""},{"path":"characters-strings.html","id":"evaluate-length","chapter":"10 Ký tự và chuỗi","heading":"Evaluate length","text":"Alternatively, use nchar() base R","code":"\nstr_length(\"abc\")## [1] 3"},{"path":"characters-strings.html","id":"patterns","chapter":"10 Ký tự và chuỗi","heading":"10.5 Patterns","text":"Many stringr functions work detect, locate, extract, match, replace, split based specified pattern.","code":""},{"path":"characters-strings.html","id":"detect-a-pattern","chapter":"10 Ký tự và chuỗi","heading":"Detect a pattern","text":"Use str_detect() detect presence/absence pattern within string. First provide string vector search (string =), pattern look (pattern =). Note default search case sensitive!argument negate = can included set TRUE want know pattern present.ignore case/capitalization, wrap pattern within regex(), within regex() add argument ignore_case = TRUE (T shorthand).str_detect() applied character vector data frame column, return TRUE FALSE values.need count TRUEs, simply sum() output. counts number TRUE.search inclusive multiple terms, include separated bars (|) within pattern = argument, shown :need build long list search terms, can combine using str_c() sep = |, define character object, reference vector later succinctly. example includes possible occupation search terms front-line medical providers.command returns number occupations contain one search terms front-line medical providers (occupation_med_frontline):Base R string search functionsThe base function grepl() works similarly str_detect(), searches matches pattern returns logical vector. basic syntax grepl(pattern, strings_to_search, ignore.case = FALSE, ...). One advantage ignore.case argument easier write (need involve regex() function).Likewise, base functions sub() gsub() act similarly str_replace(). basic syntax : gsub(pattern, replacement, strings_to_search, ignore.case = FALSE). sub() replace first instance pattern, whereas gsub() replace instances pattern.","code":"\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")## [1] TRUE\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)## [1] FALSE\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))## [1] TRUE\n# a vector/column of occupations \noccupations <- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# Detect presence of pattern \"teach\" in each string - output is vector of TRUE/FALSE\nstr_detect(occupations, \"teach\")##  [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\nsum(str_detect(occupations, \"teach\"))## [1] 1\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))## [1] 3\n# search terms\noccupation_med_frontline <- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline## [1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))## [1] 2"},{"path":"characters-strings.html","id":"convert-commas-to-periods","chapter":"10 Ký tự và chuỗi","heading":"Convert commas to periods","text":"example using gsub() convert commas periods vector numbers. useful data come parts world United States Great Britain.inner gsub() acts first lengths converting periods space \"“. period character”.\" “escaped” two slashes actually signify period, “.” regex means “character”. , result (commas) passed outer gsub() commas replaced periods.","code":"\nlengths <- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # find commas     \n                replacement = \".\",            # replace with periods\n                x = gsub(\"\\\\.\", \"\", lengths)  # vector with other periods removed (periods escaped)\n                )\n           )                                  # convert outcome to numeric"},{"path":"characters-strings.html","id":"replace-all","chapter":"10 Ký tự và chuỗi","heading":"Replace all","text":"Use str_replace_all() “find replace” tool. First, provide strings evaluated string =, pattern replaced pattern =, replacement value replacement =. example replaces instances “dead” “deceased”. Note, case sensitive.Notes:replace pattern NA, use str_replace_na().function str_replace() replaces first instance pattern within evaluated string.","code":"\noutcome <- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")## [1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\""},{"path":"characters-strings.html","id":"detect-within-logic","chapter":"10 Ký tự và chuỗi","heading":"Detect within logic","text":"Within case_when()str_detect() often used within case_when() (dplyr). Let’s say occupations column linelist. mutate() creates new column called is_educator using conditional logic via case_when(). See page data cleaning learn case_when().reminder, may important add exclusion criteria conditional logic (negate = F):","code":"\ndf <- df %>% \n  mutate(is_educator = case_when(\n    # term search within occupation, not case sensitive\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # all others\n    TRUE                                               ~ \"Not an educator\"))df <- df %>% \n  # value in new column is_educator is based on conditional logic\n  mutate(is_educator = case_when(\n    \n    # occupation column must meet 2 criteria to be assigned \"Educator\":\n    # it must have a search term AND NOT any exclusion term\n    \n    # Must have a search term\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \n    \n    # AND must NOT have an exclusion term\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # All rows not meeting above criteria\n    TRUE                                            ~ \"Not an educator\"))"},{"path":"characters-strings.html","id":"locate-pattern-position","chapter":"10 Ký tự và chuỗi","heading":"Locate pattern position","text":"locate first position pattern, use str_locate(). outputs start end position.Like str functions, \"_all\" version (str_locate_all()) return positions instances pattern within string. outputs list.","code":"\nstr_locate(\"I wish\", \"sh\")##      start end\n## [1,]     5   6\nphrases <- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" )     # position of *first* instance of the pattern##      start end\n## [1,]     6   6\n## [2,]     3   3\n## [3,]     1   1\n## [4,]     4   4\nstr_locate_all(phrases, \"h\" ) # position of *every* instance of the pattern## [[1]]\n##      start end\n## [1,]     6   6\n## \n## [[2]]\n##      start end\n## [1,]     3   3\n## \n## [[3]]\n##      start end\n## [1,]     1   1\n## [2,]     4   4\n## \n## [[4]]\n##      start end\n## [1,]     4   4"},{"path":"characters-strings.html","id":"extract-a-match","chapter":"10 Ký tự và chuỗi","heading":"Extract a match","text":"str_extract_all() returns matching patterns , useful offered several patterns via “” conditions. example, looking string vector occupations (see previous tab) either “teach”, “prof”, “tutor”.str_extract_all() returns list contains matches evaluated string. See occupation 3 two pattern matches within .str_extract() extracts first match evaluated string, producing character vector one element evaluated string. returns NA match. NAs can removed wrapping returned vector na.exclude(). Note second occupation 3’s matches shown.","code":"\nstr_extract_all(occupations, \"teach|prof|tutor\")## [[1]]\n## character(0)\n## \n## [[2]]\n## [1] \"prof\"\n## \n## [[3]]\n## [1] \"teach\" \"tutor\"\n## \n## [[4]]\n## [1] \"tutor\"\n## \n## [[5]]\n## character(0)\n## \n## [[6]]\n## character(0)\n## \n## [[7]]\n## character(0)\n## \n## [[8]]\n## character(0)\n## \n## [[9]]\n## character(0)\n## \n## [[10]]\n## character(0)\nstr_extract(occupations, \"teach|prof|tutor\")##  [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA      NA"},{"path":"characters-strings.html","id":"subset-and-count","chapter":"10 Ký tự và chuỗi","heading":"Subset and count","text":"Aligned functions include str_subset() str_count().str_subset() returns actual values contained pattern:str_count() returns vector numbers: number times search term appears evaluated value.","code":"\nstr_subset(occupations, \"teach|prof|tutor\")## [1] \"university professor\"           \"primary school teacher & tutor\"\n## [3] \"tutor\"\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))##  [1] 0 1 2 1 0 0 0 0 0 0"},{"path":"characters-strings.html","id":"regex-groups","chapter":"10 Ký tự và chuỗi","heading":"Regex groups","text":"CONSTRUCTION","code":""},{"path":"characters-strings.html","id":"special-characters","chapter":"10 Ký tự và chuỗi","heading":"10.6 Special characters","text":"Backslash \\ escapeThe backslash \\ used “escape” meaning next character. way, backslash can used quote mark display within quote marks (\\\") - middle quote mark “break” surrounding quote marks.Note - thus, want display backslash, must escape ’s meaning another backslash. must write two backslashes \\\\ display one.Special charactersRun ?\"'\" R Console display complete list special characters (appear RStudio Help pane).","code":""},{"path":"characters-strings.html","id":"regular-expressions-regex","chapter":"10 Ký tự và chuỗi","heading":"10.7 Regular expressions (regex)","text":"","code":""},{"path":"characters-strings.html","id":"regex-and-special-characters","chapter":"10 Ký tự và chuỗi","heading":"10.8 Regex and special characters","text":"Regular expressions, “regex”, concise language describing patterns strings. familiar , regular expression can look like alien language. try de-mystify language little bit.Much section adapted tutorial cheatsheet. selectively adapt knowing handbook might viewed people without internet access view tutorials.regular expression often applied extract specific patterns “unstructured” text - example medical notes, chief complaints, patient history, free text columns data frameThere four basic tools one can use create basic regular expression:Character setsMeta charactersQuantifiersGroupsCharacter setsCharacter sets, way expressing listing options character match, within brackets. match triggered characters within brackets found string. example, look vowels one use character set: “[aeiou]”. common character sets :Character sets can combined within one bracket (spaces!), \"[-Za-z]\" (upper lowercase letter), another example \"[t-z0-5]\" (lowercase t z number 0 5).Meta charactersMeta characters shorthand character sets. important ones listed :QuantifiersTypically want search match one character. Quantifiers allow designate length letters/numbers allow match.Quantifiers numbers written within curly brackets { } character quantifying, example,\"{2}\" return instances two capital letters.\"{2,4}\" return instances two four capital letters (put spaces!).\"{2,}\" return instances two capital letters.\"+\" return instances one capital letters (group extended different character encountered).Precede * asterisk return zero matches (useful sure pattern present)Using + plus symbol quantifier, match occur different character encountered. example, expression return words (alpha characters: \"[-Za-z]+\"quantifier {2} used, pairs consecutive ’s returned. Two pairs identified within AAAA.quantifier {2,4} used, groups consecutive ’s two four length returned.quantifier +, groups one returned:Relative positionThese express requirements precedes follows pattern. example, extract sentences, “two numbers followed period” (\"\"). (?<=\\.)\\s(?=[-Z])GroupsCapturing groups regular expression way organized output upon extraction.Regex examplesBelow free text examples. try extract useful information using regular expression search term.expression matches words (character hitting non-character space):expression \"[0-9]{1,2}\" matches consecutive numbers 1 2 digits length. also written \"\\\\d{1,2}\", \"[:digit:]{1,2}\".can view useful list regex expressions tips page 2 cheatsheetAlso see tutorial.","code":"\n# test string for quantifiers\ntest <- \"A-AA-AAA-AAAA\"\nstr_extract_all(test, \"A{2}\")## [[1]]\n## [1] \"AA\" \"AA\" \"AA\" \"AA\"\nstr_extract_all(test, \"A{2,4}\")## [[1]]\n## [1] \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"A+\")## [[1]]\n## [1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"\")## [[1]]\n##  [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\npt_note <- \"Patient arrived at Broward Hospital emergency ward at 18:00 on 6/12/2005. Patient presented with radiating abdominal pain from LR quadrant. Patient skin was pale, cool, and clammy. Patient temperature was 99.8 degrees farinheit. Patient pulse rate was 100 bpm and thready. Respiratory rate was 29 per minute.\"\nstr_extract_all(pt_note, \"[A-Za-z]+\")## [[1]]\n##  [1] \"Patient\"     \"arrived\"     \"at\"          \"Broward\"     \"Hospital\"    \"emergency\"  \n##  [7] \"ward\"        \"at\"          \"on\"          \"Patient\"     \"presented\"   \"with\"       \n## [13] \"radiating\"   \"abdominal\"   \"pain\"        \"from\"        \"LR\"          \"quadrant\"   \n## [19] \"Patient\"     \"skin\"        \"was\"         \"pale\"        \"cool\"        \"and\"        \n## [25] \"clammy\"      \"Patient\"     \"temperature\" \"was\"         \"degrees\"     \"farinheit\"  \n## [31] \"Patient\"     \"pulse\"       \"rate\"        \"was\"         \"bpm\"         \"and\"        \n## [37] \"thready\"     \"Respiratory\" \"rate\"        \"was\"         \"per\"         \"minute\"\nstr_extract_all(pt_note, \"[0-9]{1,2}\")## [[1]]\n##  [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\""},{"path":"characters-strings.html","id":"resources-1","chapter":"10 Ký tự và chuỗi","heading":"10.9 Resources","text":"reference sheet stringr functions can found hereA vignette stringr can found ","code":""},{"path":"factors.html","id":"factors","chapter":"11 Factors/","heading":"11 Factors/","text":"Trong R, factors là một kiểu dữ liệu cho phép sắp xếp các danh mục với một tập hợp các giá trị có thể chấp nhận.Thông thường, bạn sẽ chuyển đổi một cột từ dạng ký tự hoặc dạng số thành dạng factor khi bạn muốn sắp xếp một thứ đặc biệt cho các giá trị (“levels”) để chúng không hiển thị mặc định theo thứ tự bảng chữ cái trong các biểu đồ và bảng. Một cách sử dụng phổ biến khác của factor là chuẩn hóa các chú thích của biểu đồ để chúng không thay đổi nếu một giá trị tạm thời không có trong dữ liệu.Chương này giới thiệu cách sử dụng các hàm từ package forcats (tên viết tắt của “categorical variables”) và một số hàm base R. Chúng tôi cũng đề cập đến việc sử dụng lubridate và aweek cho các trường hợp factor đặc biệt liên quan đến tuần dịch tễ học.Bạn có thể tìm thấy danh sách đầy đủ các hàm của package forcats trực tuyến tại đường link này. Sau đây, chúng tôi sẽ chỉ trình bày một số hàm phổ biến nhất.","code":""},{"path":"factors.html","id":"chuẩn-bị","chapter":"11 Factors/","heading":"11.1 Chuẩn bị","text":"","code":""},{"path":"factors.html","id":"gọi-packages","chapter":"11 Factors/","heading":"Gọi packages","text":"Đoạn code dưới đây hiển thị cách gọi các package cần thiết cho việc phân tích. Trong sách này, chúng tôi nhấn mạnh đến việc sử dụng hàm p_load() từ package pacman, giúp cài đặt package nếu nó chưa được cài và gọi nó ra cho phiên làm việc. Bạn cũng có thể gọi các package đã được cài đặt bằng hàm library() từ base R. Xem chương R cơ bản để biết thêm thông tin về các package trong R.","code":"\npacman::p_load(\n  rio,           # import/export\n  here,          # filepaths\n  lubridate,     # working with dates\n  forcats,       # factors\n  aweek,         # create epiweeks with automatic factor levels\n  janitor,       # tables\n  tidyverse      # data mgmt and viz\n  )"},{"path":"factors.html","id":"nhập-dữ-liệu-1","chapter":"11 Factors/","heading":"Nhập dữ liệu","text":"Chúng ta sẽ nhập bộ dữ liệu về các trường hợp từ một vụ dịch Ebola mô phỏng. Để tiện muốn theo dõi, bấm để tải bộ dữ liệu linelist “đã được làm sạch” (.rds file). Nhập dữ liệu bằng hàm import() từ package rio (hàm có thể áp dụng với nhiều loại dữ liệu như .xlsx, .rds, .csv - Xem chương Nhập xuất dữ liệu để biết thêm chi tiết).","code":"\n# import your dataset\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"factors.html","id":"fct_newcat","chapter":"11 Factors/","heading":"Thêm biến danh mục mới","text":"Trong chương này, chúng tôi sẽ minh họa một trường hợp thường gặp, đó là tạo ra một biến danh mục mới.Lưu ý rằng khi bạn chuyển đổi một cột dạng số thành dạng factor, bạn sẽ không thể thực hiện các tính toán thống kê đối với dữ liệu dạng số trên cột đó nữa.","code":""},{"path":"factors.html","id":"tạo-biến","chapter":"11 Factors/","heading":"Tạo biến","text":"Chúng ta sẽ sử dụng một biến có sẵn, tên là days_onset_hosp (số ngày, tính từ khi bắt đầu có triệu chứng cho đến khi nhập viện) và tạo một biến mới có tên delay_cat bằng cách phân loại các giá trị trong mỗi hàng của biến có sẵn đó thành một số nhóm khác nhau. Chúng ta sẽ thực hiện việc này bằng hàm case_when() trong package dplyr, hàm này sẽ giúp áp dụng tuần tự các tiêu chí logic (phía bên phải) cho mỗi giá trị của biễn có sẵn và trả về giá trị bên trái tương ứng ở biến mới delay_cat. Đọc thêm về case_when() tại chương Làm sạch số liệu và các hàm quan trọng.","code":"\nlinelist <- linelist %>% \n  mutate(delay_cat = case_when(\n    # criteria                                   # new value if TRUE\n    days_onset_hosp < 2                        ~ \"<2 days\",\n    days_onset_hosp >= 2 & days_onset_hosp < 5 ~ \"2-5 days\",\n    days_onset_hosp >= 5                       ~ \">5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  "},{"path":"factors.html","id":"thứ-tự-mặc-định-của-các-giá-trị","chapter":"11 Factors/","heading":"Thứ tự mặc định của các giá trị","text":"Khi sử dụng hàm case_when(), biến mới delay_cat tạo ra sẽ là một biến danh mục với kiêu dữ liệu là ký tự - chưa phải là một factor. đó, trong bảng tần suất dưới đây, chúng ta thấy rằng các giá trị xuất hiện theo thứ tự mặc định của bảng chữ cái, điều này không có nhiều ý nghĩa trực quan:Tương tự như vậy, nếu chúng ta tạo biểu đồ cột, các giá trị cũng xuất hiện theo thứ tự này trên trục x (xem chương ggplot cơ bản để hiểu thêm về package ggplot2 - package giúp trực quan hóa dữ liệu phổ biến nhất trong R).","code":"\ntable(linelist$delay_cat, useNA = \"always\")## \n##  <2 days  >5 days 2-5 days     <NA> \n##     2990      602     2040      256\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"chuyển-đổi-sang-factor","chapter":"11 Factors/","heading":"11.2 Chuyển đổi sang factor","text":"Để chuyển đổi một biến dạng ký tự hoặc dạng số sang dạng factor, bạn có thể sử dụng bất kỳ hàm nào trong package forcats (nhiều hàm được nêu chi tiết tại mục dưới đây). Các biến sẽ chuyển đổi sang dạng factor và sau đó cũng thực hiện hoặc sắp xếp theo một thứ tự nhất định của các levels - ví dụ: hàm fct_relevel() cho phép bạn chỉ định thứ tự levels theo cách thủ công. Hàm as_factor() chỉ đơn giản là chuyển đổi biến sang dạng factor mà không có thêm bất kỳ chức năng nào khác.Hàm factor() trong base R chuyển đổi một biến thành factor và cho phép bạn tự sắp xếp thứ tự của các nhóm giá trị, dưới dạng một vectơ ký tự của đối số levels =.Dưới đây, chúng tôi sử dụng hàm mutate() và hàm fct_relevel() để chuyển đối biến có sẵn delay_cat từ dạng ký tự sang dạng factor. Biến delay_cat đã được tạo ở phần Chuẩn bị bên trên.Các “giá trị” duy nhất trong biến số được gọi là các “thứ bậc” của biến factor. Các thứ bậc này được sắp xếp theo một trật tự nhất định và có thể được ra bằng hàm levels() từ base R, hoặc bạn có thể xem nó bằng một bảng đếm thông qua hàm table()từ base R, hoặc hàm tabyl() từ package janitor. Trật tự này sẽ được hiển thị theo thứ tự của bảng chữ cái. Lưu ý rằng NA không được xem là một thứ bậc trong factor.Hàm fct_relevel() có thêm chức năng cho phép bạn có thể tự sắp xếp trật tự của các thứ bậc trong factor. Đơn giản, bạn chỉ cần viết các thứ bậc theo thứ tự bạn muốn, để chúng trong dấu ngoặc kép, được phân tách bằng dấu phẩy, như được hiển thị bên dưới. Lưu ý rằng chính tả phải khớp chính xác với tên các thứ bậc. Nếu bạn muốn tạo các thứ bậc không tồn tại trong dữ liệu, hãy sử dụng hàm fct_expand() nhé.Bây giờ chúng ta có thể thấy rằng các thứ bậc đã được sắp xếp theo một thứ tự hợp lý.Bây giờ trật tự các cột trong biểu đồ cũng trực quan hơn.","code":"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \">5 days\"  \"2-5 days\"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", \"2-5 days\", \">5 days\"))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"thêm-hoặc-xóa-thứ-bậc","chapter":"11 Factors/","heading":"11.3 Thêm hoặc xóa thứ bậc","text":"","code":""},{"path":"factors.html","id":"fct_add","chapter":"11 Factors/","heading":"Thêm thứ bậc","text":"Nếu bạn cần thêm thứ bâc trong factor, bạn có thể sử dụng hàm fct_expand(). Bạn chỉ cần viết tên biến và theo sau là tên các thứ bậc mới (phân tách bằng dấu phẩy). Bằng cách lập bảng, chúng ta có thể thấy các thứ bậc mới xuất hiện và chưa nhận giá trị nào. Bạn có thể sử dụng hàm table() trong base R, hoặc hàm tabyl() trong package janitor:Lưu ý: Package forcats có thể dễ dàng thêm các giá trị missing (NA) như là một thứ bậc. Bạn có thể xem thêm tại mục Giá trị Missing dưới đây.","code":"\nlinelist %>% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %>% \n  tabyl(delay_cat)   # print table##                       delay_cat    n    percent valid_percent\n##                         <2 days 2990 0.50781250     0.5308949\n##                        2-5 days 2040 0.34646739     0.3622159\n##                         >5 days  602 0.10224185     0.1068892\n##        Not admitted to hospital    0 0.00000000     0.0000000\n##  Transfer to other jurisdiction    0 0.00000000     0.0000000\n##                            <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"xóa-thứ-bậc","chapter":"11 Factors/","heading":"Xóa thứ bậc","text":"Nếu bạn sử dụng hàm fct_drop(), các thứ bậc “không được sử dụng” và không có quan sát nào sẽ bị loại bỏ khỏi factors. Thứ bậc mà chúng ta đã thêm ở trên (“admitted hospital”) có tổn tại nhưng không có biến số nào. Vì vậy, chúng sẽ bị loại bỏ khỏi biến factor của chúng ta bằng cách sử dụng hàm fct_drop() như sau:","code":"\nlinelist %>% \n  mutate(delay_cat = fct_drop(delay_cat)) %>% \n  tabyl(delay_cat)##  delay_cat    n    percent valid_percent\n##    <2 days 2990 0.50781250     0.5308949\n##   2-5 days 2040 0.34646739     0.3622159\n##    >5 days  602 0.10224185     0.1068892\n##       <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"fct_adjust","chapter":"11 Factors/","heading":"11.4 Thay đổi trật tự của các thứ bậc","text":"Package forcats cung cấp các hàm hữu ích để dễ dàng thay đổi trật tự của các thứ bậc trong một biến kiểu factor (sau khi một biến số được định nghĩa là một factor):Các hàm trong package này có thể được áp dụng cho biến dạng factor trong hai trường hợp dưới đây:Đối với cột trong một data frame, thông thường, việc thay đổi sẽ được giữ nguyên cho các lần sử dụng dữ liệu tiếp theoTrong một biểu đồ, sự thay đổi trật tự chỉ được áp dụng cho biểu đồ đó","code":""},{"path":"factors.html","id":"thay-đổi-thủ-công","chapter":"11 Factors/","heading":"Thay đổi thủ công","text":"Hàm này được sử dụng để thay đổi trật tự của các thứ bậc trong một biến dạng factor theo cách thủ công. Nếu hàm này được sử dụng trên một biến dạng khác, không phải factor, hàm sẽ giúp chuyển biến đó sang dạng factor trước.Trong dấu ngoặc đơn trước tiên điền tên của biến factor, sau đó điền:Tất cả các thứ bậc trong biến factor mà bạn mong muốn thay đổi trật tự (dưới dạng vector ký tự c()), hoặcChỉ một giá trị thứ bậc với vị trí tương ứng mong muốn, sử dụng đối số =Dưới đây là một ví dụ về chuyển biến delay_cat thành dạng factor (mặc dù biến này đã ở dạng Factor rồi) và sắp xếp lại các thứ bậc theo thứ tự mong muốn.Nếu bạn chỉ muốn chỉ định vị trí cho một thứ bậc, bạn có thể dùng hàm fct_relevel() và sử dụng đối số = để chỉ định một giá trị thứ bậc với vị trí tương ứng mong muốn. Ví dụ: lệnh dưới đây chuyển thứ bậc “<2 days” sang vị trí thứ hai:","code":"\n# re-define level order\nlinelist <- linelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\")))\n# re-define level order\nlinelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", after = 1)) %>% \n  tabyl(delay_cat)"},{"path":"factors.html","id":"đối-với-biểu-đồ","chapter":"11 Factors/","heading":"Đối với biểu đồ","text":"Các lệnh trong package forcats có thể được sử dụng để thay đổi trật tự của biến trong data frame hoặc trong biểu đồ. Bằng cách sử dụng các lệnh để “gói” tên biến vào trong các lệnh vẽ biểu đồ của package ggplot(), bạn có thể dảo ngược/thay đổi một trật tự có sẵn của biến. Sự thay đổi này chỉ áp dụng trong biểu đồ đang vẽ.Dưới đây, hai biểu đồ đều được vẽ bởi hàm ggplot() (xem thêm tại chương ggplot cơ bản). Trong biểu đồ đầu tiên, biến delay_cat được vẽ trên trục x của biểu đồ với thứ tự các thứ bậc là mặc định trong dữ liệu linelist. Trong biểu đồ thứ hai, biến được đặt trong bởi hàm fct_relevel() và trật tự của các thứ bậc đã được sắp xếp lại.Lưu ý rằng, ở biểu đồ thứ hai, tiêu đề mặc định của trục x được hiện khá phức tạp - bạn có thể sử tiêu đề này bằng đối số labs() trong ggplot2.","code":"\n# Alpha-numeric default order - no adjustment within ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# Factor level order adjusted within ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\"))))"},{"path":"factors.html","id":"đảo-ngược-thứ-tự","chapter":"11 Factors/","heading":"Đảo ngược thứ tự","text":"Bạn sẽ thường xuyên cần đảo ngược trật tự của các thứ bậc trong một biến. Đơn giản, bạn chỉ cần thêm tên biến vào bên trong hàm fct_rev().Lưu ý rằng, nếu bạn chỉ muốn đảo ngược thứ tự trong một biểu đồ chứ không phải thứ tự của biến đó, bạn có thể thực hiện điều đó với hàm guides() (Xem thêm tại chương Các tips với ggplot).","code":""},{"path":"factors.html","id":"theo-tần-suất","chapter":"11 Factors/","heading":"Theo tần suất","text":"Để sắp xếp trật tự các thứ bậc theo tần suất mà nó xuất hiện trong dữ liệu, hãy sử dụng hàm fct_infreq(). Tất cả các giá trị mising (NA) sẽ tự động được đưa xuống cuối, trừ khi chúng được chuyển sang một thứ bậc khác (xem thêm ở mục này). Bạn có thể đảo ngược trật tự bằng cách thêm hàm fct_rev() vào câu lệnh.Hàm này có thể được sử dụng trong ggplot(), như hình bên dưới.","code":"\n# ordered by frequency\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# reversed frequency\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")"},{"path":"factors.html","id":"theo-sự-xuất-hiện","chapter":"11 Factors/","heading":"Theo sự xuất hiện","text":"Sử dụng hàm fct_inorder() để thiết lập thứ bậc tương tự với thứ tự xuất hiện của các giá trị trong dữ liệu, bắt đầu từ hàng đầu tiên. Điều này có thể hữu ích nếu trước đó bạn đã cẩn thận sắp xếp dữ liệu trong data frame bằng hàm arrange(), sau đó sử dụng điều này để đặt trật tự các thứ bậc của biến facror.","code":""},{"path":"factors.html","id":"theo-thống-kê-tóm-tắt-của-một-cột-khác","chapter":"11 Factors/","heading":"Theo thống kê tóm tắt của một cột khác","text":"Bạn có thể sử dụng hàm fct_reorder() để sắp xếp các thứ bậc của một biến theo thống kê tóm tắt của một biến khác. Về mặt trực quan, điều này có cho kết quả là các biểu đồ như ý bạn, có các cột/điểm lên hoặc xuống theo một chiều trong toàn bộ biểu đồ.Trong các ví dụ bên dưới, trục x là delay_cat, và trục y là ct_blood (giá trị ngưỡng chu kỳ). Biểu đồ Box plots hiển thị phân bố của giá trị CT theo nhóm delay_cat. Chúng ta cần sắp xếp các box theo thứ tự tăng dần của giá trị trung vị CT của nhóm.Trong ví dụ đầu tiên bên dưới, các thứ bậc được sắp xếp một cách mặc định. Bạn có thể thấy các chiều cao của box bị lộn xộn và không theo bất kỳ thứ tự cụ thể nào. Trong ví dụ thứ hai, cột delay_cat (được sắp xếp theo trục x) đã được viết lệnh với hàm fct_reorder(), cột ct_blood được đưa ra làm đối số thứ hai và “trung vị” được đưa ra làm đối số thứ ba (bạn cũng có thể sử dụng “max”, “mean”, “min”, v.v.). đó, thứ tự các thứ bậc của biến delay_cat bây giờ sẽ phản ánh các giá trị trung vị CT tăng dần theo nhóm delay_cat. Điều này được trình bày trong biểu đồ thứ hai - các box đã được sắp xếp lại theo chiều tăng dần. Lưu ý biến missing NA sẽ luôn xuất hiện ở cuối, trừ khi được chuyển đổi thành một thứ bậc khác.Lưu ý trong ví dụ bên trên không có bước nào được yêu cầu cần thực hiện trước khi gọi hàm ggplot() - việc nhóm và tính toán đều được thực hiện bên trong hàm ggplot.","code":"\n# boxplots ordered by original factor levels\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by original alpha-numeric levels\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# boxplots ordered by median CT value\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by median CT value in group\")+\n  theme_classic()+\n  theme(legend.position = \"none\")"},{"path":"factors.html","id":"theo-giá-trị-cuối","chapter":"11 Factors/","heading":"Theo giá trị cuối","text":"Sử dụng hàm fct_reorder2() cho biểu đồ đường theo nhóm. Hàm sẽ sắp xếp thứ tự xuất hiện các nhóm (bao gồm cả phần chú giải) dọc theo biểu đồ. Nói về mặt kỹ thuật, nó “sắp xếp theo các giá trị y tương ứng với các giá trị x lớn nhất.”Ví dụ, nếu bạn có các dòng hiển thị số lượng trường hợp theo bệnh viện và thời gian, bạn có thể áp dụng hàm fct_reorder2() cho đối số color = trong aes(), sao cho thứ tự của các bệnh viện xuất hiện trong phần chú giải tương đương với thứ tự xuất hiện của các đường trong biểu đồ. Đọc thêm trong tài liệu trực tuyến sau đây.","code":"\nepidemic_data <- linelist %>%         # begin with the linelist   \n    filter(date_onset < as.Date(\"2014-09-21\")) %>%    # cut-off date, for visual clarity\n    count(                                            # get case counts per week and by hospital\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # start plot\n  geom_line(                                        # make lines\n    aes(\n      x = epiweek,                                  # x-axis epiweek\n      y = n,                                        # height is number of cases per week\n      color = fct_reorder2(hospital, epiweek, n)))+ # data grouped and colored by hospital, with factor order by height at end of plot\n  labs(title = \"Factor levels (and legend display) by line height at end of plot\",\n       color = \"Hospital\")                          # change legend title"},{"path":"factors.html","id":"fct_missing","chapter":"11 Factors/","heading":"11.5 Giá trị Missing","text":"Nếu có giá trị missing NA trong biến factor của bạn, bạn có thể dễ dàng chuyển đổi chúng thành một thứ bậc được đặt tên với hàm fct_explicit_na(). Giá trị missing NA được chuyển đổi thành “(Missing)” mặc định sẽ được xếp cuối cùng. Bạn có thể điều chỉnh tên thứ bậc bằng đối số na_level =.Ví dụ dưới đây được thực hiện trên biến delay_cat và một bảng được bằngtabyl()với các giá trị missing NA được chuyển thành “Missing delay”.","code":"\nlinelist %>% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %>% \n  tabyl(delay_cat)##      delay_cat    n    percent\n##       2-5 days 2040 0.34646739\n##        <2 days 2990 0.50781250\n##        >5 days  602 0.10224185\n##  Missing delay  256 0.04347826"},{"path":"factors.html","id":"kết-hợp-các-thứ-bậc-trong-biến-factor","chapter":"11 Factors/","heading":"11.6 Kết hợp các thứ bậc trong biến factor","text":"","code":""},{"path":"factors.html","id":"kết-hợp-thủ-công","chapter":"11 Factors/","heading":"Kết hợp thủ công","text":"Bạn có thể điều chỉnh cách hiển thị của các thứ bậc theo cách thủ công với hàm fct_recode(). Điều này giống như hàm recode() trong package dplyr (xem thêm tại chương Làm sạch số liệu và các hàm quan trọng), nhưng nó cho phép tạo các thứ bậc mới trong factor. Nếu bạn đơn giản chỉ sử dụng hàm recode() trên một factor, các giá trị được mã hóa mới sẽ bị từ chối trừ khi chúng đã được đặt ở thứ bậc cho phép.Công cụ này cũng có thể được sử dụng để “kết hợp” các thứ bậc trong factor, bằng cách gán cho nhiều thứ bậc cùng một giá trị được mã hóa lại. Bạn cần cẩn thận để không bị mất thông tin! Cân nhắc thực hiện các bước kết hợp này trong một biến mới (không ghi đè lên biến hiện tại).Hàm fct_recode() có cú pháp khác với hàm recode(). Hàm recode() sử dụng câu lệnh OLD = NEW, trong khi hàm fct_recode() sửu dụng câu lệnh NEW = OLD.Những thứ bậc sẵn có của biến delay_cat như sau:Để tạo một thứ bậc mới, bạn sử dụng câu lệnh sau fct_recode(column, \"new\" = \"old\", \"new\" = \"old\", \"new\" = \"old\") và ra như sau:Ở đây các thứ bậc cũ được kết hợp theo cách thủ công với fct_recode(). Lưu ý rằng không có lỗi phát sinh khi tạo thứ bậc mới “Less tham 5 days”.","code":"\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"<2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 2 days 2990 0.50781250     0.5308949\n##       2 to 5 days 2040 0.34646739     0.3622159\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"<2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 5 days 5030 0.85427989     0.8931108\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"rút-gọn-thành-other","chapter":"11 Factors/","heading":"Rút gọn thành “Other”","text":"Bạn có thể sử dụng hàm fct_other() để gán các thứ bậc của factor theo cách thủ công cho thứ bậc “”. Dưới đây, tất cả các thứ bậc trong biến hospital, ngoại trừ “Port Hospital” và “Central Hospital”, được gộp chung thành “”. Bạn có thể cung cấp một vectơ để giữ keep =, hoặc loại bỏ drop =. Bạn có thể thay đổi cách hiển thị của thứ bậc “” bằng hàm other_level =.","code":"\nlinelist %>%    \n  mutate(hospital = fct_other(                      # adjust levels\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # keep these separate\n    other_level = \"Other Hospital\")) %>%            # All others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table##          hospital    n    percent\n##  Central Hospital  454 0.07710598\n##     Port Hospital 1762 0.29925272\n##    Other Hospital 3672 0.62364130"},{"path":"factors.html","id":"rút-gọn-theo-tần-suất","chapter":"11 Factors/","heading":"Rút gọn theo tần suất","text":"Bạn có thể tự động kết hợp các thứ bậc trong biến factor có tần suất ít nhất bằng cách sử dụng hàm fct_lump().Để “gộp” nhiều giá trị tần suất thấp lại thành một nhóm khác “”, hãy thực hiện một trong các thao tác sau:Đặt n = là số nhóm bạn muốn giữ. n thứ bậc có tần suất nhiều nhất sẽ được giữ nguyên và tất cả các cấp độ khác sẽ kết hợp thành nhóm “”.Đặt prop = là ngưỡng tỷ lệ cho các thứ bậc bạn muốn giữ ở trên. Tất cả các giá trị khác sẽ kết hợp thành nhóm “”.Bạn có thể thay đổi cách hiển thị của thứ bậc “” bằng hàm other_level =. Dưới đây, tất cả các giá trị ngoài hai bệnh viện phổ biến nhất đều được kết hợp thành nhóm “Hospital”.","code":"\nlinelist %>%    \n  mutate(hospital = fct_lump(                      # adjust levels\n    hospital,\n    n = 2,                                          # keep top 2 levels\n    other_level = \"Other Hospital\")) %>%            # all others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table##        hospital    n   percent\n##         Missing 1469 0.2494905\n##   Port Hospital 1762 0.2992527\n##  Other Hospital 2657 0.4512568"},{"path":"factors.html","id":"hiển-thị-tất-cả-thứ-bậc","chapter":"11 Factors/","heading":"11.7 Hiển thị tất cả thứ bậc","text":"Một lợi ích của việc sử dụng factors là chuẩn hóa sự xuất hiện của các chú thích trong biểu đồ và bảng, bất kể giá trị nào thực sự có trong tập dữ liệu.Nếu bạn đang chuẩn bị nhiều bảng biểu (ví dụ: cho nhiều khu vực pháp lý), bạn sẽ muốn các chú giải và bảng xuất hiện giống hệt nhau ngay cả với các mức độ hoàn thành dữ liệu hoặc thành phần dữ liệu khác nhau.","code":""},{"path":"factors.html","id":"trong-biểu-đồ","chapter":"11 Factors/","heading":"Trong biểu đồ","text":"Trong hàm vẽ biểu đồ ggplot (), chỉ cần thêm đối số drop = FALSE trong hàm liên quan scale_xxxx(). Tất cả các thứ bậc trong biến factor sẽ được hiển thị, bất kể chúng có trong dữ liệu hay không. Nếu các thứ bậc trong biến factor của bạn được hiển thị bằng cách sử dụng fill =, thì trong scale_fill_discrete (), bạn cần thêm drop = FALSE, như được trình bày bên dưới. Nếu các thứ bậc trong biến factor của bạn được hiển thị với x = (đến trục x) color = hoặc size =, bạn sẽ cung cấp chúng tới scale_color_discrete() hoặc scale_size_discrete().Ví dụ này là một biểu đồ cột chồng của nhóm tuổi, theo bệnh viện. Việc thêm scale_fill_discrete (drop = FALSE) đảm bảo rằng tất cả các nhóm tuổi đều xuất hiện trong chú giải, ngay cả khi không có trong dữ liệu.","code":"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+                        # show all age groups in the legend, even those not present\n  labs(\n    title = \"All age groups will appear in legend, even if not present in data\")"},{"path":"factors.html","id":"trong-bảng","chapter":"11 Factors/","heading":"Trong bảng","text":"Cả hàm table() trong base R và hàm tabyl() trong package janitor đều sẽ hiển thị tất cả các thứ bậc trong factor (ngay cả các thứ bậc không sử dụng).Nếu bạn sử dụng hàm count() hoặc summarise() từ package dplyr để tạo bảng, hãy thêm đối số .drop = FALSE để hiển thị số lượng cho tất cả các thứ bậc trong factor ngay cả các thứ bậc không sử dụng.Đọc thêm tại chương Bảng mô tả,hoặc tại các link sau scale_discrete documentation, hoặc count() documentation. Bạn có thể tìm các ví dụ khác tại chương Truy vết tiếp xúc.","code":""},{"path":"factors.html","id":"tuần-dịch-tễ","chapter":"11 Factors/","heading":"11.8 Tuần dịch tễ","text":"Vui lòng xem phần thảo luận đầy đủ về cách tạo các tuần dịch tễ trong chương Nhóm dữ liệu.\nVui lòng xem chương Làm việc với ngày tháng để biết các mẹo về cách tạo và định dạng các tuần dịch tễ học.","code":""},{"path":"factors.html","id":"tuần-dịch-tễ-trong-biểu-đồ","chapter":"11 Factors/","heading":"Tuần dịch tễ trong biểu đồ","text":"Nếu mục tiêu của bạn là tạo các tuần dịch tễ học để hiển thị trong một biểu đồ, bạn có thể thực hiện việc này đơn giản với hàm floor_date() trong package lubridate, như được giải thích trong chương Nhóm dữ liệu. Các giá trị trả về sẽ thuộc loại Ngày tháng với định dạng YYYY-MM-DD. Nếu bạn sử dụng cột này trong một biểu đồ, ngày tháng sẽ tự nhiên được sắp xếp chính xác và bạn không cần phải lo lắng về thứ bậc hoặc chuyển đổi sang dạng factor. Xem biểu đồ histogram trong hàm ggplot() về các ngày khởi phát bên dưới.Trong cách tiếp cận này, bạn có thể điều chỉnh việc hiển thị của ngày tháng trên trục với scale_x_date(). Xem thêm tại trang Đường cong dịch bệnh để biết thêm thông tin. Bạn có thể chỉ định định dạng hiển thị date_labels = cho đối số scale_x_date(). Sử dụng “% Y” để đại diện cho năm có 4 chữ số và “% W” hoặc “% U” để đại diện cho số tuần (các tuần thứ Hai hoặc Chủ Nhật tương ứng).","code":"\nlinelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %>%  # create week column\n  ggplot()+                                                  # begin ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histogram of date of onset\n  scale_x_date(date_labels = \"%Y-W%W\")                       # adjust disply of dates to be YYYY-WWw"},{"path":"factors.html","id":"tuần-dịch-tễ-trong-dữ-liệu","chapter":"11 Factors/","heading":"Tuần dịch tễ trong dữ liệu","text":"Tuy nhiên, nếu mục đích của bạn với biến factor không phải để lập biểu đồ, bạn có thể tiếp cận theo một trong hai cách:Để kiểm soát tốt việc hiển thị, hãy chuyển đổi cột lubridate tuần dịch tễ (YYYY-MM-DD) sang định dạng hiển thị mong muốn (YYYY-WWw) trong chính data frame, rồi chuyển đổi nó thành dạng factor.Đầu tiên, sử dụng hàm format() từ base R để chuyển đổi hiển thị ngày từ hiển thị YYYY-MM-DD sang hiển thị YYYY-Www (xem thêm tại chương Làm việc với ngày tháng). Trong quá trình này, kiểu của biến số sẽ được chuyển đổi thành ký tự. Sau đó, chuyển đổi từ kiểu ký tự sang kiểu Factor với hàm factor().**Nguy hiểm:_** Nếu bạn đặt các tuần trước các năm (“Www-YYYY”) (“%W-%Y”), thứ tự các thứ bậc sẽ sắp xếp mặc định theo bảng chữ cái và điều này là không chính xác (ví dụ: 01-2015 sẽ là trước 35-2014). Bạn có thể cần phải điều chỉnh thứ tự theo cách thủ công, đây sẽ là một quá trình dài khó khăn .Để hiển thị nhanh theo mặc định, sử dụng hàm date2week() trong package aweek. Bạn có thể đặt ngày theo hàm week_start =, và nếu bạn đặt đối số factor = TRUE thì cột đầu ra là một factor có thứ tự. Factor sẽ bao gồm các thứ bậc cho tất cả các tuần có thể có trong khoảng thời gian - ngay cả khi không có trường hợp nào xuất hiện trong tuần đó.Xem chương Làm việc với ngày tháng để biết thêm thông tin về package aweek. Nó cũng cung cấp thông tin về hàm đảo ngược week2date().","code":"\nlinelist <- linelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # create epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convert to display (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convert to factor\n\n# Display levels\nlevels(linelist$epiweek_formatted)##  [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\" \"2014-W19\"\n##  [8] \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\" \"2014-W24\" \"2014-W25\" \"2014-W26\"\n## [15] \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\" \"2014-W31\" \"2014-W32\" \"2014-W33\"\n## [22] \"2014-W34\" \"2014-W35\" \"2014-W36\" \"2014-W37\" \"2014-W38\" \"2014-W39\" \"2014-W40\"\n## [29] \"2014-W41\" \"2014-W42\" \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\"\n## [36] \"2014-W48\" \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\"\n## [43] \"2015-W03\" \"2015-W04\" \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\" \"2015-W09\"\n## [50] \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\" \"2015-W15\" \"2015-W16\"\ndf <- linelist %>% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)"},{"path":"factors.html","id":"nguồn-tham-khảo","chapter":"11 Factors/","heading":"11.9 Nguồn tham khảo","text":"R trong Khoa học dữ liệu, chương factorsaweek package vignette","code":""},{"path":"pivoting.html","id":"pivoting","chapter":"12 Xoay trục dữ liệu","heading":"12 Xoay trục dữ liệu","text":"managing data, pivoting can understood refer one two processes:creation pivot tables, tables statistics summarise data extensive tableThe conversion table long wide format, vice versa.page, focus latter definition. former crucial step data analysis, covered elsewhere [Grouping data] [Descriptive tables] pages.page discusses formats data. useful aware idea “tidy data”, variable ’s column, observation ’s row, value ’s cell. topic can found online chapter R Data Science.","code":""},{"path":"pivoting.html","id":"preparation-2","chapter":"12 Xoay trục dữ liệu","heading":"12.1 Preparation","text":"","code":""},{"path":"pivoting.html","id":"load-packages-3","chapter":"12 Xoay trục dữ liệu","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse)    # data management + ggplot2 graphics"},{"path":"pivoting.html","id":"import-data-3","chapter":"12 Xoay trục dữ liệu","heading":"Import data","text":"","code":""},{"path":"pivoting.html","id":"malaria-count-data","chapter":"12 Xoay trục dữ liệu","heading":"Malaria count data","text":"page, use fictional dataset daily malaria cases, facility age group. want follow along, click download (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows displayed .","code":"\n# Import data\ncount_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"pivoting.html","id":"linelist-case-data","chapter":"12 Xoay trục dữ liệu","heading":"Linelist case data","text":"later part page, also use dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see [Import export] page details).","code":"\n# import your dataset\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"pivoting.html","id":"wide-to-long","chapter":"12 Xoay trục dữ liệu","heading":"12.2 Wide-to-long","text":"","code":""},{"path":"pivoting.html","id":"wide-format","chapter":"12 Xoay trục dữ liệu","heading":"“Wide” format","text":"Data often entered stored “wide” format - subject’s characteristics responses stored single row. may useful presentation, ideal types analysis.Let us take count_data dataset imported Preparation section example. can see row represents “facility-day”. actual case counts (right-columns) stored “wide” format information every age group given facility-day stored single row.observation dataset refers malaria counts one 65 facilities given date, ranging count_data$data_date %>% min() count_data$data_date %>% max(). facilities located one Province (North) four Districts (Spring, Bolo, Dingo, Barnard). dataset provides overall counts malaria, well age-specific counts three age groups - <4 years, 5-14 years, 15 years older.“Wide” data like adhering “tidy data” standards, column headers actually represent “variables” - represent values hypothetical “age group” variable.format can useful presenting information table, entering data (e.g. Excel) case report forms. However, analysis stage, data typically transformed “longer” format aligned “tidy data” standards. plotting R package ggplot2 particular works best data “long” format.Visualising total malaria counts time poses difficulty data ’s current format:However, wanted display relative contributions age group total count? case, need ensure variable interest (age group), appears dataset single column can passed ggplot2’s “mapping aesthetics” aes() argument.","code":"\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)"},{"path":"pivoting.html","id":"pivot_longer","chapter":"12 Xoay trục dữ liệu","heading":"pivot_longer()","text":"tidyr function pivot_longer() makes data “longer”. tidyr part tidyverse R packages.accepts range columns transform (specified cols =). Therefore, can operate part dataset. useful malaria data, want pivot case count columns.process, end two “new” columns - one categories (former column names), one corresponding values (e.g. case counts). can accept default names new columns, can specify names_to = values_to = respectively.Let’s see pivot_longer() action…","code":""},{"path":"pivoting.html","id":"standard-pivoting","chapter":"12 Xoay trục dữ liệu","heading":"Standard pivoting","text":"want use tidyr’s pivot_longer() function convert “wide” data “long” format. Specifically, convert four numeric columns data malaria counts two new columns: one holds age groups one holds corresponding values.Notice newly created data frame (df_long) rows (12,152 vs 3,038); become longer. fact, precisely four times long, row original dataset now represents four rows df_long, one malaria count observations (<4y, 5-14y, 15y+, total).addition becoming longer, new dataset fewer columns (8 vs 10), data previously stored four columns (beginning prefix malaria_) now stored two.Since names four columns begin prefix malaria_, made use handy “tidyselect” function starts_with() achieve result (see page [Cleaning data core functions] helper functions).position:named range:two new columns given default names name value, can override defaults provide meaningful names, can help remember stored within, using names_to values_to arguments. Let’s use names age_group counts:can now pass new dataset ggplot2, map new column count y-axis new column age_group fill = argument (column internal color). display malaria counts stacked bar chart, age group:Examine new plot, compare plot created earlier - gone wrong?encountered common problem wrangling surveillance data - also included total counts malaria_tot column, magnitude bar plot twice high .can handle number ways. simply filter totals dataset pass ggplot():Alternatively, excluded variable ran pivot_longer(), thereby maintaining dataset separate variable. See values “expand” fill new rows.","code":"\ndf_long <- count_data %>% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n# provide column with a tidyselect helper function\ncount_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )## # A tibble: 12,152 x 8\n##    location_name data_date  submitted_date Province District newid name             value\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>            <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0-4     11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5-14    12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15      23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot         46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0-4     11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5-14    10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15       5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot         26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0-4      8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5-14     5\n## # ... with 12,142 more rows\n# provide columns by position\ncount_data %>% \n  pivot_longer(\n    cols = 6:9\n  )\n# provide range of consecutive columns\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\ndf_long <- \n  count_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\"),\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long## # A tibble: 12,152 x 8\n##    location_name data_date  submitted_date Province District newid age_group        counts\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>             <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0-4      11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5-14     12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15       23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot          46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0-4      11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5-14     10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15        5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot          26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0-4       8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5-14      5\n## # ... with 12,142 more rows\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\ndf_long %>% \n  filter(age_group != \"malaria_tot\") %>% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # does not include the totals column\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )## # A tibble: 9,114 x 9\n##    location_name data_date  submitted_date Province District malaria_tot newid age_group  \n##    <chr>         <date>     <date>         <chr>    <chr>          <int> <int> <chr>      \n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rd~\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rd~\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rd~\n##  4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rd~\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rd~\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rd~\n##  7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rd~\n##  8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rd~\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rd~\n## 10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4 malaria_rd~\n## # ... with 9,104 more rows, and 1 more variable: counts <int>"},{"path":"pivoting.html","id":"pivoting-data-of-multiple-classes","chapter":"12 Xoay trục dữ liệu","heading":"Pivoting data of multiple classes","text":"example works well situations columns want “pivot longer” class (character, numeric, logical…).However, many cases , field epidemiologist, working data prepared non-specialists follow non-standard logic - Hadley Wickham noted (referencing Tolstoy) seminal article Tidy Data principles: “Like families, tidy datasets alike every messy dataset messy way.”One particularly common problem encounter need pivot columns contain different classes data. pivot result storing different data types single column, good situation. various approaches one can take separate mess creates, important step can take using pivot_longer() avoid creating situation .Take situation series observations different time steps three items , B C. Examples items individuals (e.g. contacts Ebola case traced day 21 days) remote village health posts monitored per year ensure still functional. Let’s use contact tracing example. Imagine data stored follows:can seen, data bit complicated. row stores information one item, time series running away right time progresses. Moreover, column classes alternate date character values.One particularly bad example encountered author involved cholera surveillance data, 8 new columns observations added day course 4 years. Simply opening Excel file data stored took >10 minuntes laptop!order work data, need transform data frame long format, keeping separation date column character (status) column, observation item. don’t, might end mixture variable types single column (big “-” comes data management tidy data):, pivot merged dates characters single value column. R react converting entire column class character, utility dates lost.prevent situation, can take advantage syntax structure original column names. common naming structure, observation number, underscore, either “status” “date”. can leverage syntax keep two data types separate columns pivot.:Providing character vector names_to = argument, second item (\".value\" ). special term indicates pivoted columns split based character name…must also provide “splitting” character names_sep = argument. case, underscore \"_\".Thus, naming split new columns based around underscore existing variable names.Finishing touches:Note date column currently character class - can easily convert ’s proper date class using mutate() as_date() functions described Working dates page.may also want convert observation column numeric format dropping “obs” prefix converting numeric. cando str_remove_all() stringr package (see [Characters strings] page).now, can start work data format, e.g. plotting descriptive heat tile:","code":"\ndf %>% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\")\n  )## # A tibble: 18 x 3\n##    id    observation value     \n##    <chr> <chr>       <chr>     \n##  1 A     obs1_date   2021-04-23\n##  2 A     obs1_status Healthy   \n##  3 A     obs2_date   2021-04-24\n##  4 A     obs2_status Healthy   \n##  5 A     obs3_date   2021-04-25\n##  6 A     obs3_status Unwell    \n##  7 B     obs1_date   2021-04-23\n##  8 B     obs1_status Healthy   \n##  9 B     obs2_date   2021-04-24\n## 10 B     obs2_status Healthy   \n## 11 B     obs3_date   2021-04-25\n## 12 B     obs3_status Healthy   \n## 13 C     obs1_date   2021-04-23\n## 14 C     obs1_status Missing   \n## 15 C     obs2_date   2021-04-24\n## 16 C     obs2_status Healthy   \n## 17 C     obs3_date   2021-04-25\n## 18 C     obs3_status Healthy\ndf_long <- \n  df %>% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long## # A tibble: 9 x 4\n##   id    observation date       status \n##   <chr> <chr>       <chr>      <chr>  \n## 1 A     obs1        2021-04-23 Healthy\n## 2 A     obs2        2021-04-24 Healthy\n## 3 A     obs3        2021-04-25 Unwell \n## 4 B     obs1        2021-04-23 Healthy\n## 5 B     obs2        2021-04-24 Healthy\n## 6 B     obs3        2021-04-25 Healthy\n## 7 C     obs1        2021-04-23 Missing\n## 8 C     obs2        2021-04-24 Healthy\n## 9 C     obs3        2021-04-25 Healthy\ndf_long <- \n  df_long %>% \n  mutate(\n    date = date %>% lubridate::as_date(),\n    observation = \n      observation %>% \n      str_remove_all(\"obs\") %>% \n      as.numeric()\n  )\n\ndf_long## # A tibble: 9 x 4\n##   id    observation date       status \n##   <chr>       <dbl> <date>     <chr>  \n## 1 A               1 2021-04-23 Healthy\n## 2 A               2 2021-04-24 Healthy\n## 3 A               3 2021-04-25 Unwell \n## 4 B               1 2021-04-23 Healthy\n## 5 B               2 2021-04-24 Healthy\n## 6 B               3 2021-04-25 Healthy\n## 7 C               1 2021-04-23 Missing\n## 8 C               2 2021-04-24 Healthy\n## 9 C               3 2021-04-25 Healthy\nggplot(data = df_long, mapping = aes(x = date, y = id, fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\" = \"red\", \n        \"Missing\" = \"orange\")\n  )"},{"path":"pivoting.html","id":"long-to-wide","chapter":"12 Xoay trục dữ liệu","heading":"12.3 Long-to-wide","text":"instances, may wish convert dataset wider format. , can use pivot_wider() function.typical use-case want transform results analysis format digestible reader ([Table presentation][Tables presentation]). Usually, involves transforming dataset information one subject spread multiple rows format information stored single row.","code":""},{"path":"pivoting.html","id":"data","chapter":"12 Xoay trục dữ liệu","heading":"Data","text":"section page, use case linelist (see Preparation section), contains one row per case.first 50 rows:Suppose want know counts individuals different age groups, gender:gives us long dataset great producing visualisations ggplot2, ideal presentation table:","code":"\ndf_wide <- \n  linelist %>% \n  count(age_cat, gender)\n\ndf_wide##    age_cat gender   n\n## 1      0-4      f 640\n## 2      0-4      m 416\n## 3      0-4   <NA>  39\n## 4      5-9      f 641\n## 5      5-9      m 412\n## 6      5-9   <NA>  42\n## 7    10-14      f 518\n## 8    10-14      m 383\n## 9    10-14   <NA>  40\n## 10   15-19      f 359\n## 11   15-19      m 364\n## 12   15-19   <NA>  20\n## 13   20-29      f 468\n## 14   20-29      m 575\n## 15   20-29   <NA>  30\n## 16   30-49      f 179\n## 17   30-49      m 557\n## 18   30-49   <NA>  18\n## 19   50-69      f   2\n## 20   50-69      m  91\n## 21   50-69   <NA>   2\n## 22     70+      m   5\n## 23     70+   <NA>   1\n## 24    <NA>   <NA>  86\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))"},{"path":"pivoting.html","id":"pivot-wider","chapter":"12 Xoay trục dữ liệu","heading":"Pivot wider","text":"Therefore, can use pivot_wider() transform data better format inclusion tables reports.argument names_from specifies column generate new column names, argument values_from specifies column take values populate cells. argument id_cols = optional, can provided vector column names pivoted, thus identify row.table much reader-friendly, therefore better inclusion reports. can convert pretty table several packages including flextable knitr. process elaborated page [Tables presentation].","code":"\ntable_wide <- \n  df_wide %>% \n  pivot_wider(\n    id_cols = age_cat,\n    names_from = gender,\n    values_from = n\n  )\n\ntable_wide## # A tibble: 9 x 4\n##   age_cat     f     m  `NA`\n##   <fct>   <int> <int> <int>\n## 1 0-4       640   416    39\n## 2 5-9       641   412    42\n## 3 10-14     518   383    40\n## 4 15-19     359   364    20\n## 5 20-29     468   575    30\n## 6 30-49     179   557    18\n## 7 50-69       2    91     2\n## 8 70+        NA     5     1\n## 9 <NA>       NA    NA    86\ntable_wide %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% # adds row and column totals\n  knitr::kable() %>% \n  kableExtra::row_spec(row = 10, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) "},{"path":"pivoting.html","id":"fill","chapter":"12 Xoay trục dữ liệu","heading":"12.4 Fill","text":"situations pivot, commonly bind, left gaps cells like fill.","code":""},{"path":"pivoting.html","id":"data-1","chapter":"12 Xoay trục dữ liệu","heading":"Data","text":"example, take two datasets, observations measurement number, name facility, case count time. However, second dataset also variable Year.perform bind_rows() join two datasets together, Year variable filled NA rows prior information (.e. first dataset):","code":"\ndf1 <- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 ## # A tibble: 9 x 3\n##   Measurement Facility Cases\n##         <dbl> <chr>    <dbl>\n## 1           1 Hosp 1      66\n## 2           2 Hosp 1      26\n## 3           3 Hosp 1       8\n## 4           1 Hosp 2      71\n## 5           2 Hosp 2      62\n## 6           3 Hosp 2      70\n## 7           1 Hosp 3      47\n## 8           2 Hosp 3      70\n## 9           3 Hosp 3      38\ndf2 <- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2## # A tibble: 3 x 4\n##    Year Measurement Facility Cases\n##   <dbl>       <dbl> <chr>    <dbl>\n## 1  2000           1 Hosp 4      82\n## 2  2001           2 Hosp 4      87\n## 3  2002           3 Hosp 4      46\ndf_combined <- \n  bind_rows(df1, df2) %>% \n  arrange(Measurement, Facility)\n\ndf_combined## # A tibble: 12 x 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66    NA\n##  2           1 Hosp 2      71    NA\n##  3           1 Hosp 3      47    NA\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26    NA\n##  6           2 Hosp 2      62    NA\n##  7           2 Hosp 3      70    NA\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8    NA\n## 10           3 Hosp 2      70    NA\n## 11           3 Hosp 3      38    NA\n## 12           3 Hosp 4      46  2002"},{"path":"pivoting.html","id":"fill-1","chapter":"12 Xoay trục dữ liệu","heading":"fill()","text":"case, Year useful variable include, particularly want explore trends time. Therefore, use fill() fill empty cells, specifying column fill direction (case ):Alternatively, can rearrange data need fill downward direction:now useful dataset plotting:less useful presenting table, let’s practice converting long, untidy dataframe wider, tidy dataframe:N.B. case, specify include three variables Facility, Year, Cases additional variable Measurement interfere creation table:","code":"\ndf_combined %>% \n  fill(Year, .direction = \"up\")## # A tibble: 12 x 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66  2000\n##  2           1 Hosp 2      71  2000\n##  3           1 Hosp 3      47  2000\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26  2001\n##  6           2 Hosp 2      62  2001\n##  7           2 Hosp 3      70  2001\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8  2002\n## 10           3 Hosp 2      70  2002\n## 11           3 Hosp 3      38  2002\n## 12           3 Hosp 4      46  2002\ndf_combined <- \n  df_combined %>% \n  arrange(Measurement, desc(Facility))\n\ndf_combined## # A tibble: 12 x 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47    NA\n##  3           1 Hosp 2      71    NA\n##  4           1 Hosp 1      66    NA\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70    NA\n##  7           2 Hosp 2      62    NA\n##  8           2 Hosp 1      26    NA\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38    NA\n## 11           3 Hosp 2      70    NA\n## 12           3 Hosp 1       8    NA\ndf_combined <- \n  df_combined %>% \n  fill(Year, .direction = \"down\")\n\ndf_combined## # A tibble: 12 x 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47  2000\n##  3           1 Hosp 2      71  2000\n##  4           1 Hosp 1      66  2000\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70  2001\n##  7           2 Hosp 2      62  2001\n##  8           2 Hosp 1      26  2001\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38  2002\n## 11           3 Hosp 2      70  2002\n## 12           3 Hosp 1       8  2002\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\ndf_combined %>% \n  pivot_wider(\n    id_cols = c(Facility, Year, Cases),\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  arrange(Facility) %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% \n  knitr::kable() %>% \n  kableExtra::row_spec(row = 5, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) \ndf_combined %>% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  knitr::kable()"},{"path":"pivoting.html","id":"resources-2","chapter":"12 Xoay trục dữ liệu","heading":"12.5 Resources","text":"helpful tutorial","code":""},{"path":"grouping.html","id":"grouping","chapter":"13 Nhóm dữ liệu","heading":"13 Nhóm dữ liệu","text":"page covers group aggregate data descriptive analysis. makes use tidyverse family packages common easy--use functions.Grouping data core component data management analysis. Grouped data statistically summarised group, can plotted group. Functions dplyr package (part tidyverse) make grouping subsequent operations quite easy.page address following topics:Group data group_by() functionUn-group datasummarise() grouped data statisticsThe difference count() tally()arrange() applied grouped datafilter() applied grouped datamutate() applied grouped dataselect() applied grouped dataThe base R aggregate() command alternative","code":""},{"path":"grouping.html","id":"preparation-3","chapter":"13 Nhóm dữ liệu","heading":"13.1 Preparation","text":"","code":""},{"path":"grouping.html","id":"load-packages-4","chapter":"13 Nhóm dữ liệu","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,       # to import data\n  here,      # to locate files\n  tidyverse, # to clean, handle, and plot the data (includes dplyr)\n  janitor)   # adding total rows and columns"},{"path":"grouping.html","id":"import-data-4","chapter":"13 Nhóm dữ liệu","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). dataset imported using import() function rio package. See page [Import export] various ways import data.first 50 rows linelist:","code":"\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"grouping.html","id":"grouping-1","chapter":"13 Nhóm dữ liệu","heading":"13.2 Grouping","text":"function group_by() dplyr groups rows unique values column specified . multiple columns specified, rows grouped unique combinations values across columns. unique value (combination values) constitutes group. Subsequent changes dataset calculations can performed within context group.example, command takes linelist groups rows unique values column outcome, saving output new data frame ll_by_outcome. grouping column(s) placed inside parentheses function group_by().Note perceptible change dataset running group_by(), another dplyr verb mutate(), summarise(), arrange() applied “grouped” data frame.can however “see” groupings printing data frame. print grouped data frame, see transformed tibble class object , printed, displays groupings applied many groups - written just header row.","code":"\nll_by_outcome <- linelist %>% \n  group_by(outcome)\n# print to see which groups are active\nll_by_outcome## # A tibble: 5,888 x 30\n## # Groups:   outcome [3]\n##    case_id generation date_infection date_onset date_hospitalisation date_outcome outcome\n##    <chr>        <dbl> <date>         <date>     <date>               <date>       <chr>  \n##  1 5fe599           4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>   \n##  2 8689b7           4 NA             2014-05-13 2014-05-14           2014-05-18   Recover\n##  3 11f8ea           2 NA             2014-05-16 2014-05-18           2014-05-30   Recover\n##  4 b8812a           3 2014-05-04     2014-05-18 2014-05-20           NA           <NA>   \n##  5 893f25           3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover\n##  6 be99c8           3 2014-05-03     2014-05-22 2014-05-23           2014-05-24   Recover\n##  7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29           2014-06-01   Recover\n##  8 369449           4 2014-05-28     2014-06-02 2014-06-03           2014-06-07   Death  \n##  9 f393b4           4 NA             2014-06-05 2014-06-06           2014-06-18   Recover\n## 10 1389ca           4 NA             2014-06-05 2014-06-07           2014-06-09   Death  \n## # ... with 5,878 more rows, and 23 more variables: gender <chr>, age <dbl>,\n## #   age_unit <chr>, age_years <dbl>, age_cat <fct>, age_cat5 <fct>, hospital <chr>,\n## #   lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>,\n## #   ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>,\n## #   temp <dbl>, time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>"},{"path":"grouping.html","id":"unique-groups","chapter":"13 Nhóm dữ liệu","heading":"Unique groups","text":"groups created reflect unique combination values across grouping columns.see groups number rows group, pass grouped data tally(). see just unique groups without counts can pass group_keys().See three unique values grouping column outcome: “Death”, “Recover”, NA. See nrow(linelist %>% filter(outcome == \"Death\")) deaths, nrow(linelist %>% filter(outcome == \"Recover\")) recoveries, nrow(linelist %>% filter(.na(outcome))) outcome recorded.can group one column. , data frame grouped outcome gender, tallied. Note unique combination outcome gender registered group - including missing values either column.","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  tally()## # A tibble: 3 x 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally()## # A tibble: 9 x 3\n## # Groups:   outcome [3]\n##   outcome gender     n\n##   <chr>   <chr>  <int>\n## 1 Death   f       1227\n## 2 Death   m       1228\n## 3 Death   <NA>     127\n## 4 Recover f        953\n## 5 Recover m        950\n## 6 Recover <NA>      80\n## 7 <NA>    f        627\n## 8 <NA>    m        625\n## 9 <NA>    <NA>      71"},{"path":"grouping.html","id":"new-columns-1","chapter":"13 Nhóm dữ liệu","heading":"New columns","text":"can also create new grouping column within group_by() statement. equivalent calling mutate() group_by(). quick tabulation style can handy, clarity code consider creating column mutate() step piping group_by().","code":"\n# group dat based on a binary column created *within* the group_by() command\nlinelist %>% \n  group_by(\n    age_class = ifelse(age >= 18, \"adult\", \"child\")) %>% \n  tally(sort = T)## # A tibble: 3 x 2\n##   age_class     n\n##   <chr>     <int>\n## 1 child      3618\n## 2 adult      2184\n## 3 <NA>         86"},{"path":"grouping.html","id":"adddrop-grouping-columns","chapter":"13 Nhóm dữ liệu","heading":"Add/drop grouping columns","text":"default, run group_by() data already grouped, old groups removed new one(s) apply. want add new groups existing ones, include argument .add = TRUE.** Keep groups**group column class factor may levels factor currently present data. group column, default non-present levels dropped included groups. change levels appear groups (even present data), set .drop = FALSE group_by() command.","code":"\n# Grouped by outcome\nby_outcome <- linelist %>% \n  group_by(outcome)\n\n# Add grouping by gender in addition\nby_outcome_gender <- by_outcome %>% \n  group_by(gender, .add = TRUE)"},{"path":"grouping.html","id":"un-group","chapter":"13 Nhóm dữ liệu","heading":"13.3 Un-group","text":"Data grouped remain grouped specifically ungrouped via ungroup(). forget ungroup, can lead incorrect calculations! example removing groupings:can also remove grouping specific columns, placing column name inside ungroup().NOTE: verb count() automatically ungroups data counting.","code":"\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup()\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup(gender) # remove the grouping by gender, leave grouping by outcome"},{"path":"grouping.html","id":"group_summarise","chapter":"13 Nhóm dữ liệu","heading":"13.4 Summarise","text":"See dplyr section [Descriptive tables] page detailed description produce summary tables summarise(). briefly address behavior changes applied grouped data.dplyr function summarise() (summarize()) takes data frame converts new summary data frame, columns containing summary statistics define. ungrouped data frame, summary statistics calculated rows. Applying summarise() grouped data produces summary statistics group.syntax summarise() provide name(s) new summary column(s), equals sign, statistical function apply data, shown . example, min(), max(), median(), sd(). Within statistical function, list column operated relevant argument (e.g. na.rm = TRUE). can use sum() count number rows meet logical criteria (double equals ==).example summarise() applied without grouped data. statistics returned produced entire dataset.contrast, summarise() statement applied grouped data. statistics calculated outcome group. Note grouping columns carry new data frame.TIP: summarise function works UK US spelling - summarise() summarize() call function.","code":"\n# summary statistics on ungrouped linelist\nlinelist %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males  = sum(gender == \"m\", na.rm=T))##   n_cases mean_age max_age min_age n_males\n## 1    5888 16.01831      84       0    2803\n# summary statistics on grouped linelist\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males    = sum(gender == \"m\", na.rm=T))## # A tibble: 3 x 6\n##   outcome n_cases mean_age max_age min_age n_males\n##   <chr>     <int>    <dbl>   <dbl>   <dbl>   <int>\n## 1 Death      2582     15.9      76       0    1228\n## 2 Recover    1983     16.1      84       0     950\n## 3 <NA>       1323     16.2      69       0     625"},{"path":"grouping.html","id":"counts-and-tallies","chapter":"13 Nhóm dữ liệu","heading":"13.5 Counts and tallies","text":"count() tally() provide similar functionality different. Read distinction tally() count() ","code":""},{"path":"grouping.html","id":"tally","chapter":"13 Nhóm dữ liệu","heading":"tally()","text":"tally() shorthand summarise(n = n()), group data. Thus, achieve grouped tallys must follow group_by() command. can add sort = TRUE see largest groups first.","code":"\nlinelist %>% \n  tally()##      n\n## 1 5888\nlinelist %>% \n  group_by(outcome) %>% \n  tally(sort = TRUE)## # A tibble: 3 x 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323"},{"path":"grouping.html","id":"count","chapter":"13 Nhóm dữ liệu","heading":"count()","text":"contrast, count() following:applies group_by() specified column(s)applies summarise() returns column n number rows per groupapplies ungroup()Just like group_by() can create new column within count() command:count() can called multiple times, functionality “rolling ”. example, summarise number hospitals present gender, run following. Note, name final column changed default “n” clarity (name  =).","code":"\nlinelist %>% \n  count(outcome)##   outcome    n\n## 1   Death 2582\n## 2 Recover 1983\n## 3    <NA> 1323\nlinelist %>% \n  count(age_class = ifelse(age >= 18, \"adult\", \"child\"), sort = T)##   age_class    n\n## 1     child 3618\n## 2     adult 2184\n## 3      <NA>   86\nlinelist %>% \n  # produce counts by unique outcome-gender groups\n  count(gender, hospital) %>% \n  # gather rows by gender (3) and count number of hospitals per gender (6)\n  count(gender, name = \"hospitals per gender\" ) ##   gender hospitals per gender\n## 1      f                    6\n## 2      m                    6\n## 3   <NA>                    6"},{"path":"grouping.html","id":"add-counts","chapter":"13 Nhóm dữ liệu","heading":"Add counts","text":"contrast count() summarise(), can use add_count() add new column n counts rows per group retaining data frame columns.means group’s count number, new column n, printed row group. demonstration purposes, add column re-arrange columns easier viewing. See section filter group size another example.","code":"\nlinelist %>% \n  as_tibble() %>%                   # convert to tibble for nicer printing \n  add_count(hospital) %>%           # add column n with counts by hospital\n  select(hospital, n, everything()) # re-arrange for demo purposes## # A tibble: 5,888 x 31\n##    hospital               n case_id generation date_infection date_onset date_hospitalisa~\n##    <chr>              <int> <chr>        <dbl> <date>         <date>     <date>           \n##  1 Other                885 5fe599           4 2014-05-08     2014-05-13 2014-05-15       \n##  2 Missing             1469 8689b7           4 NA             2014-05-13 2014-05-14       \n##  3 St. Mark's Matern~   422 11f8ea           2 NA             2014-05-16 2014-05-18       \n##  4 Port Hospital       1762 b8812a           3 2014-05-04     2014-05-18 2014-05-20       \n##  5 Military Hospital    896 893f25           3 2014-05-18     2014-05-21 2014-05-22       \n##  6 Port Hospital       1762 be99c8           3 2014-05-03     2014-05-22 2014-05-23       \n##  7 Missing             1469 07e3e8           4 2014-05-22     2014-05-27 2014-05-29       \n##  8 Missing             1469 369449           4 2014-05-28     2014-06-02 2014-06-03       \n##  9 Missing             1469 f393b4           4 NA             2014-06-05 2014-06-06       \n## 10 Missing             1469 1389ca           4 NA             2014-06-05 2014-06-07       \n## # ... with 5,878 more rows, and 24 more variables: date_outcome <date>, outcome <chr>,\n## #   gender <chr>, age <dbl>, age_unit <chr>, age_years <dbl>, age_cat <fct>,\n## #   age_cat5 <fct>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>,\n## #   ht_cm <dbl>, ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>,\n## #   vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>"},{"path":"grouping.html","id":"add-totals","chapter":"13 Nhóm dữ liệu","heading":"Add totals","text":"easily add total sum rows columns using tally() count(), see janitor section Descriptive tables page. package offers functions like adorn_totals() adorn_percentages() add totals convert show percentages. brief example:add complex totals rows involve summary statistics sums, see section Descriptive Tables page.","code":"\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts of two columns\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions with column denominator\n  adorn_pct_formatting() %>%                  # convert proportions to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                      Gender                           \n##  Age Category             f             m          NA_\n##           0-4  640  (22.8%)  416  (14.8%)  39  (14.0%)\n##           5-9  641  (22.8%)  412  (14.7%)  42  (15.1%)\n##         10-14  518  (18.5%)  383  (13.7%)  40  (14.4%)\n##         15-19  359  (12.8%)  364  (13.0%)  20   (7.2%)\n##         20-29  468  (16.7%)  575  (20.5%)  30  (10.8%)\n##         30-49  179   (6.4%)  557  (19.9%)  18   (6.5%)\n##         50-69    2   (0.1%)   91   (3.2%)   2   (0.7%)\n##           70+    0   (0.0%)    5   (0.2%)   1   (0.4%)\n##          <NA>    0   (0.0%)    0   (0.0%)  86  (30.9%)\n##         Total 2807 (100.0%) 2803 (100.0%) 278 (100.0%)"},{"path":"grouping.html","id":"grouping-by-date","chapter":"13 Nhóm dữ liệu","heading":"13.6 Grouping by date","text":"grouping data date, must (create) column date unit interest - example “day”, “epiweek”, “month”, etc. can make column using floor_date() lubridate, explained Epidemiological weeks section Working dates page. column, can use count() dplyr group rows unique date values achieve aggregate counts.One additional step common date situations, “fill-” dates sequence present data. Use complete() tidyr aggregated date series complete including possible date units within range. Without step, week cases reported might appear data!Within complete() re-define date column sequence dates seq.Date() minimum maximum - thus dates expanded. default, case count values new “expanded” rows NA. can set 0 using fill = argument complete(), expects named list (counts column named n, provide fill = list(n = 0). See ?complete details Working dates page example.","code":""},{"path":"grouping.html","id":"linelist-cases-into-days","chapter":"13 Nhóm dữ liệu","heading":"Linelist cases into days","text":"example grouping cases days without using complete(). Note first rows skip dates cases.add complete() command ensure every day range represented.","code":"\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%        # remove that were missing date_onset\n  count(date_onset)              # count number of rows per unique date\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%                 # remove case missing date_onset\n  count(date_onset) %>%                   # count number of rows per unique date\n  complete(                               # ensure all days appear even if no cases\n    date_onset = seq.Date(                # re-define date colume as daily sequence of dates\n      from = min(date_onset, na.rm=T), \n      to = max(date_onset, na.rm=T),\n      by = \"day\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) "},{"path":"grouping.html","id":"linelist-cases-into-weeks","chapter":"13 Nhóm dữ liệu","heading":"Linelist cases into weeks","text":"principle can applied weeks. First create new column week case using floor_date() unit = \"week\". , use count() achieve weekly case counts. Finish complete() ensure weeks represented, even contain cases.first 50 rows resulting data frame:","code":"\n# Make dataset of weekly case counts\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%                 # remove cases missing date_onset\n  mutate(week = lubridate::floor_date(date_onset, unit = \"week\")) %>%  # new column of week of onset\n  count(week) %>%                         # group data by week and count rows per group\n  complete(                               # ensure all days appear even if no cases\n    week = seq.Date(                      # re-define date colume as daily sequence of dates\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) "},{"path":"grouping.html","id":"linelist-cases-into-months","chapter":"13 Nhóm dữ liệu","heading":"Linelist cases into months","text":"aggregate cases months, use floor_date() lubridate package, argument unit = \"months\". rounds date 1st month. output class Date. Note complete() step also use = \"months\".","code":"\n# Make dataset of monthly case counts\nmonthly_counts <- linelist %>% \n  drop_na(date_onset) %>% \n  mutate(month = lubridate::floor_date(date_onset, unit = \"months\")) %>%  # new column, 1st of month of onset\n  count(month) %>%                          # count cases by month\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # include all months with no cases reported\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))"},{"path":"grouping.html","id":"daily-counts-into-weeks","chapter":"13 Nhóm dữ liệu","heading":"Daily counts into weeks","text":"aggregate daily counts weekly counts, use floor_date() . However, use group_by() summarize() instead count() need sum() daily case counts instead just counting number rows per week.","code":""},{"path":"grouping.html","id":"daily-counts-into-months","chapter":"13 Nhóm dữ liệu","heading":"Daily counts into months","text":"aggregate daily counts months counts, use floor_date() unit = \"month\" . However, use group_by() summarize() instead count() need sum() daily case counts instead just counting number rows per month.","code":""},{"path":"grouping.html","id":"arranging-grouped-data","chapter":"13 Nhóm dữ liệu","heading":"13.7 Arranging grouped data","text":"Using dplyr verb arrange() order rows data frame behaves data grouped, unless set argument .by_group =TRUE. case rows ordered first grouping columns columns specify arrange().","code":""},{"path":"grouping.html","id":"filter-on-grouped-data","chapter":"13 Nhóm dữ liệu","heading":"13.8 Filter on grouped data","text":"","code":""},{"path":"grouping.html","id":"filter","chapter":"13 Nhóm dữ liệu","heading":"filter()","text":"applied conjunction functions evaluate data frame (like max(), min(), mean()), functions now applied groups. example, want filter keep rows patients median age, now apply per group - filtering keep rows group’s median age.","code":""},{"path":"grouping.html","id":"slice-rows-per-group","chapter":"13 Nhóm dữ liệu","heading":"Slice rows per group","text":"dplyr function slice(), filters rows based position data, can also applied per group. Remember account sorting data within group get desired “slice”.example, retrieve latest 5 admissions hospital:Group linelist column hospitalArrange records latest earliest date_hospitalisation within hospital groupSlice retrieve first 5 rows hospitalslice_head() - selects n rows topslice_tail() - selects n rows endslice_sample() - randomly selects n rowsslice_min() - selects n rows highest values order_by = column, use with_ties = TRUE keep tiesslice_max() - selects n rows lowest values order_by = column, use with_ties = TRUE keep tiesSee [De-duplication] page examples detail slice().","code":"\nlinelist %>%\n  group_by(hospital) %>%\n  arrange(hospital, date_hospitalisation) %>%\n  slice_head(n = 5) %>% \n  arrange(hospital) %>%                            # for display\n  select(case_id, hospital, date_hospitalisation)  # for display## # A tibble: 30 x 3\n## # Groups:   hospital [6]\n##    case_id hospital          date_hospitalisation\n##    <chr>   <chr>             <date>              \n##  1 20b688  Central Hospital  2014-05-06          \n##  2 d58402  Central Hospital  2014-05-10          \n##  3 b8f2fd  Central Hospital  2014-05-13          \n##  4 acf422  Central Hospital  2014-05-28          \n##  5 275cc7  Central Hospital  2014-05-28          \n##  6 d1fafd  Military Hospital 2014-04-17          \n##  7 974bc1  Military Hospital 2014-05-13          \n##  8 6a9004  Military Hospital 2014-05-13          \n##  9 09e386  Military Hospital 2014-05-14          \n## 10 865581  Military Hospital 2014-05-15          \n## # ... with 20 more rows"},{"path":"grouping.html","id":"group_filter_grp_size","chapter":"13 Nhóm dữ liệu","heading":"Filter on group size","text":"function add_count() adds column n original data giving number rows row’s group.Shown , add_count() applied column hospital, values new column n reflect number rows row’s hospital group. Note values column n repeated. example , column name n changed using name = within add_count(). demonstration purposes re-arrange columns select().becomes easy filter case rows hospitalized “small” hospital, say, hospital admitted fewer 500 patients:","code":"\nlinelist %>% \n  as_tibble() %>% \n  add_count(hospital) %>%          # add \"number of rows admitted to same hospital as this row\" \n  select(hospital, n, everything())## # A tibble: 5,888 x 31\n##    hospital               n case_id generation date_infection date_onset date_hospitalisa~\n##    <chr>              <int> <chr>        <dbl> <date>         <date>     <date>           \n##  1 Other                885 5fe599           4 2014-05-08     2014-05-13 2014-05-15       \n##  2 Missing             1469 8689b7           4 NA             2014-05-13 2014-05-14       \n##  3 St. Mark's Matern~   422 11f8ea           2 NA             2014-05-16 2014-05-18       \n##  4 Port Hospital       1762 b8812a           3 2014-05-04     2014-05-18 2014-05-20       \n##  5 Military Hospital    896 893f25           3 2014-05-18     2014-05-21 2014-05-22       \n##  6 Port Hospital       1762 be99c8           3 2014-05-03     2014-05-22 2014-05-23       \n##  7 Missing             1469 07e3e8           4 2014-05-22     2014-05-27 2014-05-29       \n##  8 Missing             1469 369449           4 2014-05-28     2014-06-02 2014-06-03       \n##  9 Missing             1469 f393b4           4 NA             2014-06-05 2014-06-06       \n## 10 Missing             1469 1389ca           4 NA             2014-06-05 2014-06-07       \n## # ... with 5,878 more rows, and 24 more variables: date_outcome <date>, outcome <chr>,\n## #   gender <chr>, age <dbl>, age_unit <chr>, age_years <dbl>, age_cat <fct>,\n## #   age_cat5 <fct>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>,\n## #   ht_cm <dbl>, ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>,\n## #   vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\nlinelist %>% \n  add_count(hospital) %>% \n  filter(n < 500)"},{"path":"grouping.html","id":"mutate-on-grouped-data","chapter":"13 Nhóm dữ liệu","heading":"13.9 Mutate on grouped data","text":"retain columns rows (summarise) add new column containing group statistics, use mutate() group_by() instead summarise().useful want group statistics original dataset columns present - e.g. calculations compare one row group.example, code calculates difference row’s delay--admission median delay hospital. steps :Group data hospitalUse column days_onset_hosp (delay hospitalisation) create new column containing mean delay hospital rowCalculate difference two columnsWe select() certain columns display, demonstration purposes.","code":"\nlinelist %>% \n  # group data by hospital (no change to linelist yet)\n  group_by(hospital) %>% \n  \n  # new columns\n  mutate(\n    # mean days to admission per hospital (rounded to 1 decimal)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),\n    \n    # difference between row's delay and mean delay at their hospital (rounded to 1 decimal)\n    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %>%\n  \n  # select certain rows only - for demonstration/viewing purposes\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)## # A tibble: 5,888 x 5\n## # Groups:   hospital [6]\n##    case_id hospital                         days_onset_hosp group_delay_adm~ diff_to_group\n##    <chr>   <chr>                                      <dbl>            <dbl>         <dbl>\n##  1 5fe599  Other                                          2              2             0  \n##  2 8689b7  Missing                                        1              2.1          -1.1\n##  3 11f8ea  St. Mark's Maternity Hospital (~               2              2.1          -0.1\n##  4 b8812a  Port Hospital                                  2              2.1          -0.1\n##  5 893f25  Military Hospital                              1              2.1          -1.1\n##  6 be99c8  Port Hospital                                  1              2.1          -1.1\n##  7 07e3e8  Missing                                        2              2.1          -0.1\n##  8 369449  Missing                                        1              2.1          -1.1\n##  9 f393b4  Missing                                        1              2.1          -1.1\n## 10 1389ca  Missing                                        2              2.1          -0.1\n## # ... with 5,878 more rows"},{"path":"grouping.html","id":"select-on-grouped-data","chapter":"13 Nhóm dữ liệu","heading":"13.10 Select on grouped data","text":"verb select() works grouped data, grouping columns always included (even mentioned select()). want grouping columns, use ungroup() first.","code":""},{"path":"grouping.html","id":"resources-3","chapter":"13 Nhóm dữ liệu","heading":"13.11 Resources","text":"useful resources information:can perform summary function grouped data; see RStudio data transformation cheat sheetThe Data Carpentry page dplyr\ntidyverse reference pages group_by() groupingThis page Data manipulationSummarize conditions dplyr","code":""},{"path":"joining-matching.html","id":"joining-matching","chapter":"14 Nối dữ liệu","heading":"14 Nối dữ liệu","text":": animated example left join (image source)page describes ways “join”, “match”, “link” “bind”, otherwise combine data frames.uncommon epidemiological analysis workflow involve multiple sources data, linkage multiple datasets. Perhaps need connect laboratory data patient clinical outcomes, Google mobility data infectious disease trends, even dataset one stage analysis transformed version .page demonstrate code :Conduct joins two data frames rows matched based common values identifier columnsJoin two data frames based probabilistic (likely) matches valuesExpand data frame directly binding (“appending”) rows columns another data frame","code":""},{"path":"joining-matching.html","id":"preparation-4","chapter":"14 Nối dữ liệu","heading":"14.1 Preparation","text":"","code":""},{"path":"joining-matching.html","id":"load-packages-5","chapter":"14 Nối dữ liệu","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,            # import and export\n  here,           # locate files \n  tidyverse,      # data management and visualisation\n  RecordLinkage,  # probabilistic matches\n  fastLink        # probabilistic matches\n)"},{"path":"joining-matching.html","id":"import-data-5","chapter":"14 Nối dữ liệu","heading":"Import data","text":"begin, import cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"joining-matching.html","id":"example-datasets","chapter":"14 Nối dữ liệu","heading":"Example datasets","text":"joining section , use following datasets:“miniature” version case linelist, containing columns case_id, date_onset, hospital, first 10 rowsA separate data frame named hosp_info, contains details hospitalIn section probabilistic matching, use two different small datasets. code create datasets given section.","code":""},{"path":"joining-matching.html","id":"joins_llmini","chapter":"14 Nối dữ liệu","heading":"“Miniature” case linelist","text":"miniature case linelist, contains 10 rows columns case_id, date_onset, hospital.","code":"\nlinelist_mini <- linelist %>%                 # start with original linelist\n  select(case_id, date_onset, hospital) %>%   # select columns\n  head(10)                                    # only take the first 10 rows"},{"path":"joining-matching.html","id":"joins_hosp_info","chapter":"14 Nối dữ liệu","heading":"Hospital information data frame","text":"code create separate data frame additional information seven hospitals (catchment population, level care available). Note name “Military Hospital” belongs two different hospitals - one primary level serving 10000 residents secondary level serving 50280 residents.data frame:","code":"\n# Make the hospital information data frame\nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\", \"Secondary\", \"Primary\", \"Primary\")\n)"},{"path":"joining-matching.html","id":"pre-cleaning","chapter":"14 Nối dữ liệu","heading":"Pre-cleaning","text":"Traditional joins (non-probabilistic) case-sensitive require exact character matches values two data frames. demonstrate cleaning steps might need initiating join, clean align linelist_mini hosp_info datasets now.Identify differencesWe need values hosp_name column hosp_info data frame match values hospital column linelist_mini data frame.values linelist_mini data frame, printed base R function unique():values hosp_info data frame:can see hospitals exist data frames, many differences spelling.Align valuesWe begin cleaning values hosp_info data frame. explained [Cleaning data core functions] page, can re-code values logical criteria using dplyr’s case_when() function. four hospitals exist data frames change values align values linelist_mini. hospitals leave values (TRUE ~ hosp_name).CAUTION: Typically cleaning one create new column (e.g. hosp_name_clean), ease demonstration show modification old columnThe hospital names appear data frames aligned. two hospitals hosp_info present linelist_mini - deal later, join.Prior join, often easiest convert column lowercase uppercase. need convert values column UPPER lower case, use mutate() wrap column one functions stringr, shown page [Characters strings].str_to_upper()str_to_upper()str_to_title()","code":"\nunique(linelist_mini$hospital)## [1] \"Other\"                                \"Missing\"                             \n## [3] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [5] \"Military Hospital\"\nunique(hosp_info$hosp_name)## [1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"      \n## [5] \"ignace\"           \"sisters\"\nhosp_info <- hosp_info %>% \n  mutate(\n    hosp_name = case_when(\n      # criteria                         # new value\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\nunique(hosp_info$hosp_name)## [1] \"Central Hospital\"                     \"Military Hospital\"                   \n## [3] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\n## [5] \"ignace\"                               \"sisters\""},{"path":"joining-matching.html","id":"dplyr-joins","chapter":"14 Nối dữ liệu","heading":"14.2 dplyr joins","text":"dplyr package offers several different join functions. dplyr included tidyverse package. join functions described , simple use cases.Many thanks https://github.com/gadenbuie informative gifs!","code":""},{"path":"joining-matching.html","id":"general-syntax","chapter":"14 Nối dữ liệu","heading":"General syntax","text":"join commands can run standalone commands join two data frames new object, can used within pipe chain (%>%) merge one data frame another cleaned otherwise modified.example , function left_join() used standalone command create new joined_data data frame. inputs data frames 1 2 (df1 df2). first data frame listed baseline data frame, second one listed joined .third argument = specify columns data frame used aligns rows two data frames. names columns different, provide within c() vector shown , rows matched basis common values column ID df1 column identifier df2.columns data frames exact name, can just provide one name, within quotes.joining data frames based common values across multiple fields, list fields within c() vector. example joins rows values three columns dataset align exactly.join commands can also run within pipe chain. modify data frame piped.example , df1 passed pipes, df2 joined , df thus modified re-defined.CAUTION: Joins case-specific! Therefore useful convert values lowercase uppercase prior joining. See page characters/strings.","code":"\n# Join based on common values between column \"ID\" (first data frame) and column \"identifier\" (second data frame)\njoined_data <- left_join(df1, df2, by = c(\"ID\" = \"identifier\"))\n# Joint based on common values in column \"ID\" in both data frames\njoined_data <- left_join(df1, df2, by = \"ID\")\n# join based on same first name, last name, and age\njoined_data <- left_join(df1, df2, by = c(\"name\" = \"firstname\", \"surname\" = \"lastname\", \"Age\" = \"age\"))\ndf1 <- df1 %>%\n  filter(date_onset < as.Date(\"2020-03-05\")) %>% # miscellaneous cleaning \n  left_join(df2, by = c(\"ID\" = \"identifier\"))    # join df2 to df1"},{"path":"joining-matching.html","id":"left-and-right-joins","chapter":"14 Nối dữ liệu","heading":"Left and right joins","text":"left right join commonly used add information data frame - new information added rows already existed baseline data frame. common joins epidemiological work used add information one dataset another.using joins, written order data frames command important*.left join, first data frame written baselineIn right join, second data frame written baselineAll rows baseline data frame kept. Information (secondary) data frame joined baseline data frame match via identifier column(s). addition:Rows secondary data frame match dropped.many baseline rows match one row secondary data frame (many--one), secondary information added matching baseline row.baseline row matches multiple rows secondary data frame (one--many), combinations given, meaning new rows may added returned data frame!Animated examples left right joins (image source)ExampleBelow output left_join() hosp_info (secondary data frame, view ) linelist_mini (baseline data frame, view ). original linelist_mini nrow(linelist_mini) rows. modified linelist_mini displayed. Note following:Two new columns, catchment_pop level added left side linelist_miniAll original rows baseline data frame linelist_mini keptAny original rows linelist_mini “Military Hospital” duplicated matched two rows secondary data frame, combinations returnedThe join identifier column secondary dataset (hosp_name) disappeared redundant identifier column primary dataset (hospital)baseline row match secondary row (e.g. hospital “” “Missing”), NA (blank) fills columns secondary data frameRows secondary data frame match baseline data frame (“sisters” “ignace” hospitals) dropped","code":"\nlinelist_mini %>% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-matching.html","id":"should-i-use-a-right-join-or-a-left-join","chapter":"14 Nối dữ liệu","heading":"“Should I use a right join, or a left join?”","text":"answer question, ask “data frame retain rows?” - use one baseline. left join keep rows first data frame written command, whereas right join keeps rows second data frame.two commands achieve output - 10 rows hosp_info joined linelist_mini baseline, use different joins. result column order differ based whether hosp_info arrives right (left join) arrives left (right join). order rows may also shift accordingly. consequences can subsequently addressed, using select() re-order columns arrange() sort rows.result hosp_info linelist_mini via left join (new columns incoming right)result hosp_info linelist_mini via right join (new columns incoming left)Also consider whether use-case within pipe chain (%>%). dataset pipes baseline, likely use left join add data .","code":"\n# The two commands below achieve the same data, but with differently ordered rows and columns\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-matching.html","id":"full-join","chapter":"14 Nối dữ liệu","heading":"Full join","text":"full join inclusive joins - returns rows data frames.rows present one (match found), data frame include become longer. NA missing values used fill-gaps created. join, watch number columns rows carefully troubleshoot case-sensitivity exact character matches.“baseline” data frame one written first command. Adjustment impact records returned join, can impact resulting column order, row order, identifier columns retained.Animated example full join (image source)ExampleBelow output full_join() hosp_info (originally nrow(hosp_info), view ) linelist_mini (originally nrow(linelist_mini), view ). Note following:baseline rows kept (linelist_mini)Rows secondary match baseline kept (“ignace” “sisters”), values corresponding baseline columns case_id onset filled missing valuesLikewise, rows baseline data frame match secondary (“” “Missing”) kept, secondary columns catchment_pop level filled-missing valuesIn case one--many many--one matches (e.g. rows “Military Hospital”), possible combinations returned (lengthening final data frame)identifier column baseline kept (hospital)","code":"\nlinelist_mini %>% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-matching.html","id":"inner-join","chapter":"14 Nối dữ liệu","heading":"Inner join","text":"inner join restrictive joins - returns rows matches across data frames.\nmeans number rows baseline data frame may actually reduce. Adjustment data frame “baseline” (written first function) impact rows returned, impact column order, row order, identifier columns retained.Animated example inner join (image source)ExampleBelow output inner_join() linelist_mini (baseline) hosp_info (secondary). Note following:Baseline rows match secondary data removed (rows hospital “Missing” “”)Likewise, rows secondary data frame match baseline removed (rows hosp_name “sisters” “ignace”)identifier column baseline kept (hospital)","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-matching.html","id":"semi-join","chapter":"14 Nối dữ liệu","heading":"Semi join","text":"semi join “filtering join” uses another dataset add rows columns, perform filtering.semi-join keeps observations baseline data frame match secondary data frame (add new columns duplicate rows multiple matches). Read “filtering” joins .Animated example semi join (image source)example, code returns rows hosp_info data frame matches linelist_mini based hospital name.","code":"\nhosp_info %>% \n  semi_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))##                              hosp_name catchment_pop     level\n## 1                    Military Hospital         40500 Secondary\n## 2                    Military Hospital         10000   Primary\n## 3                        Port Hospital         50280 Secondary\n## 4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary"},{"path":"joining-matching.html","id":"anti-join","chapter":"14 Nối dữ liệu","heading":"Anti join","text":"anti join another “filtering join” returns rows baseline data frame match secondary data frame.Read filtering joins .Common scenarios anti-join include identifying records present another data frame, troubleshooting spelling join (reviewing records matched), examining records excluded another join.right_join() left_join(), baseline data frame (listed first) important. returned rows baseline data frame . Notice gif row secondary data frame (purple row 4) returned even though match baseline.Animated example anti join (image source)","code":""},{"path":"joining-matching.html","id":"simple-anti_join-example","chapter":"14 Nối dữ liệu","heading":"Simple anti_join() example","text":"simple example, let’s find hosp_info hospitals cases present linelist_mini. list hosp_info first, baseline data frame. hospitals present linelist_mini returned.","code":"\nhosp_info %>% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-matching.html","id":"complex-anti_join-example","chapter":"14 Nối dữ liệu","heading":"Complex anti_join() example","text":"another example, let us say ran inner_join() linelist_mini hosp_info. returns subset original linelist_mini records, present hosp_info.review linelist_mini records excluded inner join, can run anti-join settings (linelist_mini baseline).see hosp_info records excluded inner join, also run anti-join hosp_info baseline data frame.","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nlinelist_mini %>% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-matching.html","id":"probabalistic-matching","chapter":"14 Nối dữ liệu","heading":"14.3 Probabalistic matching","text":"unique identifier common across datasets join , consider using probabilistic matching algorithm. find matches records based similarity (e.g. Jaro–Winkler string distance, numeric distance). simple example using package fastLink .Load packagesHere two small example datasets use demonstrate probabilistic matching (cases test_results):code used make datasets:cases dataset 9 records patients awaiting test results.test_results dataset 14 records contains column result, want add records cases based probabilistic matching records.","code":"\npacman::p_load(\n  tidyverse,      # data manipulation and visualization\n  fastLink        # record matching\n  )\n# make datasets\n\ncases <- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults <- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )"},{"path":"joining-matching.html","id":"probabilistic-matching","chapter":"14 Nối dữ liệu","heading":"Probabilistic matching","text":"fastLink() function fastLink package can used apply matching algorithm. basic information. can read detail entering ?fastLink console.Define two data frames comparison arguments dfA = dfB =varnames = give column names used matching. must exist dfA dfB.stringdist.match = give columns varnames evaluated string “distance”.numeric.match = give columns varnames evaluated numeric distance.Missing values ignoredBy default, row either data frame matched one row data frame. want see evaluated matches, set dedupe.matches = FALSE. deduplication done using Winkler’s linear assignment solution.Tip: split one date column three separate numeric columns using day(), month(), year() lubridate packageThe default threshold matches 0.94 (threshold.match =) can adjust higher lower. define threshold, consider higher thresholds yield false-negatives (rows match actually match) likewise lower threshold yield false-positive matches., data matched string distance across name district columns, numeric distance year, month, day birth. match threshold 95% probability set.Review matchesWe defined object returned fastLink() fl_output. class list, actually contains several data frames within , detailing results matching. One data frames matches, contains likely matches across cases results. can access “matches” data frame fl_output$matches. , saved my_matches ease accessing later.my_matches printed, see two column vectors: pairs row numbers/indices (also called “rownames”) cases (“inds.”) results (“inds.b”) representing best matches. row number datafrane missing, match found data frame specified match threshold.Things note:Matches occurred despite slight differences name spelling dates birth:\n“Tony B. Smith” matched “Anthony B Smith”\n“Maria Rodriguez” matched “Marialisa Rodrigues”\n“Betty Chase” matched “Elizabeth Chase”\n“Olivier Laurent De Bordeaux” matched “Oliver Laurent De Bordow” (missing date birth ignored)\n“Tony B. Smith” matched “Anthony B Smith”“Maria Rodriguez” matched “Marialisa Rodrigues”“Betty Chase” matched “Elizabeth Chase”“Olivier Laurent De Bordeaux” matched “Oliver Laurent De Bordow” (missing date birth ignored)One row cases (“Blessing Adebayo”, row 9) good match results, present my_matches.Join based probabilistic matchesTo use matches join results cases, one strategy :Use left_join() join my_matches cases (matching rownames cases “inds.” my_matches)use another left_join() join results cases (matching newly-acquired “inds.b” cases rownames results)joins, clean three data frames:dfA dfB row numbers (“rowname”) converted proper column.columns my_matches converted class character, can joined character rownamesAs performed using code , resulting data frame complete contain columns cases results. Many appended suffixes “.x” “.y”, column names otherwise duplicated.Alternatively, achieve “original” 9 records cases new column(s) results, use select() results joins, contains rownames columns want add cases (e.g. column result).want subset either dataset rows matched, can use codes :, see rows match:","code":"\nfl_output <- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\n## Deduping the estimated matches.\n## Getting the match patterns for each estimated match.\n# print matches\nmy_matches <- fl_output$matches\nmy_matches##   inds.a inds.b\n## 1      1      1\n## 2      2      2\n## 3      3      3\n## 4      4      4\n## 5      8      8\n## 6      7      9\n## 7      6     10\n## 8      5     12\n# Clean data prior to joining\n#############################\n\n# convert cases rownames to a column \ncases_clean <- cases %>% rownames_to_column()\n\n# convert test_results rownames to a column\nresults_clean <- results %>% rownames_to_column()  \n\n# convert all columns in matches dataset to character, so they can be joined to the rownames\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n\n\n# Join matches to dfA, then add dfB\n###################################\n# column \"inds.b\" is added to dfA\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# column(s) from dfB are added \ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_clean <- cases %>% rownames_to_column()\n\nresults_clean <- results %>%\n  rownames_to_column() %>% \n  select(rowname, result)    # select only certain columns \n\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n# joins\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_matched <- cases[my_matches$inds.a,]  # Rows in cases that matched to a row in results\nresults_matched <- results[my_matches$inds.b,]  # Rows in results that matched to a row in cases\ncases_not_matched <- cases[!rownames(cases) %in% my_matches$inds.a,]  # Rows in cases that did NOT match to a row in results\nresults_not_matched <- results[!rownames(results) %in% my_matches$inds.b,]  # Rows in results that did NOT match to a row in cases"},{"path":"joining-matching.html","id":"probabilistic-deduplication","chapter":"14 Nối dữ liệu","heading":"Probabilistic deduplication","text":"Probabilistic matching can used deduplicate dataset well. See page deduplication methods deduplication.began cases dataset, now calling cases_dup, 2 additional rows duplicates previous rows:\nSee “Tony” “Anthony”, “Marialisa Rodrigues” “Maria Rodriguez”.Run fastLink() like , compare cases_dup data frame . two data frames provided identical, function assumes want de-duplicate. Note specify stringdist.match = numeric.match = previously.Now, can review potential duplicates getMatches(). Provide data frame dfA = dfB =, provide output fastLink() function fl.=. fl.must class fastLink.dedupe, words, result fastLink().See right-column, indicates duplicate IDs - final two rows identified likely duplicates rows 2 3.return row numbers rows likely duplicates, can count number rows per unique value dedupe.ids column, filter keep one row. case leaves rows 2 3.inspect whole rows likely duplicates, put row number command:","code":"\n## Run fastLink on the same dataset\ndedupe_output <- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## dfA and dfB are identical, assuming deduplication of a single data set.\n## Setting return.all to FALSE.\n## \n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\n## Calculating the posterior for each pair of matched observations.\n## Getting the match patterns for each estimated match.\n## Run getMatches()\ncases_dedupe <- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\ncases_dedupe %>% \n  count(dedupe.ids) %>% \n  filter(n > 1)##   dedupe.ids n\n## 1          2 2\n## 2          3 2\n# displays row 2 and all likely duplicates of it\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   ##    gender   first middle  last   yr mon day district dedupe.ids\n## 2       M Anthony     B. Smith 1970   9  19    River          2\n## 10      M    Tony     B. Smith 1970   9  19    River          2"},{"path":"joining-matching.html","id":"binding-and-aligning","chapter":"14 Nối dữ liệu","heading":"14.4 Binding and aligning","text":"Another method combining two data frames “binding” together. can also think “appending” “adding” rows columns.section also discuss “align” order rows one data frame order another data frame. topic discussed section Binding columns.","code":""},{"path":"joining-matching.html","id":"bind-rows-1","chapter":"14 Nối dữ liệu","heading":"Bind rows","text":"bind rows one data frame bottom another data frame, use bind_rows() dplyr. inclusive, column present either data frame included output. notes:Unlike base R version row.bind(), dplyr’s bind_rows() require order columns data frames. long column names spelled identically, align correctly.can optionally specify argument .id =. Provide character column name. produce new column serves identify data frame row originally came .can use bind_rows() list similarly-structured data frames combine one data frame. See example [Iteration, loops, lists] page involving import multiple linelists purrr.One common example row binding bind “total” row onto descriptive table made dplyr’s summarise() function. create table case counts median CT values hospital total row.function summarise() used data grouped hospital return summary data frame hospital. function summarise() automatically produce “totals” row, create summarising data , data grouped hospital. produces second data frame just one row. can bind data frames together achieve final table.See worked examples like [Descriptive tables] [Tables presentation] pages.hosp_summary data frame:Create data frame “total” statistics (grouped hospital). return just one row.totals data frame. Note two columns. columns also hosp_summary, one column hosp_summary totals (hospital).Now can bind rows together bind_rows().Now can view result. See final row, empty NA value fills column hospital hosp_summary. explained [Tables presentation] page, “fill-” cell “Total” using replace_na().","code":"\n# Create core table\n###################\nhosp_summary <- linelist %>% \n  group_by(hospital) %>%                        # Group data by hospital\n  summarise(                                    # Create new summary columns of indicators of interest\n    cases = n(),                                  # Number of rows per hospital-outcome group     \n    ct_value_med = median(ct_blood, na.rm=T))     # median CT value per group\n# create totals\n###############\ntotals <- linelist %>% \n  summarise(\n    cases = n(),                               # Number of rows for whole dataset     \n    ct_value_med = median(ct_blood, na.rm=T))  # Median CT for whole dataset\n# Bind data frames together\ncombined <- bind_rows(hosp_summary, totals)"},{"path":"joining-matching.html","id":"bind-columns","chapter":"14 Nối dữ liệu","heading":"Bind columns","text":"similar dplyr function bind_cols() can use combine two data frames sideways. Note rows matched position (like join ) - example 12th row data frame aligned.example, bind several summary tables together. order , also demonstrate re-arrange order rows one data frame match order another data frame, match().define case_info summary data frame linelist cases, hospital, number cases number deaths.let’s say different data frame contact_fu containing information percent exposed contacts investigated “followed-”, hospital.Note hospitals , different orders data frame. easiest solution use left_join() hospital column, also use bind_cols() one extra step.","code":"\n# Case information\ncase_info <- linelist %>% \n  group_by(hospital) %>% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\ncontact_fu <- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)"},{"path":"joining-matching.html","id":"use-match-to-align-ordering","chapter":"14 Nối dữ liệu","heading":"Use match() to align ordering","text":"row orders different, simple bind_cols() command result mis-match data. fix can use match() base R align rows data frame order another. assume approach duplicate values either data frame.use match(), syntax match(TARGET ORDER VECTOR, DATA FRAME COLUMN CHANGE), first argument desired order (either stand-alone vector, case column data frame), second argument data frame column data frame re-ordered. output match() vector numbers representing correct position ordering. can read ?match.can use numeric vector re-order data frame - place within subset brackets [ ] comma. Read base R bracket subset syntax [R basics] page. command creates new data frame, defined old one rows ordered numeric vector .Now can bind data frame columns together, correct row order. Note columns duplicated require cleaning rename(). Read aboout bind_rows() .base R alternative bind_cols cbind(), performs operation.","code":"\nmatch(case_info$hospital, contact_fu$hospital)## [1] 4 2 3 6 5 1\ncontact_fu_aligned <- contact_fu[match(case_info$hospital, contact_fu$hospital),]\nbind_cols(case_info, contact_fu)## New names:\n## * hospital -> hospital...1\n## * hospital -> hospital...4## # A tibble: 6 x 6\n##   hospital...1                cases deaths hospital...4                investigated per_fu\n##   <chr>                       <int>  <int> <chr>                       <chr>        <chr> \n## 1 Central Hospital              454    193 St. Mark's Maternity Hospi~ 80%          60%   \n## 2 Military Hospital             896    399 Military Hospital           82%          25%   \n## 3 Missing                      1469    611 Missing                     <NA>         <NA>  \n## 4 Other                         885    395 Central Hospital            78%          20%   \n## 5 Port Hospital                1762    785 Port Hospital               64%          75%   \n## 6 St. Mark's Maternity Hospi~   422    199 Other                       55%          80%"},{"path":"joining-matching.html","id":"resources-4","chapter":"14 Nối dữ liệu","heading":"14.5 Resources","text":"tidyverse page joinsThe R Data Science page relational dataTh tidyverse page dplyr bindingA vignette fastLink package’s Github pagePublication describing methodology fastLinkPublication describing RecordLinkage package","code":""},{"path":"deduplication.html","id":"deduplication","chapter":"15 Loại bỏ trùng lặp","heading":"15 Loại bỏ trùng lặp","text":"page covers following de-duplication techniques:Identifying removing duplicate rows“Slicing” rows keep certain rows (e.g. min max) group rows“Rolling-”, combining values multiple rows one row","code":""},{"path":"deduplication.html","id":"preparation-5","chapter":"15 Loại bỏ trùng lặp","heading":"15.1 Preparation","text":"","code":""},{"path":"deduplication.html","id":"load-packages-6","chapter":"15 Loại bỏ trùng lặp","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  tidyverse,   # deduplication, grouping, and slicing functions\n  janitor,     # function for reviewing duplicates\n  stringr)      # for string searches, can be used in \"rolling-up\" values"},{"path":"deduplication.html","id":"import-data-6","chapter":"15 Loại bỏ trùng lặp","heading":"Import data","text":"demonstration, use example dataset created R code .data records COVID-19 phone encounters, including encounters contacts cases. columns include recordID (computer-generated), personID, name, date encounter, time encounter, purpose encounter (either interview case contact), symptoms_ever (whether person encounter reported ever symptoms).code create obs dataset:","code":"\nobs <- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %>% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))"},{"path":"deduplication.html","id":"dedup_data","chapter":"15 Loại bỏ trùng lặp","heading":"Here is the data frame","text":"Use filter boxes along top review encounters person.things note review data:first two records 100% complete duplicates including duplicate recordID (must computer glitch!)second two rows duplicates, columns except recordIDSeveral people multiple phone encounters, various dates times, contacts /casesAt encounter, person asked ever symptoms, information missing.quick summary people purposes encounters, using tabyl() janitor:","code":"\nobs %>% \n  tabyl(name, purpose)##     name case contact\n##     adam    1       2\n##   amrish    1       3\n##    brian    1       2\n##   mariah    1       2\n##  natalie    1       0\n##   nikhil    0       2\n##   raquel    0       2\n##    smita    0       1"},{"path":"deduplication.html","id":"deduplication-1","chapter":"15 Loại bỏ trùng lặp","heading":"15.2 Deduplication","text":"section describes review remove duplicate rows data frame. also show handle duplicate elements vector.","code":""},{"path":"deduplication.html","id":"examine-duplicate-rows","chapter":"15 Loại bỏ trùng lặp","heading":"Examine duplicate rows","text":"quickly review rows duplicates, can use get_dupes() janitor package. default, columns considered duplicates evaluated - rows returned function 100% duplicates considering values columns.obs data frame, first two rows 100% duplicates - value every column (including recordID column, supposed unique - must computer glitch). returned data frame automatically includes new column dupe_count right side, showing number rows combination duplicate values.See original dataHowever, choose ignore recordID, 3rd 4th rows rows also duplicates . , values columns except recordID. can specify specific columns ignored function using - minus symbol.can also positively specify columns consider. , rows values name purpose columns returned. Notice “amrish” now dupe_count equal 3 reflect three “contact” encounters.*Scroll left rows**See original data.See ?get_dupes details, see online reference","code":"\n# 100% duplicates across all columns\nobs %>% \n  janitor::get_dupes()\n# Duplicates when column recordID is not considered\nobs %>% \n  janitor::get_dupes(-recordID)         # if multiple columns, wrap them in c()\n# duplicates based on name and purpose columns ONLY\nobs %>% \n  janitor::get_dupes(name, purpose)"},{"path":"deduplication.html","id":"keep-only-unique-rows","chapter":"15 Loại bỏ trùng lặp","heading":"Keep only unique rows","text":"keep unique rows data frame, use distinct() dplyr (demonstrated [Cleaning data core functions] page). Rows duplicates removed first rows kept. default, “first” means highest rownumber (order rows top--bottom). unique rows remain.example , run distinct() column recordID excluded consideration - thus two duplicate rows removed. first row (“adam”) 100% duplicated removed. Also row 3 (“amrish”) duplicate every column except recordID (considered) also removed. obs dataset n now nrow(obs)-2, nrow(obs) rows).Scroll left see entire data frameCAUTION: using distinct() grouped data, function apply group.Deduplicate based specific columnsYou can also specify columns basis de-duplication. way, de-duplication applies rows duplicates within specified columns. Unless set .keep_all = TRUE, columns mentioned dropped.example , de-duplication applies rows identical values name purpose columns. Thus, “brian” 2 rows instead 3 - first “contact” encounter “case” encounter. adjust brian’s latest encounter purpose kept, see tab Slicing within groups.Scroll left see entire data frameSee original data.","code":"\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(across(-recordID), # reduces data frame to only unique rows (keeps first one of any duplicates)\n           .keep_all = TRUE) \n\n# if outside pipes, include the data as first argument \n# distinct(obs)\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns\n  arrange(name)                                  # arrange for easier viewing"},{"path":"deduplication.html","id":"deduplicate-elements-in-a-vector","chapter":"15 Loại bỏ trùng lặp","heading":"Deduplicate elements in a vector","text":"function duplicated() base R evaluate vector (column) return logical vector length (TRUE/FALSE). first time value appears, return FALSE (duplicate), subsequent times value appears return TRUE. Note NA treated value.return duplicated elements, can use brackets subset original vector:return unique elements, use unique() base R. remove NAs output, nest na.omit() within unique().","code":"\nx <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)##  [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\nx[duplicated(x)]## [1]  1 NA  4  4  1  2\nunique(x)           # alternatively, use x[!duplicated(x)]## [1]  1  2 NA  4  5\nunique(na.omit(x))  # remove NAs ## [1] 1 2 4 5"},{"path":"deduplication.html","id":"using-base-r-1","chapter":"15 Loại bỏ trùng lặp","heading":"Using base R","text":"return duplicate rowsIn base R, can also see rows 100% duplicates data frame df command duplicated(df) (returns logical vector rows).Thus, can also use base subset [ ] data frame see duplicated rows df[duplicated(df),] (don’t forget comma, meaning want see columns!).return unique rowsSee notes . see unique rows add logical negator ! front duplicated() function:df[!duplicated(df),]return rows duplicates certain columnsSubset df within duplicated() parentheses, function operate certain columns df.specify columns, provide column numbers names comma (remember, within duplicated() function).sure keep comma , outside duplicated() function well!example, evaluate columns 2 5 duplicates: df[!duplicated(df[, 2:5]),]\nevaluate columns name purpose duplicates: df[!duplicated(df[, c(\"name\", \"purpose)]),]","code":""},{"path":"deduplication.html","id":"slicing","chapter":"15 Loại bỏ trùng lặp","heading":"15.3 Slicing","text":"“slice” data frame apply filter rows row number/position. becomes particularly useful multiple rows per functional group (e.g. per “person”) want keep one .basic slice() function accepts numbers returns rows positions. numbers provided positive, returned. negative, rows returned. Numbers must either positive negative.See original data.several variations: provided column number rows return (n =).slice_min() slice_max() keep row(s) minimium maximum value(s) specified column. also works return “min” “max” ordered factors.slice_head() slice_tail() - keep first last row(s).slice_sample() - keep random sample rows.Use arguments n = prop = specify number proportion rows keep. using function pipe chain, provide data argument first (e.g. slice(data, n = 2)). See ?slice information.arguments:.order_by = used slice_min() slice_max() column order slicing.with_ties = TRUE default, meaning ties kept..preserve = FALSE default. TRUE grouping structure re-calculated slicing.weight_by = Optional, numeric column weight (bigger number likely get sampled). Also replace = whether sampling done /without replacement.TIP: using slice_max() slice_min(), sure specify/write n = (e.g. n = 2, just 2). Otherwise may get error Error:…empty. NOTE: may encounter function top_n(), superseded slice functions.","code":"\nobs %>% slice(4)  # return the 4th row##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        3        2 amrish 2020-01-02 14:20         1 contact            No\nobs %>% slice(c(2,4))  # return rows 2 and 4##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        1        1   adam 2020-01-01 09:00         1 contact          <NA>\n## 2        3        2 amrish 2020-01-02 14:20         1 contact            No\n#obs %>% slice(c(2:4))  # return rows 2 through 4\nobs %>% slice_max(encounter, n = 1)  # return rows with the largest encounter number##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n## 2       13        3 mariah 2020-01-06 08:32         3 contact            No\n## 3       16        5  brian 2020-01-07 07:59         3    case            No"},{"path":"deduplication.html","id":"slice-with-groups","chapter":"15 Loại bỏ trùng lặp","heading":"Slice with groups","text":"slice_*() functions can useful applied grouped data frame slice operation performed group separately. Use function group_by() conjunction slice() group data take slice group.helpful de-duplication multiple rows per person want keep one . first use group_by() key columns per person, use slice function column differ among grouped rows.example , keep latest encounter per person, group rows name use slice_max() n = 1 date column. aware! apply function like slice_max() dates, date column must class Date.default, “ties” (e.g. date scenario) kept, still get multiple rows people (e.g. adam). avoid set with_ties = FALSE. get back one row per person.CAUTION: using arrange(), specify .by_group = TRUE data arranged within group.DANGER: with_ties = FALSE, first row tie kept. may deceptive. See Mariah, two encounters latest date (6 Jan) first (earliest) one kept. Likely, want keep later encounter day. See “break” ties next example. , example can see Amrish’s row 5 Jan kept, Brian’s row 7 Jan kept. See original data.Breaking “ties”Multiple slice statements can run “break ties”. case, person multiple encounters latest date, encounter latest time kept (lubridate::hm() used convert character times sortable time class).\nNote now, one row kept “Mariah” 6 Jan encounter 3 08:32, encounter 2 07:25.example , also possible slice encounter number, showed slice date time example purposes.TIP: use slice_max() slice_min() “character” column, mutate ordered factor class!See original data.","code":"\nobs %>% \n  group_by(name) %>%       # group the rows by 'name'\n  slice_max(date,          # keep row per group with maximum date value \n            n = 1,         # keep only the single highest row \n            with_ties = F) # if there's a tie (of date), take the first row\n# Example of multiple slice statements to \"break ties\"\nobs %>%\n  group_by(name) %>%\n  \n  # FIRST - slice by latest date\n  slice_max(date, n = 1, with_ties = TRUE) %>% \n  \n  # SECOND - if there is a tie, select row with latest time; ties prohibited\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)"},{"path":"deduplication.html","id":"keep-all-but-mark-them","chapter":"15 Loại bỏ trùng lặp","heading":"Keep all but mark them","text":"want keep records mark analysis, consider two-step approach utilizing unique recordID/encounter number:Reduce/slice orginal data frame rows analysis. Save/retain reduced data frame.original data frame, mark rows appropriate case_when(), based whether record unique identifier (recordID example) present reduced data frame.See original data.","code":"\n# 1. Define data frame of rows to keep for analysis\nobs_keep <- obs %>%\n  group_by(name) %>%\n  slice_max(encounter, n = 1, with_ties = FALSE) # keep only latest encounter per person\n\n\n# 2. Mark original data frame\nobs_marked <- obs %>%\n\n  # make new dup_record column\n  mutate(dup_record = case_when(\n    \n    # if record is in obs_keep data frame\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # all else marked as \"Ignore\" for analysis purposes\n    TRUE                            ~ \"Ignore\"))\n\n# print\nobs_marked##    recordID personID    name       date  time encounter purpose symptoms_ever\n## 1         1        1    adam 2020-01-01 09:00         1 contact          <NA>\n## 2         1        1    adam 2020-01-01 09:00         1 contact          <NA>\n## 3         2        2  amrish 2020-01-02 14:20         1 contact            No\n## 4         3        2  amrish 2020-01-02 14:20         1 contact            No\n## 5         4        3  mariah 2020-01-05 12:00         1    case            No\n## 6         5        2  amrish 2020-01-05 16:10         3    case           Yes\n## 7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes\n## 8         7        5   brian 2020-01-05 15:20         1 contact            No\n## 9         8        6   smita 2020-01-05 14:20         1 contact           Yes\n## 10        9        7  raquel 2020-01-05 12:30         1 contact          <NA>\n## 11       10        2  amrish 2020-01-02 10:24         2 contact           Yes\n## 12       11        1    adam 2020-01-05 09:40         2    case            No\n## 13       12        3  mariah 2020-01-06 07:25         2 contact            No\n## 14       13        3  mariah 2020-01-06 08:32         3 contact            No\n## 15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes\n## 16       15        5   brian 2020-01-06 15:31         2 contact           Yes\n## 17       16        5   brian 2020-01-07 07:59         3    case            No\n## 18       17        7  raquel 2020-01-07 11:13         2 contact            No\n## 19       18        8 natalie 2020-01-07 17:12         1    case            No\n##      dup_record\n## 1        Ignore\n## 2        Ignore\n## 3        Ignore\n## 4        Ignore\n## 5        Ignore\n## 6  For analysis\n## 7        Ignore\n## 8        Ignore\n## 9  For analysis\n## 10       Ignore\n## 11       Ignore\n## 12 For analysis\n## 13       Ignore\n## 14 For analysis\n## 15 For analysis\n## 16       Ignore\n## 17 For analysis\n## 18 For analysis\n## 19 For analysis"},{"path":"deduplication.html","id":"calculate-row-completeness","chapter":"15 Loại bỏ trùng lặp","heading":"Calculate row completeness","text":"Create column contains metric row’s completeness (non-missingness). helpful deciding rows prioritize others de-duplicating/slicing.example, “key” columns want measure completeness saved vector column names.new column key_completeness created mutate(). new value row defined calculated fraction: number non-missing values row among key columns, divided number key columns.involves function rowSums() base R. Also used ., within piping refers data frame point pipe (case, subset brackets []).*Scroll right see rows**See original data.","code":"\n# create a \"key variable completeness\" column\n# this is a *proportion* of the columns designated as \"key_cols\" that have non-missing values\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %>% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) "},{"path":"deduplication.html","id":"str_rollup","chapter":"15 Loại bỏ trùng lặp","heading":"15.4 Roll-up values","text":"section describes:“roll-” values multiple rows just one row, variationsOnce “rolled-” values, overwrite/prioritize values cellThis tab uses example dataset Preparation tab.","code":""},{"path":"deduplication.html","id":"roll-up-values-into-one-row","chapter":"15 Loại bỏ trùng lặp","heading":"Roll-up values into one row","text":"code example uses group_by() summarise() group rows person, paste together unique values within grouped rows. Thus, get one summary row per person. notes:suffix appended new columns (\"_roll\" example)want show unique values per cell, wrap na.omit() unique()na.omit() removes NA values, desired can removed paste0(.x)…result one row per group (ID), entries arranged date pasted together. Scroll left see rowsSee original data.variation shows unique values :variation appends suffix column.\ncase \"_roll\" signify rolled:","code":"\n# \"Roll-up\" values into one row per group (per \"personID\") \ncases_rolled <- obs %>% \n  \n  # create groups by name\n  group_by(personID) %>% \n  \n  # order the rows within each group (e.g. by date)\n  arrange(date, .by_group = TRUE) %>% \n  \n  # For each column, paste together all values within the grouped rows, separated by \";\"\n  summarise(\n    across(everything(),                           # apply to all columns\n           ~paste0(na.omit(.x), collapse = \"; \"))) # function is defined which combines non-NA values\n# Variation - show unique values only \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                                   # apply to all columns\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # function is defined which combines unique non-NA values\n# Variation - suffix added to column names \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll is appended to column names"},{"path":"deduplication.html","id":"overwrite-valueshierarchy","chapter":"15 Loại bỏ trùng lặp","heading":"Overwrite values/hierarchy","text":"want evaluate rolled values, keep specific value (e.g. “best” “maximum” value), can use mutate() across desired columns, implement case_when(), uses str_detect() stringr package sequentially look string patterns overwrite cell content.Now can see column symptoms_ever person EVER said “Yes” symptoms, “Yes” displayed.See original data.","code":"\n# CLEAN CASES\n#############\ncases_clean <- cases_rolled %>% \n    \n    # clean Yes-No-Unknown vars: replace text with \"highest\" value present in the string\n    mutate(across(c(contains(\"symptoms_ever\")),                     # operates on specified columns (Y/N/U)\n             list(mod = ~case_when(                                 # adds suffix \"_mod\" to new cols; implements case_when()\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # if \"Yes\" is detected, then cell value converts to yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # then, if \"No\" is detected, then cell value converts to no\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # then, if \"Unknown\" is detected, then cell value converts to Unknown\n               TRUE                        ~ as.character(.x)))),   # then, if anything else if it kept as is\n      .keep = \"unused\")                                             # old columns removed, leaving only _mod columns"},{"path":"deduplication.html","id":"probabilistic-de-duplication","chapter":"15 Loại bỏ trùng lặp","heading":"15.5 Probabilistic de-duplication","text":"Sometimes, may want identify “likely” duplicates based similarity (e.g. string “distance”) across several columns name, age, sex, date birth, etc. can apply probabilistic matching algorithm identify likely duplicates.See page [Joining data] explanation method. section Probabilistic Matching contains example applying algorithms compare data frame , thus performing probabilistic de-duplication.","code":""},{"path":"deduplication.html","id":"resources-5","chapter":"15 Loại bỏ trùng lặp","heading":"15.6 Resources","text":"Much information page adapted resources vignettes online:datanoviadplyr tidyverse referencecran janitor vignette","code":""},{"path":"iteration.html","id":"iteration","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"16 Lặp, vòng lặp, và danh sách","text":"Epidemiologists often faced repeating analyses subgroups countries, districts, age groups. many situations involving iteration. Coding iterative operations using approaches help perform repetitive tasks faster, reduce chance error, reduce code length.page introduce two approaches iterative operations - using loops using package purrr.loops iterate code across series inputs, less common R programming languages. Nevertheless, introduce learning tool referenceThe purrr package tidyverse approach iterative operations - works “mapping” function across many inputs (values, columns, datasets, etc.)Along way, ’ll show examples like:Importing exporting multiple filesCreating epicurves multiple jurisdictionsRunning T-tests several columns data frameIn purrr section also provide several examples creating handling lists.","code":""},{"path":"iteration.html","id":"chuẩn-bị-1","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"16.1 Chuẩn bị","text":"","code":""},{"path":"iteration.html","id":"load-packages-7","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n     rio,         # import/export\n     here,        # file locator\n     purrr,       # iteration\n     tidyverse    # data management and visualization\n)"},{"path":"iteration.html","id":"import-data-7","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"iteration.html","id":"for-loops","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"16.2 for loops","text":"","code":""},{"path":"iteration.html","id":"iter_loops","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"for loops in R","text":"loops emphasized R, common programming languages. beginner, can helpful learn practice easier “explore”, “de-bug”, otherwise grasp exactly happening iteration, especially yet comfortable writing functions.may move quickly loops iterating mapped functions purrr (see section ).","code":""},{"path":"iteration.html","id":"core-components","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Core components","text":"loop three core parts:sequence items iterate throughThe operations conduct per item sequenceThe container results (optional)basic syntax : (item sequence) {operations using item}. Note parentheses curly brackets. results printed console, stored container R object.simple loop example .","code":"\nfor (num in c(1,2,3,4,5)) {  # the SEQUENCE is defined (numbers 1 to 5) and loop is opened with \"{\"\n  print(num + 2)             # The OPERATIONS (add two to each sequence number and print)\n}                            # The loop is closed with \"}\"                            ## [1] 3\n## [1] 4\n## [1] 5\n## [1] 6\n## [1] 7\n                             # There is no \"container\" in this example"},{"path":"iteration.html","id":"sequence","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Sequence","text":"“” part loop - operations run “” item sequence. sequence can series values (e.g. names jurisdictions, diseases, column names, list elements, etc), can series consecutive numbers (e.g. 1,2,3,4,5). approach utilities, described .basic structure sequence statement item vector.can write character word place “item” (e.g. “”, “num”, “hosp”, “district”, etc.). value “item” changes iteration loop, proceeding value vector.vector character values, column names, perhaps sequence numbers - values change iteration. can use within loop operations using “item” term.Example: sequence character valuesIn example, loop performed value pre-defined character vector hospital names.chosen term hosp represent values vector hospital_names. first iteration loop, value hosp hospital_names[[1]]. second loop hospital_names[[2]]. …Example: sequence column namesThis variation character sequence , names existing R object extracted become vector. example, column names data frame. Conveniently, operations code loop, column names can used index (subset) original data frameBelow, sequence names() (column names) linelist data frame. “item” name col, represent column name loops proceeds.purposes example, include operations code inside loop, run every value sequence. code, sequence values (column names) used index (subset) linelist, one---time. taught [R basics] page, double branckets [[ ]] used subset. resulting column passed .na(), sum() produce number values column missing. result printed console - one number column.note indexing column names - whenever referencing column just write “col”! col represents just character column name! refer entire column must use column name index linelist via linelist[[col]].Sequence numbersIn approach, sequence series consecutive numbers. Thus, value “item” character value (e.g. “Central Hospital” “date_onset”) number. useful looping data frames, can use “item” number inside loop index data frame row number.example, let’s say want loop every row data frame extract certain information. “items” numeric row numbers. Often, “items” case written .loop process explained words “every item sequence numbers 1 total number rows data frame, X”. first iteration loop, value “item” 1. second iteration, 2, etc.sequence looks like code: (1:nrow(linelist)) {OPERATIONS CODE} represents “item” 1:nrow(linelist) produces sequence consecutive numbers 1 number rows linelist.want sequence numbers, starting vector (data frame), use shortcut seq_along() return sequence numbers element vector. example, (seq_along(hospital_names) {OPERATIONS CODE}.code actually returns numbers, become value respective loop.One advantage using numbers sequence easy also use number index container stores loop outputs. example Operations section .","code":"\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\nhospital_names # print## [1] \"Other\"                                \"Missing\"                             \n## [3] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [5] \"Military Hospital\"                    \"Central Hospital\"\n# a 'for loop' with character sequence\n\nfor (hosp in hospital_names){       # sequence\n  \n       # OPERATIONS HERE\n  }\nfor (col in names(linelist)){        # loop runs for each column in linelist; column name represented by \"col\" \n  \n  # Example operations code - print number of missing values in column\n  print(sum(is.na(linelist[[col]])))  # linelist is indexed by current value of \"col\"\n     \n}## [1] 0\n## [1] 0\n## [1] 2087\n## [1] 256\n## [1] 0\n## [1] 936\n## [1] 1323\n## [1] 278\n## [1] 86\n## [1] 0\n## [1] 86\n## [1] 86\n## [1] 86\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 2088\n## [1] 2088\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 149\n## [1] 765\n## [1] 0\n## [1] 256\nfor (i in 1:nrow(linelist)) {  # use on a data frame\n  # OPERATIONS HERE\n}  \nseq_along(hospital_names)  # use on a named vector## [1] 1 2 3 4 5 6"},{"path":"iteration.html","id":"operations","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Operations","text":"code within curly brackets { } loop. want code run “item” sequence. Therefore, careful every part code changes “item” correctly coded actually changes! E.g. remember use [[ ]] indexing.example , iterate row linelist. gender age values row pasted together stored container character vector cases_demographics. Note also use indexing [[]] save loop output correct position “container” vector.","code":"\n# create container to store results - a character vector\ncases_demographics <- vector(mode = \"character\", length = nrow(linelist))\n\n# the for loop\nfor (i in 1:nrow(linelist)){\n  \n  # OPERATIONS\n  # extract values from linelist for row i, using brackets for indexing\n  row_gender  <- linelist$gender[[i]]\n  row_age     <- linelist$age_years[[i]]    # don't forget to index!\n     \n  # combine gender-age and store in container vector at indexed location\n  cases_demographics[[i]] <- str_c(row_gender, row_age, sep = \",\") \n\n}  # end for loop\n\n\n# display first 10 rows of container\nhead(cases_demographics, 10)##  [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\""},{"path":"iteration.html","id":"container","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Container","text":"Sometimes results loop printed console RStudio Plots pane. times, want store outputs “container” later use. container vector, data frame, even list.efficient create container results even beginning loop. practice, means creating empty vector, data frame, list. can created functions vector() vectors lists, matrix() data.frame() data frame.Empty vectorUse vector() specify mode = based expected class objects insert - either “double” (hold numbers), “character”, “logical”. also set length = advance. length loop sequence.Say want store median delay--admission hospital. use “double” set length number expected outputs (number unique hospitals data set).Empty data frameYou can make empty data frame specifying number rows columns like :Empty listYou may want store plots created loop list. list like vector, holds R objects within can different classes. Items list single number, dataframe, vector, even another list.actually initialize empty list using vector() command , mode = \"list\". Specify length however wish.","code":"\ndelays <- vector(\n  mode = \"double\",                            # we expect to store numbers\n  length = length(unique(linelist$hospital))) # the number of unique hospitals in the dataset\ndelays <- data.frame(matrix(ncol = 2, nrow = 3))\nplots <- vector(mode = \"list\", length = 16)"},{"path":"iteration.html","id":"printing","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Printing","text":"Note print within loop likely need explicitly wrap function print().example , sequence explicit character vector, used subset linelist hospital. results stored container, rather printed console print() function.","code":"\nfor (hosp in hospital_names){ \n     hospital_cases <- linelist %>% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}## [1] 885\n## [1] 1469\n## [1] 422\n## [1] 1762\n## [1] 896\n## [1] 454"},{"path":"iteration.html","id":"testing-your-for-loop","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Testing your for loop","text":"test loop, can run command make temporary assignment “item”, <- 10 hosp <- \"Central Hospital\". outside loop run operations code (code within curly brackets) see expected results produced.","code":""},{"path":"iteration.html","id":"looping-plots","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Looping plots","text":"put three components together (container, sequence, operations) let’s try plot epicurve hospital (see page [Epidemic curves]).can make nice epicurve cases gender using incidence2 package :produce separate plot hospital’s cases, can put epicurve code within loop.First, save named vector unique hospital names, hospital_names. loop run names: (hosp hospital_names). iteration loop, current hospital name vector represented hosp use within loop.Within loop operations, can write R code normal, use “item” (hosp case) knowing value changing. Within loop:filter() applied linelist, column hospital must equal current value hospThe incidence object created filtered linelistThe plot current hospital created, auto-adjusting title uses hospThe plot current hospital temporarily saved printedThe loop moves onward repeat next hospital hospital_names","code":"\n# create 'incidence' object\noutbreak <- incidence2::incidence(   \n     x = linelist,                   # dataframe - complete linelist\n     date_index = date_onset,        # date column\n     interval = \"week\",              # aggregate counts weekly\n     groups = gender,                # group values by gender\n     na_as_group = TRUE)             # missing gender is own group\n\n# plot epi curve\nplot(outbreak,                       # name of incidence object\n     fill = \"gender\",                # color bars by gender\n     color = \"black\",                # outline color of bars\n     title = \"Outbreak of ALL cases\" # title\n     )\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\n\n# for each name (\"hosp\") in hospital_names, create and print the epi curve\nfor (hosp in hospital_names) {\n     \n     # create incidence object specific to the current hospital\n     outbreak_hosp <- incidence2::incidence(\n          x = linelist %>% filter(hospital == hosp),   # linelist is filtered to the current hospital\n          date_index = date_onset,\n          interval = \"week\", \n          groups = gender,\n          na_as_group = TRUE\n     )\n     \n     # Create and save the plot. Title automatically adjusts to the current hospital\n     plot_hosp <- plot(\n       outbreak_hosp,\n       fill = \"gender\",\n       color = \"black\",\n       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n     )\n     \n     # print the plot for the current hospital\n     print(plot_hosp)\n     \n} # end the for loop when it has been run for every hospital in hospital_names "},{"path":"iteration.html","id":"tracking-progress-of-a-loop","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Tracking progress of a loop","text":"loop many iterations can run many minutes even hours. Thus, can helpful print progress R console. statement can placed within loop operations print every 100th number. Just adjust “item” loop.","code":"# loop with code to print progress every 100 iterations\nfor (i in seq_len(nrow(linelist))){\n\n  # print progress\n  if(i %% 100==0){    # The %% operator is the remainder\n    print(i)\n\n}"},{"path":"iteration.html","id":"iter_purrr","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"16.3 purrr and lists","text":"Another approach iterative operations purrr package - tidyverse approach iteration.faced performing task several times, probably worth creating generalised solution can use across many inputs. example, producing plots multiple jurisdictions, importing combining many files.also advantages purrr - can use pipes %>%, handles errors better normal loops, syntax quite clean simple! using loop, can probably clearly succinctly purrr!Keep mind purrr functional programming tool. , operations iteratively applied wrapped functions. See [Writing functions] page learn write functions.purrr also almost entirely based around lists vectors - think applying function element list/vector!","code":""},{"path":"iteration.html","id":"load-packages-8","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Load packages","text":"purrr part tidyverse, need install/load separate package.","code":"\npacman::p_load(\n     rio,            # import/export\n     here,           # relative filepaths\n     tidyverse,      # data mgmt and viz\n     writexl,        # write Excel file with multiple sheets\n     readxl          # import Excel with multiple sheets\n)"},{"path":"iteration.html","id":"map","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"map()","text":"One core purrr function map(), “maps” (applies) function input element list/vector provide.basic syntax map(.x = SEQUENCE, .f = FUNCTION, ARGUMENTS). bit detail:.x = inputs upon .f function iteratively applied - e.g. vector jurisdiction names, columns data frame, list data frames.f = function apply element .x input - function like print() already exists, custom function define. function often written tilde ~ (details ).notes syntax:function needs arguments specified, can written parentheses tilde (e.g. .f = mean). provide arguments value iteration, provide within map() outside .f = argument, na.rm = T map(.x = my_list, .f = mean, na.rm=T).can use .x (simply .) within .f = function placeholder .x value iterationUse tilde syntax (~) greater control function - write function normal parentheses, : map(.x = my_list, .f = ~mean(., na.rm = T)). Use syntax particularly value argument change iteration, value .x (see examples )output using map() list - list object class like vector whose elements can different classes. , list produced map() contain many data frames, many vectors, many single values, even many lists! alternative versions map() explained produce types outputs (e.g. map_dfr() produce data frame, map_chr() produce character vectors, map_dbl() produce numeric vectors).","code":""},{"path":"iteration.html","id":"iter_combined","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Example - import and combine Excel sheets","text":"Let’s demonstrate common epidemiologist task: - want import Excel workbook case data, data split across different named sheets workbook. efficiently import combine sheets one data frame?Let’s say sent Excel workbook. sheet contains cases given hospital.one approach uses map():map() function import() runs Excel sheetCombine imported data frames one using bind_rows()Along way, preserve original sheet name row, storing information new column final data frameFirst, need extract sheet names save . provide Excel workbook’s file path function excel_sheets() package readxl, extracts sheet names. store character vector called sheet_names.names:Now vector names, map() can provide one--one function import(). example, sheet_names .x import() function .f.Recall [Import export] page used Excel workbooks, import() can accept argument = specifying sheet import. Within .f function import(), provide = .x, whose value change iteration vector sheet_names - first “Central Hospital”, “Military Hospital”, etc.note - used map(), data Excel sheet saved separate data frame within list. want list elements (data frames) name, pass sheet_names map() pass set_names() purrr, ensures list element gets appropriate name.save output list combined.inspect output, see data Excel sheet saved list name. good, quite finished.Lastly, use function bind_rows() (dplyr) accepts list similarly-structured data frames combines one data frame. create new column list element names, use argument .id = provide desired name new column.whole sequence commands:now one data frame column containing sheet origin!variations map() aware . example, map_dfr() returns data frame, list. Thus, used task bind rows. able capture sheet (hospital) case came .variations include map_chr(), map_dbl(). useful functions two reasons. Firstly. automatically convert output iterative function vector (list). Secondly, can explicitly control class data comes back - ensure data comes back character vector map_chr(), numeric vector map_dbl(). Lets return later section!functions map_at() map_if() also useful iteration - allow specify elements list iterate ! work simply applying vector indexes/names (case map_at()) logical test (case map_if()).Lets use example didn’t want read first sheet hospital data. use map_at() instead map(), specify .= argument c(-1) means use first element .x. Alternatively, can provide vector positive numbers, names, .= specify elements use.Note first sheet name still appear element output list - single character name (data frame). need remove element binding rows. cover remove modify list elements later section.","code":"\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\nsheet_names## [1] \"Central Hospital\"              \"Military Hospital\"            \n## [3] \"Missing\"                       \"Other\"                        \n## [5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\ncombined <- sheet_names %>% \n  purrr::set_names() %>% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")  # extract sheet names\n \ncombined <- sheet_names %>%                                     # begin with sheet names\n  purrr::set_names() %>%                                        # set their names\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %>%  # iterate, import, save in list\n  bind_rows(.id = \"origin_sheet\") # combine list of data frames, preserving origin in new column  \nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined <- sheet_names %>% \n     purrr::set_names() %>% \n     # exclude the first sheet\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))"},{"path":"iteration.html","id":"split-dataset-and-export","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Split dataset and export","text":", give example split dataset parts use map() iteration export part separate Excel sheet, separate CSV file.","code":""},{"path":"iteration.html","id":"split-dataset","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Split dataset","text":"Let’s say complete case linelist data frame, now want create separate linelist hospital export separate CSV file. , following steps:Use group_split() (dplyr) split linelist data frame unique values column hospital. output list containing one data frame per hospital subset.can run View(linelist_split) see list contains 6 data frames (“tibbles”), representing cases one hospital.However, note data frames list names default! want name, use name saving CSV file.One approach extracting names use pull() (dplyr) extract hospital column data frame list. , safe, convert values character use unique() get name particular data frame. steps applied data frame via map().can now see list elements name. names can accessed via names(linelist_split).","code":"\nlinelist_split <- linelist %>% \n     group_split(hospital)\nnames(linelist_split) <- linelist_split %>%   # Assign to names of listed data frames \n     # Extract the names by doing the following to each data frame: \n     map(.f = ~pull(.x, hospital)) %>%        # Pull out hospital column\n     map(.f = ~as.character(.x)) %>%          # Convert to character, just in case\n     map(.f = ~unique(.x))                    # Take the unique hospital name\nnames(linelist_split)## [1] \"Central Hospital\"                     \"Military Hospital\"                   \n## [3] \"Missing\"                              \"Other\"                               \n## [5] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\""},{"path":"iteration.html","id":"more-than-one-group_split-column","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"More than one group_split() column","text":"wanted split linelist one grouping column, produce subset linelist intersection hospital gender, need different approach naming list elements. involves collecting unique “group keys” using group_keys() dplyr - returned data frame. can combine group keys values unite() shown , assign conglomerate names linelist_split.Now combine groupings together, separated dashes, assign names list elements linelist_split. takes extra lines replace NA “Missing”, use unite() dplyr combine column values together (separated dashes), convert un-named vector can used names linelist_split.","code":"\n# split linelist by unique hospital-gender combinations\nlinelist_split <- linelist %>% \n     group_split(hospital, gender)\n\n# extract group_keys() as a dataframe\ngroupings <- linelist %>% \n     group_by(hospital, gender) %>%       \n     group_keys()\n\ngroupings      # show unique groupings ## # A tibble: 18 x 2\n##    hospital                             gender\n##    <chr>                                <chr> \n##  1 Central Hospital                     f     \n##  2 Central Hospital                     m     \n##  3 Central Hospital                     <NA>  \n##  4 Military Hospital                    f     \n##  5 Military Hospital                    m     \n##  6 Military Hospital                    <NA>  \n##  7 Missing                              f     \n##  8 Missing                              m     \n##  9 Missing                              <NA>  \n## 10 Other                                f     \n## 11 Other                                m     \n## 12 Other                                <NA>  \n## 13 Port Hospital                        f     \n## 14 Port Hospital                        m     \n## 15 Port Hospital                        <NA>  \n## 16 St. Mark's Maternity Hospital (SMMH) f     \n## 17 St. Mark's Maternity Hospital (SMMH) m     \n## 18 St. Mark's Maternity Hospital (SMMH) <NA>\n# Combine into one name value \nnames(linelist_split) <- groupings %>% \n     mutate(across(everything(), replace_na, \"Missing\")) %>%  # replace NA with \"Missing\" in all columns\n     unite(\"combined\", sep = \"-\") %>%                         # Unite all column values into one\n     setNames(NULL) %>% \n     as_vector() %>% \n     as.list()"},{"path":"iteration.html","id":"export-as-excel-sheets","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Export as Excel sheets","text":"export hospital linelists Excel workbook one linelist per sheet, can just provide named list linelist_split write_xlsx() function writexl package. ability save one Excel workbook multiple sheets. list element names automatically applied sheet names.can now open Excel file see hospital sheet.","code":"\nlinelist_split %>% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))"},{"path":"iteration.html","id":"export-as-csv-files","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Export as CSV files","text":"bit complex command, can also export hospital-specific linelist separate CSV file, file name specific hospital.use map(): take vector list element names (shown ) use map() iterate , applying export() (rio package, see [Import export] page) data frame list linelist_split name. also use name create unique file name. works:begin vector character names, passed map() .xThe .f function export() , requires data frame file path write toThe input .x (hospital name) used within .f extract/index specific element linelist_split list. results one data frame time provided export().example, map() iterates “Military Hospital”, linelist_split[[.x]] actually linelist_split[[\"Military Hospital\"]], thus returning second element linelist_split - cases Military Hospital.file path provided export() dynamic via use str_glue() (see [Characters strings] page):\n() used get base file path specify “data” folder (note single quotes interrupt str_glue() double quotes)\n() used get base file path specify “data” folder (note single quotes interrupt str_glue() double quotes)slash /, .x prints current hospital name make file identifiableFinally extension “.csv” export() uses create CSV fileNow can see file saved “data” folder R Project “Epi_R_handbook”!","code":"\nnames(linelist_split) %>%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))"},{"path":"iteration.html","id":"custom-functions","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Custom functions","text":"may want create function provide map().Let’s say want create epidemic curves hospital’s cases. using purrr, .f function can ggplot() extensions + usual. output map() always list, plots stored list. plots, can extracted plotted ggarrange() function ggpubr package (documentation).map() code looks messy, can achieve result saving specific ggplot() command custom user-defined function, example can name make_epicurve()). function used within map(). .x iteratively replaced hospital name, used hosp_name make_epicurve() function. See page [Writing functions].","code":"\n# load package for plotting elements from list\npacman::p_load(ggpubr)\n\n# map across the vector of 6 hospital \"names\" (created earlier)\n# use the ggplot function specified\n# output is a list with 6 ggplots\n\nhospital_names <- unique(linelist$hospital)\n\nmy_plots <- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %>% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n# Create function\nmake_epicurve <- function(hosp_name){\n  \n  ggplot(data = linelist %>% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n# mapping\nmy_plots <- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)"},{"path":"iteration.html","id":"mapping-a-function-across-columns","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Mapping a function across columns","text":"Another common use-case map function across many columns. , map() function t.test() across numeric columns data frame linelist, comparing numeric values gender.Recall page [Simple statistical tests] t.test() can take inputs formula format, t.test(numeric column ~ binary column). example, following:numeric columns interest selected linelist - become .x inputs map()function t.test() supplied .f function, applied numeric columnWithin parentheses t.test():\nfirst ~ precedes .f map() iterate .x\n.x represents current column supplied function t.test()\nsecond ~ part t-test equation described \nt.test() function expects binary column right-hand side equation. supply vector linelist$gender independently statically (note included select()).\nfirst ~ precedes .f map() iterate .xthe .x represents current column supplied function t.test()second ~ part t-test equation described abovethe t.test() function expects binary column right-hand side equation. supply vector linelist$gender independently statically (note included select()).map() returns list, output list t-test results - one list element numeric column analysed.list t.test_results looks like opened (Viewed) RStudio. highlighted parts important examples page.can see top whole list named t.test_results five elements. five elements named age, wt_km, ht_cm, ct_blood, temp variable used t-test gender linelist.five elements lists, elements within p.value conf.int. elements like p.value single numbers, whereas estimate consist two elements (mean group f mean group m).Note: Remember want apply function certain columns data frame, can also simply use mutate() across(), explained [Cleaning data core functions] page. example applying .character() “age” columns. Note placement parentheses commas.","code":"\n# Results are saved as a list\nt.test_results <- linelist %>% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %>%  # keep only some numeric columns to map across\n  map(.f = ~t.test(.x ~ linelist$gender))        # t.test function, with equation NUMERIC ~ CATEGORICAL\n# convert columns with column name containing \"age\" to class Character\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  "},{"path":"iteration.html","id":"extract-from-lists","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Extract from lists","text":"map() produces output class List, spend time discussing extract data lists using accompanying purrr functions. demonstrate , use list t.test_results previous section. list 5 lists - 5 lists contains results t-test column linelist data frame binary column gender. See image section visual list structure.","code":""},{"path":"iteration.html","id":"names-of-elements","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Names of elements","text":"extract names elements , simply use names() base R. case, use names() t.test_results return names sub-list, names 5 variables t-tests performed.","code":"\nnames(t.test_results)## [1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\""},{"path":"iteration.html","id":"elements-by-name-or-position","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Elements by name or position","text":"extract list elements name position can use brackets [[ ]] described [R basics] page. use double brackets index list t.tests_results display first element results t-test age.However, demonstrate use simple flexible purrr functions map() pluck() achieve outcomes.","code":"\nt.test_results[[1]] # first element by position## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results[[1]][\"p.value\"] # return element named \"p.value\" from first element  ## $p.value\n## [1] 2.350374e-96"},{"path":"iteration.html","id":"pluck","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"pluck()","text":"pluck() pulls elements name position. example - extract t-test results age, can use pluck() like :Index deeper levels specifying levels commas. extracts element named “p.value” list age within list t.test_results. can also use numbers instead character names.can extract inner elements first-level elements using map() run pluck() function across first-level element. example, code extracts “p.value” elements lists within t.test_results. list t-test results .x iterated across, pluck() .f function iterated, value “p-value” provided function.another alternative, map() offers shorthand can write element name quotes, pluck . use map() output list, whereas use map_chr() named character vector use map_dbl() named numeric vector.can read pluck() ’s purrr documentation. sibling function chuck() return error instead NULL element exist.","code":"\nt.test_results %>% \n  pluck(\"age\")        # alternatively, use pluck(1)## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results %>% \n  pluck(\"age\", \"p.value\")## [1] 2.350374e-96\nt.test_results %>%\n  map(pluck, \"p.value\")   # return every p-value## $age\n## [1] 2.350374e-96\n## \n## $wt_kg\n## [1] 2.664367e-182\n## \n## $ht_cm\n## [1] 3.515713e-144\n## \n## $ct_blood\n## [1] 0.4473498\n## \n## $temp\n## [1] 0.5735923\nt.test_results %>% \n  map_dbl(\"p.value\")   # return p-values as a named numeric vector##           age         wt_kg         ht_cm      ct_blood          temp \n##  2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01"},{"path":"iteration.html","id":"convert-list-to-data-frame","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Convert list to data frame","text":"complex topic - see Resources section complete tutorials. Nevertheless, demonstrate converting list t-test results data frame. create data frame columns variable, p-value, means two groups (male female).new approaches functions used:function tibble() used create tibble (like data frame)\nsurround tibble() function curly brackets { } prevent entire t.test_results stored first tibble column\nsurround tibble() function curly brackets { } prevent entire t.test_results stored first tibble columnWithin tibble(), column created explicitly, similar syntax mutate():\n. represents t.test_results\ncreate column t-test variable names (names list element) use names() described \ncreate column p-values use map_dbl() described pull p.value elements convert numeric vector\n. represents t.test_resultsTo create column t-test variable names (names list element) use names() described aboveTo create column p-values use map_dbl() described pull p.value elements convert numeric vectorBut now let’s add columns containing means group (males females).need extract element estimate, actually contains two elements within (mean group f mean group m). , simplified vector map_chr() map_dbl(). Instead, use map(), used within tibble() create column class list within tibble! Yes, possible!list column, several tidyr functions (part tidyverse) help “rectangle” “un-nest” “nested list” columns. Read , running vignette(\"rectangle\"). brief:unnest_wider() - gives element list-column columnunnest_longer() - gives element list-column rowhoist() - acts like unnest_wider() specify elements unnestBelow, pass tibble unnest_wider() specifying tibble’s means column (nested list). result means replaced two new columns, reflecting two elements previously means cell.","code":"\nt.test_results %>% {\n  tibble(\n    variables = names(.),\n    p         = map_dbl(., \"p.value\"))\n  }## # A tibble: 5 x 2\n##   variables         p\n##   <chr>         <dbl>\n## 1 age       2.35e- 96\n## 2 wt_kg     2.66e-182\n## 3 ht_cm     3.52e-144\n## 4 ct_blood  4.47e-  1\n## 5 temp      5.74e-  1\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\"))}## # A tibble: 5 x 3\n##   variables         p means       \n##   <chr>         <dbl> <named list>\n## 1 age       2.35e- 96 <dbl [2]>   \n## 2 wt_kg     2.66e-182 <dbl [2]>   \n## 3 ht_cm     3.52e-144 <dbl [2]>   \n## 4 ct_blood  4.47e-  1 <dbl [2]>   \n## 5 temp      5.74e-  1 <dbl [2]>\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %>% \n  unnest_wider(means)## # A tibble: 5 x 4\n##   variables         p `mean in group f` `mean in group m`\n##   <chr>         <dbl>             <dbl>             <dbl>\n## 1 age       2.35e- 96              12.7              19.6\n## 2 wt_kg     2.66e-182              45.8              59.6\n## 3 ht_cm     3.52e-144             109.              142. \n## 4 ct_blood  4.47e-  1              21.2              21.2\n## 5 temp      5.74e-  1              38.6              38.6"},{"path":"iteration.html","id":"discard-keep-and-compact-lists","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"Discard, keep, and compact lists","text":"working purrr often involves lists, briefly explore purrr functions modify lists. See Resources section complete tutorials purrr functions.list_modify() many uses, one can remove list elementkeep() retains elements specified .p =, function supplied .p = evaluates TRUEdiscard() removes elements specified .p, function supplied .p = evaluates TRUEcompact() removes empty elementsHere examples using combined list created section using map() import combine multiple files (contains 6 case linelist data frames):Elements can removed name list_modify() setting name equal NULL.can also remove elements criteria, providing “predicate” equation .p = (equation evaluates either TRUE FALSE). Place tilde ~ function use .x represent list element. Using keep() list elements evaluate TRUE kept. Inversely, using discard() list elements evaluate TRUE removed.example, list elements discarded class data frames.predicate function can also reference elements/columns within list item. example, , list elements mean column ct_blood 25 discarded.command remove empty list elements:","code":"\ncombined %>% \n  list_modify(\"Central Hospital\" = NULL)   # remove list element by name\n# keep only list elements with more than 500 rows\ncombined %>% \n  keep(.p = ~nrow(.x) > 500)  \n# Discard list elements that are not data frames\ncombined %>% \n  discard(.p = ~class(.x) != \"data.frame\")\n# keep only list elements where ct_blood column mean is over 25\ncombined %>% \n  discard(.p = ~mean(.x$ct_blood) > 25)  \n# Remove all empty list elements\ncombined %>% \n  compact()"},{"path":"iteration.html","id":"pmap","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"pmap()","text":"SECTION CONSTRUCTION","code":""},{"path":"iteration.html","id":"apply-functions","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"16.4 Apply functions","text":"“apply” family functions base R alternative purrr iterative operations. can read .","code":""},{"path":"iteration.html","id":"resources-6","chapter":"16 Lặp, vòng lặp, và danh sách","heading":"16.5 Resources","text":"loops Data CarpentryThe R Data Science page iterationVignette write/read Excel filesA purrr tutorial jennybcAnother purrr tutorial Rebecca BarterA purrr tutorial map, pmap, imappurrr cheatsheetpurrr tips trickskeep discard","code":""},{"path":"tables-descriptive.html","id":"tables-descriptive","chapter":"17 Bảng mô tả","heading":"17 Bảng mô tả","text":"Chương này minh họa cách sử dụng các package janitor, dplyr, gtsummary, rstatix, và base R để tóm tắt dữ liệu và tạo bảng với thống kê mô tả.Chương này bao gồm cách để tạo bảng cơ bản, trong khi đó chương Trình bày bảng bao gồm cách để định dạng đẹp và chúng.*Mỗi package này đều có những ưu và nhược điểm trong từng khía cạnh như sự đơn giản, khả năng tiếp cận kết quả, chất lượng kết quả được hiển thị. Sử dụng chương này để quyết định cách tiếp cận nào phù hợp với trường hợp của bạn.Bạn có một số lựa chọn khi tạo bảng tóm tắt và bảng chéo. Một số yếu tố cần xem xét bao gồm tính đơn giản của code, khả năng tùy chỉnh, đầu ra mong muốn (được ra R console, dưới dạng dataframe hoặc dưới dạng hình ảnh “đẹp” .png/.jpeg /.html) và dễ xử lý hậu kỳ. Hãy xem xét các điểm dưới đây khi bạn chọn công cụ cho tình huống của mình.Dùng tabyl() từ janitor để tạo và “làm đẹp” cho bảng và bảng chéoDùng get_summary_stats() từ rstatix để dễ dàng tạo data frame các tóm tắt thống kê dạng số cho nhiều cột và / hoặc nhómDùng summarise() và count() từ dplyr dành choo các thống kê phức tạp hơn, đầu ra của tidy dataframe hoặc chuẩn bị dữ liệu cho ggplot()Dùng tbl_summary() từ gtsummary để tạo ra các bảng chi tiết sẵn sàng xuất bảnDùng table() từ base R nếu bạn không có khả năng truy cập vào các package trên","code":""},{"path":"tables-descriptive.html","id":"chuẩn-bị-2","chapter":"17 Bảng mô tả","heading":"17.1 Chuẩn bị","text":"","code":""},{"path":"tables-descriptive.html","id":"gọi-packages-1","chapter":"17 Bảng mô tả","heading":"Gọi packages","text":"Đoạn code này hiển thị việc gọi các packages cần thiết cho các phân tích. Trong sổ tay này, chúng tôi nhấn mạnh đến lệnh p_load() từ pacman, giúp cài đặt các package nếu cần và gọi chúng để sử dụng. Bạn cũng có thể gọi các package đã được cài đặt với library() từ base R. Xem chương R cơ bản để biết thêm thông tin về các package của R.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics \n  gtsummary,    # summary statistics and tests\n  rstatix,      # summary statistics and statistical tests\n  janitor,      # adding totals and percents to tables\n  scales,       # easily convert proportions to percents  \n  flextable     # converting tables to pretty images\n  )"},{"path":"tables-descriptive.html","id":"nhập-dữ-liệu-2","chapter":"17 Bảng mô tả","heading":"Nhập dữ liệu","text":"Chúng ta sẽ nhập bộ dữ liệu về các trường hợp từ một vụ dịch Ebola mô phỏng. Nếu bạn muốn theo dõi, bấm để tải xuống dữ liệu linelist “đã làm sạch” (.rds file). Nhập dữ liệu của bạn bằng hàm import() từ package rio (chấp nhận nhiều loại tệp như .xlsx, .rds, .csv - xem thêm chi tiết tại chương Nhập xuất dữ liệu).50 hàng đầu tiên của linelist được hiển thị như dưới đây.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"tables-descriptive.html","id":"duyệt-dữ-liệu","chapter":"17 Bảng mô tả","heading":"17.2 Duyệt dữ liệu","text":"","code":""},{"path":"tables-descriptive.html","id":"skimr-package","chapter":"17 Bảng mô tả","heading":"skimr package","text":"Khi sử dụng package skimr package, bạn có thể có được cái nhìn tổng quan chi tiết và đẹp về mặt thẩm mỹ của từng biến trong tập dữ liệu của mình. Đọc thêm về skimr tại trang github của nhà phát triển.Dưới đây, hàm skim() được áp dụng cho toàn bộ data frame linelist giúp bạn có cái nhìn tổng quan về data frame và tóm tắt của tất cả các cột (theo lớp).\nTable 17.1: Data summary\nVariable type: characterVariable type: DateVariable type: factorVariable type: numericBạn cũng có thể sử dụng hàm summary() từ base R, để lấy thông tin về toàn bộ tập dữ liệu, nhưng kết quả đầu ra có thể khó đọc hơn với sử dụng skimr. đó, kết quả không được hiển thị bên dưới để tiết kiệm không gian trang.","code":"\n## get information about each variable in a dataset \nskim(linelist)\n## get information about each column in a dataset \nsummary(linelist)"},{"path":"tables-descriptive.html","id":"thống-kê-tóm-tắt","chapter":"17 Bảng mô tả","heading":"Thống kê tóm tắt","text":"Bạn có thể sử dụng các hàm base R để trả về thống kê tóm tắt trên một cột dữ liệu dạng số. Bạn có thể trả về hầu hết các thống kê tóm tắt hữu ích cho một cột dạng số bằng cách sử dụng hàm summary(), như dưới đây. Lưu ý rằng tên data frame cũng phải được xác định như hình dưới đây.Bạn có thể truy cập và lưu một phần cụ thể của nó bằng dấu ngoặc vuông [ ]:Bạn có thể trả về các thống kê riêng lẻ với các hàm base R như max(), min(), median(), mean(), quantile(), sd(), và range(). Xem chương R cơ bản để có danh sách đầy đủ.THẬN TRỌNG: Nếu dữ liệu của bạn chứa các giá trị missing, R muốn bạn biết điều này và đó sẽ trả về NA trừ khi bạn chỉ định cho các hàm toán học ở trên mà bạn muốn R bỏ qua các giá trị bị thiếu, thông qua đối số na.rm = TRUE.Bạn có thể sử dụng hàm get_summary_stats() từ package rstatix để trả về thống kê tóm tắt ở định dạng data frame. Điều này có thể hữu ích cho việc thực hiện các hoạt động tiếp theo hoặc vẽ biểu đồ trên các con số. Xem chương Các kiểm định thống kê cơ bản để biết thêm chi tiết về package rstatix và các hàm của nó.","code":"\nsummary(linelist$age_years)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.02   23.00   84.00      86\nsummary(linelist$age_years)[[2]]            # return only the 2nd element## [1] 6\n# equivalent, alternative to above by element name\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \nlinelist %>% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # columns to calculate for\n    type = \"common\")                    # summary stats to return## # A tibble: 5 x 10\n##   variable     n   min   max median   iqr  mean     sd    se    ci\n##   <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n## 2 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n## 3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n## 4 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025\n## 5 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475"},{"path":"tables-descriptive.html","id":"tbl_janitor","chapter":"17 Bảng mô tả","heading":"17.3 janitor package","text":"Package janitor cung cấp hàm tabyl() giúp tạo ra các bảng đơn và bảng chéo, có thể được “tô điểm” hoặc sửa đổi bằng các hàm trợ giúp để hiển thị phần trăm, tỷ lệ, số đếm, v.v.Sau đây, chúng ta sẽ pipe linelist data frame tới các hàm của janitor và kết quả. Nếu muốn, bạn cũng có thể lưu các bảng kết quả bằng toán tử gán <-.","code":""},{"path":"tables-descriptive.html","id":"tabyl-đơn-giản","chapter":"17 Bảng mô tả","heading":"tabyl đơn giản","text":"Cách sử dụng mặc định của hàm tabyl() trên một cột cụ thể tạo ra các giá trị duy nhất, số lượng và “phần trăm” (tỷ lệ thực tế) theo cột. Tỷ lệ có thể có nhiều chữ số thập phân. Bạn có thể điều chỉnh số lượng số thập phân với hàm adorn_rounding() như được mô tả bên dưới.Như bạn có thể thấy ở trên, các giá trị missing sẽ được hiển thị trong một hàng có nhãn <NA>. Bạn có thể ngăn điều này bằng cách thêm show_na = FALSE. Nếu không có giá trị missing, hàng này sẽ không xuất hiện. Nếu có giá trị missing, tất cả các tỷ lệ sẽ được trình bày dưới dạng thô (mẫu số bao gồm cả NA) và “hợp lý” (mẫu số không bao gồm NA).Nếu giá trị cột là dạng Factor và chỉ một vài level nhất định có trong dữ liệu của bạn, thì tất cả các level sẽ vẫn xuất hiện trong bảng. Bạn có thể loại bỏ tính năng này bằng cách thêm show_missing_levels = FALSE. Đọc thêm trong chương [Factors].","code":"\nlinelist %>% tabyl(age_cat)##  age_cat    n     percent valid_percent\n##      0-4 1095 0.185971467   0.188728025\n##      5-9 1095 0.185971467   0.188728025\n##    10-14  941 0.159816576   0.162185453\n##    15-19  743 0.126188859   0.128059290\n##    20-29 1073 0.182235054   0.184936229\n##    30-49  754 0.128057065   0.129955188\n##    50-69   95 0.016134511   0.016373664\n##      70+    6 0.001019022   0.001034126\n##     <NA>   86 0.014605978            NA"},{"path":"tables-descriptive.html","id":"bảng-chéo","chapter":"17 Bảng mô tả","heading":"Bảng chéo","text":"Bảng chéo được tạo bằng cách thêm một hoặc nhiều cột vào hàm tabyl(). Lưu ý rằng bây giờ chỉ có số lượng được hiện thị - tỷ lệ và phần trăm có thể được thêm vào bằng các bước bổ sung sẽ được trình bày bên dưới.","code":"\nlinelist %>% tabyl(age_cat, gender)##  age_cat   f   m NA_\n##      0-4 640 416  39\n##      5-9 641 412  42\n##    10-14 518 383  40\n##    15-19 359 364  20\n##    20-29 468 575  30\n##    30-49 179 557  18\n##    50-69   2  91   2\n##      70+   0   5   1\n##     <NA>   0   0  86"},{"path":"tables-descriptive.html","id":"tbl_adorn","chapter":"17 Bảng mô tả","heading":"“Tô điểm” cho tabyl","text":"Sử dụng các hàm “tô điểm” của janitor để thêm tổng hoặc chuyển đổi thành tỷ lệ, phần trăm hoặc điều chỉnh hiển thị. Thông thường, bạn sẽ pipe tabyl thông qua một số hàm này..Hãy cẩn trọng về thứ tự bạn áp dụng các hàm trên. Dưới đây là một số ví dụ.Bảng một chiều đơn giản với phần trăm thay vì tỷ lệ mặc định.Bảng chéo với tổng hàng và phần trăm hàng.Bảng chéo được điều chỉnh để cả số lượng và phần trăm đều được hiển thị.","code":"\nlinelist %>%               # case linelist\n  tabyl(age_cat) %>%       # tabulate counts and proportions by age category\n  adorn_pct_formatting()   # convert proportions to percents##  age_cat    n percent valid_percent\n##      0-4 1095   18.6%         18.9%\n##      5-9 1095   18.6%         18.9%\n##    10-14  941   16.0%         16.2%\n##    15-19  743   12.6%         12.8%\n##    20-29 1073   18.2%         18.5%\n##    30-49  754   12.8%         13.0%\n##    50-69   95    1.6%          1.6%\n##      70+    6    0.1%          0.1%\n##     <NA>   86    1.5%             -\nlinelist %>%                                  \n  tabyl(age_cat, gender) %>%                  # counts by age and gender\n  adorn_totals(where = \"row\") %>%             # add total row\n  adorn_percentages(denominator = \"row\") %>%  # convert counts to proportions\n  adorn_pct_formatting(digits = 1)            # convert proportions to percents##  age_cat     f     m    NA_\n##      0-4 58.4% 38.0%   3.6%\n##      5-9 58.5% 37.6%   3.8%\n##    10-14 55.0% 40.7%   4.3%\n##    15-19 48.3% 49.0%   2.7%\n##    20-29 43.6% 53.6%   2.8%\n##    30-49 23.7% 73.9%   2.4%\n##    50-69  2.1% 95.8%   2.1%\n##      70+  0.0% 83.3%  16.7%\n##     <NA>  0.0%  0.0% 100.0%\n##    Total 47.7% 47.6%   4.7%\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions\n  adorn_pct_formatting() %>%                  # convert to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                      Gender                           \n##  Age Category             f             m          NA_\n##           0-4  640  (22.8%)  416  (14.8%)  39  (14.0%)\n##           5-9  641  (22.8%)  412  (14.7%)  42  (15.1%)\n##         10-14  518  (18.5%)  383  (13.7%)  40  (14.4%)\n##         15-19  359  (12.8%)  364  (13.0%)  20   (7.2%)\n##         20-29  468  (16.7%)  575  (20.5%)  30  (10.8%)\n##         30-49  179   (6.4%)  557  (19.9%)  18   (6.5%)\n##         50-69    2   (0.1%)   91   (3.2%)   2   (0.7%)\n##           70+    0   (0.0%)    5   (0.2%)   1   (0.4%)\n##          <NA>    0   (0.0%)    0   (0.0%)  86  (30.9%)\n##         Total 2807 (100.0%) 2803 (100.0%) 278 (100.0%)"},{"path":"tables-descriptive.html","id":"in-với-tabyl","chapter":"17 Bảng mô tả","heading":"In với tabyl","text":"Theo mặc định, lệnh tabyl sẽ kết quả thô vào R console của bạn.Ngoài ra, bạn có thể chuyển tabyl sang flextable hoặc package tương tự để dưới dạng hình ảnh “đẹp” trong RStudio Viewer, có thể được xuất dưới dạng .png, .jpeg, .html, v.v. Điều này đã được thảo luận trong chương Trình bày bảng . Lưu ý rằng nếu theo cách này và sử dụng adorn_titles(), bạn cần thêm vào placement = \"combined\".Age Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%) 941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%) 743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%) 754 (12.8%)50-69  2  (0.1%) 91  (3.2%) 2  (0.7%)  95  (1.6%)70+  0  (0.0%)  5  (0.2%) 1  (0.4%)   6  (0.1%)  0  (0.0%)  0  (0.0%)86 (30.9%)  86  (1.5%)","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% # this is necessary to print as image\n  flextable::flextable() %>%    # convert to pretty image\n  flextable::autofit()          # format to one line per row "},{"path":"tables-descriptive.html","id":"sử-dụng-trên-các-bảng-khác","chapter":"17 Bảng mô tả","heading":"Sử dụng trên các bảng khác","text":"Bạn có thể sử dụng các hàmadorn_*() của janitor lên các bảng khác, chẳng hạn các bảng được tạo bởi hàm summarise() và count() của dplyr, hoặc table() từ base R. Đơn giản chỉ cần pipe bảng đến hàm mong muốn của package janitor. Ví dụ:","code":"\nlinelist %>% \n  count(hospital) %>%   # dplyr function\n  adorn_totals()        # janitor function##                              hospital    n\n##                      Central Hospital  454\n##                     Military Hospital  896\n##                               Missing 1469\n##                                 Other  885\n##                         Port Hospital 1762\n##  St. Mark's Maternity Hospital (SMMH)  422\n##                                 Total 5888"},{"path":"tables-descriptive.html","id":"lưu-với-tabyl","chapter":"17 Bảng mô tả","heading":"Lưu với tabyl","text":"Nếu bạn muốn chuyển đổi bảng thành một hình ảnh “đẹp” với package flextable, bạn có thể lưu nó bằng các hàm như save_as_html(), save_as_word(), save_as_ppt(), và save_as_image() từ package flextable (sẽ được bàn luận kỹ hơn ở chương Trình bày bảng). Ví dụ dưới đây, bảng được lưu lại dưới dạng tệp Word, và có khả năng chỉnh sửa được.","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% \n  flextable::flextable() %>%                     # convert to image\n  flextable::autofit() %>%                       # ensure only one line per row\n  flextable::save_as_docx(path = \"tabyl.docx\")   # save as Word document to filepath"},{"path":"tables-descriptive.html","id":"janitor_age_out_stats","chapter":"17 Bảng mô tả","heading":"Thống kê","text":"Bạn có thể áp dụng các kiểm định thống kê bằng tabyls, ví dụ như chisq.test() hoặc fisher.test() từ package stats, như được trình bày dưới đây. Chú ý là giá trị missing không được cho phép vì vậy chúng được loại bỏ khỏi tabyl bằng tùy chọn show_na = FALSE.Xem chương Các kiểm định thống kê cơ bản để có thêm code và các mẹo liên quan đến thống kê.","code":"\nage_by_outcome <- linelist %>% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)## \n##  Pearson's Chi-squared test\n## \n## data:  age_by_outcome\n## X-squared = 6.4931, df = 7, p-value = 0.4835"},{"path":"tables-descriptive.html","id":"các-mẹo-khác","chapter":"17 Bảng mô tả","heading":"Các mẹo khác","text":"Thêm đối số na.rm = TRUE để loại bỏ các giá trị missing.Nếu áp dụng bất kỳ hàm trợ giúp adorn_*() nào cho các bảng không được tạo bởi tabyl(), bạn có thể chỉ định (các) cột cụ thể để áp dụng chúng chẳng hạn như adorn_percentage(,,,c(cases,deaths)) (chỉ định chúng cho đối số không tên thứ 4). Thay vào đó, hãy cân nhắc sử dụng hàm summarise().Bạn có thể tìm đọc thêm ở janitor page và tabyl vignette.","code":""},{"path":"tables-descriptive.html","id":"dplyr-package","chapter":"17 Bảng mô tả","heading":"17.4 dplyr package","text":"dplyr là một phần của package tidyverse và là một công cụ quản lý dữ liệu rất phổ biến. Tạo bảng với các hàm của dplyr như summarise() và count() là một cách tiếp cận hữu ích để tính toán các tóm tắt thống kê, tổng hợp theo nhóm, hoặc chuyển bảng tới ggplot().summarise() tạo một data frame tổng hợp mới. Nếu dữ liệu được tách nhóm, nó sẽ trả về data frame có một hàng với thống kê tóm tắt được chỉ định cho toàn bộ data frame. Nếu dữ liệu được nhóm lại, data frames sẽ có một hàng cho từng nhóm (xem chương Nhóm dữ liệu).Bên trong dấu ngoặc đơn của hàm summarise(), bạn sẽ cung cấp tên của từng cột cần tổng hợp mới, theo sau là dấu bằng và một hàm thống kê để áp dụng.MẸO: Hàm summarise hoạt động được với cả cách viết Anh-Anh và Anh-Mỹ (summarise() và summarize()).","code":""},{"path":"tables-descriptive.html","id":"lấy-số-lượng","chapter":"17 Bảng mô tả","heading":"Lấy số lượng","text":"Hàm đơn giản nhất để áp dụng cùng với hàm summarise() là n(). Để trống dấu ngoặc đơn để đếm số hàng.Điều này sẽ thú vị hơn nếu chúng ta đã nhóm dữ liệu trước đó.Lệnh trên có thể được rút ngắn bằng cách sử dụng hàmcount() thay thế. count() làm những việc sau:Nhóm dữ liệu theo các cột được cung cấp cho nóTổng hợp chúng với n() (tạo cột n)Tách nhóm dữ liệuBạn có thể thay đổi tên của cột đếm từ mặc định là n thành một cái gì đó cụ thể chẳng hạn như name =.Tạo bảng đếm cho hai hoặc nhiều cột sẽ vẫn trả về địng dạng “dọc”, với số lượng ở cột n. Xem chương [Pivoting dữ liệu] để hiểu thêm về định dạng dữ liệu “dọc” và “ngang”.","code":"\nlinelist %>%                 # begin with linelist\n  summarise(n_rows = n())    # return new summary dataframe with column n_rows##   n_rows\n## 1   5888\nlinelist %>% \n  group_by(age_cat) %>%     # group data by unique values in column age_cat\n  summarise(n_rows = n())   # return number of rows *per group*## # A tibble: 9 x 2\n##   age_cat n_rows\n##   <fct>    <int>\n## 1 0-4       1095\n## 2 5-9       1095\n## 3 10-14      941\n## 4 15-19      743\n## 5 20-29     1073\n## 6 30-49      754\n## 7 50-69       95\n## 8 70+          6\n## 9 <NA>        86\nlinelist %>% \n  count(age_cat)##   age_cat    n\n## 1     0-4 1095\n## 2     5-9 1095\n## 3   10-14  941\n## 4   15-19  743\n## 5   20-29 1073\n## 6   30-49  754\n## 7   50-69   95\n## 8     70+    6\n## 9    <NA>   86\nlinelist %>% \n  count(age_cat, outcome)##    age_cat outcome   n\n## 1      0-4   Death 471\n## 2      0-4 Recover 364\n## 3      0-4    <NA> 260\n## 4      5-9   Death 476\n## 5      5-9 Recover 391\n## 6      5-9    <NA> 228\n## 7    10-14   Death 438\n## 8    10-14 Recover 303\n## 9    10-14    <NA> 200\n## 10   15-19   Death 323\n## 11   15-19 Recover 251\n## 12   15-19    <NA> 169\n## 13   20-29   Death 477\n## 14   20-29 Recover 367\n## 15   20-29    <NA> 229\n## 16   30-49   Death 329\n## 17   30-49 Recover 238\n## 18   30-49    <NA> 187\n## 19   50-69   Death  33\n## 20   50-69 Recover  38\n## 21   50-69    <NA>  24\n## 22     70+   Death   3\n## 23     70+ Recover   3\n## 24    <NA>   Death  32\n## 25    <NA> Recover  28\n## 26    <NA>    <NA>  26"},{"path":"tables-descriptive.html","id":"hiện-tất-cả-các-cấp-độ","chapter":"17 Bảng mô tả","heading":"Hiện tất cả các cấp độ","text":"Nếu bạn tạo bảng cho một cột có kiểu dữ liệu là factor, bạn có thể chắc chắng rằng tất cả các cấp độ được trình bày (không chỉ các cấp có giá trị trong dữ liệu) bằng cách thêm .drop = FALSE vào lệnh summarise() hoặc count().Kỹ thuật này rất hữu ích để chuẩn hóa các bảng/biểu đồ của bạn. Ví dụ: nếu bạn đang tạo số liệu cho nhiều nhóm con, hoặc liên tục tạo số liệu cho các báo cáo thường quy. Trong các trường hợp này, sự hiện diện của các giá trị trong dữ liệu có thể dao động, nhưng bạn có thể xác định các mức không đổi.Xem chương [Factors] để có nhiều thông tin hơn.","code":""},{"path":"tables-descriptive.html","id":"tbl_dplyr_prop","chapter":"17 Bảng mô tả","heading":"Tỷ lệ","text":"Tỷ lệ có thể được thêm vào bằng cách piping bảng tới hàm mutate() để tạo một cột mới. Định nghĩa cột mới là thương của số quan sát của từng yếu tố (mặc định là n) và tổng số quan sát sum() của cột (sẽ trả về giá trị là một tỷ lệ).Lưu ý trong trường hợp này, sum() trong lệnh mutate() sẽ trả về giá trị của toàn bộ cột n để dùng làm mẫu số của tỷ lệ. Như đã được giải thích trong chương Nhóm dữ liệu, nếu sum() được sử dụng với dữ liệu đã được nhóm (vd: nếu hàm mutate() được theo ngay phía sai hàm group_by()), nó sẽ trả về kết quả tổng hợp theo nhóm. Như đã nếu ở trên, count() hoàn thành nhiệm vụ của mình bằng cách tách nhóm. Vì vậy, trong trường hợp này chúng ta sẽ lấy toàn bộ tỷ lệ của cột.Để dễ dàng hiển thị phần trăm, bạn có thể đưa tỷ lệ vào trong hàm percent() từ package scales (lưu ý là điều nãy sẽ chuyển kết quả thành dạng ký tự (character)).Dưới đây là phương pháp tính tỷ lệ trong nhóm. Nó dựa trên các cấp độ nhóm dữ liệu khác nhau được áp dụng và loại bỏ một cách có chọn lọc. Đầu tiên, dữ liệu được nhóm theo outcome thông qua hàm group_by(). Sau đó, hàm count() được áp dụng. Hàm này sẽ tiếp tục nhóm dữ liệu phân theo age_cat và trả vế số lượng theo từng tổ hợp outcome-age-cat. Quan trọng là - khi nó kết thúc quy trình của mình, hàm count() sẽ tách nhóm theo age_cat, nên nhóm dữ liệu duy nhất còn lại là nhóm ban đầu theo outcome. đó, bước cuối cùng để tính toán tỷ lệ (mẫu số là sum(n)) vẫn được nhóm theo outcome.","code":"\nage_summary <- linelist %>% \n  count(age_cat) %>%                     # group and count by gender (produces \"n\" column)\n  mutate(                                # create percent of column - note the denominator\n    percent = scales::percent(n / sum(n))) \n\n# print\nage_summary##   age_cat    n percent\n## 1     0-4 1095  18.60%\n## 2     5-9 1095  18.60%\n## 3   10-14  941  15.98%\n## 4   15-19  743  12.62%\n## 5   20-29 1073  18.22%\n## 6   30-49  754  12.81%\n## 7   50-69   95   1.61%\n## 8     70+    6   0.10%\n## 9    <NA>   86   1.46%\nage_by_outcome <- linelist %>%                  # begin with linelist\n  group_by(outcome) %>%                         # group by outcome \n  count(age_cat) %>%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group"},{"path":"tables-descriptive.html","id":"vẽ-biểu-đồ","chapter":"17 Bảng mô tả","heading":"Vẽ biểu đồ","text":"Để hiển thị kết quả từ một bảng “dài” như trên thì vẽ biểu đồ bằng hàm ggplot() tương đối trực quan. Dữ liệu một cách tự nhiên có định dạng “dọc”, nên tương thích với ggplot() một cách tự nhiên. Xem thêm các ví dụ ở chương ggplot cơ bản và Các tips với ggplot.","code":"\nlinelist %>%                      # begin with linelist\n  count(age_cat, outcome) %>%     # group and tabulate counts by two columns\n  ggplot()+                       # pass new data frame to ggplot\n    geom_col(                     # create bar plot\n      mapping = aes(   \n        x = outcome,              # map outcome to x-axis\n        fill = age_cat,           # map age_cat to the fill\n        y = n))                   # map the counts column `n` to the height"},{"path":"tables-descriptive.html","id":"tổng-hợp-thống-kê","chapter":"17 Bảng mô tả","heading":"Tổng hợp thống kê","text":"Một điểm mạnh của dplyr và summarise() là khả năng trả về các bảng tổng hợp thống kê nâng cao hơn như median(), mean(), max(), min(), sd() (độ lệch chuẩn), và phân vị. Bạn cũng có thể sử dụng sum() để trả vể số lượng dòng thỏa mãn một điều kiện logic nào đó. Như trên, các kết quả đầu ra này có thể được tạo cho toàn bộ data frame hoặc theo nhóm.Cú pháp là tương tự- bên trong dấu ngoặc hàm summarise() bạn cung cấp tên của từng cột tổng hợp được theo sau bởi dâu bằng và hàm thống kê được áp dụng. Trong hàm thống kê, cung cấp (các) cột sẽ được tính toán và bất kỳ các đối số có liên quan (vd: na.rm = TRUE cho tất cả các hàm toán học).Bạn cũng có thể sử dụng hàm sum() để trả vể số lượng dòng thỏa mãn một điều kiện logic cụ thể. Biểu thức điều kiện sẽ được đếm nếu nó được đánh giá là TRUE. Ví dụ:sum(age_years < 18, na.rm=T)sum(gender == \"male\", na.rm=T)sum(response %% c(\"Likely\", \"Likely\"))Dưới đây, bộ dữ liệu linelist được tổng hợp để mô tả những ngày trì hoãn từ khi bắt đầu có triệu chứng đến khi nhập viện (cột days_onset_hosp), phân theo bệnh viện.Một vài mẹp:Sử dụng sum() với một biểu thức logic để “đếm” các dòng đáp ứng các tiêu chí nhất định (==)Sử dụng sum() với một biểu thức logic để “đếm” các dòng đáp ứng các tiêu chí nhất định (==)Lưu ý cách sử dụng của na.rm = TRUE bên trong biểu thức toán học như là sum(), nếu không NA sẽ được trả lại nếu dữ liệu có giá trị missingLưu ý cách sử dụng của na.rm = TRUE bên trong biểu thức toán học như là sum(), nếu không NA sẽ được trả lại nếu dữ liệu có giá trị missingSử dụng hàm percent() từ package scales để dễ dàng chuyển đổi tỷ lệ phần trăm\nThiết lập accuracy = bằng 0.1 hoặc 0.01 để đảm bảo kết quả hiển thị 1 hoặc 2 chữ số thập phân sau dấ phẩy\nSử dụng hàm percent() từ package scales để dễ dàng chuyển đổi tỷ lệ phần trămThiết lập accuracy = bằng 0.1 hoặc 0.01 để đảm bảo kết quả hiển thị 1 hoặc 2 chữ số thập phân sau dấ phẩySử dụng hàm round() từ base R để chỉ định số thập phânSử dụng hàm round() từ base R để chỉ định số thập phânĐể tính toán các thống kê này trên toàn bộ tập dữ liệu, sử dụng summarise() và không có group_by()Để tính toán các thống kê này trên toàn bộ tập dữ liệu, sử dụng summarise() và không có group_by()Bạn có thể tạo các cột cho các mục đích tính toán sau này (ví dụ: mẫu số) mà thậm chí bạn bỏ ra khỏi data frame của mình với hàm select().Bạn có thể tạo các cột cho các mục đích tính toán sau này (ví dụ: mẫu số) mà thậm chí bạn bỏ ra khỏi data frame của mình với hàm select().","code":"\nsummary_table <- linelist %>%                                        # begin with linelist, save out as new object\n  group_by(hospital) %>%                                             # group all calculations by hospital\n  summarise(                                                         # only the below summary columns will be returned\n    cases       = n(),                                                # number of rows per group\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # max delay\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # mean delay, rounded\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # standard deviation of delays, rounded\n    delay_3     = sum(days_onset_hosp >= 3, na.rm = T),               # number of rows with delay of 3 or more days\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convert previously-defined delay column to percent \n  )\n\nsummary_table  # print## # A tibble: 6 x 7\n##   hospital                         cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n##   <chr>                            <int>     <dbl>      <dbl>    <dbl>   <int> <chr>      \n## 1 Central Hospital                   454        12        1.9      1.9     108 24%        \n## 2 Military Hospital                  896        15        2.1      2.4     253 28%        \n## 3 Missing                           1469        22        2.1      2.3     399 27%        \n## 4 Other                              885        18        2        2.2     234 26%        \n## 5 Port Hospital                     1762        16        2.1      2.2     470 27%        \n## 6 St. Mark's Maternity Hospital (~   422        18        2.1      2.3     116 27%"},{"path":"tables-descriptive.html","id":"thống-kê-có-điều-kiện","chapter":"17 Bảng mô tả","heading":"Thống kê có điều kiện","text":"Bạn có thể sẽ muốn trả về các thống kê có điều kiện - vd: số hàng tối đa đáp ứng các tiêu chí nhất định. Điều này có thể thực hiện được bằng cáhc subsetting cột bằng dấu ngoặc vuông [ ]. Ví dụ dưới đây trả về nhiệt độ tối đa cho những bệnh nhân được phân loại là có hoặc không bị sốt. Tuy nhiên hãy lưu ý - có thể thích hợp hơn nếu thêm một cột khác vào hàm group_by() và pivot_wider() (như được minh họa dưới đây).","code":"\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )## # A tibble: 6 x 3\n##   hospital                             max_temp_fvr max_temp_no\n##   <chr>                                       <dbl>       <dbl>\n## 1 Central Hospital                             40.4        38  \n## 2 Military Hospital                            40.5        38  \n## 3 Missing                                      40.6        38  \n## 4 Other                                        40.8        37.9\n## 5 Port Hospital                                40.6        38  \n## 6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9"},{"path":"tables-descriptive.html","id":"gắn-với-nhau","chapter":"17 Bảng mô tả","heading":"Gắn với nhau","text":"Hàm str_glue() từ package stringr rất hữu ích để kết hợp các giá trị từ một số cột thành một cột mới. Trong trường hợp này nó được sử dụng sau hàm summarise().Trong chương Ký tự và chuỗi, có nhiều lựa chọn khác nhau để kết hợp các cột được thảo luận, bao gồm cả unite(), và paste0(). Trong trường hợp sử dụng này, chúng tôi ủng hộ str_glue() bởi vì nó linh hoạt hơn unite() và có cú pháp đơn giẩn hơn paste0().Dưới đây, data frame summary_table (được tạo bên trên) được biến đổi để kết hợp cột delay_mean và delay_sd, định dạng dấu ngoặc đơn được thêm vào cột mới, và các cột cũ tương ứng của chúng bị xóa.Sau đó, để làm cho bảng dễ nhìn hơn, tổng hàng được thêm vào bằng hàm adorn_totals() từ janitor (bỏ qua các cột không phải số). Cuối cùng, chúng tôi sử dụng hàm select() từ dplyr để sắp xếp và đặt tên lại cho các cột.Bây giờ bạn có thể chuyển kết quả tới flextable và chúng thành bảng trong Word, .png, .jpeg, .html, Powerpoint, RMarkdown, v.v.! (xem chương Trình bày bảng).","code":"\nsummary_table %>% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %>%  # combine and format other values\n  select(-c(delay_mean, delay_sd)) %>%                       # remove two old columns   \n  adorn_totals(where = \"row\") %>%                            # add total row\n  select(                                                    # order and rename cols\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )##                         Hospital Name Cases Max delay Mean (sd) Delay 3+ days\n##                      Central Hospital   454        12 1.9 (1.9)           108\n##                     Military Hospital   896        15 2.1 (2.4)           253\n##                               Missing  1469        22 2.1 (2.3)           399\n##                                 Other   885        18   2 (2.2)           234\n##                         Port Hospital  1762        16 2.1 (2.2)           470\n##  St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116\n##                                 Total  5888       101         -          1580\n##  % delay 3+ days\n##              24%\n##              28%\n##              27%\n##              26%\n##              27%\n##              27%\n##                -"},{"path":"tables-descriptive.html","id":"bách-phân-vị","chapter":"17 Bảng mô tả","heading":"Bách phân vị","text":"Bách phân vị và tứ phân vị trong dplyr xứng đáng được đề cập tới. Để trả về tứ phân vị, sử dụng quantile() với các giá trị mặc định hoặc chỉ rõ giá trị bạn muốn bằng đối số probs =.Nếu bạn muốn trả về phân vị theo nhóm, bạn có thể gặp phải các kết quả đầu ra dài và ít hữu ích hơn nếu bạn chỉ cần thêm cột vào group_by(). Thay vào đó, hãy thử cách tiếp cận này - tạo một cột cho mỗi mức phân vị mong muốn.Mặc dù dplyr summarise() chắc chắn cung cấp khả năng kiểm soát tốt hơn, bạn có thể thấy rằng tất cả các thống kê tổng hợp mà bạn cần có thể được tạo ra với hàm get_summary_stat() từ package rstatix. Nếu thực hiện trên dữ liệu đã được nhóm, nó sẽ trả về các phân vị 0%, 25%, 50%, 75%, và 100%. applied ungrouped data, can specify percentiles probs = c(.05, .5, .75, .98).","code":"\n# get default percentile values of age (0%, 25%, 50%, 75%, 100%)\nlinelist %>% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))##   age_percentiles\n## 1               0\n## 2               6\n## 3              13\n## 4              23\n## 5              84\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %>% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )##   age_percentiles\n## 1               1\n## 2              13\n## 3              23\n## 4              48\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )## # A tibble: 6 x 5\n##   hospital                               p05   p50   p75   p98\n##   <chr>                                <dbl> <dbl> <dbl> <dbl>\n## 1 Central Hospital                         1    12    21  48  \n## 2 Military Hospital                        1    13    24  45  \n## 3 Missing                                  1    13    23  48.2\n## 4 Other                                    1    13    23  50  \n## 5 Port Hospital                            1    14    24  49  \n## 6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\nlinelist %>% \n  group_by(hospital) %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## `mutate_if()` ignored the following grouping variables:\n## Column `variable`\n## `mutate_if()` ignored the following grouping variables:\n## Column `variable`\n## `mutate_if()` ignored the following grouping variables:\n## Column `variable`\n## `mutate_if()` ignored the following grouping variables:\n## Column `variable`\n## `mutate_if()` ignored the following grouping variables:\n## Column `variable`\n## `mutate_if()` ignored the following grouping variables:\n## Column `variable`## # A tibble: 6 x 8\n##   hospital                             variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <chr>                                <chr>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 Central Hospital                     age        445     0     6    12    21     58\n## 2 Military Hospital                    age        884     0     6    14    24     72\n## 3 Missing                              age       1441     0     6    13    23     76\n## 4 Other                                age        873     0     6    13    23     69\n## 5 Port Hospital                        age       1739     0     6    14    24     68\n## 6 St. Mark's Maternity Hospital (SMMH) age        420     0     7    12    22     84\nlinelist %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## `mutate_if()` ignored the following grouping variables:\n## Column `variable`## # A tibble: 1 x 7\n## # Groups:   variable [1]\n##   variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <chr>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 age       5802     0     6    13    23     84"},{"path":"tables-descriptive.html","id":"tóm-tắt-dữ-liệu-tổng-hợp","chapter":"17 Bảng mô tả","heading":"Tóm tắt dữ liệu tổng hợp","text":"Nếu bạn bắt đầu với dữ liệu tổng hợp (aggregated data), sử dụng n() để trả về số lượng các dòng, không phải là tổng của các số lượng được đếm. Để lấy tổng, sử dụng sum() trên cột của dữ liệu đếm.Ví dụ, giả sử bạn đang bắt đầu với data frame đếm số lượng như bên dưới, gọi là linelist_agg - nó hiển thị ở định dạng “dọc”, các trường hợp được tính theo outcome và giới tính.Sau đây chúng ta sẽ tạo data frame minh hoạt số trường hợp của linelist được đếm theo outcome và gender (các giá trị missing được loại bỏ để rõ ràng).Để tính tổng số lượng (trong cột n) theo nhóm bạn có thể sử dụng hàm summarise() nhưng đặt cột mới bằng sum(n, na.rm=T). Để thêm phần tử điều kiện vào phép toán tổng, bạn có thể sử dụng cú pháp dấu ngoặc vuông tập hợp con [ ] trên cột đếm.","code":"\nlinelist_agg <- linelist %>% \n  drop_na(gender, outcome) %>% \n  count(outcome, gender)\n\nlinelist_agg##   outcome gender    n\n## 1   Death      f 1227\n## 2   Death      m 1228\n## 3 Recover      f  953\n## 4 Recover      m  950\nlinelist_agg %>% \n  group_by(outcome) %>% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))## # A tibble: 2 x 4\n##   outcome total_cases male_cases female_cases\n##   <chr>         <int>      <int>        <int>\n## 1 Death          2455       1228         1227\n## 2 Recover        1903        950          953"},{"path":"tables-descriptive.html","id":"across-trên-nhiều-cột","chapter":"17 Bảng mô tả","heading":"across() trên nhiều cột","text":"Bạn có thể sử dụng summarise() trên nhiều cột bằng hàm across(). Điều này làm cho mọi thứ dễ dàng hơn khi bạn muốn tính toán các thống kê giống nhau cho nhiều cột. Đặt across() bên trong summarise() và chỉ rõ những điều sau:.cols = tên cột viết dưới dạng vector c() hoặc sử dụng các hàm trợ giúp chọn cột “tidyselect” (được giải thích bên dưới).fns = hàm thực hiện (không có dấu ngoặc) - bạn có thể đưa nhiều hàm vào thông qua list()Ví dụ dưới đây, mean() được áp dụng cho các cột dữ liệu dạng số. Một vectơ tên của các cột được gán cho .cols = và hàm duy nhất mean được xác định (không có dấu ngoặc) cho .fns =. Bất kỳ đối số bổ sung nào cho hàm (vd: na.rm=TRUE) được cung cấp phía sau .fns =, ngăn cách bởi dấu phẩy.Có thể khó để hiểu được thứ tự của dấu ngoặc đơn và dấu phẩy chính xác khi sử dụng across(). Hãy nhớ là bên trong hàm across() bạn phải bao gồm các cột, các hàm, và tất cả những đối số cần thiết cho các hàm.Nhiều hàm có thể được chạy cùng một lúc. Dưới đây hàm mean và sd được cung cấp cho .fns = bên trong một list(). Bạn có cơ hội cung cấp tên ký tự (vd: “mean” và “sd”) để thêm vào tên các cột mới.Dưới đây là danh sách các hàm trợ giúp “tidyselect” bạn có thể cung cấp cho .cols = để lựa chọn cột:everything() - tất cả các cột khác không được đề cậplast_col() - cột cuối cùngwhere() - áp dụng một hàm cho tất cả các cột và chọn những cột trả về giá trị TRUEstarts_with() - khớp với một tiền tố được chỉ định. Ví dụ: starts_with(\"date\")ends_with() - khớp với một hậu tố được chỉ định. Ví dụ: ends_with(\"_end\")contains() - cột chứa một chuỗi ký tự. Ví dụ: contains(\"time\")matches() - áp dụng một biểu thức chính quy (regex). Ví dụ: contains(\"[pt]al\")num_range() - khoảng giá trị sốany_of() - khớp nếu cột được đặt tên. Hữu ích nếu tên có thể không tồn tại. Ví dụ: any_of(date_onset, date_death, cardiac_arrest)Ví dụ, để trả về giá trị trung bình của tất cả các cột dạng số, sử dụng () và thêm vào hàm .numeric() (không có dấu ngoặc). Tất cả những thứ này vẫn được đặt trong hàm across().","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # columns\n                   .fns = mean,                               # function\n                   na.rm=T))                                  # extra arguments## # A tibble: 3 x 5\n##   outcome age_years  temp wt_kg ht_cm\n##   <chr>       <dbl> <dbl> <dbl> <dbl>\n## 1 Death        15.9  38.6  52.6  125.\n## 2 Recover      16.1  38.6  52.5  125.\n## 3 <NA>         16.2  38.6  53.0  125.\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # columns\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiple functions \n                   na.rm=T))                                 # extra arguments## # A tibble: 3 x 9\n##   outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd ht_cm_mean\n##   <chr>            <dbl>        <dbl>     <dbl>   <dbl>      <dbl>    <dbl>      <dbl>\n## 1 Death             15.9         12.3      38.6   0.962       52.6     18.4       125.\n## 2 Recover           16.1         13.0      38.6   0.997       52.5     18.6       125.\n## 3 <NA>              16.2         12.8      38.6   0.976       53.0     18.9       125.\n## # ... with 1 more variable: ht_cm_sd <dbl>\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(\n    .cols = where(is.numeric),  # all numeric columns in the data frame\n    .fns = mean,\n    na.rm=T))## # A tibble: 3 x 12\n##   outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp   bmi\n##   <chr>        <dbl> <dbl>     <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl> <dbl> <dbl>\n## 1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6  45.6\n## 2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6  47.7\n## 3 <NA>          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6  48.3\n## # ... with 1 more variable: days_onset_hosp <dbl>"},{"path":"tables-descriptive.html","id":"tbls_pivot_wider","chapter":"17 Bảng mô tả","heading":"Xoay trục ngang (Pivot wider)","text":"Nếu bạn thích bảng của mình ở định dạng “rộng”, bạn có thể biến đổi nó sử dụng hàm tidyr pivot_wider(). Bạn có thể sẽ cần đặt lại tên cho các cột bằng rename(). Để tìm hiểu thêm, vui lòng xem chương [Pivoting dữ liệu].Ví dụ sau đây bắt đầu bằng một bảng “dài” age_by_outcome từ mục Tỷ lệ. Để dễ hình dung, chúng ta tạo lại bảng và ra:Để xoay trục ngang, chúng ta tạo các cột mới từ các giá trị trong cột hiện có age_cat (bằng cách đặt names_from = age_cat). Chúng ta cũng chỉ định rằng các giá trị bảng mới sẽ đến từ cột hiện có n, với values_from = n. Các cột không được đề cập trong lệnh pivoting (outcome) sẽ không thay đổi ở phía ngoài cùng bên trái.","code":"\nage_by_outcome <- linelist %>%                  # begin with linelist\n  group_by(outcome) %>%                         # group by outcome \n  count(age_cat) %>%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group\nage_by_outcome %>% \n  select(-percent) %>%   # keep only counts for simplicity\n  pivot_wider(names_from = age_cat, values_from = n)  ## # A tibble: 3 x 10\n## # Groups:   outcome [3]\n##   outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n##   <chr>   <int> <int>   <int>   <int>   <int>   <int>   <int> <int> <int>\n## 1 Death     471   476     438     323     477     329      33     3    32\n## 2 Recover   364   391     303     251     367     238      38     3    28\n## 3 <NA>      260   228     200     169     229     187      24    NA    26"},{"path":"tables-descriptive.html","id":"tbl_dplyr_totals","chapter":"17 Bảng mô tả","heading":"Tổng các hàng","text":"Khi hàm summarise() vận hành trên dữ liệu đã được nhóm, nó không tính “tổng” một cách tự động. Sau đây là hai cách tiếp cận giúp bạn thêm tổng hàng:","code":""},{"path":"tables-descriptive.html","id":"janitors-adorn_totals","chapter":"17 Bảng mô tả","heading":"janitor’s adorn_totals()","text":"Nếu bảng của bạn chỉ chứa duy nhất số lượng hoặc tỷ lệ/tỷ lệ phần trăm có thể được tổng hợp thành một tổng, thì bạn có thể tính tổng sử dụng hàm adorn_totals() của package janitor như đã được mô tả bên trên. Lưu ý là hàm này chỉ có thể tính tổng của các cột định dạng là số - nếu bạn muốn tính các loại tổng khác, vui lòng xem cách tiếp cận tiếp theo bằng dplyr.Dưới đây, bộ dữ liệu linelist được nhóm theo giới và tóm tắt thành một bảng mô tả số trường hợp có outcome đã biết, tử vong và phục hồi. Piping bảng tới hàm adorn_totals() để thêm tổng các hàng ở hàng dưới cùng thể hiện giá trị tổng của từng cột. Các hàm adorn_*() khác điều chỉnh cách kết quả được hiển thị như được comment trong phần code.","code":"\nlinelist %>% \n  group_by(gender) %>%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Number of rows in group where outcome is not missing\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Number of rows in group where outcome is Death\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Number of rows in group where outcome is Recovered\n  ) %>% \n  adorn_totals() %>%                                # Adorn total row (sums of each numeric column)\n  adorn_percentages(\"col\") %>%                      # Get column proportions\n  adorn_pct_formatting() %>%                        # Convert proportions to percents\n  adorn_ns(position = \"front\")                      # display % and counts (with counts in front)##  gender known_outcome       n_death     n_recover\n##       f 2180  (47.8%) 1227  (47.5%)  953  (48.1%)\n##       m 2178  (47.7%) 1228  (47.6%)  950  (47.9%)\n##    <NA>  207   (4.5%)  127   (4.9%)   80   (4.0%)\n##   Total 4565 (100.0%) 2582 (100.0%) 1983 (100.0%)"},{"path":"tables-descriptive.html","id":"summarise-trên-dữ-liệu-tổng-rồi-sau-đó-bind_rows","chapter":"17 Bảng mô tả","heading":"summarise() trên dữ liệu “tổng” rồi sau đó bind_rows()","text":"Nếu bảng của bạn chứa các phép tính thống kế chẳng hạn như median(), mean(), v.v, thì cách tiếp cận dùng hàm adorn_totals() bên trên sẽ không đủ. Thay vào đó, để có được thống kê tóm tắt cho toàn bộ tập dữ liệu, bạn phải tính toán chúng bằng lệnh summarise() một cách độc lập sau đó gắn các kết quả này với bảng tổng hợp theo nhóm ban đầu. Để làm điều này, bạn có thể sử dụng hàm bind_rows() từ dplyr như được mô tả trong chương Nối dữ liệu. Dưới đây là một ví dụ:Bạn có thể tạo bảng tổng hợp của outcome theo bệnh viện với group_by() và summarise() như sau:Để tính tổng, vẫn sử dụng hàm summarise() nhưng chỉ nhóm dữ liệu theo outcome (không theo bệnh viện), như dưới đây:Bây giờ chúng ta có thể nối hai data frames này lại với nhau. Lưu ý là bảng by_hospital có 4 cột trong khi đó bảng kết quả totals có 3 cột. Bằng việc sử dụng bind_rows(), các cột được kết hợp theo tên, và bất kỳ khoảng trống nào sẽ được điền vào bằng giá trị NA (ví dụ ở cột hospital là các giá trị cho hai hàng totals mới). Sau khi gắn các hàng, chúng ta chuyển các khoảng trống đó thành “Tổng” bằng cách sử dụng replace_na() (xem chương Làm sạch số liệu và các hàm quan trọng).Đây là bảng mới với các hàng “Tổng” ở các hàng dưới cùng của bảng.Bảng này đang có định dạng “dài”, có thể là những gì bạn muốn. Tuy nhiên, bạn có thể xoay bảng này rộng hơn theo chiều ngang để dễ đọc. Xem thêm ở phần Xoay trục ngang (Pivot wider) bên trên, và chương Xoay trục dữ liệu. Bạn cũng có thêm nhiều cột nữa, và sắp xếp chúng một cách đẹp mắt. Phần code được trình bày bên dưới.Tiếp đó bạn có thể bảng kết quả dưới dạng một bức ảnh đẹp - sau đây là output được bằng flextable. Bạn có thể đọc chuyên sâu hơn về ví dụ này và cách tạo được bảng “đẹp” tương tự thế này trong chương Trình bày bảng.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nby_hospital <- linelist %>% \n  filter(!is.na(outcome) & hospital != \"Missing\") %>%  # Remove cases with missing outcome or hospital\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T))               # median CT value per group\n  \nby_hospital # print table## # A tibble: 10 x 4\n## # Groups:   hospital [5]\n##    hospital                             outcome     N ct_value\n##    <chr>                                <chr>   <int>    <dbl>\n##  1 Central Hospital                     Death     193       22\n##  2 Central Hospital                     Recover   165       22\n##  3 Military Hospital                    Death     399       21\n##  4 Military Hospital                    Recover   309       22\n##  5 Other                                Death     395       22\n##  6 Other                                Recover   290       21\n##  7 Port Hospital                        Death     785       22\n##  8 Port Hospital                        Recover   579       21\n##  9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n## 10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\ntotals <- linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # These statistics are now by outcome only     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # print table## # A tibble: 2 x 3\n##   outcome     N ct_value\n##   <chr>   <int>    <dbl>\n## 1 Death    1971       22\n## 2 Recover  1469       22\ntable_long <- bind_rows(by_hospital, totals) %>% \n  mutate(hospital = replace_na(hospital, \"Total\"))\ntable_long %>% \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known)                                  # Arrange rows from lowest to highest (Total row at bottom)## # A tibble: 6 x 8\n## # Groups:   hospital [6]\n##   hospital N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death ct_value_Death\n##   <chr>      <int>     <int> <chr>                  <dbl>   <int> <chr>              <dbl>\n## 1 St. Mar~     325       126 38.8%                     22     199 61.2%                 22\n## 2 Central~     358       165 46.1%                     22     193 53.9%                 22\n## 3 Other        685       290 42.3%                     21     395 57.7%                 22\n## 4 Militar~     708       309 43.6%                     22     399 56.4%                 21\n## 5 Port Ho~    1364       579 42.4%                     21     785 57.6%                 22\n## 6 Total       3440      1469 42.7%                     22    1971 57.3%                 22"},{"path":"tables-descriptive.html","id":"tbl_gt","chapter":"17 Bảng mô tả","heading":"17.5 gtsummary package","text":"Nếu bạn muốn các thống kê tóm tắt của mình dưới dạng đồ họa đẹp mắt, sẵn sàng xuất bản, bạn có thể sử dụng package gtsummary và hàm của nó tbl_summary(). Phần code ban đầu có thể trông phức tạp một chút, nhưng kết quả đầu ra trông rất đẹp và ra Viewer panel của RStudio dưới dạng một ảnh HTML. Đọc bản tóm tắt ở đây.Bạn cũng có thể thêm kết quả của các kiểm định thống kê vào các bảng của gtsummary. Quy trình này được trình bày ở mục gtsummary trong chương Các kiểm định thống kê cơ bản.Để giới thiệu về tbl_summary(), trước tiên chúng ta sẽ chỉ ra các quy trình cơ bản nhất, giúp bạn thực sự tạo ra một bảng lớn và đẹp. Sau đó, chúng ta sẽ tìm hiểu chi tiết hơn về cách thực hiện các điều chỉnh và các bảng được thiết kế sẵn.","code":""},{"path":"tables-descriptive.html","id":"bảng-tổng-hợp","chapter":"17 Bảng mô tả","heading":"Bảng tổng hợp","text":"Cách làm việc mặc định của tbl_summary() khá kinh ngạc - nó lấy các cột bạn cung cấp và tạo một bảng tóm tắt chỉ trong một lệnh. Hàm ra số liệu thống kê phù hợp với lớp cột: trung vị và khoảng tứ phân vị (IQR) cho các cột số, và số lượng (%) cho các cột danh mục. Giá trị missing được chuyển đổi thành “Unknown”. Chú thích được thêm vào cuối bảng để giải thích các phép tính thống kê, trong khi tổng N được hiển thị ở trên cùng.\n          1\n          \n           \n          Median (IQR); n (%)\n          ","code":"\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>%  # keep only the columns of interest\n  tbl_summary()                                                  # default"},{"path":"tables-descriptive.html","id":"các-điều-chỉnh","chapter":"17 Bảng mô tả","heading":"Các điều chỉnh","text":"Bây giờ chúng tôi sẽ giải thích cách hoạt động của hàm và cách điều chỉnh. Các đối số chính được trình bày chi tiết bên dưới:=\nBạn có thể phân tầng bảng của mình theo một cột (ví dụ theo outcome), để tạo thành bảng 2 chiều.statistic =\nSử dụng phương trình để chỉ định thống kê nào sẽ được hiển thị và cách hiển thị chúng. Có hai vế của phương trình, được ngăn cách bởi dấu ~. Ở vế phải, trong dấu ngoặc kép, là hiển thị phép toán thống kê mong muốn, và ở vế trái là các cột mà phép thống kê đó sẽ áp dụng.Vế phải của phương trình sử dụng cú pháp của hàm str_glue() từ stringr (xem Ký tự và chuỗi), với chuỗi hiển thị mong muốn trong dấu ngoặc kép và các phép toán thống kê trong dấu ngoặc nhọn. Bạn có thể thêm các phép thống kê như là “n” (số lượng), “N” (mẫu số), “mean”, “median”, “sd”, “max”, “min”, phân vị “p##” như là “p25”, hoặc phần trăm của một tổng như là “p”. Xem ?tbl_summary để biết thêm chi tiết.Đối với phía bên trái của phương trình, bạn có thể chỉ định các cột theo tên (ví dụ: age hoặc c(age, gender)) hoặc sử dụng các hàm trợ giúp như all_continuous(), all_categorical(), contains(), starts_with(), v.v.Một ví dụ đơn giản về phương trình statistic = có thể tham khảo ở bên dưới, để chỉ giá trị trung bình của cột age_years:\n          1\n          \n           \n          Mean\n          Một phương trình phức tạp hơn một chút có thể như\"({min}, {max})\", kết hợp các giá trị max và min trong dấu ngoặc đơn và được phân tách bằng dấu phẩy:\n          1\n          \n           \n          (Range)\n          Bạn cũng có thể phân biệt cú pháp cho các cột hoặc loại cột riêng biệt. Trong ví dụ phức tạp hơn bên dưới, giá trị được cung cấp cho statistc = là một danh sách chỉ ra rằng đối với tất cả các cột dạng số thì bảng sẽ ra giá trị trung bình và độ lệch chuẩn bên trong ngoặc, trong khi các cột dạng danh sách thì sẽ ra n, mẫu số, và phần trăm.digits =\nĐiều chỉnh các chữ số và làm tròn. Theo tùy chọn, điều này có thể được chỉ định chỉ dành cho các cột dạng số liên tục (như bên dưới).label =\nĐiều chỉnh cách hiển thị tên cột. Cung cấp tên cột và nhãn mong muốn của nó được phân tách bằng dấu ngã. Theo mặc định thì tên cột được hiển thị.missing_text =\nĐiều chỉnh cách giá trị missing được hiển thị. Mặc định hiển thị là “Unknown”.type =\nSử dụng để điều chỉnh số lượng cấp độ của thống kê được hiển thị Cú pháp tương tự như statistic = trong đó bạn cung cấp một phương trình với các cột ở bên trái và một giá trị ở bên phải. Hai trường hợp phổ biến bao gồm:type = all_categorical() ~ \"categorical\" Buộc các cột nhị phân (ví dụ: fever có/không) hiển thị tất cả các cấp độ thay vì chỉ hiện thị hàng “có”type = all_continuous() ~ \"continuous2\" Cho phép các kết quả thống kê được trình bày theo nhiều dòng cho mỗi biến, như được trình bày trong phần sauTrong ví dụ dưới đây, mỗi đối số này được sử dụng để điều chỉnh bảng ban đầu:\n          1\n          \n           \n          Mean (SD); n / N (%)\n          ","code":"\nlinelist %>% \n  select(age_years) %>%         # keep only columns of interest \n  tbl_summary(                  # create summary table\n    statistic = age_years ~ \"{mean}\") # print mean of age\nlinelist %>% \n  select(age_years) %>%                       # keep only columns of interest \n  tbl_summary(                                # create summary table\n    statistic = age_years ~ \"({min}, {max})\") # print min and max of age\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>% # keep only columns of interest\n  tbl_summary(     \n    by = outcome,                                               # stratify entire table by outcome\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats and format for continuous columns\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats and format for categorical columns\n    digits = all_continuous() ~ 1,                              # rounding for continuous columns\n    type   = all_categorical() ~ \"categorical\",                 # force all categorical levels to display\n    label  = list(                                              # display labels for column names\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # how missing values should display\n  )## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"tables-descriptive.html","id":"thống-kê-nhiều-dòng-cho-các-biến-liên-tục","chapter":"17 Bảng mô tả","heading":"Thống kê nhiều dòng cho các biến liên tục","text":"Nếu bạn muốn nhiều dòng thống kê cho các biến liên tục, bạn có thể thiết lập type = thành “continuous2”. Bạn có thể kết hợp tất cả các yếu tố được hiển thị trước đó trong một bảng bằng cách chọn thống kê bạn muốn hiển thị. Để làm điều này, bạn cần cho hàm biết rằng bạn muốn khôi phục bảng bằng cách nhập type là “continuous2”. Số lượng các giá trị missing được hiển thị là “Unknown”.Có nhiều cách khác để chỉnh sửa các bảng này, bao gồm thêm giá trị p, chỉnh sửa màu sắc và tiêu đề, v.v. Các phần này được đề cập trong tài liệu trợ giúp đính kèm (nhập ?tbl_summary trong cửa sổ Console), và một số được đề cập trong chương Các kiểm định thống kê cơ bản.","code":"\nlinelist %>% \n  select(age_years, temp) %>%                      # keep only columns of interest\n  tbl_summary(                                     # create summary table\n    type = all_continuous() ~ \"continuous2\",       # indicate that you want to print multiple statistics \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # line 1: mean and SD\n      \"{median} ({p25}, {p75})\",                   # line 2: median and IQR\n      \"{min}, {max}\")                              # line 3: min and max\n    )"},{"path":"tables-descriptive.html","id":"base-r-1","chapter":"17 Bảng mô tả","heading":"17.6 base R","text":"Bạn có thể sử dụng hàm table() để tạo bảng đơn và bảng chéo các cột. Không giống như các cách ở trên, bạn phải chỉ định data frame mỗi khi bạn tham chiếu đến tên cột, như được trình bày dưới đây.THẬN TRỌNG: Giá trị NA (missing) sẽ không sẽ không được lập bảng trừ khi bạn bao gồm đối số useNA = \"always\" (cũng có thể được đặt thành “” hoặc “ifany”).MẸO: Bạn có thể sử dụng %$% từ package magrittr để loại bỏ việc lặp lại các data frame trong các hàm base. Chẳng hạn, ví dụ bên dưới có thể được viết lại thành linelist %$% table(outcome, useNA = \"always\")Có thể lập bảng chéo từ nhiều cột bằng cách liệt kê chúng nối tiếp nhau, phân tách bằng dấu phẩy. Hoặc là, bạn có thể gán cho mỗi cột một “tên” như Outcome = linelist$outcome.","code":"\ntable(linelist$outcome, useNA = \"always\")## \n##   Death Recover    <NA> \n##    2582    1983    1323\nage_by_outcome <- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # save table as object\nage_by_outcome   # print table##        \n##         Death Recover <NA>\n##   0-4     471     364  260\n##   5-9     476     391  228\n##   10-14   438     303  200\n##   15-19   323     251  169\n##   20-29   477     367  229\n##   30-49   329     238  187\n##   50-69    33      38   24\n##   70+       3       3    0\n##   <NA>     32      28   26"},{"path":"tables-descriptive.html","id":"tỷ-lệ","chapter":"17 Bảng mô tả","heading":"Tỷ lệ","text":"Để trả về tỷ lệ, hãy chuyển bảng trên vào hàm prop.table(). Sử dụng đối số margins = để chỉ định xem bạn muốn tỷ lệ của hàng (1), của cột (2) hay của toàn bảng (3). Để dễ nhìn, chúng ta pipe bảng trên vào hàm round() của base R, chỉ định 2 chữ số sau dấu phẩy.","code":"\n# get proportions of table defined above, by rows, rounded\nprop.table(age_by_outcome, 1) %>% round(2)##        \n##         Death Recover <NA>\n##   0-4    0.43    0.33 0.24\n##   5-9    0.43    0.36 0.21\n##   10-14  0.47    0.32 0.21\n##   15-19  0.43    0.34 0.23\n##   20-29  0.44    0.34 0.21\n##   30-49  0.44    0.32 0.25\n##   50-69  0.35    0.40 0.25\n##   70+    0.50    0.50 0.00\n##   <NA>   0.37    0.33 0.30"},{"path":"tables-descriptive.html","id":"tổng","chapter":"17 Bảng mô tả","heading":"Tổng","text":"Để thêm tổng hàng và tổng cột, hãy chuyển bảng vào hàm addmargins(). Cách này hoạt động cho cả số lượng và tỷ lệ.","code":"\naddmargins(age_by_outcome)##        \n##         Death Recover <NA>  Sum\n##   0-4     471     364  260 1095\n##   5-9     476     391  228 1095\n##   10-14   438     303  200  941\n##   15-19   323     251  169  743\n##   20-29   477     367  229 1073\n##   30-49   329     238  187  754\n##   50-69    33      38   24   95\n##   70+       3       3    0    6\n##   <NA>     32      28   26   86\n##   Sum    2582    1983 1323 5888"},{"path":"tables-descriptive.html","id":"chuyển-đổi-thành-data-frame","chapter":"17 Bảng mô tả","heading":"Chuyển đổi thành data frame","text":"Chuyển đổi trực tiếp một đối tượng dạng table() sang một data frame không phải là một đường thẳng. Cách tiếp cận được trình bày như dưới đây:Tạo một bảng, mà không sử dụng useNA = \"always\". Thay vào đó chuyển giá trị NA thành “(Missing)” với hàm fct_explicit_na() của package forcats.Thêm tổng (tùy chọn) bằng cách piping tới addmargins()Pipe tới hàm .data.frame.matrix() của base RPipe bảng trên vào hàm rownames_to_column() của package tibble, ghi rõ tên cho cột đầu tiênIn, Xem hoặc xuất bảng như mong muốn. Trong ví dụ này, chúng ta sử dụng hàm flextable() từ package flextable như đã được mô tả trong chương Kết quả sẽ được ra cửa sổ RStudio viewer dưới dạng một hình ảnh HTML đẹp.Age CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888","code":"\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %>% \n  addmargins() %>% \n  as.data.frame.matrix() %>% \n  tibble::rownames_to_column(var = \"Age Category\") %>% \n  flextable::flextable()"},{"path":"tables-descriptive.html","id":"nguồn-1","chapter":"17 Bảng mô tả","heading":"17.7 Nguồn","text":"Phần lớn thông tin trong chương này được tham khảo từ các nguồn và bản tóm tắt trực tuyến dưới đây:gtsummarydplyr","code":""},{"path":"stat-tests.html","id":"stat-tests","chapter":"18 Các kiểm định thống kê cơ bản","heading":"18 Các kiểm định thống kê cơ bản","text":"Chương này sẽ trình bày cách để thực hiện các phép kiểm định thống kê cơ bản bằng cách sử dụng base R, rstatix, và gtsummary.Kiểm định tKiểm định Shapiro-WilkKiểm định tổng thứ hạng WilcoxonKiểm định Kruskal-WallisKiểm định Chi-squared (Chi bình phương)Tương quan giữa các biến định lượng…nhiều kiểm định khác có thể được thực hiện, nhưng chúng tôi chỉ trình bày các kiểm định thông dụng và kết nối với các phần khác trong cuốn sổ tay này.Mỗi package được đề cập bên trên đều có một số ưu điểm và khuyết điểm nhất định:Sử dụng các câu lệnh của base để các kết quả đầu ra thống kê trong R ConsoleSử dụng các câu lệnh của rstatix để cho kết quả dưới dạng data frame hoặc khi muốn thực hiện các kiểm định theo nhómSử dụng các câu lệnh của gtsummary khi muốn kết quả là các bảng biểu có thể sử dụng được ngay","code":""},{"path":"stat-tests.html","id":"các-bước-chuẩn-bị","chapter":"18 Các kiểm định thống kê cơ bản","heading":"18.1 Các bước chuẩn bị","text":"","code":""},{"path":"stat-tests.html","id":"gọi-các-packages","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Gọi các packages","text":"Đoạn code này hiển thị việc gọi các package cần thiết cho phân tích. Trong cuốn sổ tay này, chúng tôi nhấn mạnh đến hàm p_load() trong package pacman, cài đặt gói lệnh nếu cần thiết và gọi chúng ra để sử dụng. Các package đã cài đặt cũng có thể được gọi ra bằng library() từ base R. Xem thêm thông tin các package của R trong chương R cơ bản.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics, \n  gtsummary,    # summary statistics and tests\n  rstatix,      # statistics\n  corrr,        # correlation analayis for numeric variables\n  janitor,      # adding totals and percents to tables\n  flextable     # converting tables to HTML\n  )"},{"path":"stat-tests.html","id":"nhập-số-liệu","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Nhập số liệu","text":"Chúng ta nhập bộ số liệu của các ca bệnh về một vụ dịch Ebola mô phỏng. Để tiện theo dõi, bấm để tải bộ số liệu linelist “đã được làm sạch” (.rds file). Nhập số liệu bằng hàm import() từ package rio package (nó chấp nhận nhiều loại tập tin như .xlsx, .rds, .csv - xem thêm chương Nhập xuất dữ liệu để biết thêm chi tiết).50 hàng đầu tiên của bộ dữ liệu linelist được hiển thị như dưới đây.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"stat-tests.html","id":"các-kiểm-định-trong-base-r","chapter":"18 Các kiểm định thống kê cơ bản","heading":"18.2 Các kiểm định trong base R","text":"Các lệnh trong base R functions conduct statistical tests. có thể được sử dụng để thực hiện các kiểm định thống kê. Các câu lệnh tương đối đơn giản và kết quả sẽ hiển thị trong bảng điều khiển R Console. Tuy nhiên, kết quả đầu ra thường dưới dạng liệt kê, vì thế sẽ khó thao tác hơn nếu muốn sử dụng kết quả trong các thao tác tiếp theo.","code":""},{"path":"stat-tests.html","id":"kiểm-định-t","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định t","text":"Một kiểm định t, hay còn được gọi là “Student’s t-Test”, thường được sử dụng để xác định có sự khác biệt có ý nghĩa thống kê giữa giá trị trung bình của hai nhóm. Bên dưới là cú pháp để thực hiện kiểm định này tùy thuộc vào các cột có trong cùng một data frame hay không.Cú pháp 1: Đây là cú pháp khi cột của biến liên tục và phân loại nằm trong cùng một data frame. Đặt biến liên tục bên trái và biến phân loại bên phải của phương trình. Ghi rõ bộ số liệu sau data =. Các tùy chọn khác như số liệu bắt cặp, viết thêm paired = TRUE, khoảng tin cậy, viết thêm conf.level = (mặc định là 0.95), và giả thuyết thay thế alternative = (hai đuôi - “two.sided”, hoặc một đuôi nhỏ hơn hay lớn hơn - “less”, “greater”). Gõ ?t.test để biết thêm chi tiết.Cú pháp 2: Đây là cú pháp khi sánh hai véc tơ dạng số. Ví dụ như hai cột nằm trong hai bộ số liệu khác nhau.Kiểm định t cũng được sử dụng để xác định có sự khác biệt có ý nghĩa thống kê giữa giá trị trung bình của mẫu với một số giá trị cụ thể. Đây là phép kiểm định t cho một mẫu với trung bình quần thể giả thuyết/đã biết như mu =:","code":"\n## compare mean age by outcome group with a t-test\nt.test(age_years ~ gender, data = linelist)## \n##  Welch Two Sample t-test\n## \n## data:  age_years by gender\n## t = -21.344, df = 4902.3, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.571920 -6.297975\n## sample estimates:\n## mean in group f mean in group m \n##        12.60207        19.53701\nt.test(df1$age_years, df2$age_years)\nt.test(linelist$age_years, mu = 45)"},{"path":"stat-tests.html","id":"kiểm-định-shapiro-wilk","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Shapiro-Wilk","text":"Kiểm định Shapiro-Wilk có thể được sử để xác định xem một mẫu có phân bố bình thường/phân bố chuản hay không (một giả định của nhiều kiểm định khác, ví dụ như kiểm định t). Tuy nhiên, phép kiểm định này chỉ có thể được sử dụng cho một mẫu có từ 3 đến 5000 quan sát. Đối với cỡ mẫu lớn hơn, nên sử dụng biểu đồ quantile-quantile plot.","code":"\nshapiro.test(linelist$age_years)"},{"path":"stat-tests.html","id":"kiểm-định-tổng-thứ-hạng-wilcoxon","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định tổng thứ hạng Wilcoxon","text":"Kiểm định tổng thứ hạng Wilcoxon, hay còn gọi là kiểm định Mann–Whitney U, thường được sử dụng để giúp xác định xem hai mẫu có cùng phân bố hay không khi quần thể của chúng không có phân bố chuẩn hoặc có phương sai không bằng nhau.","code":"\n## compare age distribution by outcome group with a wilcox test\nwilcox.test(age_years ~ outcome, data = linelist)## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  age_years by outcome\n## W = 2501868, p-value = 0.8308\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"stat-tests.html","id":"kiểm-định-kruskal-wallis","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Kruskal-Wallis","text":"Kiểm định Kruskal-Wallis là một phần mở rộng của kiểm định tổng thứ hạng Wilcoxon mà có thể được sử dụng để kiểm định sự khác biệt trong phân bố của nhiều hơn hai mẫu. Khi có hai mẫu được sử dụng, nó cho kết quả giống như của kiểm định tổng thứ hạng Wilcoxon.","code":"\n## compare age distribution by outcome group with a kruskal-wallis test\nkruskal.test(age_years ~ outcome, linelist)## \n##  Kruskal-Wallis rank sum test\n## \n## data:  age_years by outcome\n## Kruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308"},{"path":"stat-tests.html","id":"kiểm-định-chi-bình-phương","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Chi bình phương","text":"Kiểm định Chi bình phương của Pearson được sử dụng trong kiểm tra sự khác biệt có ý nghĩa thống kê giữa các biến phân loại.","code":"\n## compare the proportions in each group with a chi-squared test\nchisq.test(linelist$gender, linelist$outcome)## \n##  Pearson's Chi-squared test with Yates' continuity correction\n## \n## data:  linelist$gender and linelist$outcome\n## X-squared = 0.0011841, df = 1, p-value = 0.9725"},{"path":"stat-tests.html","id":"rstatix-package","chapter":"18 Các kiểm định thống kê cơ bản","heading":"18.3 rstatix package","text":"Package rstatix cho phép thực hiện các kiểm định thống kê và truy xuất kết quả “dễ sử dụng cho các tính toán tiếp theo”. Có nghĩa là kết quả xuất tự động thành một data frame để có thể thực hiện các thao tác tiếp theo. Nó cũng dễ dàng để nhóm dữ liệu mà sẽ được chuyền vào các hàm, ở đó các thống kê được thực hiện cho từng nhóm.","code":""},{"path":"stat-tests.html","id":"tóm-tắt-thống-kê","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Tóm tắt thống kê","text":"Hàm get_summary_stats() là một cách thực hiện tóm tắt thống kê nhanh. Chỉ cần đưa bộ số liệu và chỉ định các cột muốn phân tích vào hàm này. Nếu không có cột nào được cụ thể, tóm tắt thống kê sẽ tính toán cho tất cả các cột.Tóm tắt thống kê đầy đủ sẽ cho kết quả mặc định như sau: số quan sát (n), giá trị nhỏ nhất, giá trị lớn nhất, trung vị, giá trị tứ phân vị thứ nhất (25%), giá trị tứ phân vị thứ ba (75%), khoảng tứ phân vị, độ lệch tuyệt đối của trung vị (mad), trung bình, độ lệch chuẩn, sai số chuẩn và khoảng tin cậy của trung bình.Có thể tóm tắt một số giá trị thống kê bằng cách cung cấp một trong số các giá trị sau đến type =: “full”, “common”, “robust”, “five_number”, “mean_sd”, “mean_se”, “mean_ci”, “median_iqr”, “median_mad”, “quantile”, “mean”, “median”, “min”, “max”.Nó cũng có thể được sử dụng để nhóm số liệu, sao cho một hàng được trả về cho mỗi biến nhóm:Bạn cũng có thể sử dụng rstatix để thực hiện các kiểm định thống kê:","code":"\nlinelist %>%\n  rstatix::get_summary_stats(age, temp)## # A tibble: 2 x 13\n##   variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se    ci\n##   <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166 0.325\n## 2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013 0.025\nlinelist %>%\n  group_by(hospital) %>%\n  rstatix::get_summary_stats(age, temp, type = \"common\")## # A tibble: 12 x 11\n##    hospital               variable     n   min   max median   iqr  mean     sd    se    ci\n##    <chr>                  <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n##  1 Central Hospital       age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n##  2 Central Hospital       temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n##  3 Military Hospital      age        884   0    72     14    18    16.1 12.4   0.417 0.818\n##  4 Military Hospital      temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n##  5 Missing                age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n##  6 Missing                temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n##  7 Other                  age        873   0    69     13    17    16.0 12.5   0.422 0.828\n##  8 Other                  temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n##  9 Port Hospital          age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n## 10 Port Hospital          temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n## 11 St. Mark's Maternity ~ age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n## 12 St. Mark's Maternity ~ temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095"},{"path":"stat-tests.html","id":"kiểm-định-t-1","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định t","text":"USử dụng cú pháp để chỉ định cột biến liên tục và cột biến phân loại:Hoặc sử dụng ~ 1 và ghi rõ mu = cho kiểm định t một mẫu. Cú pháp này có thể sử dụng để thực hiện cho nhóm.Nếu có thể, các kiểm định thống kê có thể thực hiện theo nhóm, như được trình bày bên dưới.","code":"\nlinelist %>% \n  t_test(age_years ~ gender)## # A tibble: 1 x 10\n##   .y.       group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl> <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****\nlinelist %>% \n  t_test(age_years ~ 1, mu = 30)## # A tibble: 1 x 7\n##   .y.       group1 group2         n statistic    df     p\n## * <chr>     <chr>  <chr>      <int>     <dbl> <dbl> <dbl>\n## 1 age_years 1      null model  5888     -84.2  5801     0\nlinelist %>% \n  group_by(gender) %>% \n  t_test(age_years ~ 1, mu = 18)## # A tibble: 3 x 8\n##   gender .y.       group1 group2         n statistic    df         p\n## * <chr>  <chr>     <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n## 1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n## 2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n## 3 <NA>   age_years 1      null model   278     -3.80   191 1.96e-  4"},{"path":"stat-tests.html","id":"kiểm-định-shapiro-wilk-1","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Shapiro-Wilk","text":"Như đã đề cập bên trên, cỡ mẫu phải nằm trong khoảng từ 3 đến 5000.","code":"\nlinelist %>% \n  head(500) %>%            # first 500 rows of case linelist, for example only\n  shapiro_test(age_years)## # A tibble: 1 x 3\n##   variable  statistic        p\n##   <chr>         <dbl>    <dbl>\n## 1 age_years     0.917 6.67e-16"},{"path":"stat-tests.html","id":"kiểm-định-tổng-thứ-hạng-wilcoxon-1","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định tổng thứ hạng Wilcoxon","text":"","code":"\nlinelist %>% \n  wilcox_test(age_years ~ gender)## # A tibble: 1 x 9\n##   .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****"},{"path":"stat-tests.html","id":"kiểm-định-kruskal-wallis-1","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Kruskal-Wallis","text":"Cũng được biết như kiểm định Mann-Whitney U.","code":"\nlinelist %>% \n  kruskal_test(age_years ~ outcome)## # A tibble: 1 x 6\n##   .y.           n statistic    df     p method        \n## * <chr>     <int>     <dbl> <int> <dbl> <chr>         \n## 1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis"},{"path":"stat-tests.html","id":"kiểm-định-chi-bình-phương-1","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Chi bình phương","text":"Hàm kiểm định Chi bình phương chấp nhận một bảng, vì vậy đầu tiên là tạo một bảng chéo. Có nhiều cách để tạo một bảng chéo (xem chương Bảng mô tả) nhưng ở đây chúng ta sử dụng hàm tabyl() từ janitor avà bỏ cột ngoài cùng bên trái của nhãn giá trị trước khi đưa vào hàm chisq_test().Có rất nhiều hàm và kiểm định thống kê có thể được thực hiện bằng các hàm trong package rstatix. Đọc các tài liệu về rstatix online ở đây hoặc gõ ?rstatix.","code":"\nlinelist %>% \n  tabyl(gender, outcome) %>% \n  select(-1) %>% \n  chisq_test()## # A tibble: 1 x 6\n##       n statistic     p    df method          p.signif\n## * <dbl>     <dbl> <dbl> <int> <chr>           <chr>   \n## 1  5888      3.53 0.473     4 Chi-square test ns"},{"path":"stat-tests.html","id":"stats_gt","chapter":"18 Các kiểm định thống kê cơ bản","heading":"18.4 gtsummary package","text":"Sử dụng package gtsummary nếu bạn đang muốn thêm kết quả của một kiểm định thống kê vào một bảng đẹp được tạo ra bằng package này (như đã được mô tả trong phần gtsummary của chương Bảng mô tả).Khi thực hiện các kiểm định sánh bằng hàm tbl_summary, dùng thêm hàm add_p để đưa cột giá trị p và kiểm định được sử dụng vào bảng. Có thể xuất nhiều giá trị p mà được hiệu chỉnh cho nhiều kiểm định bằng cách dùng thêm hàm add_q. Gõ lệnh ?tbl_summary để biết thêm chi tiết.","code":""},{"path":"stat-tests.html","id":"kiểm-định-chi-bình-phương-2","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Chi bình phương","text":"Được sử dụng để sánh các tỷ lệ của một biến phân loại trong hai nhóm. Kiểm định thống kê mặc định cho biến phân loại trong hàm add_p() là kiểm định Chi bình phương về tính độc lập với hiệu chỉnh liên tục, nhưng nếu có bất kỳ giá trị kỳ vọng nào nhỏ hơn 5 thì kiểm định chính xác của Fisher sẽ được sử dụng.\n          1\n          \n           \n          n (%)\n          \n          2\n          \n           \n          Pearson's Chi-squared test\n          ","code":"\nlinelist %>% \n  select(gender, outcome) %>%    # keep variables of interest\n  tbl_summary(by = outcome) %>%  # produce summary table and specify grouping variable\n  add_p()                        # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stat-tests.html","id":"kiểm-định-t-2","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định t","text":"Được sử dụng để sánh sự khác biệt về trung bình của một biến trung bình trong hai nhóm. Ví dụ như sánh tuổi trung bình với kết cục của bệnh nhân.\n          1\n          \n           \n          Mean (SD)\n          \n          2\n          \n           \n          Welch Two Sample t-test\n          ","code":"\nlinelist %>% \n  select(age_years, outcome) %>%             # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age_years ~ \"{mean} ({sd})\", # specify what statistics to show\n    by = outcome) %>%                        # specify the grouping variable\n  add_p(age_years ~ \"t.test\")                # specify what tests to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stat-tests.html","id":"kiểm-định-tổng-thứ-hạng-wilcoxon-2","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định tổng thứ hạng Wilcoxon","text":"Được dùng để sánh sự phân bố của một biến liên tục trong hai nhóm. Kiểm định mặc định là kiểm định tổng thứ hang Wilcoxon và trung vị (khoảng tứ phân vị IQR) khi sánh hai nhóm. Tuy nhiên, đối với số liệu không có phân bố chuẩn hoặc sánh nhiều nhóm, kiểm định Kruskal-wallis là kiểm định thích hợp hơn.\n          1\n          \n           \n          Median (IQR)\n          \n          2\n          \n           \n          Wilcoxon rank sum test\n          ","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (this is default so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"wilcox.test\")                     # specify what test to perform (default so could leave brackets empty)## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stat-tests.html","id":"kiểm-định-kruskal-wallis-2","chapter":"18 Các kiểm định thống kê cơ bản","heading":"Kiểm định Kruskal-wallis","text":"Được sử dụng để sánh sự phân bố của một biến liên tục trong hai hay nhiều nhóm, bất kể số liệu có phân bố chuẩn hay không.\n          1\n          \n           \n          Median (IQR)\n          \n          2\n          \n           \n          Kruskal-Wallis rank sum test\n          ","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (default, so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"kruskal.test\")                    # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stat-tests.html","id":"tương-quan","chapter":"18 Các kiểm định thống kê cơ bản","heading":"18.5 Tương quan","text":"Mối tương quan giữa các biến định lượng có thể được kiển bằng cách sử dụng lệnh corrr từ package tidyverse. Lệnh này cũng cho phép tính các hệ số tương quan bằng phương pháp Pearson, Kendall hoặc Spearman. Gói lệnh này tạo ra một bảng kết quả và cũng có chức năng tự động vẽ các giá trị.","code":"\ncorrelation_tab <- linelist %>% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %>%   # keep numeric variables of interest\n  correlate()      # create correlation table (using default pearson)\n\ncorrelation_tab    # print## # A tibble: 6 x 7\n##   term            generation       age ct_blood days_onset_hosp    wt_kg    ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>    <dbl>    <dbl>\n## 1 generation        NA       -0.0222    0.179         -0.288    -0.0302  -0.00942\n## 2 age               -0.0222  NA         0.00849       -0.000635  0.833    0.877  \n## 3 ct_blood           0.179    0.00849  NA             -0.600    -0.00636  0.0181 \n## 4 days_onset_hosp   -0.288   -0.000635 -0.600         NA         0.0153  -0.00953\n## 5 wt_kg             -0.0302   0.833    -0.00636        0.0153   NA        0.884  \n## 6 ht_cm             -0.00942  0.877     0.0181        -0.00953   0.884   NA\n## remove duplicate entries (the table above is mirrored) \ncorrelation_tab <- correlation_tab %>% \n  shave()\n\n## view correlation table \ncorrelation_tab## # A tibble: 6 x 7\n##   term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>  <dbl> <dbl>\n## 1 generation        NA       NA        NA              NA       NA        NA\n## 2 age               -0.0222  NA        NA              NA       NA        NA\n## 3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n## 4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n## 5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n## 6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n## plot correlations \nrplot(correlation_tab)"},{"path":"stat-tests.html","id":"nguồn-2","chapter":"18 Các kiểm định thống kê cơ bản","heading":"18.6 Nguồn","text":"Phần lớn thông tin trong phần này được phỏng theo các nguồn sau:gtsummary\ndplyr\ncorrr\nsthda correlation","code":""},{"path":"regression.html","id":"regression","chapter":"19 Hồi quy đơn và đa biến","heading":"19 Hồi quy đơn và đa biến","text":"Trong chương này, chúng tôi trình bày cách sử dụng các hàm hồi quy trong base R rnhư hàm glm() và package gtsummary để xem xét các mối liên quan giữa các biến (ví dụ như tỷ số chênh, tỷ số nguy cơ, tỷ số rủi ro). Chúng tôi cũng trình bày cách sử dụng các hàm như tidy() trong package broom để sắp xếp các kết quả hồi quy.Phân tích đơn biến: bảng 2 x 2Phân tích phân tầng: ước lượng của mantel-haenszelPhân tích đa biến: lựa chọn biến số, lựa chọn mô hình, mô hình cuối cùngBiểu đồ Forest plotĐối với hồi quy Cox, xem chương Phân tích sống còn.CHÚ Ý: Chúng tôi sử dụng thuật ngữ đa biến (multivariable) để nói đến một hồi quy có nhiều biến giải thích. Thuật ngữ này khác với mô hình đa biến (multivariate model), là một mô hình đa biến có nhiều biến kết cục – xem chi tiết trong bài xã luận này","code":""},{"path":"regression.html","id":"chuẩn-bị-3","chapter":"19 Hồi quy đơn và đa biến","heading":"19.1 Chuẩn bị","text":"","code":""},{"path":"regression.html","id":"gọi-packages-2","chapter":"19 Hồi quy đơn và đa biến","heading":"Gọi packages","text":"Đoạn mã này hiển thị cách tải các gói lệnh cần thiết cho phân tích. Trong cuốn sổ tay này, chúng tôi nhấn mạnh hàm p_load() thuộc package pacman, giúp cài đặt package khi cần thiết và gọi nó ra để sử dụng. Có thể gọi các package đã cài đặt bằng hàm library() trong base R. Xem thêm thông tin về các package của R trong chương R cơ bản.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse,    # data management + ggplot2 graphics, \n  stringr,      # manipulate text strings \n  purrr,        # loop over objects in a tidy way\n  gtsummary,    # summary statistics and tests \n  broom,        # tidy up results from regressions\n  lmtest,       # likelihood-ratio tests\n  parameters,   # alternative to tidy up results from regressions\n  see          # alternative to visualise forest plots\n  )"},{"path":"regression.html","id":"nhập-số-liệu-1","chapter":"19 Hồi quy đơn và đa biến","heading":"Nhập số liệu","text":"Chúng tôi nhập bộ số liệu của các ca bệnh được mô phỏng từ một vụ dịch Ebola. Để tiện làm theo, bấm để tải số liệu linelist “đã được làm sạch” (dưới dạng tệp .rds ). Nhập số liệu này bằng hàm import() trong package rio (nó chấp nhận nhiều loại tập tin như .xlsx, .rds, .csv – xem chi tiết trong chương Nhập xuất dữ liệu).Bên dưới là hiển thị của 50 hàng đầu tiên của bộ số liệu linelist.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"regression.html","id":"làm-sạch-số-liệu","chapter":"19 Hồi quy đơn và đa biến","heading":"Làm sạch số liệu","text":"","code":""},{"path":"regression.html","id":"lưu-trữ-các-biến-giải-thích","chapter":"19 Hồi quy đơn và đa biến","heading":"Lưu trữ các biến giải thích","text":"Tên của các biến giải thích sẽ được lưu trữ dưới dạng một véc tơ ký tự. Véc tơ này sẽ được đề cập về sau.","code":"\n## define variables of interest \nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")"},{"path":"regression.html","id":"chuyển-đổi-sang-số-1-và-số-0","chapter":"19 Hồi quy đơn và đa biến","heading":"Chuyển đổi sang số 1 và số 0","text":"Sau đây, giá trị của các biến giải thích được chuyển đổi từ “có”/“không”, “nam”/“nữ” và “chết”/“sống” thành 1 / 0, để hợp với các đặc tính của mô hình hồi quy logistic. TĐể thực hiện việc này một cách hiệu quả, sử dụng hàm across() từ dplyr để chuyển đổi nhiều biến cùng một lúc. Để áp dụng cho mỗi biến, dùng hàm case_when() (cũng trong package dplyr) để chuyển đổi các giá trị cụ thể thành 1 và 0. Xem các mục về across() và case_when() trong chương Làm sạch số liệu và các hàm quan trọng).Chú ý: dấu “.” bên dưới đại diện cho cột`````đang được xử lý trong hàmacross()` tại thời điểm đó.","code":"\n## convert dichotomous variables to 0/1 \nlinelist <- linelist %>%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## for each column listed and \"outcome\"\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## recode male, yes and death to 1\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0,           ## female, no and recover to 0\n      TRUE                            ~ NA_real_)    ## otherwise set to missing\n    )\n  )"},{"path":"regression.html","id":"loại-bỏ-các-hàng-có-giá-trị-missing","chapter":"19 Hồi quy đơn và đa biến","heading":"Loại bỏ các hàng có giá trị missing","text":"Để bỏ các hàng có giá trị missing, dùng hàm drop_na() trong package tidyr. Tuy nhiên, chúng ta chỉ muốn thực hiện điều này cho các hàng có giá trị missing đối với các cột đang được quan tâm.Trước hết, chúng ta phải đảm bảo rằng vectơ explanatory_vars bao gồm các biến age (age có thể tạo ra một lỗi trong thao tác của hàm case_when() trước đó, mà chỉ dành cho biến nhị phân). Sau đó chúng ta pipe bộ dữ liệu linelist tới hàm drop_na() để bỏ các hàng có giá trị missing cho biến outcome hoặc bất kỳ biển giải thích explanatory_vars nào.Trước khi thực hiện các lệnh này, kiểm tra số hàng trong bộ số liệu linelist bằng hàm nrow(linelist).Kiểm tra số hàng còn lại của linelist bằng hàm nrow(linelist).","code":"\n## add in age_category to the explanatory vars \nexplanatory_vars <- c(explanatory_vars, \"age_cat\")\n\n## drop rows with missing information for variables of interest \nlinelist <- linelist %>% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))"},{"path":"regression.html","id":"phân-tích-đơn-biến","chapter":"19 Hồi quy đơn và đa biến","heading":"19.2 Phân tích đơn biến","text":"Cũng giống như chương Bảng mô tả, chúng ta cần xác định packahe nào trong R mà chúng ta muốn sử dụng. Chúng tôi trình bày hai chọn lựa để thực hiện các phân tích đơn biến:Dùng hàm có sẵn trong base để nhanh kết quả ra console. Sử dụng package broom để làm gọn kết quả.Dùng package gtsummary để lập mô hình và nhận các kết quả đầu ra sẵn sàng để công bố","code":""},{"path":"regression.html","id":"base-r-2","chapter":"19 Hồi quy đơn và đa biến","heading":"base R","text":"","code":""},{"path":"regression.html","id":"hồi-quy-tuyến-tính","chapter":"19 Hồi quy đơn và đa biến","heading":"Hồi quy tuyến tính","text":"Hàm lm() trong base cho phép thực hiện hồi quy tuyến tính để đánh giá mối quan hệ giữa biến đầu ra dạng số (numeric) và các biến giải thích mà được giả định là có mối quan hệ tuyến tính.Cung cấp phương trình dưới dạng công thức với tên của biến đầu ra và các biến giải thích được phân tách bằng dấu ngã ~. Bên cạnh đó, chỉ rõ bộ số liệu nào được sử dụng với data =. Kết quả của mô hình được định nghĩa dưới dạng đối tượng của R để sử dụng về sau.Sau đó tóm tắt kết quả của mô hình bằng hàm summary() để xem các hệ số (ước tính), P-value, phần dư và các đo lường khác.Ngoài ra, có thể dùng hàm tidy() trong package broom để xuất kết quả vào trong một bảng. Kết quả bên dưới cho chúng ta biết khi tăng thêm một tuổi thì chiều cao tăng 3,5 cm và mối quan hệ này có ý nghĩa thống kê.Sau đó, có thể sử dụng kết quả hồi quy này để đưa vào ggplot. Để thực hiện điều này, trước tiên chúng ta đưa các giá trị quan sát và đường thẳng hồi quy (fitted line) vào một data frame bằng cách dùng hàm augment() trong package broom.Bạn cũng có thể vẽ đường hồi quy tuyến tính đơn bằng package ggplot thông qua hàm geom_smooth().Xem thêm các hướng dẫn chi tiết trong mục Nguồn ở cuối chương này.","code":"\nlm_results <- lm(ht_cm ~ age, data = linelist)\nsummary(lm_results)## \n## Call:\n## lm(formula = ht_cm ~ age, data = linelist)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -128.579  -15.854    1.177   15.887  175.483 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  69.9051     0.5979   116.9   <2e-16 ***\n## age           3.4354     0.0293   117.2   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 23.75 on 4165 degrees of freedom\n## Multiple R-squared:  0.7675, Adjusted R-squared:  0.7674 \n## F-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: < 2.2e-16\ntidy(lm_results)## # A tibble: 2 x 5\n##   term        estimate std.error statistic p.value\n##   <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n## 1 (Intercept)    69.9     0.598       117.       0\n## 2 age             3.44    0.0293      117.       0\n## pull the regression points and observed data in to one dataset\npoints <- augment(lm_results)\n\n## plot the data using age as the x-axis \nggplot(points, aes(x = age)) + \n  ## add points for height \n  geom_point(aes(y = ht_cm)) + \n  ## add your regression line \n  geom_line(aes(y = .fitted), colour = \"red\")\n## add your data to a plot \n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## show points\n  geom_point() + \n  ## add a linear regression \n  geom_smooth(method = \"lm\", se = FALSE)## `geom_smooth()` using formula 'y ~ x'"},{"path":"regression.html","id":"hồi-quy-logistic","chapter":"19 Hồi quy đơn và đa biến","heading":"Hồi quy Logistic","text":"Hàm glm() trong package stats (một phần của base R) được sử dụng để fit (chọn mô hình dự đoán tối ưu dựa trên số liệu quan sát) đối với Mô hình Tuyến tính Tổng quát (GLM).glm() có thể được sử dụng cho cả hồi quy logistic đơn biến và đa biến (ví dụ như để tính tỷ số chênh ). Sau đây là những thành phần chính của hàm:formula = Mô hình được cung cấp cho glm() dưới dạng một phương trình với biến kết cục ở bên trái và biến giải thích ở bên phải dấu ngã ~.family = Xác định loại mô hình sẽ thực hiện. Đối với hồi quy logistic, sử dụng family = \"binomial\", đối với hồi quy poisson sử dụng family = \"poisson\". Các ví dụ khác được trình bày trong bảng bên dưới.data = Cụ thể bộ số liệuNếu cần, có thể cụ thể hàm liên kết bằng cú pháp family = familytype(link = \"linkfunction\")). Bạn có thể tìm đọc thêm về các họ hồi quy khác và các tùy chọn đối số như là weights = và subset = bằng cách gõ (?glm).Khi thực hiện glm() , phổ biến nhất là lưu kết quả dưới dạng một đối tượng của R được đặt tên. Sau đó, có thể xuất kết quả ra console bằng cách sử dụng hàm summary() như được trình bày bên dưới, hoặc thực hiện các thao tác khác từ kết quả (ví dụ như lấy lũy thừa).Nếu cần thực hiện một hồi quy nhị thức âm, có thể sử dụng package MASS. Hàn glm.nb() uses cũng sử dụng cùng cú pháp như glm(). Để xem qua các hồi quy khác, xem trên trang thống kê của UCLA.","code":"\n# arguments for glm()\nglm(formula, family, data, weights, subset, ...)"},{"path":"regression.html","id":"phân-tích-đơn-biến-sử-dụng-glm","chapter":"19 Hồi quy đơn và đa biến","heading":"Phân tích đơn biến sử dụng glm()","text":"Trong ví dụ này, chúng tôi đánh giá mối liên quan giữa nhóm tuổi và biến kết cục tử vong (được mã hóa là 1 trong phần chuẩn bị). Bên dưới là một mô hình đơn biến của biến kết cục outcome theo age_cat. Chúng tôi lưu kết quả đầu ra được đặt tên là model và sau đó kết quả đến console bằng hàm summary(). Lưu ý, các ước tính được tạo ra là các giá trị lôgarít của tỷ số chênh (log odds) và giá trị tham chiếu là giá trị đầu tiên của biến age_cat (“0-4”).Để thay đổi giá trị tham chiếu của một biến Factor và chuyển giá trị mong muốn lên vị trí đầu tiên, dùng hàm fct_relevel() (xem chương [Factors]). Ở ví dụ bên dưới, chúng tôi lấy biến age_cat và đặt nhóm tuổi “20-29” làm giá trị tham chiếu trước khi chuyển số liệu đã sửa đổi vào hàm glm().","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n## \n## Deviance Residuals: \n##    Min      1Q  Median      3Q     Max  \n## -1.339  -1.278   1.024   1.080   1.354  \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)   \n## (Intercept)   0.233738   0.072805   3.210  0.00133 **\n## age_cat5-9   -0.062898   0.101733  -0.618  0.53640   \n## age_cat10-14  0.138204   0.107186   1.289  0.19726   \n## age_cat15-19 -0.005565   0.113343  -0.049  0.96084   \n## age_cat20-29  0.027511   0.102133   0.269  0.78765   \n## age_cat30-49  0.063764   0.113771   0.560  0.57517   \n## age_cat50-69 -0.387889   0.259240  -1.496  0.13459   \n## age_cat70+   -0.639203   0.915770  -0.698  0.48518   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4\nlinelist %>% \n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %>% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %>% \n  summary()## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n## \n## Deviance Residuals: \n##    Min      1Q  Median      3Q     Max  \n## -1.339  -1.278   1.024   1.080   1.354  \n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)   0.26125    0.07163   3.647 0.000265 ***\n## age_cat0-4   -0.02751    0.10213  -0.269 0.787652    \n## age_cat5-9   -0.09041    0.10090  -0.896 0.370220    \n## age_cat10-14  0.11069    0.10639   1.040 0.298133    \n## age_cat15-19 -0.03308    0.11259  -0.294 0.768934    \n## age_cat30-49  0.03625    0.11302   0.321 0.748390    \n## age_cat50-69 -0.41540    0.25891  -1.604 0.108625    \n## age_cat70+   -0.66671    0.91568  -0.728 0.466546    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4"},{"path":"regression.html","id":"in-kết-quả","chapter":"19 Hồi quy đơn và đa biến","heading":"In kết quả","text":"Đối với hầu hết các mục đích sử dụng, kết quả đầu ra cần phải có một số sửa đổi. Hàm làm gọn tidy() trong package broom có những tiện lợi để hiển thị kết quả của mô hình.Ở đây, chúng tôi trình bày cách để kết hợp các kết quả đầu ra của mô hình vào trong một bảng.Lấy lũy thừa logarit của ước lượng tỉ số chênh và khoảng tin cậy bằng cách đưa mô hình vào hàm tidy() và thiết lập lũy thừa exponentiate = TRUE và conf.int = TRUE.Bên dưới là bảng kết quả đầu ra của model:Kết hợp các kết quả của mô hình vào trong một bảng đếm. Dưới đây, chúng tôi tạo một bảng đếm bằng hàm tabyl() từ package janitor, như được đề cập trong chương Bảng mô tả.Đây là cách mà bảng counts_table được hiển thị:Bây giờ chúng ta có thể nối bảng counts_table và kết quả của mô hình model lại với nhau theo chiều ngang bằng hàm nối cột bind_cols() (dplyr). Hãy nhớ rằng đối với hàm bind_cols() các hàng trong hai cấu trúc dữ liệu trên phải được căn chỉnh hoàn hảo. Trong đoạn code này, bởi vì chúng ta đang thực hiện một chuỗi các thuật toán pipe, chúng ta sử dụng dấu . để đại diện cho đối tượng được nối trong bảng đếm counts_table khi chúng tôi nối nó với kết quả mô hình model. Để kết thúc quy trình này, chúng ta sử dụng hàm select() để chọn các cột mong muốn và thứ tự của nó, và cuối cùng áp dụng hàm round() trong base R để làm tròn với hai chữ số thập phân cho tất cả các cột.Đây là hiển thị của cấu trúc đã được kết hợp, nó được xuất gọn gẽ dưới dạng một hình bằng thông qua một hàm trong package flextable. Chương Trình bày bảng giải thích cách tùy chỉnh các bảng như vậy bằng flextable, hoặc có thể sử dụng các gói lệnh khác như knitr hoặc GT.","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %>% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %>%        # exponentiate and produce CIs\n  mutate(across(where(is.numeric), round, digits = 2))  # round all numeric columns\ncounts_table <- linelist %>% \n  janitor::tabyl(age_cat, outcome)\ncombined <- counts_table %>%           # begin with table of counts\n  bind_cols(., model) %>%              # combine with the outputs of the regression \n  select(term, 2:3, estimate,          # select and re-order cols\n         conf.low, conf.high, p.value) %>% \n  mutate(across(where(is.numeric), round, digits = 2)) ## round to 2 decimal places\ncombined <- combined %>% \n  flextable::qflextable()"},{"path":"regression.html","id":"vòng-lặp-cho-nhiều-mô-hình-đơn-biến","chapter":"19 Hồi quy đơn và đa biến","heading":"Vòng lặp cho nhiều mô hình đơn biến","text":"Sau đây chúng tôi trình bày một phương pháp sử dụng glm() và tidy() để có một cách tiếp cận đơn giản hơn, xem thêm ở phần gtsummary.Để thực hiện các mô hình cho một số biến giải thích và cho ra các tỷ số chênh trong phân tích đơn biến (nghĩa là không có kiểm soát lẫn nhau), chúng ta có thể sử dụng các cách tiếp cận dưới đây. Sử dụng hàm str_c() từ package stringr để tạo ra các công thức cho phân tích đơn biến (xem chương Ký tự và chuỗi), thực hiện hàm glm() cho mỗi công thức, chuyển mỗi kết quả đầu ra của glm() đến hàm tidy() và cuối cùng thu gọn lại tất các kết quả đầu ra của mô hình bằng hàm nối dòng bind_rows() từ tidyr. Phương pháp này sử dụng hàm map() từ package purrr để lặp - xem chương [Lặp, vòng lặp và danh sách] để biết thêm thông tin về công cụ này.Tạo một véctơ tên các cột của biến giải thích. Chúng ta đã tạo biến này explanatory_vars trong phần chuẩn bị của chương này.Tạo một véctơ tên các cột của biến giải thích. Chúng ta đã tạo biến này explanatory_vars trong phần chuẩn bị của chương này.Sử dụng hàm str_c() để tạo các công thức chuỗi với biến kết cục outcome ở bên trái và tên một cột của véctơ explanatory_vars ở bên phải. Dấu chấm . trong hàm này thay thế cho tên cột trong véctơ explanatory_vars.Sử dụng hàm str_c() để tạo các công thức chuỗi với biến kết cục outcome ở bên trái và tên một cột của véctơ explanatory_vars ở bên phải. Dấu chấm . trong hàm này thay thế cho tên cột trong véctơ explanatory_vars.Đưa các công thức chuỗi này vào hàm map() và đặt ~glm() làm hàm áp dụng cho mỗi đầu vào. Bên trong hàm glm(), thiết lập công thức hồi quy .formula(.x) trong đó .x sẽ được thay thế bằng các công thức chuỗi đã được tạo bên trên. Hàm map() sẽ lặp từng công thức chuỗi và thực hiện hồi quy cho từng công thức.Đưa các công thức chuỗi này vào hàm map() và đặt ~glm() làm hàm áp dụng cho mỗi đầu vào. Bên trong hàm glm(), thiết lập công thức hồi quy .formula(.x) trong đó .x sẽ được thay thế bằng các công thức chuỗi đã được tạo bên trên. Hàm map() sẽ lặp từng công thức chuỗi và thực hiện hồi quy cho từng công thức.Kết quả đầu ra của hàm map() đầu tiên sẽ được chuyển đến hàm map() thứ hai mà sử dụng hàm tidy() để làm gọn các kết quả đầu ra.Kết quả đầu ra của hàm map() đầu tiên sẽ được chuyển đến hàm map() thứ hai mà sử dụng hàm tidy() để làm gọn các kết quả đầu ra.Cuối cùng, kết quả đầu ra của hàm map() thứ hai (một danh sách các data frames đã được làm gọn) được tóm tắt bằng hàm nối dòng bind_rows(), kết quả cho ra một data frame với tất cả các kết quả đơn biến.Cuối cùng, kết quả đầu ra của hàm map() thứ hai (một danh sách các data frames đã được làm gọn) được tóm tắt bằng hàm nối dòng bind_rows(), kết quả cho ra một data frame với tất cả các kết quả đơn biến.Lúc này, kết quả xuất ra của models dài hơn bởi vì kết quả bây giờ bao gồm các kết quả đầu ra của một số hồi quy đơn biến. Nhấp nút tiếp theo để xem tất cả các hàng của model.Như lúc trước, chúng ta có thể tạo một bảng đếm từ bộ số liệu linelist cho mỗi biến giải thích, gắn chúng với models, và tạo ra một bảng đẹp. Chúng ta bắt đầu với các biến giải thích này, và lặp lại các biến này thông qua hàm map(). Chúng ta lặp lại qua một hàm người dùng tạo ra mà liên quan đến việc tạo ra một bảng đếm bằng cách dùng các hàm trong package dplyr Sau đó, kết quả được kết nối trình tự với kết quả của mô hình models.Bên dưới là cấu trúc số liệu kết nối được tạo ra. Xem chương Trình bày bảng để có thêm ý tưởng về cách chuyển đổi bảng số liệu này thành một bảng đẹp trên HTML (ví dụ như với package flextable).","code":"\nexplanatory_vars %>% str_c(\"outcome ~ \", .)## [1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\"  \"outcome ~ cough\"  \n## [5] \"outcome ~ aches\"   \"outcome ~ vomit\"   \"outcome ~ age_cat\"\nmodels <- explanatory_vars %>%       # begin with variables of interest\n  str_c(\"outcome ~ \", .) %>%         # combine each variable into formula (\"outcome ~ variable of interest\")\n  \n  # iterate through each univariate formula\n  map(                               \n    .f = ~glm(                       # pass the formulas one-by-one to glm()\n      formula = as.formula(.x),      # within glm(), the string formula is .x\n      family = \"binomial\",           # specify type of glm (logistic)\n      data = linelist)) %>%          # dataset\n  \n  # tidy up each of the glm regression outputs from above\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponentiate \n      conf.int = TRUE)) %>%          # return confidence intervals\n  \n  # collapse the list of regression outputs in to one data frame\n  bind_rows() %>% \n  \n  # round all numeric columns\n  mutate(across(where(is.numeric), round, digits = 2))\n## for each explanatory variable\nuniv_tab_base <- explanatory_vars %>% \n  map(.f = \n    ~{linelist %>%                ## begin with linelist\n        group_by(outcome) %>%     ## group data set by outcome\n        count(.data[[.x]]) %>%    ## produce counts for variable of interest\n        pivot_wider(              ## spread to wide format (as in cross-tabulation)\n          names_from = outcome,\n          values_from = n) %>% \n        drop_na(.data[[.x]]) %>%         ## drop rows with missings\n        rename(\"variable\" = .x) %>%      ## change variable of interest column to \"variable\"\n        mutate(variable = as.character(variable))} ## convert to character, else non-dichotomous (categorical) variables come out as factor and cant be merged\n      ) %>% \n  \n  ## collapse the list of count outputs in to one data frame\n  bind_rows() %>% \n  \n  ## merge with the outputs of the regression \n  bind_cols(., models) %>% \n  \n  ## only keep columns interested in \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %>% \n  \n  ## round decimal places\n  mutate(across(where(is.numeric), round, digits = 2))"},{"path":"regression.html","id":"reg_gt_uni","chapter":"19 Hồi quy đơn và đa biến","heading":"gtsummary package","text":"Sau đây chúng tôi sẽ trình bày cách sử dụng hàm tbl_uvregression() từ package gtsummary. Cũng giống như trong chương Bảng mô tả, các hàm trong gtsummary thực hiện tốt các thống kê và xuất ra các kết quả khá chuyên nghiệp. Hàm này xuất ra một bảng kết quả của hồi quy đơn biến.Chúng ta chỉ chọn các cột cần thiết từ bộ số liệu linelist (ecác biến giải thích và biến kết cục) và pipe chúng vào hàm tbl_uvregression(). Chúng ta sẽ thực hiện hồi quy đơn biến cho mỗi cột như được xác định trong véctơ explanatory_vars trong mục Chuẩn bị (gender, fever, chills, cough, aches, vomit, và age_cat).Trong hàm này, chúng ta cung cấp thêm phương pháp thực hiện method = là glm (không có dấu ngoặc kép), biến kết cục y = cột kết quả (biến outcome), cụ thể method.args = mà chúng ta muốn thực hiện hồi quy logistic qua family = binomial, và lấy lũy thừa của kết quả.Kết quả đầu ra dưới dạng HTML và chứa cột đếm\n          1\n          \n           \n          = Odds Ratio, CI = Confidence Interval\n          Chúng ta có thể sửa đổi đối với kết quả đầu ra của bảng này, ví dụ như điều chỉnh các nhãn, tô đậm các hàng theo giá trị p, .v.v. Xem hướng dẫn tại đây và các tài liệu trực tuyến khác.","code":"\nuniv_tab <- linelist %>% \n  dplyr::select(explanatory_vars, outcome) %>% ## select variables of interest\n\n  tbl_uvregression(                         ## produce univariate table\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = outcome,                            ## define outcome variable\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n## view univariate results table \nuniv_tab"},{"path":"regression.html","id":"phân-tích-phân-tầng","chapter":"19 Hồi quy đơn và đa biến","heading":"19.3 Phân tích phân tầng","text":"Hiện tại, phân tích phần tầng sử dụng package gtsummary đang được xây dựng, phần này sẽ được cập nhật trong thời gian thích hợp.","code":""},{"path":"regression.html","id":"phân-tích-đa-biến","chapter":"19 Hồi quy đơn và đa biến","heading":"19.4 Phân tích đa biến","text":"Đối với phân tích đa biến, chúng tôi trình bày hai cách tiếp cận:glm() và tidy()Package gtsummaryQuy trình thực hiện khá tương tự và chỉ khác ở bước cuối cùng để kết nối kết quả lại với nhau.","code":""},{"path":"regression.html","id":"thực-hiện-phân-tích-đa-biến","chapter":"19 Hồi quy đơn và đa biến","heading":"Thực hiện phân tích đa biến","text":"Ở đây chúng tôi sử dụng hàm glm() nhưng thêm nhiều biến hơn vào bên phải của phương trình và được phân tách với nhau bằng dấu cộng (+).Để thực hiện mô hình với tất cả các biến giải thích, chúng ta thực hiện lệnh sau:Nếu muốn bao gồm hai biến và tương tác của hai biến này, chúng ta có thể phân tách chúng bằng dấu hoa thị * thay cho dấu +. Nếu chúng ta chỉ muốn cụ thể sự tương tác, phân tách chúng bằng dấu hai chấm :. Ví dụ:Một tùy chọn khác, chúng ta có thể sử dụng đoạn mã này để sử dụng một véc tơ đã được định nghĩa trước của các cột và tạo lại lệnh trên bằng cách sử dụng hàm str_c(). Điều này có thể hữu ích nếu chúng ta thay đổi tên các biến giải thích, hoặc bạn không muốn gõ lại tất cả mọi thứ.","code":"\nmv_reg <- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)## \n## Call:\n## glm(formula = outcome ~ gender + fever + chills + cough + aches + \n##     vomit + age_cat, family = \"binomial\", data = linelist)\n## \n## Deviance Residuals: \n##    Min      1Q  Median      3Q     Max  \n## -1.383  -1.279   1.029   1.078   1.346  \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)\n## (Intercept)   0.069054   0.131726   0.524    0.600\n## gender        0.002448   0.065133   0.038    0.970\n## fever         0.004309   0.080522   0.054    0.957\n## chills        0.034112   0.078924   0.432    0.666\n## cough         0.138584   0.089909   1.541    0.123\n## aches        -0.070705   0.104078  -0.679    0.497\n## vomit         0.086098   0.062618   1.375    0.169\n## age_cat5-9   -0.063562   0.101851  -0.624    0.533\n## age_cat10-14  0.136372   0.107275   1.271    0.204\n## age_cat15-19 -0.011074   0.113640  -0.097    0.922\n## age_cat20-29  0.026552   0.102780   0.258    0.796\n## age_cat30-49  0.059569   0.116402   0.512    0.609\n## age_cat50-69 -0.388964   0.262384  -1.482    0.138\n## age_cat70+   -0.647443   0.917375  -0.706    0.480\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5700.2  on 4153  degrees of freedom\n## AIC: 5728.2\n## \n## Number of Fisher Scoring iterations: 4\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n## run a regression with all variables of interest \nmv_reg <- explanatory_vars %>%  ## begin with vector of explanatory column names\n  str_c(collapse = \"+\") %>%     ## combine all names of the variables of interest separated by a plus\n  str_c(\"outcome ~ \", .) %>%    ## combine the names of variables of interest with outcome in formula style\n  glm(family = \"binomial\",      ## define type of glm as logistic,\n      data = linelist)          ## define your dataset"},{"path":"regression.html","id":"xây-dựng-mô-hình","chapter":"19 Hồi quy đơn và đa biến","heading":"Xây dựng mô hình","text":"Chúng ta có thể xây dựng mô hình theo từng bước, lưu các mô hình khác nhau với một số biến giải thích. Chúng ta có thể sử dụng kiểm định tỷ số khả dĩ (likelihood-ratio tests) để sánh các mô hình này bằng cách sử dụng hàm lrtest() từ package lmtest, như dưới đây:CHÚ Ý: Sử dụng hàn anova(model1, model2, test = \"Chisq) trong base R cũng cho kết quả tương tựMột tùy chọn khác là lấy đối tượng của mô hình và sử dụng hàm step() từ package stats. Chỉ rõ hướng lựa chọn biến mà chúng ta muốn sử dụng khi xây dựng mô hình.Để hiển thị rõ số, chúng ta có thể tắt ký hiệu khoa học trong R bằng lệnh sauNhư được mô tả trong phần phân tích đơn biến, chuyển kết quả đầu ra của mô hình vào hàm tidy() để lấy lũy thừa cho các hệ số và khoảng tin cậy (CIs). Cuối cùng, làm tròn tất cả các cột số với hai số thập phân. Kéo qua để xem tất cả các hàng.Đây là hiển thị kết quả dưới dạng data frame looks:","code":"\nmodel1 <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 <- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)## Likelihood ratio test\n## \n## Model 1: outcome ~ age_cat\n## Model 2: outcome ~ age_cat + gender\n##   #Df  LogLik Df  Chisq Pr(>Chisq)\n## 1   8 -2852.6                     \n## 2   9 -2852.6  1 0.0002     0.9883\n## choose a model using forward selection based on AIC\n## you can also do \"backward\" or \"both\" by adjusting the direction\nfinal_mv_reg <- mv_reg %>%\n  step(direction = \"forward\", trace = FALSE)\noptions(scipen=999)\nmv_tab_base <- final_mv_reg %>% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>%  ## get a tidy dataframe of estimates \n  mutate(across(where(is.numeric), round, digits = 2))          ## round "},{"path":"regression.html","id":"gộp-kết-quả-phân-tích-đơn-biến-và-đa-biến","chapter":"19 Hồi quy đơn và đa biến","heading":"Gộp kết quả phân tích đơn biến và đa biến","text":"","code":""},{"path":"regression.html","id":"gộp-bằng-package-gtsummary","chapter":"19 Hồi quy đơn và đa biến","heading":"Gộp bằng package gtsummary","text":"Hàm tbl_regression() trong package gtsummary sẽ lấy kết quả đầu tra từ một hồi quy (hàm glm() trong trường hợp này) và tạo ra một bảng tóm tắt đẹp.Hãy xem bảng sau:\n          1\n          \n           \n          = Odds Ratio, CI = Confidence Interval\n          Chúng ta cũng có thể kết hợp một số bảng kết quả đầu ra bằng cách dùng hàm tbl_merge() trong package gtsummary. Bây giờ chúng ta hộp các kết quả đa biến với kết quả đơn biến đã được tạo bên trên bằng package gtsummary:\n          1\n          \n           \n          = Odds Ratio, CI = Confidence Interval\n          ","code":"\n## show results table of final regression \nmv_tab <- tbl_regression(final_mv_reg, exponentiate = TRUE)\nmv_tab\n## combine with univariate results \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # set header names"},{"path":"regression.html","id":"gộp-bằng-package-dplyr","chapter":"19 Hồi quy đơn và đa biến","heading":"Gộp bằng package dplyr","text":"Một cách khác để gộp các kết quả đơn biến và đa biến từ các hàm glm()/tidy() bằng cách sử dụng các hàm kết nối từ package dplyr.Kết nối kết quả đơn biến trước đó (univ_tab_base, chứa được các cột đếm) với kết quả đa biến đã được làm gọn mv_tab_baseSử dụng hàm select() để giữ lại, sắp xếp lại thứ tự và đặt lại tên các cột mà chúng ta muốnSử dụng hàm round() để làm tròn tất cả các cột với hai số thập phân","code":"\n## combine univariate and multivariable tables \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %>% \n  ## choose columns and rename them\n  select( # new name =  old name\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %>% \n  mutate(across(where(is.double), round, 2))   ## # A tibble: 20 x 11\n##    characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval mv_or\n##    <chr>              <dbl> <dbl>   <dbl>       <dbl>        <dbl>     <dbl> <dbl>\n##  1 (Intercept)          909  1168    1.28        1.18         1.4       0     1.07\n##  2 gender               916  1174    1           0.88         1.13      0.97  1   \n##  3 (Intercept)          340   436    1.28        1.11         1.48      0     1.07\n##  4 fever               1485  1906    1           0.85         1.17      0.99  1   \n##  5 (Intercept)         1472  1877    1.28        1.19         1.37      0     1.07\n##  6 chills               353   465    1.03        0.89         1.21      0.68  1.03\n##  7 (Intercept)          272   309    1.14        0.97         1.34      0.13  1.07\n##  8 cough               1553  2033    1.15        0.97         1.37      0.11  1.15\n##  9 (Intercept)         1636  2114    1.29        1.21         1.38      0     1.07\n## 10 aches                189   228    0.93        0.76         1.14      0.51  0.93\n## 11 (Intercept)          931  1144    1.23        1.13         1.34      0     1.07\n## 12 vomit                894  1198    1.09        0.96         1.23      0.17  1.09\n## 13 (Intercept)          338   427    1.26        1.1          1.46      0     1.07\n## 14 age_cat5-9           365   433    0.94        0.77         1.15      0.54  0.94\n## 15 age_cat10-14         273   396    1.15        0.93         1.42      0.2   1.15\n## 16 age_cat15-19         238   299    0.99        0.8          1.24      0.96  0.99\n## 17 age_cat20-29         345   448    1.03        0.84         1.26      0.79  1.03\n## 18 age_cat30-49         228   307    1.07        0.85         1.33      0.58  1.06\n## 19 age_cat50-69          35    30    0.68        0.41         1.13      0.13  0.68\n## 20 age_cat70+             3     2    0.53        0.07         3.2       0.49  0.52\n## # ... with 3 more variables: mvv_ci_low <dbl>, mv_ci_high <dbl>, mv_pval <dbl>"},{"path":"regression.html","id":"biểu-đồ-forest-plot","chapter":"19 Hồi quy đơn và đa biến","heading":"19.5 Biểu đồ Forest plot","text":"Phần này hướng dẫn cách tạo ra một biểu đồ của các kết quả hồi quy. Có hai lựa chọn để tạo biểu đồ, chúng ta có thể tự tạo một biểu đồ bằng cách sử dụng package ggplot2 hoặc sử dụng một meta-package có tên easystats (một package gồm nhiều package).Nếu chưa quen thuộc với gói lệnh tạo biểu đồ ggplot2, xem thêm chương ggplot cơ bản.","code":""},{"path":"regression.html","id":"ggplot2-package","chapter":"19 Hồi quy đơn và đa biến","heading":"ggplot2 package","text":"Bạn có thể xây dựng một forest plot với hàm ggplot() bằng cách vẽ các thành phần của kết quả hồi quy đa biến. Thêm các lớp của biều đồ bằng cách sử dụng các “geoms”:Các ước lượng bằng hàm geom_point()Khoảng tin cậy bằng hàm geom_errorbar()Đường thẳng đứng ở vị trí = 1 bằng hàm geom_vline()Trước khi tạo biểu đồ, chúng ta sử dụng hàm fct_relevel() từ package forcats để đặt thứ tự các biến trên trục y. Hàm ggplot() cho phép hiển thị theo thứ tự chữ-số mà có thể không hiển thị tốt cho các giá trị của biến tuổi (“30” có thể hiển thị trước “5”). Xem chương [Factors] để biết thêm chi tiết.","code":"\n## remove the intercept term from your multivariable results\nmv_tab_base %>% \n  \n  #set order of levels to appear along y-axis\n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %>%\n  \n  # remove \"intercept\" row from plot\n  filter(term != \"(Intercept)\") %>% \n  \n  ## plot with variable on the y axis and estimate (OR) on the x axis\n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## show the estimate as a point\n  geom_point() + \n  \n  ## add in an error bar for the confidence intervals\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## show where OR = 1 is for reference as a dashed line\n  geom_vline(xintercept = 1, linetype = \"dashed\")"},{"path":"regression.html","id":"easystats-packages","chapter":"19 Hồi quy đơn và đa biến","heading":"easystats packages","text":"Lựa chọn thứ hai là sử dụng một sự kết hợp của các package trong easystats, nếu chúng ta không muốn mức độ kiểm soát chặt chẽ mà package ggplot2 cung cấp.Hàm model_parameters() từ package parameters thực hiện tương đương với hàm tidy() trong package broom . Sau đó, package see chấp nhận các kết quả đầu ra và tạo một biểu đồ forest plot mặc định giống như cho một đối tượng ggplot().","code":"\npacman::p_load(easystats)\n\n## remove the intercept term from your multivariable results\nfinal_mv_reg %>% \n  model_parameters(exponentiate = TRUE) %>% \n  plot()"},{"path":"regression.html","id":"nguồn-3","chapter":"19 Hồi quy đơn và đa biến","heading":"19.6 Nguồn","text":"Nội dung của chương này được tham khảo từ các nguồn sau:Linear regression RgtsummaryUCLA stats pagesthda stepwise regression","code":""},{"path":"missing-data.html","id":"missing-data","chapter":"20 Dữ liệu Missing","heading":"20 Dữ liệu Missing","text":"page cover :Assess missingnessFilter rows missingnessPlot missingness timeHandle NA displayed plotsPerform missing value imputation: MCAR, MAR, MNAR","code":""},{"path":"missing-data.html","id":"preparation-6","chapter":"20 Dữ liệu Missing","heading":"20.1 Preparation","text":"","code":""},{"path":"missing-data.html","id":"load-packages-9","chapter":"20 Dữ liệu Missing","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,           # import/export\n  tidyverse,     # data mgmt and viz\n  naniar,        # assess and visualize missingness\n  mice           # missing data imputation\n)"},{"path":"missing-data.html","id":"import-data-8","chapter":"20 Dữ liệu Missing","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"missing-data.html","id":"convert-missing-on-import","chapter":"20 Dữ liệu Missing","heading":"Convert missing on import","text":"importing data, aware values classified missing. example, 99, 999, “Missing”, blank cells (\"“), cells empty space (” \"). can convert NA (R’s version missing data) data import command.\nSee page importing page section Missing data details, exact syntax varies file type.","code":""},{"path":"missing-data.html","id":"missing-values-in-r","chapter":"20 Dữ liệu Missing","heading":"20.2 Missing values in R","text":"explore ways missingness presented assessed R, along adjacent values functions.","code":""},{"path":"missing-data.html","id":"na","chapter":"20 Dữ liệu Missing","heading":"NA","text":"R, missing values represented reserved (special) value - NA. Note typed without quotes. “NA” different just normal character value (also Beatles lyric song Hey Jude).data may ways representing missingness, “99”, “Missing”, “Unknown” - may even empty character value \"\" looks “blank”, single space \" \". aware consider whether convert NA import data cleaning na_if().data cleaning, may also want convert way - changing NA “Missing” similar replace_na() fct_explicit_na() factors.","code":""},{"path":"missing-data.html","id":"versions-of-na","chapter":"20 Dữ liệu Missing","heading":"Versions of NA","text":"time, NA represents missing value everything works fine. However, circumstances may encounter need variations NA specific object class (character, numeric, etc). rare, aware.\ntypical scenario creating new column dplyr function case_when(). described Cleaning data core functions page, function evaluates every row data frame, assess whether rows meets specified logical criteria (right side code), assigns correct new value (left side code). Importantly: values right side must class.want NA right side, may need specify one special NA options listed . right side values character, consider using “Missing” instead otherwise use NA_character_. numeric, use NA_real_. dates logical, can use NA.NA - use dates logical TRUE/FALSENA_character_ - use charactersNA_real_ - use numericAgain, likely encounter variations unless using case_when() create new column. See R documentation NA information.","code":"\nlinelist <- linelist %>% \n  \n  # Create new \"age_years\" column from \"age\" column\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,       # if age is given in years, assign original value\n    age_unit == \"months\" ~ age/12,    # if age is given in months, divide by 12\n    is.na(age_unit)      ~ age,       # if age UNIT is missing, assume years\n    TRUE                 ~ NA_real_)) # any other circumstance, assign missing"},{"path":"missing-data.html","id":"null","chapter":"20 Dữ liệu Missing","heading":"NULL","text":"NULL another reserved value R. logical representation statement neither true false. returned expressions functions whose values undefined. Generally assign NULL value, unless writing functions perhaps writing [shiny app][Dashboards Shiny] return NULL specific scenarios.Null-ness can assessed using .null() conversion can made .null().See blog post difference NULL NA.","code":""},{"path":"missing-data.html","id":"nan","chapter":"20 Dữ liệu Missing","heading":"NaN","text":"Impossible values represented special value NaN. example force R divide 0 0. can assess .nan(). may also encounter complementary functions including .infinite() .finite().","code":""},{"path":"missing-data.html","id":"inf","chapter":"20 Dữ liệu Missing","heading":"Inf","text":"Inf represents infinite value, divide number 0.example might impact work: let’s say vector/column z contains values: z <- c(1, 22, NA, Inf, NaN, 5)want use max() column find highest value, can use na.rm = TRUE remove NA calculation, Inf NaN remain Inf returned. resolve , can use brackets [ ] .finite() subset finite values used calculation: max(z[.finite(z)]).","code":"\nz <- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # returns NA\nmax(z, na.rm=T)                  # returns Inf\nmax(z[is.finite(z)])             # returns 22"},{"path":"missing-data.html","id":"examples","chapter":"20 Dữ liệu Missing","heading":"Examples","text":"“NAs introduced coercion” common warning message. can happen attempt make illegal conversion like inserting character value vector otherwise numeric.NULL ignored vector.Variance one number results NA.","code":"\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))## Warning: NAs introduced by coercion## [1] 10 20 NA 40\nmy_vector <- c(25, NA, 10, NULL)  # define\nmy_vector                         # print## [1] 25 NA 10\nvar(22)## [1] NA"},{"path":"missing-data.html","id":"useful-functions","chapter":"20 Dữ liệu Missing","heading":"20.3 Useful functions","text":"following useful base R functions assessing handling missing values:","code":""},{"path":"missing-data.html","id":"is.na-and-is.na","chapter":"20 Dữ liệu Missing","heading":"is.na() and !is.na()","text":"Use .na()identify missing values, use opposite (! front) identify non-missing values. return logical value (TRUE FALSE). Remember can sum() resulting vector count number TRUE, e.g. sum(.na(linelist$date_outcome)).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)## [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n!is.na(my_vector)## [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\nsum(is.na(my_vector))## [1] 2"},{"path":"missing-data.html","id":"na.omit","chapter":"20 Dữ liệu Missing","heading":"na.omit()","text":"function, applied data frame, remove rows missing values. also base R.\napplied vector, remove NA values vector applied . example:","code":"\nna.omit(my_vector)## [1]  1  4 56  5 22\n## attr(,\"na.action\")\n## [1] 4 6\n## attr(,\"class\")\n## [1] \"omit\""},{"path":"missing-data.html","id":"drop_na","chapter":"20 Dữ liệu Missing","heading":"drop_na()","text":"tidyr function useful [data cleaning pipeline][Cleaning data core functions]. run parentheses empty, removes rows missing values. column names specified parentheses, rows missing values columns dropped. can also use “tidyselect” syntax specify columns.","code":"\nlinelist %>% \n  drop_na(case_id, date_onset, age) # drops rows missing values for any of these columns"},{"path":"missing-data.html","id":"na.rm-true","chapter":"20 Dữ liệu Missing","heading":"na.rm = TRUE","text":"run mathematical function max(), min(), sum() mean(), NA values present returned value NA. default behavior intentional, alerted data missing.can avoid removing missing values calculation. , include argument na.rm = TRUE (“na.rm” stands “remove NA”).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     ## [1] NA\nmean(my_vector, na.rm = TRUE)## [1] 17.6"},{"path":"missing-data.html","id":"assess-missingness-in-a-data-frame","chapter":"20 Dữ liệu Missing","heading":"20.4 Assess missingness in a data frame","text":"can use package naniar assess visualize missingness data frame linelist.","code":"\n# install and/or load package\npacman::p_load(naniar)"},{"path":"missing-data.html","id":"quantifying-missingness","chapter":"20 Dữ liệu Missing","heading":"Quantifying missingness","text":"find percent values missing use pct_miss(). Use n_miss() get number missing values.two functions return percent rows missing value, entirely complete, respectively. Remember NA means missing, `\"\" \" \" counted missing.","code":"\n# percent of ALL data frame values that are missing\npct_miss(linelist)## [1] 6.688745\n# Percent of rows with any value missing\npct_miss_case(linelist)   # use n_complete() for counts## [1] 69.12364\n# Percent of rows that are complete (no values missing)  \npct_complete_case(linelist) # use n_complete() for counts## [1] 30.87636"},{"path":"missing-data.html","id":"visualizing-missingness","chapter":"20 Dữ liệu Missing","heading":"Visualizing missingness","text":"gg_miss_var() function show number (%) missing values column. nuances:can add column name (quote) argument facet = see plot groupsBy default, counts shown instead percents, change show_pct = TRUEYou can add axis title labels normal ggplot() + labs(...)data piped %>% function. facet = argument also used split data.can use vis_miss() visualize data frame heatmap, showing whether value missing . can also select() certain columns data frame provide columns function.","code":"\ngg_miss_var(linelist, show_pct = TRUE)\nlinelist %>% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n# Heatplot of missingness across the entire data frame  \nvis_miss(linelist)"},{"path":"missing-data.html","id":"explore-and-visualize-missingness-relationships","chapter":"20 Dữ liệu Missing","heading":"Explore and visualize missingness relationships","text":"visualize something ??? default, ggplot() removes points missing values plots.naniar offers solution via geom_miss_point(). creating scatterplot two columns, records one values missing value present shown setting missing values 10% lower lowest value column, coloring distinctly.scatterplot , red dots records value one column present value column missing. allows see distribution missing values relation non-missing values.assess missingness data frame stratified another column, consider gg_miss_fct(), returns heatmap percent missingness data frame factor/categorical (date) column:function can also used date column see missingness changed time:","code":"\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\ngg_miss_fct(linelist, age_cat5)\ngg_miss_fct(linelist, date_onset)## Warning: Removed 29 rows containing missing values (geom_tile)."},{"path":"missing-data.html","id":"shadow-columns","chapter":"20 Dữ liệu Missing","heading":"“Shadow” columns","text":"Another way visualize missingness one column values second column using “shadow” naniar can create. bind_shadow() creates binary NA/NA column every existing column, binds new columns original dataset appendix \"_NA\". doubles number columns - see :“shadow” columns can used plot proportion values missing, another column.example, plot shows proportion records missing days_onset_hosp (number days symptom onset hospitalisation), record’s value date_hospitalisation. Essentially, plotting density x-axis column, stratifying results (color =) shadow column interest. analysis works best x-axis numeric date column.can also use “shadow” columns stratify statistical summary, shown :alternative way plot proportion column’s values missing time shown . involve naniar. example shows percent weekly observations missing).Aggregate data useful time unit (days, weeks, etc.), summarizing proportion observations NA (values interest)Plot proportion missing line using ggplot(), take linelist, add new column week, group data week, calculate percent week’s records value missing. (note: want % 7 days calculation slightly different).plot proportion missing line, week. [ggplot basics] page unfamiliar ggplot2 plotting package.","code":"\nshadowed_linelist <- linelist %>% \n  bind_shadow()\n\nnames(shadowed_linelist)##  [1] \"case_id\"                 \"generation\"              \"date_infection\"         \n##  [4] \"date_onset\"              \"date_hospitalisation\"    \"date_outcome\"           \n##  [7] \"outcome\"                 \"gender\"                  \"age\"                    \n## [10] \"age_unit\"                \"age_years\"               \"age_cat\"                \n## [13] \"age_cat5\"                \"hospital\"                \"lon\"                    \n## [16] \"lat\"                     \"infector\"                \"source\"                 \n## [19] \"wt_kg\"                   \"ht_cm\"                   \"ct_blood\"               \n## [22] \"fever\"                   \"chills\"                  \"cough\"                  \n## [25] \"aches\"                   \"vomit\"                   \"temp\"                   \n## [28] \"time_admission\"          \"bmi\"                     \"days_onset_hosp\"        \n## [31] \"case_id_NA\"              \"generation_NA\"           \"date_infection_NA\"      \n## [34] \"date_onset_NA\"           \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n## [37] \"outcome_NA\"              \"gender_NA\"               \"age_NA\"                 \n## [40] \"age_unit_NA\"             \"age_years_NA\"            \"age_cat_NA\"             \n## [43] \"age_cat5_NA\"             \"hospital_NA\"             \"lon_NA\"                 \n## [46] \"lat_NA\"                  \"infector_NA\"             \"source_NA\"              \n## [49] \"wt_kg_NA\"                \"ht_cm_NA\"                \"ct_blood_NA\"            \n## [52] \"fever_NA\"                \"chills_NA\"               \"cough_NA\"               \n## [55] \"aches_NA\"                \"vomit_NA\"                \"temp_NA\"                \n## [58] \"time_admission_NA\"       \"bmi_NA\"                  \"days_onset_hosp_NA\"\nggplot(data = shadowed_linelist,          # data frame with shadow columns\n  mapping = aes(x = date_hospitalisation, # numeric or date column\n                colour = age_years_NA)) + # shadow column of interest\n  geom_density()                          # plots the density curves\nlinelist %>%\n  bind_shadow() %>%                # create the shows cols\n  group_by(date_outcome_NA) %>%    # shadow col for stratifying\n  summarise(across(\n    .cols = age_years,             # variable of interest for calculations\n    .fns = list(\"mean\" = mean,     # stats to calculate\n                \"sd\" = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # other arguments for the stat calculations## # A tibble: 2 x 6\n##   date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min age_years_max\n##   <fct>                    <dbl>        <dbl>         <dbl>         <dbl>         <dbl>\n## 1 !NA                       16.0         12.6          158.             0            84\n## 2 NA                        16.2         12.9          167.             0            69\noutcome_missing <- linelist %>%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %>%   # create new week column\n  group_by(week) %>%                                             # group the rows by week\n  summarise(                                                     # summarize each week\n    n_obs = n(),                                                  # number of records\n    \n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),        # number of records missing the value\n    outcome_p_miss  = outcome_missing / n_obs,                    # proportion of records missing the value\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),           # number of records as dead\n    outcome_p_dead  = outcome_dead / n_obs) %>%                   # proportion of records as dead\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %>%         # pivot all columns except week, to long format for ggplot\n  filter(stringr::str_detect(statistic, \"_p_\"))                  # keep only the proportion values\nggplot(data = outcome_missing)+\n    geom_line(\n      mapping = aes(x = week, y = value, group = statistic, color = statistic),\n      size = 2,\n      stat = \"identity\")+\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\"))+\n    scale_y_continuous(breaks = c(seq(0,1,0.1)))+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")"},{"path":"missing-data.html","id":"using-data-with-missing-values","chapter":"20 Dữ liệu Missing","heading":"20.5 Using data with missing values","text":"","code":""},{"path":"missing-data.html","id":"filter-out-rows-with-missing-values","chapter":"20 Dữ liệu Missing","heading":"Filter out rows with missing values","text":"quickly remove rows missing values, use dplyr function drop_na().original linelist nrow(linelist) rows. adjusted number rows shown :can specify drop rows missingness certain columns:can list columns one , use “tidyselect” helper functions:","code":"\nlinelist %>% \n  drop_na() %>%     # remove rows with ANY missing values\n  nrow()## [1] 1818\nlinelist %>% \n  drop_na(date_onset) %>% # remove rows missing date_onset \n  nrow()## [1] 5632\nlinelist %>% \n  drop_na(contains(\"date\")) %>% # remove rows missing values in any \"date\" column \n  nrow()## [1] 3029"},{"path":"missing-data.html","id":"handling-na-in-ggplot","chapter":"20 Dữ liệu Missing","heading":"Handling NA in ggplot()","text":"often wise report number values excluded plot caption. example:ggplot(), can add labs() within caption =. caption, can use str_glue() stringr package paste values together sentence dynamically adjust data. example :Note use \\n new line.Note multiple column contribute values plotted (e.g. age sex reflected plot), must filter columns well correctly calculate number shown.Sometimes, can easier save string object commands prior ggplot() command, simply reference named string object within str_glue().","code":"\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} from Central Hospital;\n  {nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown.\"))  "},{"path":"missing-data.html","id":"na-in-factors","chapter":"20 Dữ liệu Missing","heading":"NA in factors","text":"column interest factor, use fct_explicit_na() forcats package convert NA values character value. See detail [Factors] page. default, new value “(Missing)” can adjusted via na_level = argument.","code":"\npacman::p_load(forcats)   # load package\n\nlinelist <- linelist %>% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)## [1] \"f\"       \"m\"       \"Missing\""},{"path":"missing-data.html","id":"imputation","chapter":"20 Dữ liệu Missing","heading":"20.6 Imputation","text":"Sometimes, analyzing data, important “fill gaps” impute missing data can always simply analyze dataset removing missing values, can cause problems many ways. two examples:removing observations missing values variables large amount missing data, might reduce power ability types analysis. example, discovered earlier, small fraction observations linelist dataset missing data across variables. removed majority dataset ’d losing lot information! , variables amount missing data–analysis ’s probably reasonable drop every variable lot missing data either.removing observations missing values variables large amount missing data, might reduce power ability types analysis. example, discovered earlier, small fraction observations linelist dataset missing data across variables. removed majority dataset ’d losing lot information! , variables amount missing data–analysis ’s probably reasonable drop every variable lot missing data either.Depending data missing, analysis non-missing data might lead biased misleading results. example, learned earlier missing data patients whether ’ve important symptoms like fever cough. , one possibility, maybe information wasn’t recorded people just obviously weren’t sick. case, just removed observations ’d excluding healthiest people dataset might really bias results.Depending data missing, analysis non-missing data might lead biased misleading results. example, learned earlier missing data patients whether ’ve important symptoms like fever cough. , one possibility, maybe information wasn’t recorded people just obviously weren’t sick. case, just removed observations ’d excluding healthiest people dataset might really bias results.’s important think data might missing addition seeing much missing. can help decide important might impute missing data, also method imputing missing data might best situation.","code":""},{"path":"missing-data.html","id":"types-of-missing-data","chapter":"20 Dữ liệu Missing","heading":"Types of missing data","text":"three general types missing data:Missing Completely Random (MCAR). means relationship probability data missing variables data. probability missing cases rare situation. , strong reason believe data MCAR analyzing non-missing data without imputing won’t bias results (although may lose power). [TODO: consider discussing statistical tests MCAR]Missing Completely Random (MCAR). means relationship probability data missing variables data. probability missing cases rare situation. , strong reason believe data MCAR analyzing non-missing data without imputing won’t bias results (although may lose power). [TODO: consider discussing statistical tests MCAR]Missing Random (MAR). name actually bit misleading MAR means data missing systematic, predictable way based information . example, maybe every observation dataset missing value fever actually recorded every patient chills aches just assumed fever temperature never taken. true, easily predict every missing observation chills aches fever well use information impute missing data. practice, spectrum. Maybe patient chills aches likely fever well didn’t temperature taken, always. still predictable even isn’t perfectly predictable. common type missing dataMissing Random (MAR). name actually bit misleading MAR means data missing systematic, predictable way based information . example, maybe every observation dataset missing value fever actually recorded every patient chills aches just assumed fever temperature never taken. true, easily predict every missing observation chills aches fever well use information impute missing data. practice, spectrum. Maybe patient chills aches likely fever well didn’t temperature taken, always. still predictable even isn’t perfectly predictable. common type missing dataMissing Random (MNAR). Sometimes, also called Missing Random (NMAR). assumes probability value missing systematic predictable using information also isn’t missing randomly. situation data missing unknown reasons reasons don’t information . example, dataset maybe information age missing elderly patients either don’t know refuse say old . situation, missing data age related value (thus isn’t random) isn’t predictable based information . MNAR complex often best way dealing try collect data information data missing rather attempt impute .Missing Random (MNAR). Sometimes, also called Missing Random (NMAR). assumes probability value missing systematic predictable using information also isn’t missing randomly. situation data missing unknown reasons reasons don’t information . example, dataset maybe information age missing elderly patients either don’t know refuse say old . situation, missing data age related value (thus isn’t random) isn’t predictable based information . MNAR complex often best way dealing try collect data information data missing rather attempt impute .general, imputing MCAR data often fairly simple, MNAR challenging impossible. Many common data imputation methods assume MAR.","code":""},{"path":"missing-data.html","id":"useful-packages","chapter":"20 Dữ liệu Missing","heading":"Useful packages","text":"useful packages imputing missing data Mmisc, missForest (uses random forests impute missing data), mice (Multivariate Imputation Chained Equations). section ’ll just use mice package, implements variety techniques. maintainer mice package published online book imputing missing data goes detail (https://stefvanbuuren.name/fimd/).code load mice package:","code":"\npacman::p_load(mice)"},{"path":"missing-data.html","id":"mean-imputation","chapter":"20 Dữ liệu Missing","heading":"Mean Imputation","text":"Sometimes simple analysis strong reason think can assume MCAR, can simply set missing numerical values mean variable. Perhaps can assume missing temperature measurements dataset either MCAR just normal values. code create new variable replaces missing temperature values mean temperature value dataset. However, many situations replacing data mean can lead bias, careful.also similar process replacing categorical data specific value. dataset, imagine knew observations missing value outcome (can “Death” “Recover”) actually people died (note: actually true dataset):","code":"\nlinelist <- linelist %>%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\nlinelist <- linelist %>%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))"},{"path":"missing-data.html","id":"regression-imputation","chapter":"20 Dữ liệu Missing","heading":"Regression imputation","text":"somewhat advanced method use sort statistical model predict missing value likely replace predicted value. example creating predicted values observations temperature missing, age fever , using simple linear regression using fever status age years predictors. practice ’d want use better model sort simple approach., using modeling approach mice package create imputed values missing temperature observations:type approach advanced methods like using missForest package replace missing data predicted values. case, prediction model random forest instead linear regression. can use types models well. However, approach works well MCAR bit careful believe MAR MNAR accurately describes situation. quality imputation depend good prediction model even good model variability imputed data may underestimated.","code":"\nsimple_temperature_model_fit <- lm(temp ~ fever + age_years, data = linelist)\n\n#using our simple temperature model to predict values just for the observations where temp is missing\npredictions_for_missing_temps <- predict(simple_temperature_model_fit,\n                                        newdata = linelist %>% filter(is.na(temp))) \nmodel_dataset <- linelist %>%\n  select(temp, fever, age_years)  \n\ntemp_imputed <- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = F)## Warning: Number of logged events: 1\ntemp_imputed_values <- temp_imputed$imp$temp"},{"path":"missing-data.html","id":"locf-and-bocf","chapter":"20 Dữ liệu Missing","heading":"LOCF and BOCF","text":"Last observation carried forward (LOCF) baseline observation carried forward (BOCF) imputation methods time series/longitudinal data. idea take previous observed value replacement missing data. multiple values missing succession, method searches last observed value.fill() function tidyr package can used LOCF BOCF imputation (however, packages HMISC, zoo, data.table also include methods ). show fill() syntax ’ll make simple time series dataset containing number cases disease quarter years 2000 2001. However, year value subsequent quarters Q1 missing ’ll need impute . fill() junction also demonstrated [Pivoting data] page.Note: make sure data sorted correctly using fill() function. fill() defaults filling “” can also impute values different directions changing .direction parameter. can make similar dataset year value recorded end year missing earlier quarters:example, LOCF BOCF clearly right things , complicated situations may harder decide methods appropriate. example, may missing laboratory values hospital patient first day. Sometimes, can mean lab values didn’t change…also mean patient recovered values different first day! Use methods caution.","code":"\n#creating our simple dataset\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n#imputing the missing year values:\ndisease %>% fill(year)## # A tibble: 8 x 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197\n#creating our slightly different dataset\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n#imputing the missing year values in the \"up\" direction:\ndisease %>% fill(year, .direction = \"up\")## # A tibble: 8 x 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197"},{"path":"missing-data.html","id":"multiple-imputation","chapter":"20 Dữ liệu Missing","heading":"Multiple Imputation","text":"online book mentioned earlier author mice package (https://stefvanbuuren.name/fimd/) contains detailed explanation multiple imputation ’d want use . , basic explanation method:multiple imputation, create multiple datasets missing values imputed plausible data values (depending research data might want create less imputed datasets, mice package sets default number 5). difference rather single, specific value imputed value drawn estimated distribution (includes randomness). result, datasets slightly different different imputed values (however, non-missing data imputed datasets). still use sort predictive model imputation new datasets (mice many options prediction methods including Predictive Mean Matching, logistic regression, random forest) mice package can take care many modeling details., created new imputed datasets, can apply apply whatever statistical model analysis planning new imputed datasets pool results models together. works well reduce bias MCAR many MAR settings often results accurate standard error estimates.example applying Multiple Imputation process predict temperature linelist dataset using age fever status (simplified model_dataset ):used mice default method imputation, Predictive Mean Matching. used imputed datasets separately estimate pool results simple linear regressions datasets. many details ’ve glossed many settings can adjust Multiple Imputation process using mice package. example, won’t always numerical data might need use imputation methods (can still use mice package many types data methods). , robust analysis missing data significant concern, Multiple Imputation good solution isn’t always much work complete case analysis.","code":"\n# imputing missing values for all variables in our model_dataset, and creating 10 new imputed datasets\nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) ## Warning: Number of logged events: 1\nmodel_fit <- with(multiple_imputation, lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))##          term     estimate    std.error     statistic        df   p.value\n## 1 (Intercept) 3.703143e+01 0.0270863456 1367.16240465  26.83673 0.0000000\n## 2   age_years 3.867829e-05 0.0006090202    0.06350905 171.44363 0.9494351\n## 3    feveryes 1.978044e+00 0.0193587115  102.17849544 176.51325 0.0000000"},{"path":"missing-data.html","id":"resources-7","chapter":"20 Dữ liệu Missing","heading":"20.7 Resources","text":"Vignette naniar packageGallery missing value visualizationsOnline book multiple imputation R maintainer mice package","code":""},{"path":"standardization.html","id":"standardization","chapter":"21 Tỷ lệ chuẩn hóa","heading":"21 Tỷ lệ chuẩn hóa","text":"page show two ways standardize outcome, hospitalizations mortality, characteristics age sex.Using dsr packageUsing PHEindicatormethods packageWe begin extensively demonstrating processes data preparation/cleaning/joining, common combining population data multiple countries, standard population data, deaths, etc.","code":""},{"path":"standardization.html","id":"overview","chapter":"21 Tỷ lệ chuẩn hóa","heading":"21.1 Overview","text":"two main ways standardize: direct indirect standardization.\nLet’s say like standardize mortality rate age sex country country B, compare standardized rates countries.direct standardization, know number -risk population number deaths stratum age sex, country country B. One stratum example females ages 15-44.indirect standardization, need know total number deaths age- sex structure country. option therefore feasible age- sex-specific mortality rates population numbers available. Indirect standardization furthermore preferable case small numbers per stratum, estimates direct standardization influenced substantial sampling variation.","code":""},{"path":"standardization.html","id":"preparation-7","chapter":"21 Tỷ lệ chuẩn hóa","heading":"21.2 Preparation","text":"show standardization done, use fictitious population counts death counts country country B, age (5 year categories) sex (female, male). make datasets ready use, perform following preparation steps:Load packagesLoad datasetsJoin population death data two countriesPivot longer one row per age-sex stratumClean reference population (world standard population) join country dataIn scenario, data may come different format. Perhaps data province, city, catchment area. may one row death information age sex (significant proportion) deaths. case, see pages [Grouping data], [Pivoting data], [Descriptive tables] create dataset event population counts per age-sex stratum.also need reference population, standard population. purposes exercise use world_standard_population_by_sex. World standard population based populations 46 countries developed 1960. many “standard” populations - one example, website NHS Scotland quite informative European Standard Population, World Standard Population Scotland Standard Population.","code":""},{"path":"standardization.html","id":"load-packages-10","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.CAUTION: newer version R, dsr package directly downloaded CRAN. However, still available CRAN archive. can install use one. non-Mac users:Mac users:","code":"\npacman::p_load(\n     rio,                 # import/export data\n     here,                # locate files\n     tidyverse,           # data management and visualization\n     stringr,             # cleaning characters and strings\n     frailtypack,         # needed for dsr, for frailty models\n     dsr,                 # standardise rates\n     PHEindicatormethods) # alternative for rate standardisation\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n# Other solution that may work\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")"},{"path":"standardization.html","id":"load-population-data","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Load population data","text":"See [Download handbook data] page instructions download example data handbook. can import Standardisation page data directly R Github repository running following import() commands:First load demographic data (counts males females 5-year age category) two countries comparing, “Country ” “Country B”.","code":"\n# import demographics for country A directly from Github\nA_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryA.csv\")\n\n# import demographics for country B directly from Github\nB_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryB.csv\")\n\n# import demographics for country B directly from Github\nstandard_pop_data <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n# Country A\nA_demo <- import(\"country_demographics.csv\")\n# Country B\nB_demo <- import(\"country_demographics_2.csv\")"},{"path":"standardization.html","id":"load-death-counts","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Load death counts","text":"Conveniently, also counts deaths time period interest, age sex. country’s counts separate file, shown .Deaths Country ADeaths Country B","code":""},{"path":"standardization.html","id":"clean-populations-and-deaths","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Clean populations and deaths","text":"need join transform data following ways:Combine country populations one dataset pivot “long” age-sex stratum one rowCombine country death counts one dataset pivot “long” age-sex stratum one rowJoin deaths populationsFirst, combine country populations datasets, pivot longer, minor cleaning. See page [Pivoting data] detail.combined population data now look like (click see countries B):now perform similar operations two deaths datasets.deaths data now look like , contain data countries:now join deaths population data based common columns Country, age_cat5, Sex. adds column Deaths.can now classify Sex, age_cat5, Country factors set level order using fct_relevel() function forcats package, described page [Factors]. Note, classifying factor levels doesn’t visibly change data, arrange() command sort Country, age category, sex.CAUTION: deaths per stratum, consider using 10-, 15-year categories, instead 5-year categories age.","code":"\npop_countries <- A_demo %>%  # begin with country A dataset\n     bind_rows(B_demo) %>%        # bind rows, because cols are identically named\n     pivot_longer(                       # pivot longer\n          cols = c(m, f),                   # columns to combine into one\n          names_to = \"Sex\",                 # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Population\") %>%     # name for new column containing the numeric values pivoted\n     mutate(Sex = recode(Sex,            # re-code values for clarity\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\ndeaths_countries <- A_deaths %>%    # begin with country A deaths dataset\n     bind_rows(B_deaths) %>%        # bind rows with B dataset, because cols are identically named\n     pivot_longer(                  # pivot longer\n          cols = c(Male, Female),        # column to transform into one\n          names_to = \"Sex\",              # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Deaths\") %>%      # name for new column containing the numeric values pivoted\n     rename(age_cat5 = AgeCat)      # rename for clarity\ncountry_data <- pop_countries %>% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\ncountry_data <- country_data %>% \n  mutate(\n    Country = fct_relevel(Country, \"A\", \"B\"),\n      \n    Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n        \n    age_cat5 = fct_relevel(\n      age_cat5,\n      \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n      \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n      \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n      \"60-64\", \"65-69\", \"70-74\",\n      \"75-79\", \"80-84\", \"85\")) %>% \n          \n  arrange(Country, age_cat5, Sex)"},{"path":"standardization.html","id":"load-reference-population","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Load reference population","text":"Lastly, direct standardisation, import reference population (world “standard population” sex)","code":"\n# Reference population\nstandard_pop_data <- import(\"world_standard_population_by_sex.csv\")"},{"path":"standardization.html","id":"clean-reference-population","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Clean reference population","text":"age category values country_data standard_pop_data data frames need aligned.Currently, values column age_cat5 standard_pop_data data frame contain word “years” “plus”, country_data data frame . make age category values match. use str_replace_all() stringr package, described page [Characters strings], replace patterns space \"\".Furthermore, package dsr expects standard population, column containing counts called \"pop\". rename column accordingly.CAUTION: try use str_replace_all() remove plus symbol, won’t work special symbol. “Escape” specialnes putting two back slashes front, str_replace_call(column, \"\\\\+\", \"\"). ","code":"\n# Remove specific string from column values\nstandard_pop_clean <- standard_pop_data %>%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"),   # remove \"year\"\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"),    # remove \"plus\"\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %>%   # remove \" \" space\n     \n     rename(pop = WorldStandardPopulation)   # change col name to \"pop\", as this is expected by dsr package"},{"path":"standardization.html","id":"standard_all","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Create dataset with standard population","text":"Finally, package PHEindicatormethods, detailed , expects standard populations joined country event population counts. , create dataset all_data purpose.complete dataset looks like :","code":"\nall_data <- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))"},{"path":"standardization.html","id":"dsr-package","chapter":"21 Tỷ lệ chuẩn hóa","heading":"21.3 dsr package","text":"demonstrate calculating comparing directly standardized rates using dsr package. dsr package allows calculate compare directly standardized rates (indirectly standardized rates!).data Preparation section, made separate datasets country counts standard population:country_data object, population table number population number deaths per stratum per countrythe standard_pop_clean object, containing number population per stratum reference population, World Standard PopulationWe use separate datasets dsr approach.","code":""},{"path":"standardization.html","id":"standardized-rates","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Standardized rates","text":", calculate rates per country directly standardized age sex. use dsr() function.note - dsr() expects one data frame country populations event counts (deaths), separate data frame reference population. also expects reference population dataset unit-time column name “pop” (assured data Preparation section).many arguments, annotated code . Notably, event = set column Deaths, fu = (“follow-”) set Population column. set subgroups comparison column Country standardize based age_cat5 Sex. last two columns assigned particular named argument. See ?dsr details., see country lower crude mortality rate country B, higher standardized rate direct age sex standardization.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_rate <- dsr::dsr(\n     data = country_data,  # specify object containing number of deaths per stratum\n     event = Deaths,       # column containing number of deaths per stratum \n     fu = Population,      # column containing number of population per stratum\n     subgroup = Country,   # units we would like to compare\n     age_cat5,             # other columns - rates will be standardized by these\n     Sex,\n     refdata = standard_pop_clean, # reference population data frame, with column called pop\n     method = \"gamma\",      # method to calculate 95% CI\n     sig = 0.95,            # significance level\n     mp = 100000,           # we want rates per 100.000 population\n     decimals = 2)          # number of decimals)\n\n\n# Print output as nice-looking HTML table\nknitr::kable(mortality_rate) # show mortality rate before and after direct standardization"},{"path":"standardization.html","id":"standardized-rate-ratios","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Standardized rate ratios","text":"standardized mortality rate 1.22 times higher country compared country B (95% CI 1.17-1.27).","code":"\n# Calculate RR\nmortality_rr <- dsr::dsrr(\n     data = country_data, # specify object containing number of deaths per stratum\n     event = Deaths,      # column containing number of deaths per stratum \n     fu = Population,     # column containing number of population per stratum\n     subgroup = Country,  # units we would like to compare\n     age_cat5,\n     Sex,                 # characteristics to which we would like to standardize \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",      # reference for comparison\n     estimate = \"ratio\",  # type of estimate\n     sig = 0.95,          # significance level\n     mp = 100000,         # we want rates per 100.000 population\n     decimals = 2)        # number of decimals\n\n# Print table\nknitr::kable(mortality_rr) "},{"path":"standardization.html","id":"standardized-rate-difference","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Standardized rate difference","text":"Country 4.24 additional deaths per 100.000 population (95% CI 3.24-5.24) compared country .","code":"\n# Calculate RD\nmortality_rd <- dsr::dsrr(\n     data = country_data,       # specify object containing number of deaths per stratum\n     event = Deaths,            # column containing number of deaths per stratum \n     fu = Population,           # column containing number of population per stratum\n     subgroup = Country,        # units we would like to compare\n     age_cat5,                  # characteristics to which we would like to standardize\n     Sex,                        \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",            # reference for comparison\n     estimate = \"difference\",   # type of estimate\n     sig = 0.95,                # significance level\n     mp = 100000,               # we want rates per 100.000 population\n     decimals = 2)              # number of decimals\n\n# Print table\nknitr::kable(mortality_rd) "},{"path":"standardization.html","id":"standard_phe","chapter":"21 Tỷ lệ chuẩn hóa","heading":"21.4 PHEindicatormethods package","text":"Another way calculating standardized rates PHEindicatormethods package. package allows calculate directly well indirectly standardized rates. show .section use all_data data frame created end Preparation section. data frame includes country populations, death events, world standard reference population. can view .","code":""},{"path":"standardization.html","id":"directly-standardized-rates","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Directly standardized rates","text":", first group data Country pass function phe_dsr() get directly standardized rates per country.note - reference (standard) population can provided column within country-specific data frame separate vector. provided within country-specific data frame, set stdpoptype = \"field\". provided vector, set stdpoptype = \"vector\". latter case, make sure ordering rows strata similar country-specific data frame reference population, records matched position. example , provided reference population column within country-specific data frame.See help ?phr_dsr links References section information.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_ds_rate_phe <- all_data %>%\n     group_by(Country) %>%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          stdpop = pop,               # standard populations for each stratum\n          stdpoptype = \"field\")       # either \"vector\" for a standalone vector or \"field\" meaning std populations are in the data  \n\n# Print table\nknitr::kable(mortality_ds_rate_phe)"},{"path":"standardization.html","id":"standard_indirect","chapter":"21 Tỷ lệ chuẩn hóa","heading":"Indirectly standardized rates","text":"indirect standardization, need reference population number deaths number population per stratum. example, calculating rates country using country B reference population, standard_pop_clean reference population include number deaths per stratum., first create reference population country B. , pass mortality population data country , combine reference population, pass function phe_isr(), get indirectly standardized rates. course, can also vice versa.note - example , reference population provided separate data frame. case, make sure x =, n =, x_ref = n_ref = vectors ordered standardization category (stratum) values country-specific data frame, records matched position.See help ?phr_isr links References section information.","code":"\n# Create reference population\nrefpopCountryB <- country_data %>% \n  filter(Country == \"B\") \n\n# Calculate rates for country A indirectly standardized by age and sex\nmortality_is_rate_phe_A <- country_data %>%\n     filter(Country == \"A\") %>%\n     PHEindicatormethods::phe_isr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          x_ref = refpopCountryB$Deaths,  # reference number of deaths for each stratum\n          n_ref = refpopCountryB$Population)  # reference population for each stratum\n\n# Print table\nknitr::kable(mortality_is_rate_phe_A)"},{"path":"standardization.html","id":"resources-8","chapter":"21 Tỷ lệ chuẩn hóa","heading":"21.5 Resources","text":"like see another reproducible example using dsr please see vignetteFor another example using PHEindicatormethods, please go websiteSee PHEindicatormethods reference pdf file","code":""},{"path":"moving-average.html","id":"moving-average","chapter":"22 Đường trung bình động","heading":"22 Đường trung bình động","text":"page cover two methods calculate visualize moving averages:Calculate slider packageCalculate within ggplot() command tidyquant package","code":""},{"path":"moving-average.html","id":"preparation-8","chapter":"22 Đường trung bình động","heading":"22.1 Preparation","text":"","code":""},{"path":"moving-average.html","id":"load-packages-11","chapter":"22 Đường trung bình động","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  tidyverse,      # for data management and viz\n  slider,         # for calculating moving averages\n  tidyquant       # for calculating moving averages within ggplot\n)"},{"path":"moving-average.html","id":"import-data-9","chapter":"22 Đường trung bình động","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"moving-average.html","id":"calculate-with-slider","chapter":"22 Đường trung bình động","heading":"22.2 Calculate with slider","text":"Use approach calculate moving average data frame prior plotting.slider package provides several “sliding window” functions compute rolling averages, cumulative sums, rolling regressions, etc. treats data frame vector rows, allowing iteration row-wise data frame.common functions:slide_dbl() - iterates numeric (hence \"_dbl\") column performing operation using sliding window\nslide_sum() - rolling sum shortcut function slide_dbl()\nslide_mean() - rolling average shortcut function slide_dbl()\nslide_sum() - rolling sum shortcut function slide_dbl()slide_mean() - rolling average shortcut function slide_dbl()slide_index_dbl() - applies rolling window numeric column using separate column index window progression (useful rolling date dates absent)\nslide_index_sum() - rolling sum shortcut function indexing\nslide_index_mean() - rolling mean shortcut function indexing\nslide_index_sum() - rolling sum shortcut function indexingslide_index_mean() - rolling mean shortcut function indexingThe slider package many functions covered Resources section page. briefly touch upon common.Core arguments.x, first argument default, vector iterate apply function .= “index” versions slider functions - provide column “index” roll (see section ).f =, second argument default, either:\nfunction, written without parentheses, like mean, \nformula, converted function. example ~ .x - mean(.x) return result current value minus mean window’s value\nfunction, written without parentheses, like mean, orA formula, converted function. example ~ .x - mean(.x) return result current value minus mean window’s valueFor details see reference materialWindow sizeSpecify size window using either ., ., arguments:.= - Provide integer.= - Provide integer.complete = - Set TRUE want calculation performed complete windowsFor example, achieve 7-day window including current value six previous, use .= 6. achieve “centered” window provide number .= .=.default, .complete = FALSE full window rows exist, functions use available rows perform calculation. Setting TRUE restricts calculations performed complete windows.Expanding windowTo achieve cumulative operations, set .= argument Inf. conduct operation current value coming .","code":""},{"path":"moving-average.html","id":"roll_index","chapter":"22 Đường trung bình động","heading":"Rolling by date","text":"likely use-case rolling calculation applied epidemiology examine metric time. example, rolling measurement case incidence, based daily case counts.clean time series data values every date, may OK use slide_dbl(), demonstrated Time series outbreak detection page.However, many applied epidemiology circumstances may dates absent data, events recorded. cases, best use “index” versions slider functions.","code":""},{"path":"moving-average.html","id":"indexed-data","chapter":"22 Đường trung bình động","heading":"Indexed data","text":", show example using slide_index_dbl() case linelist. Let us say objective calculate rolling 7-day incidence - sum cases using rolling 7-day window. looking example rolling average, see section grouped rolling.begin, dataset daily_counts created reflect daily case counts linelist, calculated count() dplyr.daily_counts data frame - nrow(daily_counts) rows, day represented one row, especially early epidemic days present (cases admitted days).crucial recognize standard rolling function (like slide_dbl() use window 7 rows, 7 days. , absent dates, windows actually extend 7 calendar days!“smart” rolling window can achieved slide_index_dbl(). “index” means function uses separate column “index” rolling window. window simply based rows data frame.index column date, added ability specify window extent .= /.= units lubridate days() months(). things, function include absent days windows (NA values).Let’s show comparison. , calculate rolling 7-day case incidence regular indexed windows.Observe regular column first 7 rows count steadily increases despite rows within 7 days ! adjacent “indexed” column accounts absent calendar days, 7-day sums much lower, least period epidemic cases farther .Now can plot data using ggplot():","code":"\n# make dataset of daily counts\ndaily_counts <- linelist %>% \n  count(date_hospitalisation, name = \"new_cases\")\nrolling <- daily_counts %>% \n  mutate(                                # create new columns\n    # Using slide_dbl()\n    ###################\n    reg_7day = slide_dbl(\n      new_cases,                         # calculate on new_cases\n      .f = ~sum(.x, na.rm = T),          # function is sum() with missing values removed\n      .before = 6),                      # window is the ROW and 6 prior ROWS\n    \n    # Using slide_index_dbl()\n    #########################\n    indexed_7day = slide_index_dbl(\n        new_cases,                       # calculate on new_cases\n        .i = date_hospitalisation,       # indexed with date_onset \n        .f = ~sum(.x, na.rm = TRUE),     # function is sum() with missing values removed\n        .before = days(6))               # window is the DAY and 6 prior DAYS\n    )\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)"},{"path":"moving-average.html","id":"roll_slider_group","chapter":"22 Đường trung bình động","heading":"Rolling by group","text":"group data prior using slider function, sliding windows applied group. careful arrange rows desired order group.time new group begins, sliding window re-start. Therefore, one nuance aware data grouped set .complete = TRUE, empty values transition groups. function moved downward rows, every transition grouping column re-start accrual minimum window size allow calculation.See handbook page [Grouping data] details grouping data., count linelist cases date hospital. arrange rows ascending order, first ordering hospital within date. Next set group_by(). can create new rolling average.new dataset:can now plot moving averages, displaying data group specifying ~ hospital facet_wrap() ggplot(). fun, plot two geometries - geom_col() showing daily case counts geom_line() showing 7-day moving average.DANGER: get error saying “slide() deprecated tsibble 0.9.0 now defunct. Please use slider::slide() instead.”, means slide() function tsibble package masking slide() function slider package. Fix specifying package command, slider::slide_dbl().","code":"\ngrouped_roll <- linelist %>%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %>% \n\n  arrange(hospital, date_hospitalisation) %>%   # arrange rows by hospital and then by date\n  \n  group_by(hospital) %>%              # group by hospital \n    \n  mutate(                             # rolling average  \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases,                 # the count of cases per hospital-day\n      .i = date_hospitalisation,      # index on date of admission\n      .f = mean,                      # use mean()                   \n      .before = days(6)               # use the day and the 6 days prior\n      )\n  )\nggplot(data = grouped_roll)+\n  geom_col(                       # plot daly case counts as grey bars\n    mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(                      # plot rolling average as line colored by hospital\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # create mini-plots per hospital\n  theme_classic()+                 # simplify background  \n  theme(legend.position = \"none\")+ # remove legend\n  labs(                            # add plot labels\n    title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")"},{"path":"moving-average.html","id":"calculate-with-tidyquant-within-ggplot","chapter":"22 Đường trung bình động","heading":"22.3 Calculate with tidyquant within ggplot()","text":"package tidyquant offers another approach calculating moving averages - time within ggplot() command .linelist data counted date onset, plotted faded line (alpha < 1). Overlaid top line created geom_ma() package tidyquant, set window 7 days (n = 7) specified color thickness.default geom_ma() uses simple moving average (ma_fun = \"SMA\"), types can specified, :“EMA” - exponential moving average (weight recent observations)“WMA” - weighted moving average (wts used weight observations moving average)Others can found function documentationSee vignette details options available within tidyquant.","code":"\nlinelist %>% \n  count(date_onset) %>%                 # count cases per day\n  drop_na(date_onset) %>%               # remove cases missing onset date\n  ggplot(aes(x = date_onset, y = n))+   # start ggplot\n    geom_line(                          # plot raw values\n      size = 1,\n      alpha = 0.2                       # semi-transparent line\n      )+             \n    tidyquant::geom_ma(                 # plot moving average\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal()                       # simple background"},{"path":"moving-average.html","id":"resources-9","chapter":"22 Đường trung bình động","heading":"22.4 Resources","text":"See helpful online vignette slider packageThe slider github pageA slider vignettetidyquant vignetteIf use case requires “skip ” weekends even holidays, might like almanac package.","code":""},{"path":"time-series.html","id":"time-series","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23 Chuỗi thời gian và phát hiện ổ dịch","text":"","code":""},{"path":"time-series.html","id":"overview-1","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.1 Overview","text":"tab demonstrates use several packages time series analysis.\nprimarily relies packages tidyverts\nfamily, also use RECON trending\npackage fit models appropriate infectious disease epidemiology.Note example use dataset surveillance package\nCampylobacter Germany (see data chapter,\nhandbook details). However, wanted run code dataset\nmultiple countries strata, example code template \nr4epis github repo.Topics covered include:Time series dataDescriptive analysisFitting regressionsRelation two time seriesOutbreak detectionInterrupted time series","code":""},{"path":"time-series.html","id":"preparation-9","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.2 Preparation","text":"","code":""},{"path":"time-series.html","id":"packages-1","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               slider,       # for calculating moving averages\n               imputeTS,     # for filling in missing values\n               feasts,       # for time series decomposition and autocorrelation\n               forecast,     # fit sin and cosin terms to data (note: must load after feasts)\n               trending,     # fit and assess models \n               tmaptools,    # for getting geocoordinates (lon/lat) based on place names\n               ecmwfr,       # for interacting with copernicus sateliate CDS API\n               stars,        # for reading in .nc (climate data) files\n               units,        # for defining units of measurement (climate data)\n               yardstick,    # for looking at model accuracy\n               surveillance  # for aberration detection\n               )"},{"path":"time-series.html","id":"load-data","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Load data","text":"can download data used handbook via instructions [Download handbook data] page.example dataset used section weekly counts campylobacter cases reported Germany 2001 2011. \ncan click download data file (.xlsx).dataset reduced version dataset available surveillance package.\n(details load surveillance package see ?campyDE)Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 10 rows counts displayed .","code":"\n# import the counts into R\ncounts <- rio::import(\"campylobacter_germany.xlsx\")"},{"path":"time-series.html","id":"clean-data","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Clean data","text":"code makes sure date column appropriate format.\ntab using tsibble package yearweek\nfunction used create calendar week variable. several \nways (see Working dates\npage details), however time series best keep within one framework (tsibble).","code":"\n## ensure the date column is in the appropriate format\ncounts$date <- as.Date(counts$date)\n\n## create a calendar week variable \n## fitting ISO definitons of weeks starting on a monday\ncounts <- counts %>% \n     mutate(epiweek = yearweek(date, week_start = 1))"},{"path":"time-series.html","id":"download-climate-data","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Download climate data","text":"relation two time series section page, comparing\ncampylobacter case counts climate data.Climate data anywhere world can downloaded EU’s Copernicus\nSatellite. exact measurements, based model (similar \ninterpolation), however benefit global hourly coverage well forecasts.can download climate data files [Download handbook data] page.purposes demonstration , show R code use ecmwfr package pull data Copernicus\nclimate data store. need create free account order \nwork. package website useful walkthrough\n. example code go , \nappropriate API keys. replace X’s account\nIDs. need download one year data time otherwise server times-.sure coordinates location want download data\n, can use tmaptools package pull coordinates open street\nmaps. alternative option photon\npackage, however released CRAN yet; nice thing \nphoton provides contextual data several\nmatches search.","code":"\n## retrieve location coordinates\ncoords <- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## pull together long/lats in format for ERA-5 querying (bounding box) \n## (as just want a single point can repeat coords)\nrequest_coords <- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Pulling data modelled from copernicus satellite (ERA-5 reanalysis)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## set up key for weather data \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## run for each year of interest (otherwise server times out)\nfor (i in 2002:2011) {\n  \n  ## pull together a query \n  ## see here for how to do: https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## change request to a list using addin button above (python to list)\n  ## Target is the name of the output file!!\n  request <- request <- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## download the file and store it in the current working directory\n  file <- wf_request(user     = \"XXXXX\",  # user ID (for authentication)\n                     request  = request,  # the request\n                     transfer = TRUE,     # download the file\n                     path     = here::here(\"data\", \"Weather\")) ## path to save the data\n  }"},{"path":"time-series.html","id":"load-climate-data","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Load climate data","text":"Whether downloaded climate data via handbook, used code , now 10 years “.nc” climate data files stored folder computer.Use code import files R stars package.files imported object data, convert data frame.","code":"\n## define path to weather folder \nfile_paths <- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # replace with your own file path \n  full.names = TRUE)\n\n## only keep those with the current name of interest \nfile_paths <- file_paths[str_detect(file_paths, \"germany\")]\n\n## read in all the files as a stars object \ndata <- stars::read_stars(file_paths)## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp,\n## change to a data frame \ntemp_data <- as_tibble(data) %>% \n  ## add in variables and correct units\n  mutate(\n    ## create an calendar week variable \n    epiweek = tsibble::yearweek(time), \n    ## create a date variable (start of calendar week)\n    date = as.Date(epiweek),\n    ## change temperature from kelvin to celsius\n    t2m = set_units(t2m, celsius), \n    ## change precipitation from metres to millimetres \n    tp  = set_units(tp, mm)) %>% \n  ## group by week (keep the date too though)\n  group_by(epiweek, date) %>% \n  ## get the average per week\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))## `summarise()` has grouped output by 'epiweek'. You can override using the `.groups` argument."},{"path":"time-series.html","id":"time-series-data","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.3 Time series data","text":"number different packages structuring handling time series\ndata. said, focus tidyverts family packages \nuse tsibble package define time series object. data set\ndefined time series object means much easier structure analysis.use tsibble() function specify “index”, .e. variable\nspecifying time unit interest. case epiweek variable.data set weekly counts province, example, also\nable specify grouping variable using key = argument.\nallow us analysis group.Looking class(counts) tells top tidy data frame\n(“tbl_df”, “tbl”, “data.frame”), additional properties time series\ndata frame (“tbl_ts”).can take quick look data using ggplot2. see plot \nclear seasonal pattern, missings. However, \nseems issue reporting beginning year; cases drop\nlast week year increase first week next year.DANGER: datasets aren’t clean example.\nneed check duplicates missings . ","code":"\n## define time series object \ncounts <- tsibble(counts, index = epiweek)\n## plot a line graph of cases by week\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()"},{"path":"time-series.html","id":"duplicates","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Duplicates","text":"tsibble allow duplicate observations. row need \nunique, unique within group (key variable).\npackage functions help identify duplicates. include\nare_duplicated() gives TRUE/FALSE vector whether row \nduplicate, duplicates() gives data frame duplicated rows.See page De-duplication\ndetails select rows want.","code":"\n## get a vector of TRUE/FALSE whether rows are duplicates\nare_duplicated(counts, index = epiweek) \n\n## get a data frame of any duplicated rows \nduplicates(counts, index = epiweek) "},{"path":"time-series.html","id":"missings","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Missings","text":"saw brief inspection missings, also\nsaw seems problem reporting delay around new year.\nOne way address problem set values missing \nimpute values. simplest form time series imputation draw\nstraight line last non-missing next non-missing value.\nuse imputeTS package function na_interpolation().See Missing data page options imputation.Another alternative calculate moving average, try smooth\napparent reporting issues (see next section, page Moving averages).","code":"\n## create a variable with missings instead of weeks with reporting issues\ncounts <- counts %>% \n     mutate(case_miss = if_else(\n          ## if epiweek contains 52, 53, 1 or 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## then set to missing \n          NA_real_, \n          ## otherwise keep the value in case\n          case\n     ))\n\n## alternatively interpolate missings by linear trend \n## between two nearest adjacent points\ncounts <- counts %>% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## to check what values have been imputed compared to the original\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series.html","id":"descriptive-analysis","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.4 Descriptive analysis","text":"","code":""},{"path":"time-series.html","id":"timeseries_moving","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Moving averages","text":"data noisy (counts jumping ) can helpful \ncalculate moving average. example , week calculate \naverage number cases four previous weeks. smooths data, \nmake interpretable. case really add much, \nstick interpolated data analysis.\nSee Moving averages page detail.","code":"\n## create a moving average variable (deals with missings)\ncounts <- counts %>% \n     ## create the ma_4w variable \n     ## slide over each row of the case variable\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## for each row calculate the name\n                               ~ mean(.x, na.rm = TRUE),\n                               ## use the four previous weeks\n                               .before = 4))\n\n## make a quick visualisation of the difference \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")"},{"path":"time-series.html","id":"periodicity","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Periodicity","text":"define custom function create periodogram. See [Writing functions] page information write functions R.First, function defined. arguments include dataset column counts, start_week = first week dataset, number indicate many periods per year (e.g. 52, 12), lastly output style (see details code ).NOTE: possible use weeks add sin cosine terms, however use function generate terms (see regression section ) ","code":"\n## Function arguments\n#####################\n## x is a dataset\n## counts is variable with count data or rates within x \n## start_week is the first week in your dataset\n## period is how many units in a year \n## output is whether you want return spectral periodogram or the peak weeks\n  ## \"periodogram\" or \"weeks\"\n\n# Define function\nperiodogram <- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## make sure is not a tsibble, filter to project and only keep columns of interest\n    prepare_data <- dplyr::as_tibble(x)\n    \n    # prepare_data <- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data <- dplyr::select(prepare_data, {{counts}})\n    \n    ## create an intermediate \"zoo\" time series to be able to use with spec.pgram\n    zoo_cases <- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## get a spectral periodogram not using fast fourier transform \n    periodo <- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## return the peak weeks \n    periodo_weeks <- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## get spectral periodogram for extracting weeks with the highest frequencies \n## (checking of seasonality) \nperiodo <- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## pull spectrum and frequence in to a dataframe for plotting\nperiodo <- data.frame(periodo$freq, periodo$spec)\n\n## plot a periodogram showing the most frequently occuring periodicity \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n## get a vector weeks in ascending order \npeak_weeks <- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")"},{"path":"time-series.html","id":"decomposition","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Decomposition","text":"Classical decomposition used break time series several parts, \ntaken together make pattern see.\ndifferent parts :trend-cycle (long-term direction data)seasonality (repeating patterns)random (left removing trend season)","code":"\n## decompose the counts dataset \ncounts %>% \n  # using an additive classical decomposition model\n  model(classical_decomposition(case_int, type = \"additive\")) %>% \n  ## extract the important information from the model\n  components() %>% \n  ## generate a plot \n  autoplot()"},{"path":"time-series.html","id":"autocorrelation","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Autocorrelation","text":"Autocorrelation tells relation counts week\nweeks (called lags).Using ACF() function, can produce plot shows us number lines\nrelation different lags. lag 0 (x = 0), line \nalways 1 shows relation observation (shown ).\nfirst line shown (x = 1) shows relation observation\nobservation (lag 1), second shows relation \nobservation observation last (lag 2) lag \n52 shows relation observation observation 1\nyear (52 weeks ).Using PACF() function (partial autocorrelation) shows type relation\nadjusted weeks . less informative determining\nperiodicity.can formally test null hypothesis independence time series (.e. \nautocorrelated) using Ljung-Box test (stats package).\nsignificant p-value suggests autocorrelation data.","code":"\n## using the counts dataset\ncounts %>% \n  ## calculate autocorrelation using a full years worth of lags\n  ACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## using the counts data set \ncounts %>% \n  ## calculate the partial autocorrelation using a full years worth of lags\n  PACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## test for independance \nBox.test(counts$case_int, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  counts$case_int\n## X-squared = 462.65, df = 1, p-value < 2.2e-16"},{"path":"time-series.html","id":"fitting-regressions","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.5 Fitting regressions","text":"possible fit large number different regressions time series,\nhowever, demonstrate fit negative binomial regression - \noften appropriate counts data infectious diseases.","code":""},{"path":"time-series.html","id":"fourier-terms","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Fourier terms","text":"Fourier terms equivalent sin cosin curves. difference \nfit based finding appropriate combination curves explain\ndata.fitting one fourier term, equivalent fitting sin\ncosin frequently occurring lag seen periodogram (\ncase 52 weeks). use fourier() function forecast package.code assign using $, fourier() returns two columns (one\nsin one cosin) added dataset list, called\n“fourier” - list can used normal variable regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  fourier(K = 1)"},{"path":"time-series.html","id":"negative-binomial","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Negative binomial","text":"possible fit regressions using base stats MASS\nfunctions (e.g. lm(), glm() glm.nb()). However using \ntrending package, allows calculating appropriate confidence\nprediction intervals (otherwise available).\nsyntax , specify outcome variable tilde (~)\nadd various exposure variables interest separated plus (+).difference first define model fit() \ndata. useful allows comparing multiple different models\nsyntax.TIP: wanted use rates, rather \ncounts include population variable logarithmic offset term, adding\noffset(log(population). need set population 1, \nusing predict() order produce rate. TIP: fitting complex models \nARIMA prophet, see fable package.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier)\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series.html","id":"residuals","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Residuals","text":"see well model fits observed data need look residuals.\nresiduals difference observed counts counts\nestimated model. calculate simply using case_int - estimate,\nresiduals() function extracts directly regression us.see , explaining variation\nmodel. might fit fourier terms,\naddress amplitude. However example leave .\nplots show model worse peaks troughs (counts \nhighest lowest) might likely underestimate\nobserved counts.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = residuals(fitted_model$fitted_model, type = \"response\"))\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  observed$resid\n## X-squared = 346.64, df = 1, p-value < 2.2e-16"},{"path":"time-series.html","id":"relation-of-two-time-series","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.6 Relation of two time series","text":"look using weather data (specifically temperature) explain\ncampylobacter case counts.","code":""},{"path":"time-series.html","id":"merging-datasets","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Merging datasets","text":"can join datasets using week variable. merging see \nhandbook section joining.","code":"\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts <- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")"},{"path":"time-series.html","id":"descriptive-analysis-1","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Descriptive analysis","text":"First plot data see obvious relation.\nplot shows clear relation seasonality two\nvariables, temperature might peak weeks case number.\npivoting data, see handbook section pivoting data.","code":"\ncounts %>% \n  ## keep the variables we are interested \n  select(epiweek, case_int, t2m) %>% \n  ## change your data in to long format\n  pivot_longer(\n    ## use epiweek as your key\n    !epiweek,\n    ## move column names to the new \"measure\" column\n    names_to = \"measure\", \n    ## move cell values to the new \"values\" column\n    values_to = \"value\") %>% \n  ## create a plot with the dataset above\n  ## plot epiweek on the x axis and values (counts/celsius) on the y \n  ggplot(aes(x = epiweek, y = value)) + \n    ## create a separate plot for temperate and case counts \n    ## let them set their own y-axes\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## plot both as a line\n    geom_line()"},{"path":"time-series.html","id":"lags-and-cross-correlation","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Lags and cross-correlation","text":"formally test weeks highly related cases temperature.\ncan use cross-correlation function (CCF()) feasts package.\nalso visualise (rather using arrange) using autoplot() function.see lag 4 weeks highly correlated,\nmake lagged temperature variable include regression.DANGER: Note first four weeks data\nlagged temperature variable missing (NA) - four\nweeks prior get data . order use dataset trending\npredict() function, need use simulate_pi = FALSE argument within\npredict() . want use simulate option, \ndrop missings store new data set adding drop_na(t2m_lag4)\ncode chunk .","code":"\ncounts %>% \n  ## calculate cross-correlation between interpolated counts and temperature\n  CCF(case_int, t2m,\n      ## set the maximum lag to be 52 weeks\n      lag_max = 52, \n      ## return the correlation coefficient \n      type = \"correlation\") %>% \n  ## arange in decending order of the correlation coefficient \n  ## show the most associated lags\n  arrange(-ccf) %>% \n  ## only show the top ten \n  slice_head(n = 10)## # A tsibble: 10 x 2 [1W]\n##      lag   ccf\n##    <lag> <dbl>\n##  1    4W 0.749\n##  2    5W 0.745\n##  3    3W 0.735\n##  4    6W 0.729\n##  5    2W 0.727\n##  6    7W 0.704\n##  7    1W 0.695\n##  8    8W 0.671\n##  9    0W 0.649\n## 10  -47W 0.638\ncounts <- counts %>% \n  ## create a new variable for temperature lagged by four weeks\n  mutate(t2m_lag4 = lag(t2m, n = 4))"},{"path":"time-series.html","id":"negative-binomial-with-two-variables","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Negative binomial with two variables","text":"fit negative binomial regression done previously. time add \ntemperature variable lagged four weeks.CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. investigate individual terms, can pull original negative binomial\nregression trending format using get_model() pass \nbroom package tidy() function retrieve exponentiated estimates associated\nconfidence intervals.shows us lagged temperature, controlling trend seasonality,\nsimilar case counts (estimate ~ 1) significantly associated.\nsuggests might good variable use predicting future case\nnumbers (climate forecasts readily available).quick visual inspection model shows might better job \nestimating observed case counts.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier + \n    ## use the temperature lagged by four weeks \n    t2m_lag4\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)## # A tibble: 5 x 7\n##   term           estimate  std.error statistic  p.value   conf.low  conf.high\n##   <chr>             <dbl>      <dbl>     <dbl>    <dbl>      <dbl>      <dbl>\n## 1 (Intercept)   5.83      0.108          53.8  0         5.61       6.04     \n## 2 epiweek       0.0000846 0.00000774     10.9  8.13e-28  0.0000695  0.0000998\n## 3 fourierS1-52 -0.285     0.0214        -13.3  1.84e-40 -0.327     -0.243    \n## 4 fourierC1-52 -0.195     0.0200         -9.78 1.35e-22 -0.234     -0.157    \n## 5 t2m_lag4      0.00667   0.00269         2.48 1.30e- 2  0.00139    0.0119\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series.html","id":"residuals-1","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Residuals","text":"investigate residuals see well model fits observed data.\nresults interpretation similar previous regression,\nmay feasible stick simpler model without temperature.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = case_int - estimate)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")## Warning: Removed 4 row(s) containing missing values (geom_path).## Warning: Removed 4 rows containing missing values (geom_point).\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") ## Warning: Removed 4 rows containing non-finite values (stat_bin).\n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")## Warning: Removed 4 rows containing missing values (geom_point).\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  observed$resid\n## X-squared = 339.52, df = 1, p-value < 2.2e-16"},{"path":"time-series.html","id":"outbreak-detection","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.7 Outbreak detection","text":"demonstrate two (similar) methods detecting outbreaks .\nfirst builds sections .\nuse trending package fit regressions previous years, \npredict expect see following year. observed counts \nexpect, suggest outbreak.\nsecond method based similar principles uses surveillance package,\nnumber different algorithms aberration detection.CAUTION: Normally, interested current year (know counts present week). example pretending week 39 2011.","code":""},{"path":"time-series.html","id":"trending-package","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"trending package","text":"method define baseline (usually 5 years data).\nfit regression baseline data, use predict estimates\nnext year.","code":""},{"path":"time-series.html","id":"cut-off-date","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Cut-off date","text":"easier define dates one place use throughout \nrest code.define start date (observations started) cut-date\n(end baseline period - period want predict starts).\n~also define many weeks year interest (one going \npredicting)~.\nalso define many weeks baseline cut-end date\ninterested predicting .NOTE: example pretend currently end September 2011 (“2011 W39”).","code":"\n## define start date (when observations began)\nstart_date <- min(counts$epiweek)\n\n## define a cut-off week (end of baseline, start of prediction period)\ncut_off <- yearweek(\"2010-12-31\")\n\n## define the last date interested in (i.e. end of prediction)\nend_date <- yearweek(\"2011-12-31\")\n\n## find how many weeks in period (year) of interest\nnum_weeks <- as.numeric(end_date - cut_off)"},{"path":"time-series.html","id":"add-rows-1","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Add rows","text":"able forecast tidyverse format, need right number\nrows dataset, .e. one row week end_datedefined .\ncode allows add rows grouping variable - example\nmultiple countries one dataset, group country \nadd rows appropriately .\ngroup_by_key() function tsibble allows us grouping\npass grouped data dplyr functions, group_modify() \nadd_row(). specify sequence weeks one maximum week\ncurrently available data end week.","code":"\n## add in missing weeks till end of year \ncounts <- counts %>%\n  ## group by the region\n  group_by_key() %>%\n  ## for each group add rows from the highest epiweek to the end of year\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))"},{"path":"time-series.html","id":"fourier-terms-1","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Fourier terms","text":"need redefine fourier terms - want fit baseline\ndate predict (extrapolate) terms next year.\nneed combine two output lists fourier() function together;\nfirst one baseline data, second one predicts \nyear interest (defining h argument).N.b. bind rows use rbind() (rather tidyverse bind_rows) \nfourier columns list (named individually).","code":"\n## define fourier terms (sincos) \ncounts <- counts %>% \n  mutate(\n    ## combine fourier terms for weeks prior to  and after 2010 cut-off date\n    ## (nb. 2011 fourier terms are predicted)\n    fourier = rbind(\n      ## get fourier terms for previous years\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for 2011 (using baseline data)\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = num_weeks\n        )\n      )\n    )"},{"path":"time-series.html","id":"split-data-and-fit-regression","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Split data and fit regression","text":"now split dataset baseline period prediction\nperiod. done using dplyr group_split() function group_by(),\ncreate list two data frames, one cut-one\n.use purrr package pluck() function pull datasets \nlist (equivalent using square brackets, e.g. dat[[1]]), can fit\nmodel baseline data, use predict() function data\ninterest cut-.See page [Iteration, loops, lists] learn purrr.CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. previously, can visualise model ggplot. highlight alerts \nred dots observed counts 95% prediction interval.\ntime also add vertical line label forecast starts.","code":"\n# split data for fitting and prediction\ndat <- counts %>% \n  group_by(epiweek <= cut_off) %>%\n  group_split()\n\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier\n)\n\n# define which data to use for fitting and which for predicting\nfitting_data <- pluck(dat, 2)\npred_data <- pluck(dat, 1) %>% \n  select(case_int, epiweek, fourier)\n\n# fit model \nfitted_model <- trending::fit(model, fitting_data)\n\n# get confint and estimates for fitted data\nobserved <- fitted_model %>% \n  predict(simulate_pi = FALSE)\n\n# forecast with data want to predict with \nforecasts <- fitted_model %>% \n  predict(pred_data, simulate_pi = FALSE)\n\n## combine baseline and predicted datasets\nobserved <- bind_rows(observed, forecasts)\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## plot in points for the observed counts above expected\n  geom_point(\n    data = filter(observed, case_int > upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Removed 13 row(s) containing missing values (geom_path)."},{"path":"time-series.html","id":"prediction-validation","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Prediction validation","text":"Beyond inspecting residuals, important investigate good model \npredicting cases future. gives idea reliable \nthreshold alerts .traditional way validating see well can predict latest\nyear present one (don’t yet know counts “current year”).\nexample data set use data 2002 2009 predict 2010,\nsee accurate predictions . refit model include\n2010 data use predict 2011 counts.can seen figure Hyndman et al “Forecasting principles\npractice”.figure reproduced permission authorsThe downside using data available , \nfinal model using prediction.alternative use method called cross-validation. scenario \nroll data available fit multiple models predict one year ahead.\nuse data model, seen figure \n[Hyndman et al text]((https://otexts.com/fpp3/).\nexample, first model uses 2002 predict 2003, second uses 2002 \n2003 predict 2004, .\nfigure reproduced permission authorsIn use purrr package map() function loop dataset.\nput estimates one data set merge original case counts,\nuse yardstick package compute measures accuracy.\ncompute four measures including: Root mean squared error (RMSE), Mean absolute error\n(MAE), Mean absolute scaled error (MASE), Mean absolute percent error (MAPE).CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. ","code":"\n## Cross validation: predicting week(s) ahead based on sliding window\n\n## expand your data by rolling over in 52 week windows (before + after) \n## to predict 52 week ahead\n## (creates longer and longer chains of observations - keeps older data)\n\n## define window want to roll over\nroll_window <- 52\n\n## define weeks ahead want to predict \nweeks_ahead <- 52\n\n## create a data set of repeating, increasingly long data\n## label each data set with a unique id\n## only use cases before year of interest (i.e. 2011)\ncase_roll <- counts %>% \n  filter(epiweek < cut_off) %>% \n  ## only keep the week and case counts variables\n  select(epiweek, case_int) %>% \n    ## drop the last x observations \n    ## depending on how many weeks ahead forecasting \n    ## (otherwise will be an actual forecast to \"unknown\")\n    slice(1:(n() - weeks_ahead)) %>%\n    as_tsibble(index = epiweek) %>% \n    ## roll over each week in x after windows to create grouping ID \n    ## depending on what rolling window specify\n    stretch_tsibble(.init = roll_window, .step = 1) %>% \n  ## drop the first couple - as have no \"before\" cases\n  filter(.id > roll_window)\n\n\n## for each of the unique data sets run the code below\nforecasts <- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## only keep the current fold being fit \n  mini_data <- filter(case_roll, .id == i) %>% \n    as_tibble()\n  \n  ## create an empty data set for forecasting on \n  forecast_data <- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## add the forecast data to the original \n  mini_data <- bind_rows(mini_data, forecast_data)\n  \n  ## define the cut off based on latest non missing count data \n  cv_cut_off <- mini_data %>% \n    ## only keep non-missing rows\n    drop_na(case_int) %>% \n    ## get the latest week\n    summarise(max(epiweek)) %>% \n    ## extract so is not in a dataframe\n    pull()\n  \n  ## make mini_data back in to a tsibble\n  mini_data <- tsibble(mini_data, index = epiweek)\n  \n  ## define fourier terms (sincos) \n  mini_data <- mini_data %>% \n    mutate(\n    ## combine fourier terms for weeks prior to  and after cut-off date\n    fourier = rbind(\n      ## get fourier terms for previous years\n      forecast::fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for following year (using baseline data)\n      fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # split data for fitting and prediction\n  dat <- mini_data %>% \n    group_by(epiweek <= cv_cut_off) %>%\n    group_split()\n\n  ## define the model you want to fit (negative binomial) \n  model <- glm_nb_model(\n    ## set number of cases as outcome of interest\n    case_int ~\n      ## use epiweek to account for the trend\n      epiweek +\n      ## use the furier terms to account for seasonality\n      fourier\n  )\n\n  # define which data to use for fitting and which for predicting\n  fitting_data <- pluck(dat, 2)\n  pred_data <- pluck(dat, 1)\n  \n  # fit model \n  fitted_model <- trending::fit(model, fitting_data)\n  \n  # forecast with data want to predict with \n  forecasts <- fitted_model %>% \n    predict(pred_data, simulate_pi = FALSE) %>% \n    ## only keep the week and the forecast estimate\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## make the list in to a data frame with all the forecasts\nforecasts <- bind_rows(forecasts)\n\n## join the forecasts with the observed\nforecasts <- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## using {yardstick} compute metrics\n  ## RMSE: Root mean squared error\n  ## MAE:  Mean absolute error  \n  ## MASE: Mean absolute scaled error\n  ## MAPE: Mean absolute percent error\nmodel_metrics <- bind_rows(\n  ## in your forcasted dataset compare the observed to the predicted\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %>% \n  ## only keep the metric type and its output\n  select(Metric  = .metric, \n         Measure = .estimate) %>% \n  ## make in to wide format so can bind rows after\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## return model metrics \nmodel_metrics## # A tibble: 1 x 4\n##    rmse   mae  mase  mape\n##   <dbl> <dbl> <dbl> <dbl>\n## 1  252.  199.  1.96  17.3"},{"path":"time-series.html","id":"surveillance-package","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"surveillance package","text":"section use surveillance package create alert thresholds\nbased outbreak detection algorithms. several different methods\navailable package, however focus two options .\ndetails, see papers application\ntheory\nalogirthms used.first option uses improved Farrington method. fits negative\nbinomial glm (including trend) -weights past outbreaks (outliers) \ncreate threshold level.second option use glrnb method. also fits negative binomial glm\nincludes trend fourier terms (favoured ). regression used\ncalculate “control mean” (~fitted values) - uses computed\ngeneralized likelihood ratio statistic assess shift mean\nweek. Note threshold week takes account previous\nweeks sustained shift alarm triggered.\n(Also note alarm algorithm reset)order work surveillance package, first need define \n“surveillance time series” object (using sts() function) fit within \nframework.","code":"\n## define surveillance time series object\n## nb. you can include a denominator with the population object (see ?sts)\ncounts_sts <- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## subset to only keep the year from start_date \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## subset to only keep the week from start_date\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## define the type of data (in this case weekly)\n                  freq = 52)\n\n## define the week range that you want to include (ie. prediction period)\n## nb. the sts object only counts observations without assigning a week or \n## year identifier to them - so we use our data to define the appropriate observations\nweekrange <- cut_off - start_date"},{"path":"time-series.html","id":"farrington-method","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"Farrington method","text":"define parameters Farrington method list.\nrun algorithm using farringtonFlexible() can extract \nthreshold alert using farringtonmethod@upperboundto include \ndataset. also possible extract TRUE/FALSE week triggered\nalert (threshold) using farringtonmethod@alarm.can visualise results ggplot done previously.","code":"\n## define control\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  b = 9, ## how many years backwards for baseline\n  w = 2, ## rolling window size in weeks\n  weightsThreshold = 2.58, ## reweighting past outbreaks (improved noufaily method - original suggests 1)\n  ## pastWeeksNotIncluded = 3, ## use all weeks available (noufaily suggests drop 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normally, however 1 is advised in the improved method (i.e. always keep)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## apply farrington flexible method\nfarringtonmethod <- farringtonFlexible(counts_sts, ctrl)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from farrington \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] <- farringtonmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series.html","id":"glrnb-method","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"GLRNB method","text":"Similarly GLRNB method define parameters list,\nfit algorithm extract upper bounds.CAUTION: method uses “brute force” (similar bootstrapping) calculating thresholds, can take long time!See GLRNB vignette\ndetails.Visualise outputs previously.","code":"\n## define control options\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  mu0 = list(S = 1,    ## number of fourier terms (harmonics) to include\n  trend = TRUE,   ## whether to include trend or not\n  refit = FALSE), ## whether to refit model after each alarm\n  ## cARL = threshold for GLR statistic (arbitrary)\n     ## 3 ~ middle ground for minimising false positives\n     ## 1 fits to the 99%PI of glm.nb - with changes after peaks (threshold lowered for alert)\n   c.ARL = 2,\n   # theta = log(1.5), ## equates to a 50% increase in cases in an outbreak\n   ret = \"cases\"     ## return threshold upperbound as case counts\n  )\n\n## apply the glrnb method\nglrnbmethod <- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from glrnb \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] <- glrnbmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series.html","id":"interrupted-timeseries","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.8 Interrupted timeseries","text":"Interrupted timeseries (also called segmented regression intervention analysis),\noften used assessing impact vaccines incidence disease.\ncan used assessing impact wide range interventions introductions.\nexample changes hospital procedures introduction new disease\nstrain population.\nexample pretend new strain Campylobacter introduced\nGermany end 2008, see affects number cases.\nuse negative binomial regression . regression time \nsplit two parts, one intervention (introduction new strain )\none (pre post-periods). allows us calculate incidence rate ratio comparing \ntwo time periods. Explaining equation might make clearer (just\nignore!).negative binomial regression can defined follows:\\[\\log(Y_t)= β_0 + β_1 \\times t+ β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]:\n\\(Y_t\\)number cases observed time \\(t\\)\\(pop_t\\) population size 100,000s time \\(t\\) (used )\\(t_0\\) last year pre-period (including transition time )\\(δ(x\\) indicator function (0 x≤0 1 x>0)\\((x)^+\\) cut operator (x x>0 0 otherwise)\\(e_t\\) denotes residual\nAdditional terms trend season can added needed.\\(β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+\\) generalised linear\npart post-period zero pre-period.\nmeans \\(β_2\\) \\(β_3\\) estimates effects intervention.need re-calculate fourier terms without forecasting , use\ndata available us (.e. retrospectively). Additionally need calculate\nextra terms needed regression.use terms fit negative binomial regression, produce \ntable percentage change. example shows \nsignificant change.CAUTION: Note use simulate_pi = FALSE\nwithin predict() argument. default behaviour trending\nuse ciTools package estimate prediction interval. \nwork NA counts, also produces granular intervals.\nSee ?trending::predict.trending_model_fit details. previously can visualise outputs regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  as_tsibble(index = epiweek) %>% \n  fourier(K = 1)\n\n## define intervention week \nintervention_week <- yearweek(\"2008-12-31\")\n\n## define variables for regression \ncounts <- counts %>% \n  mutate(\n    ## corresponds to t in the formula\n      ## count of weeks (could probably also just use straight epiweeks var)\n    # linear = row_number(epiweek), \n    ## corresponds to delta(t-t0) in the formula\n      ## pre or post intervention period\n    intervention = as.numeric(epiweek >= intervention_week), \n    ## corresponds to (t-t0)^+ in the formula\n      ## count of weeks post intervention\n      ## (choose the larger number between 0 and whatever comes from calculation)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## add in whether in the pre- or post-period \n    intervention + \n    ## add in the time post intervention \n    time_post\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n\n\n\n## show estimates and percentage change in a table\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %>% \n  ## only keep the intervention value \n  filter(term == \"intervention\") %>% \n  ## change the IRR to percentage change for estimate and CIs \n  mutate(\n    ## for each of the columns of interest - create a new column\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## apply the formula to calculate percentage change\n            .f = function(i) 100 * (i - 1), \n      ## add a suffix to new column names with \"_perc\"\n      .names = \"{.col}_perc\")\n    ) %>% \n  ## only keep (and rename) certain columns \n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)## # A tibble: 1 x 7\n##       IRR `95%CI low` `95%CI high` `Percentage chang~ `95%CI low (perc)` `95%CI high (per~\n##     <dbl>       <dbl>        <dbl>              <dbl>              <dbl>             <dbl>\n## 1 -0.0661      -0.135      0.00305              -107.              -113.             -99.7\n## # ... with 1 more variable: p-value <dbl>\nggplot(observed, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Removed 13 row(s) containing missing values (geom_path)."},{"path":"time-series.html","id":"resources-10","chapter":"23 Chuỗi thời gian và phát hiện ổ dịch","heading":"23.9 Resources","text":"forecasting: principles practice textbookEPIET timeseries analysis case studiesPenn State course\nSurveillance package manuscript","code":""},{"path":"epidemic-models.html","id":"epidemic-models","chapter":"24 Mô hình hóa dịch bệnh","heading":"24 Mô hình hóa dịch bệnh","text":"","code":""},{"path":"epidemic-models.html","id":"overview-2","chapter":"24 Mô hình hóa dịch bệnh","heading":"24.1 Overview","text":"exists growing body tools epidemic modelling lets us conduct\nfairly complex analyses minimal effort. section provide \noverview use tools :estimate effective reproduction number Rt related statistics\ndoubling timeproduce short-term projections future incidenceIt intended overview methodologies statistical methods\nunderlying tools, please refer Resources tab links \npapers covering . Make sure understanding \nmethods using tools; ensure can accurately\ninterpret results.example one outputs ’ll producing section.","code":""},{"path":"epidemic-models.html","id":"preparation-10","chapter":"24 Mô hình hóa dịch bệnh","heading":"24.2 Preparation","text":"use two different methods packages Rt estimation,\nnamely EpiNow EpiEstim, well projections package \nforecasting case incidence.code chunk shows loading packages required analyses.\nhandbook emphasize p_load() pacman, installs package necessary loads use.\ncan also load installed packages library() base R. See page [R basics] information R packages.use cleaned case linelist analyses section. want follow along, click download “clean” linelist (.rds file). See [Download handbook data] page download example data used handbook.","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   epicontacts,  # Analysing transmission networks\n   EpiNow2,      # Rt estimation\n   EpiEstim,     # Rt estimation\n   projections,  # Incidence projections\n   incidence2,   # Handling incidence data\n   epitrix,      # Useful epi functions\n   distcrete     # Discrete delay distributions\n)\n# import the cleaned linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"epidemic-models.html","id":"estimating-rt","chapter":"24 Mô hình hóa dịch bệnh","heading":"24.3 Estimating Rt","text":"","code":""},{"path":"epidemic-models.html","id":"epinow2-vs.-epiestim","chapter":"24 Mô hình hóa dịch bệnh","heading":"EpiNow2 vs. EpiEstim","text":"reproduction number R measure transmissibility disease \ndefined expected number secondary cases per infected case. \nfully susceptible population, value represents basic reproduction\nnumber R0. However, number susceptible individuals \npopulation changes course outbreak pandemic, various\nresponse measures implemented, commonly used measure \ntransmissibility effective reproduction number Rt; \ndefined expected number secondary cases per infected case given\ntime t.EpiNow2 package provides sophisticated framework estimating\nRt. two key advantages commonly used package,\nEpiEstim:accounts delays reporting can therefore estimate Rt\neven recent data incomplete.estimates Rt dates infection rather dates \nonset reporting, means effect intervention \nimmediately reflected change Rt, rather \ndelay.However, also two key disadvantages:requires knowledge generation time distribution (.e. distribution\ndelays infection primary secondary cases), incubation\nperiod distribution (.e. distribution delays infection symptom\nonset) delay distribution relevant data (e.g. \ndates reporting, require distribution delays symptom\nonset reporting). allow accurate estimation \nRt, EpiEstim requires serial interval distribution\n(.e. distribution delays symptom onset primary \nsecondary case), may distribution available .EpiNow2 significantly slower EpiEstim, anecdotally factor\n100-1000! example, estimating Rt sample outbreak\nconsidered section takes four hours (run large\nnumber iterations ensure high accuracy probably reduced \nnecessary, however points stands algorithm slow \ngeneral). may unfeasible regularly updating \nRt estimates.package choose use therefore depend data, time \ncomputational resources available .","code":""},{"path":"epidemic-models.html","id":"epinow2","chapter":"24 Mô hình hóa dịch bệnh","heading":"EpiNow2","text":"","code":""},{"path":"epidemic-models.html","id":"estimating-delay-distributions","chapter":"24 Mô hình hóa dịch bệnh","heading":"Estimating delay distributions","text":"delay distributions required run EpiNow2 depend data \n. Essentially, need able describe delay date \ninfection date event want use estimate Rt. \nusing dates onset, simply incubation period\ndistribution. using dates reporting, require \ndelay infection reporting. distribution unlikely known\ndirectly, EpiNow2 lets chain multiple delay distributions together; \ncase, delay infection symptom onset (e.g. incubation\nperiod, likely known) symptom onset reporting (\ncan often estimate data).dates onset cases example linelist, \nrequire incubation period distribution link data (e.g. dates \nsymptom onset) date infection. can either estimate distribution\ndata use values literature.literature estimate incubation period Ebola (taken\npaper) \nmean 9.1, standard deviation 7.3 maximum value 30 \nspecified follows:Note EpiNow2 requires delay distributions provided log\nscale, hence log call around value (except max parameter ,\nconfusingly, provided natural scale). mean_sd sd_sd\ndefine standard deviation mean standard deviation estimates. \nknown case, choose fairly arbitrary value 0.1.analysis, instead estimate incubation period distribution\nlinelist using function bootstrapped_dist_fit, \nfit lognormal distribution observed delays infection onset\nlinelist.distribution require generation time. data \ninfection times transmission links, can estimate \ndistribution linelist calculating delay infection times\ninfector-infectee pairs. , use handy get_pairwise function\npackage epicontacts, allows us calculate pairwise\ndifferences linelist properties transmission pairs. first create \nepicontacts object (see [Transmission chains] page \ndetails):fit difference infection times transmission pairs,\ncalculated using get_pairwise, gamma distribution:","code":"\nincubation_period_lit <- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n## estimate incubation period\nincubation_period <- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma generation time\ngeneration_time <- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)"},{"path":"epidemic-models.html","id":"running-epinow2","chapter":"24 Mô hình hóa dịch bệnh","heading":"Running EpiNow2","text":"Now just need calculate daily incidence linelist, can \neasily dplyr functions group_by() n(). Note\nEpiNow2 requires column names date confirm.can estimate Rt using epinow function. notes \ninputs:can provide number ‘chained’ delay distributions delays\nargument; simply insert alongside incubation_period object\nwithin delay_opts function.return_output ensures output returned within R just saved \nfile.verbose specifies want readout progress.horizon indicates many days want project future incidence .pass additional options stan argument specify long\nwant run inference . Increasing samples chains give\naccurate estimate better characterises uncertainty, however\ntake longer run.","code":"\n## get incidence from onset dates\ncases <- linelist %>%\n  group_by(date = date_onset) %>%\n  summarise(confirm = n())\n## run epinow\nepinow_res <- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)"},{"path":"epidemic-models.html","id":"analysing-outputs","chapter":"24 Mô hình hóa dịch bệnh","heading":"Analysing outputs","text":"code finished running, can plot summary easily follows. Scroll image see full extent.can also look various summary statistics:analyses custom plotting, can access summarised daily\nestimates via $estimates$summarised. convert default\ndata.table tibble ease use dplyr.example, let’s make plot doubling time Rt. \nlook first months outbreak Rt well\none, avoid plotting extremely high doublings times.use formula log(2)/growth_rate calculate doubling time \nestimated growth rate.","code":"\n## plot summary figure\nplot(epinow_res)\n## summary table\nepinow_res$summary##                                  measure                  estimate  numeric_estimate\n## 1: New confirmed cases by infection date                4 (2 -- 6) <data.table[1x9]>\n## 2:        Expected change in daily cases                    Unsure              0.56\n## 3:            Effective reproduction no.        0.88 (0.73 -- 1.1) <data.table[1x9]>\n## 4:                        Rate of growth -0.012 (-0.028 -- 0.0052) <data.table[1x9]>\n## 5:          Doubling/halving time (days)          -60 (130 -- -25) <data.table[1x9]>\n## extract summary and convert to tibble\nestimates <- as_tibble(epinow_res$estimates$summarised)\nestimates\n## make wide df for median plotting\ndf_wide <- estimates %>%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date < as.Date(\"2014-09-01\")\n  ) %>%\n  ## convert growth rates to doubling times\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## rename variable to reflect transformation\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## make long df for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credibel\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-models.html","id":"epiestim","chapter":"24 Mô hình hóa dịch bệnh","heading":"EpiEstim","text":"run EpiEstim, need provide data daily incidence specify \nserial interval (.e. distribution delays symptom onset \nprimary secondary cases).Incidence data can provided EpiEstim vector, data frame, incidence\nobject original incidence package. can even distinguish imports\nlocally acquired infections; see documentation ?estimate_R \ndetails.create input using incidence2. See page [Epidemic curves] examples incidence2 package. Since updates incidence2 package don’t completely align estimateR()’s expected input, minor additional steps needed. incidence object consists tibble dates respective case counts. use complete() tidyr ensure dates included (even cases), rename() columns align expected estimate_R() later step.package provides several options specifying serial interval, \ndetails provided documentation ?estimate_R. \ncover two .","code":"\n## get incidence from onset date\ncases <- incidence2::incidence(linelist, date_index = date_onset) %>% # get case counts by day\n  tidyr::complete(date_index = seq.Date(                              # ensure all dates are represented\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %>%                                       # convert NA counts to 0\n  rename(I = count,                                                   # rename to names expected by estimateR\n         dates = date_index)## 256 missing observations were removed."},{"path":"epidemic-models.html","id":"using-serial-interval-estimates-from-the-literature","chapter":"24 Mô hình hóa dịch bệnh","heading":"Using serial interval estimates from the literature","text":"Using option method = \"parametric_si\", can manually specify mean \nstandard deviation serial interval config object created using \nfunction make_config. use mean standard deviation 12.0 5.2, respectively, defined \npaper:can estimate Rt estimate_R function:plot summary outputs:","code":"\n## make config\nconfig_lit <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\nepiestim_res_lit <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_lit\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\nplot(epiestim_res_lit)"},{"path":"epidemic-models.html","id":"using-serial-interval-estimates-from-the-data","chapter":"24 Mô hình hóa dịch bệnh","heading":"Using serial interval estimates from the data","text":"data dates symptom onset transmission links, can\nalso estimate serial interval linelist calculating delay\nonset dates infector-infectee pairs. EpiNow2\nsection, use get_pairwise function epicontacts\npackage, allows us calculate pairwise differences linelist\nproperties transmission pairs. first create epicontacts object\n(see [Transmission chains] page details):fit difference onset dates transmission pairs, calculated\nusing get_pairwise, gamma distribution. use handy fit_disc_gamma\nepitrix package fitting procedure, require \ndiscretised distribution.pass information config object, run EpiEstim\nplot results:","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n## make config\nconfig_emp <- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## run epiestim\nepiestim_res_emp <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_emp\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\n## plot outputs\nplot(epiestim_res_emp)"},{"path":"epidemic-models.html","id":"specifying-estimation-time-windows","chapter":"24 Mô hình hóa dịch bệnh","heading":"Specifying estimation time windows","text":"default options provide weekly sliding estimate might act \nwarning estimating Rt early outbreak \nprecise estimate. can change setting later start date \nestimation shown . Unfortunately, EpiEstim provides \nclunky way specifying estimations times, provide \nvector integers referring start end dates time\nwindow.Now re-run EpiEstim can see estimates start June:","code":"\n## define a vector of dates starting on June 1st\nstart_dates <- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %>%\n  ## subtract the starting date to convert to numeric\n  `-`(min(cases$dates)) %>%\n  ## convert to integer\n  as.integer()\n\n## add six days for a one week sliding window\nend_dates <- start_dates + 6\n  \n## make config\nconfig_partial <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n## run epiestim\nepiestim_res_partial <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## plot outputs\nplot(epiestim_res_partial)"},{"path":"epidemic-models.html","id":"analysing-outputs-1","chapter":"24 Mô hình hóa dịch bệnh","heading":"Analysing outputs","text":"main outputs can accessed via $R. example, create plot \nRt measure “transmission potential” given product \nRt number cases reported day; represents \nexpected number cases next generation infection.","code":"\n## make wide dataframe for median\ndf_wide <- epiestim_res_lit$R %>%\n  rename_all(clean_labels) %>%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %>%\n  mutate(\n    ## extract the median date from t_start and t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %>%\n  ## merge in daily incidence data\n  left_join(cases, \"dates\") %>%\n  ## calculate risk across all r estimates\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %>%\n  ## seperate r estimates and risk estimates\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %>%\n  ## assign factor levels\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make long dataframe from quantiles\ndf_long <- df_wide %>%\n  select(-variable, -median) %>%\n  ## seperate r/risk estimates and quantile levels\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %>%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-models.html","id":"projecting-incidence","chapter":"24 Mô hình hóa dịch bệnh","heading":"24.4 Projecting incidence","text":"","code":""},{"path":"epidemic-models.html","id":"epinow2-1","chapter":"24 Mô hình hóa dịch bệnh","heading":"EpiNow2","text":"Besides estimating Rt, EpiNow2 also supports forecasting \nRt projections case numbers integration \nEpiSoon package hood. need specify horizon\nargument epinow function call, indicating many days want \nproject future; see EpiNow2 section “Estimating\nRt” details get EpiNow2 running. \nsection, just plot outputs analysis, stored \nepinow_res object.","code":"\n## define minimum date for plot\nmin_date <- as.Date(\"2015-03-01\")\n\n## extract summarised estimates\nestimates <-  as_tibble(epinow_res$estimates$summarised)\n\n## extract raw data on case incidence\nobservations <- as_tibble(epinow_res$estimates$observations) %>%\n  filter(date > min_date)\n\n## extract forecasted estimates of case numbers\ndf_wide <- estimates %>%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date > min_date\n  )\n\n## convert to even longer format for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14)"},{"path":"epidemic-models.html","id":"projections","chapter":"24 Mô hình hóa dịch bệnh","heading":"projections","text":"projections package developed RECON makes easy make short\nterm incidence forecasts, requiring knowledge effective reproduction\nnumber Rt serial interval. cover use\nserial interval estimates literature use estimates\nlinelist.","code":""},{"path":"epidemic-models.html","id":"using-serial-interval-estimates-from-the-literature-1","chapter":"24 Mô hình hóa dịch bệnh","heading":"Using serial interval estimates from the literature","text":"projections requires discretised serial interval distribution class\ndistcrete package distcrete. use gamma distribution\nmean 12.0 standard deviation 5.2 defined \npaper. \nconvert values shape scale parameters required gamma\ndistribution, use function gamma_mucv2shapescale \nepitrix package.quick check make sure serial interval looks correct. \naccess density gamma distribution just defined $d, \nequivalent calling dgamma:","code":"\n## get shape and scale parameters from the mean mu and the coefficient of\n## variation (e.g. the ratio of the standard deviation to the mean)\nshapescale <- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## make distcrete object\nserial_interval_lit <- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n## check to make sure the serial interval looks correct\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)"},{"path":"epidemic-models.html","id":"using-serial-interval-estimates-from-the-data-1","chapter":"24 Mô hình hóa dịch bệnh","heading":"Using serial interval estimates from the data","text":"data dates symptom onset transmission links, can\nalso estimate serial interval linelist calculating delay\nonset dates infector-infectee pairs. EpiNow2\nsection, use get_pairwise function epicontacts\npackage, allows us calculate pairwise differences linelist\nproperties transmission pairs. first create epicontacts object\n(see [Transmission chains] page details):fit difference onset dates transmission pairs, calculated\nusing get_pairwise, gamma distribution. use handy fit_disc_gamma\nepitrix package fitting procedure, require \ndiscretised distribution.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspect estimate\nserial_interval[c(\"mu\", \"sd\")]## $mu\n## [1] 11.51242\n## \n## $sd\n## [1] 7.700005"},{"path":"epidemic-models.html","id":"projecting-incidence-1","chapter":"24 Mô hình hóa dịch bệnh","heading":"Projecting incidence","text":"project future incidence, still need provide historical incidence \nform incidence object, well sample plausible\nRt values. generate values using Rt\nestimates generated EpiEstim previous section (“Estimating\nRt”) stored epiestim_res_emp object. code ,\nextract mean standard deviation estimates Rt \nlast time window outbreak (using tail function access last\nelement vector), simulate 1000 values gamma distribution using\nrgamma. can also provide vector Rt values \nwant use forward projections.use project() function make actual forecast. specify \nmany days want project via n_days arguments, specify \nnumber simulations using n_sim argument.can handily plot incidence projections using plot() \nadd_projections() functions. can easily subset incidence object \nshow recent cases using square bracket operator.can also easily extract raw estimates daily case numbers \nconverting output dataframe.","code":"\n## create incidence object from dates of onset\ninc <- incidence::incidence(linelist$date_onset)## 256 missing observations were removed.\n## extract plausible r values from most recent estimate\nmean_r <- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r <- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale <- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r <- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## check distribution\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n## make projection\nproj <- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n## plot incidence and projections\nplot(inc[inc$dates > as.Date(\"2015-03-01\")]) %>%\n  add_projections(proj)\n## convert to data frame for raw data\nproj_df <- as.data.frame(proj)\nproj_df"},{"path":"epidemic-models.html","id":"resources-11","chapter":"24 Mô hình hóa dịch bệnh","heading":"24.5 Resources","text":"paper describing\nmethodology implemented EpiEstim.paper describing\nmethodology implemented EpiNow2.paper describing\nvarious methodological practical considerations estimating Rt.","code":""},{"path":"contact-tracing.html","id":"contact-tracing","chapter":"25 Truy vết tiếp xúc","heading":"25 Truy vết tiếp xúc","text":"page demonstrates descriptive analysis contact tracing data, addessing key considerations approaches unique kinds data.page references many core R data management visualisation competencies covered pages (e.g. data cleaning, pivoting, tables, time-series analyses), highlight examples specific contact tracing useful operational decision making. example, includes visualizing contact tracing follow-data time across geographic areas, producing clean Key Performance Indicator (KPI) tables contact tracing supervisors.demonstration purposes use sample contact tracing data Go.Data platform. principles covered apply contact tracing data platforms - may just need undergo different data pre-processing steps depending structure data.can read Go.Data project Github Documentation site Community Practice.","code":""},{"path":"contact-tracing.html","id":"preparation-11","chapter":"25 Truy vết tiếp xúc","heading":"25.1 Preparation","text":"","code":""},{"path":"contact-tracing.html","id":"load-packages-12","chapter":"25 Truy vết tiếp xúc","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,          # importing data  \n  here,         # relative file pathways  \n  janitor,      # data cleaning and tables\n  lubridate,    # working with dates\n  epikit,       # age_categories() function\n  apyramid,     # age pyramids\n  tidyverse,    # data manipulation and visualization\n  RColorBrewer, # color palettes\n  formattable,  # fancy tables\n  kableExtra    # table formatting\n)"},{"path":"contact-tracing.html","id":"import-data-10","chapter":"25 Truy vết tiếp xúc","heading":"Import data","text":"import sample datasets contacts, “follow-”. data retrieved un-nested Go.Data API stored “.rds” files.can download example data handbook [Download handbook data] page.want download example contact tracing data specific page, use three download links :\nClick download\ncase investigation data (.rds file)\n\nClick download\ncontact registration data (.rds file)\n\nClick download\ncontact follow-data (.rds file)\noriginal form downloadable files, data reflect data provided Go.Data API (learn APIs ). example purposes , clean data make easier read page. using Go.Data instance, can view complete instructions retrieve data ., datasets imported using import() function rio package. See page [Import export] various ways import data. use () specify file path - provide file path specific computer. use select() select certain columns data, simplify purposes demonstration.","code":""},{"path":"contact-tracing.html","id":"case-data","chapter":"25 Truy vết tiếp xúc","heading":"Case data","text":"data table cases, information .nrow(cases) cases:","code":"\ncases <- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %>% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)"},{"path":"contact-tracing.html","id":"contacts-data","chapter":"25 Truy vết tiếp xúc","heading":"Contacts data","text":"data table contacts information . , provide file path. importing perform preliminary data cleaning steps including:Set age_class factor reverse level order younger ages firstSelect certain column, re-naming one themArtificially assign rows missing admin level 2 “Djembe”, improve clarity example visualisationsHere nrow(contacts) rows contacts dataset:","code":"\ncontacts <- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %>% \n  mutate(age_class = forcats::fct_rev(age_class)) %>% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %>% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))"},{"path":"contact-tracing.html","id":"follow-up-data","chapter":"25 Truy vết tiếp xúc","heading":"Follow-up data","text":"data records “follow-” interactions contacts. contact supposed encounter day 14 days exposure.import perform cleaning steps. select certain columns, also convert character column lowercase values.first 50 rows nrow(followups)-row followups dataset (row follow-interaction, outcome status followup_status column):","code":"\nfollowups <- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %>% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %>% \n  mutate(followup_status = str_to_lower(followup_status))"},{"path":"contact-tracing.html","id":"relationships-data","chapter":"25 Truy vết tiếp xúc","heading":"Relationships data","text":"import data showing relationship cases contacts. select certain column show.first 50 rows relationships dataset, records relationships cases contacts.","code":"\nrelationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)"},{"path":"contact-tracing.html","id":"descriptive-analyses","chapter":"25 Truy vết tiếp xúc","heading":"25.2 Descriptive analyses","text":"can use techniques covered pages handbook conduct descriptive analyses cases, contacts, relationships. examples.","code":""},{"path":"contact-tracing.html","id":"demographics","chapter":"25 Truy vết tiếp xúc","heading":"Demographics","text":"demonstrated page covering [Demographic pyramids][Demographic pyramids Likert-scales], can visualise age gender distribution (use apyramid package).","code":""},{"path":"contact-tracing.html","id":"age-and-gender-of-contacts","chapter":"25 Truy vết tiếp xúc","heading":"Age and Gender of contacts","text":"pyramid compares age distribution contacts, gender. Note contacts missing age included bar top. can change default behavior, consider listing number missing caption.Go.Data data structure, relationships dataset contains ages cases contacts, use dataset create age pyramid showing differences two groups people. relationships data frame mutated transform numberic age columns categories (see [Cleaning data core functions] page). also pivot dataframe longer facilitate easy plotting ggplot2 (see [Pivoting data]).Now can plot transformed dataset age_pyramid() , replacing gender category (contact, case).can also view characteristics occupational breakdown (e.g. form pie chart).","code":"\napyramid::age_pyramid(\n  data = contacts,                                   # use contacts dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"gender\") +                             # gender for halfs of pyramid\n  labs(\n    fill = \"Gender\",                                 # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # title of the plot\n  theme_minimal()                                    # simple background\nrelation_age <- relationships %>% \n  select(source_age, target_age) %>% \n  transmute(                              # transmute is like mutate() but removes all other columns not mentioned\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %>% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # pivot longer\n\n\nrelation_age## # A tibble: 200 x 2\n##    category         age_class\n##    <chr>            <fct>    \n##  1 source_age_class 80+      \n##  2 target_age_class 15-19    \n##  3 source_age_class <NA>     \n##  4 target_age_class 50-54    \n##  5 source_age_class <NA>     \n##  6 target_age_class 20-24    \n##  7 source_age_class 30-34    \n##  8 target_age_class 45-49    \n##  9 source_age_class 40-44    \n## 10 target_age_class 30-34    \n## # ... with 190 more rows\napyramid::age_pyramid(\n  data = relation_age,                               # use modified relationship dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"category\") +                           # by cases and contacts\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # to specify colors AND labels\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts and cases\")+ # title of the plot\n  theme_minimal()                                              # simple background\n# Clean dataset and get counts by occupation\nocc_plot_data <- cases %>% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # make NA missing values a category\n         occupation = forcats::fct_infreq(occupation)) %>%   # order factor levels in order of frequency\n  count(occupation)                                          # get counts by occupation\n  \n# Make pie chart\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Known occupations of COVID-19 cases\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())"},{"path":"contact-tracing.html","id":"contacts-per-case","chapter":"25 Truy vết tiếp xúc","heading":"Contacts per case","text":"number contacts per case can important metric assess quality contact enumeration compliance population toward public health response.Depending data structure, can assessed dataset contains cases contacts. Go.Data datasets, links cases (“sources”) contacts (“targets”) stored relationships dataset.dataset, row contact, source case listed row. contacts relationships multiple cases, exists may need account plotting (explore !).begin counting number rows (contacts) per source case. saved data frame.use geom_histogram() plot data histogram.","code":"\ncontacts_per_case <- relationships %>% \n  count(source_visualid)\n\ncontacts_per_case## # A tibble: 23 x 2\n##    source_visualid     n\n##    <chr>           <int>\n##  1 CASE-2020-0001     13\n##  2 CASE-2020-0002      5\n##  3 CASE-2020-0003      2\n##  4 CASE-2020-0004      4\n##  5 CASE-2020-0005      5\n##  6 CASE-2020-0006      3\n##  7 CASE-2020-0008      3\n##  8 CASE-2020-0009      3\n##  9 CASE-2020-0010      3\n## 10 CASE-2020-0012      3\n## # ... with 13 more rows\nggplot(data = contacts_per_case)+        # begin with count data frame created above\n  geom_histogram(mapping = aes(x = n))+  # print histogram of number of contacts per case\n  scale_y_continuous(expand = c(0,0))+   # remove excess space below 0 on y-axis\n  theme_light()+                         # simplify background\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )"},{"path":"contact-tracing.html","id":"contact-follow-up","chapter":"25 Truy vết tiếp xúc","heading":"25.3 Contact Follow Up","text":"Contact tracing data often contain “follow-” data, record outcomes daily symptom checks persons quarantine. Analysis data can inform response strategy, identify contacts -risk loss--follow--risk developing disease.","code":""},{"path":"contact-tracing.html","id":"data-cleaning","chapter":"25 Truy vết tiếp xúc","heading":"Data cleaning","text":"data can exist variety formats. may exist “wide” format Excel sheet one row per contact, one column per follow-“day”. See [Pivoting data] descriptions “long” “wide” data pivot data wider longer.Go.Data example, data stored followups data frame, “long” format one row per follow-interaction. first 50 rows look like :CAUTION: Beware duplicates dealing followup data; several erroneous followups day given contact. Perhaps seems error reflects reality - e.g. contact tracer submit follow-form early day reach contact, submit second form later reached. depend operational context want handle duplicates - just make sure document approach clearly. Let’s see many instances “duplicate” rows :example data, records applies ones missing ID! can remove . , purposes demonstration go show steps de-duplication one follow-encoutner per person per day. See page [De-duplication] detail. assume recent encounter record correct one. also take opportunity clean followup_number column (“day” follow-range 1 - 14).follow-encounter, follow-status (whether encounter occurred , contact symptoms ). see values can run quick tabyl() (janitor) table() (base R) (see [Descriptive tables]) followup_status see frequency outcomes.dataset, “seen_not_ok” means “seen symptoms”, “seen_ok” means “seen without symptoms”.","code":"\nfollowups %>% \n  count(contact_id, date_of_followup) %>%   # get unique contact_days\n  filter(n > 1)                             # view records where count is more than 1  ## # A tibble: 3 x 3\n##   contact_id date_of_followup     n\n##   <chr>      <date>           <int>\n## 1 <NA>       2020-09-03           2\n## 2 <NA>       2020-09-04           2\n## 3 <NA>       2020-09-05           2\nfollowups_clean <- followups %>%\n  \n  # De-duplicate\n  group_by(contact_id, date_of_followup) %>%        # group rows per contact-day\n  arrange(contact_id, desc(date_of_followup)) %>%   # arrange rows, per contact-day, by date of follow-up (most recent at top)\n  slice_head() %>%                                  # keep only the first row per unique contact id  \n  ungroup() %>% \n  \n  # Other cleaning\n  mutate(followup_number = replace(followup_number, followup_number > 14, NA)) %>% # clean erroneous data\n  drop_na(contact_id)                               # remove rows with missing contact_id\nfollowups_clean %>% \n  tabyl(followup_status)##  followup_status   n    percent\n##           missed  10 0.02325581\n##    not_attempted   5 0.01162791\n##    not_performed 319 0.74186047\n##      seen_not_ok   6 0.01395349\n##          seen_ok  90 0.20930233"},{"path":"contact-tracing.html","id":"plot-over-time","chapter":"25 Truy vết tiếp xúc","heading":"Plot over time","text":"dates data continuous, use histogram plot date_of_followup assigned x-axis. can achieve “stacked” histogram specifying fill = argument within aes(), assign column followup_status. Consequently, can set legend title using fill = argument labs().can see contacts identified waves (presumably corresponding epidemic waves cases), follow-completion seemingly improve course epidemic.CAUTION: preparing many plots (e.g. multiple jurisdictions) want legends appear identically even varying levels data completion data composition. may plots follow-statuses present data, still want categories appear legends. ggplots (like ), can specify drop = FALSE argument scale_fill_discrete(). tables, use tabyl() shows counts factor levels, using count() dplyr add argument .drop = FALSE include counts factor levels.","code":"\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # show all factor levels (followup_status) in the legend, even those not used\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # dynamic subtitle"},{"path":"contact-tracing.html","id":"daily-individual-tracking","chapter":"25 Truy vết tiếp xúc","heading":"Daily individual tracking","text":"outbreak small enough, may want look contact individually see status course follow-. Fortunately, followups dataset already contains column day “number” follow-(1-14). exist data, create calculating difference encounter date date follow-intended begin contact.convenient visualisation mechanism (number cases large) can heat plot, made geom_tile(). See details [heat plot] page.","code":"\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # grey gridlines\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))"},{"path":"contact-tracing.html","id":"analyse-by-group","chapter":"25 Truy vết tiếp xúc","heading":"Analyse by group","text":"Perhaps follow-data viewed daily weekly basis operational decision-making. may want meaningful disaggregations geographic area contact-tracing team. can adjusting columns provided group_by().","code":"\nplot_by_region <- followups_clean %>%                                        # begin with follow-up dataset\n  count(admin_1_name, admin_2_name, followup_status) %>%   # get counts by unique region-status (creates column 'n' with counts)\n  \n  # begin ggplot()\n  ggplot(                                         # begin ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # reorder admin factor levels by the numeric values in column 'n'\n                  y = n,                            # heights of bar from column 'n'\n                  fill = followup_status,           # color stacked bars by their status\n                  label = n))+                      # to pass to geom_label()              \n  geom_col()+                                     # stacked bars, mapping inherited from above \n  geom_text(                                      # add text, mapping inherited from above\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # Simplify background\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # introduce facets \n\nplot_by_region"},{"path":"contact-tracing.html","id":"kpi-tables","chapter":"25 Truy vết tiếp xúc","heading":"25.4 KPI Tables","text":"number different Key Performance Indicators (KPIs) can calculated tracked varying levels disaggregations across different time periods monitor contact tracing performance. calculations basic table format; fairly easy swap different KPIs.numerous sources contact tracing KPIs, one ResolveToSaveLives.org. majority work walking data structure thinking inclusion/exclusion criteria. show examples ; using Go.Data metadata structure:walk sample exercise creating nice table visual show contact follow-across admin areas. end, make fit presentation formattable package (use packages like flextable - see [Tables presentation]).create table like depend structure contact tracing data. Use [Descriptive tables] page learn summarise data using dplyr functions.create table dynamic change data change. make results interesting, set report_date allow us simulate running table certain day (pick 10th June 2020). data filtered date.Now, based data structure, following:Begin followups data summarise contain, unique contact:date latest record (matter status encounter)date latest encounter contact “seen”encounter status final “seen” encounter (e.g. symptoms, without symptoms)Join data contacts data, contains information overall contact status, date last exposure case, etc. Also calculate metrics interest contact days since last exposureWe group enhanced contact data geographic region (admin_2_name) calculate summary statistics per regionFinally, format table nicely presentationFirst summarise follow-data get information interest:data look:Now add information contacts dataset, calculate additional columns.data look. Note contacts column right, new calculated column far right.Next summarise contacts data region, achieve concise data frame summary statistic columns.now apply styling formattable knitr packages, including footnote shows “” date.","code":"\n# Set \"Report date\" to simulate running the report with data \"as of\" this date\nreport_date <- as.Date(\"2020-06-10\")\n\n# Create follow-up data to reflect the report date.\ntable_data <- followups_clean %>% \n  filter(date_of_followup <= report_date)\nfollowup_info <- table_data %>% \n  group_by(contact_id) %>% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %>% \n  ungroup()\ncontacts_info <- followup_info %>% \n  right_join(contacts, by = \"contact_id\") %>% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\ncontacts_table <- contacts_info %>% \n  \n  group_by(`Admin 2` = admin_2_name) %>%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure < 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure >= 8 & days_since_exposure < 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen >= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %>% \n    \n  arrange(desc(`Registered contacts`))\ncontacts_table %>%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %>%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %>%\n  kable_styling(\"hover\", full_width = FALSE) %>%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %>% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))"},{"path":"contact-tracing.html","id":"transmission-matrices","chapter":"25 Truy vết tiếp xúc","heading":"25.5 Transmission Matrices","text":"discussed [Heat plots] page, can create matrix “infected ” using geom_tile().new contacts created, Go.Data stores relationship information relationships API endpoint; can see first 50 rows dataset . means can create heat plot relatively steps given contact already joined ’s source case.done age pyramid comparing cases contacts, can select variables need create columns categorical age groupings sources (cases) targets (contacts).described previously, create cross-tabulation;convert long format proportions;create heat-map age.","code":"\nheatmap_ages <- relationships %>% \n  select(source_age, target_age) %>% \n  mutate(                              # transmute is like mutate() but removes all other columns\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \ncross_tab <- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab##             target_cases\n## source_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64\n##        0-4     0   0     0     0     0     0     0     0     0     1     0     1     0\n##        5-9     0   0     1     0     0     0     0     1     0     0     0     1     0\n##        10-14   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        15-19   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        20-24   1   1     0     1     2     0     2     1     0     0     0     1     0\n##        25-29   1   2     0     0     0     0     0     0     0     0     0     0     0\n##        30-34   0   0     0     0     0     0     0     0     1     1     0     1     0\n##        35-39   0   2     0     0     0     0     0     0     0     1     0     0     0\n##        40-44   0   0     0     0     1     0     2     1     0     3     1     1     0\n##        45-49   1   2     2     0     0     0     3     0     1     0     3     2     1\n##        50-54   1   2     1     2     0     0     1     0     0     3     4     1     0\n##        55-59   0   1     0     0     1     1     2     0     0     0     0     0     0\n##        60-64   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        65-69   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        70-74   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        75-79   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        80+     1   0     0     2     1     0     0     0     1     0     0     0     0\n##             target_cases\n## source_cases 65-69 70-74 75-79 80+\n##        0-4       0     0     0   0\n##        5-9       0     0     0   0\n##        10-14     0     0     0   0\n##        15-19     0     0     0   0\n##        20-24     0     0     0   1\n##        25-29     0     0     0   0\n##        30-34     0     0     0   0\n##        35-39     0     0     0   0\n##        40-44     0     0     1   1\n##        45-49     0     0     0   1\n##        50-54     1     0     0   1\n##        55-59     0     0     0   0\n##        60-64     0     0     0   0\n##        65-69     0     0     0   0\n##        70-74     0     0     0   0\n##        75-79     0     0     0   0\n##        80+       0     0     0   0\nlong_prop <- data.frame(prop.table(cross_tab))\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = target_cases,         # x-axis is case age\n      y = source_cases,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # labels\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"contact-tracing.html","id":"resources-12","chapter":"25 Truy vết tiếp xúc","heading":"25.6 Resources","text":"https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reportinghttps://worldhealthorganization.github.io/godata/https://community-godata..int/","code":""},{"path":"survey-analysis.html","id":"survey-analysis","chapter":"26 Phân tích khảo sát","heading":"26 Phân tích khảo sát","text":"","code":""},{"path":"survey-analysis.html","id":"overview-3","chapter":"26 Phân tích khảo sát","heading":"26.1 Overview","text":"page demonstrates use several packages survey analysis.survey R packages rely survey package\nweighted analysis.\nuse survey well srvyr\n(wrapper survey allowing tidyverse-style coding) \ngtsummary\n(wrapper survey allowing publication ready tables).\noriginal survey package allow tidyverse-style coding,\nadded benefit allowing survey-weighted generalised linear\nmodels (added page later date).\nalso demonstrate using function sitrep\npackage create sampling weights (n.b package currently yet CRAN,\ncan installed github).page based work done “R4Epis” project;\ndetailed code R-markdown templates see “R4Epis” github page.\nsurvey package based code based early versions \nEPIET case studies.current page address sample size calculations sampling.\nsimple use sample size calculator see OpenEpi.\nGIS basics page handbook\neventually section spatial random sampling, page \neventually section sampling frames well sample size calculations.Survey dataObservation timeWeightingSurvey design objectsDescriptive analysisWeighted proportionsWeighted rates","code":""},{"path":"survey-analysis.html","id":"preparation-12","chapter":"26 Phân tích khảo sát","heading":"26.2 Preparation","text":"","code":""},{"path":"survey-analysis.html","id":"packages-2","chapter":"26 Phân tích khảo sát","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page [R basics] information R packages.\nalso demonstrate using p_load_gh() function pacman install load package github yet published CRAN.","code":"\n## load packages from CRAN\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               survey,       # for survey functions\n               srvyr,        # dplyr wrapper for survey package\n               gtsummary,    # wrapper for survey package to produce tables\n               apyramid,     # a package dedicated to creating age pyramids\n               patchwork,    # for combining ggplots\n               ggforce       # for alluvial/sankey plots\n               ) \n\n## load packages from github\npacman::p_load_gh(\n     \"R4EPI/sitrep\"          # for observation time / weighting functions\n)"},{"path":"survey-analysis.html","id":"load-data-1","chapter":"26 Phân tích khảo sát","heading":"Load data","text":"example dataset used section:fictional mortality survey data.fictional population counts survey area.data dictionary fictional mortality survey data.based MSF OCA ethical review board pre-approved survey. \nfictional dataset produced part “R4Epis” project.\nbased data collected using KoboToolbox,\ndata collection software based Open Data Kit.Kobo allows export collected data, well data dictionary\ndataset. strongly recommend simplifies data cleaning\nuseful looking variables/questions.TIP: Kobo data dictionary variable\nnames “name” column survey sheet.\nPossible values variable specified choices sheet.\nchoices tab, “name” shortened value “label::english” \n“label::french” columns appropriate long versions.\nUsing epidict package msf_dict_survey() function import Kobo\ndictionary excel file re-format can used easily recode. CAUTION: example dataset \nexport (Kobo export different questionnaire levels individually)\n- see survey data section merge different levels.dataset imported using import() function rio package. See page Import export various ways import data.first 10 rows survey displayed .also want import data sampling population can produce\nappropriate weights. data can different formats, however \nsuggest seen (can just typed excel).first 10 rows survey displayed .cluster surveys may want add survey weights cluster level.\nread data .\nAlternatively counts, entered \ntibble.\ncase need one column cluster identifier \nmatches survey data, another column number households \ncluster.","code":"\n# import the survey data\nsurvey_data <- rio::import(\"survey_data.xlsx\")\n\n# import the dictionary into R\nsurvey_dict <- rio::import(\"survey_dict.xlsx\") \n# import the population data\npopulation <- rio::import(\"population.xlsx\")\n## define the number of households in each cluster\ncluster_counts <- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))"},{"path":"survey-analysis.html","id":"clean-data-1","chapter":"26 Phân tích khảo sát","heading":"Clean data","text":"makes sure date column appropriate format.\nseveral ways (see Working dates\npage details), however using dictionary define dates quick easy.also create age group variable using age_categories() function \nepikit - see cleaning data\nhandbook section details.\naddition, create character variable defining district various clusters\n.Finally, recode yes/variables TRUE/FALSE variables - otherwise\ncant used survey proportion functions.","code":"\n## select the date variable names from the dictionary \nDATEVARS <- survey_dict %>% \n  filter(type == \"date\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filter to match the column names of your data\n  pull(name) # select date vars\n  \n## change to dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## add those with only age in months to the year variable (divide by twelve)\nsurvey_data <- survey_data %>% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## define age group variable\nsurvey_data <- survey_data %>% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## create a character variable based off groups of a different variable \nsurvey_data <- survey_data %>% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## select the yes/no variable names from the dictionary \nYNVARS <- survey_dict %>% \n  filter(type == \"yn\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filter to match the column names of your data\n  pull(name) # select yn vars\n  \n## change to dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))"},{"path":"survey-analysis.html","id":"survey-data","chapter":"26 Phân tích khảo sát","heading":"26.3 Survey data","text":"numerous different sampling designs can used surveys. \ndemonstrate code :\n- Stratified\n- Cluster\n- Stratified clusterAs described (depending design questionnaire) data \nlevel exported separate dataset Kobo. example \none level households one level individuals within households.two levels linked unique identifier.\nKobo dataset variable \"_index\" household level, \nmatches \"_parent_index\" individual level.\ncreate new rows household matching individual,\nsee handbook section joining\ndetails.","code":"\n## join the individual and household data to form a complete data set\nsurvey_data <- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## create a unique identifier by combining indeces of the two levels \nsurvey_data <- survey_data %>% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))"},{"path":"survey-analysis.html","id":"observation-time","chapter":"26 Phân tích khảo sát","heading":"26.4 Observation time","text":"mortality surveys want now long individual present \nlocation able calculate appropriate mortality rate period\ninterest. relevant surveys, particularly mortality\nsurveys important conducted frequently among mobile displaced\npopulations.first define time period interest, also known recall\nperiod (.e. time participants asked report answering\nquestions).\ncan use period set inappropriate dates missing, .e. deaths\nreported outside period interest.can use date variables define start end dates individual.\ncan use find_start_date() function sitrep fine causes \ndates use calculate difference days (person-time).start date:\nEarliest appropriate arrival event within recall period\nEither beginning recall period (define advance), \ndate start recall applicable (e.g. arrivals births)end date:\nEarliest appropriate departure event within recall period\nEither end recall period, date end recall\napplicable (e.g. departures, deaths)","code":"\n## set the start/end of recall period\n## can be changed to date variables from dataset \n## (e.g. arrival date & date questionnaire)\nsurvey_data <- survey_data %>% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end   = as.Date(\"2018-05-01\")\n  )\n\n\n# set inappropriate dates to NA based on rules \n## e.g. arrivals before start, departures departures after end\nsurvey_data <- survey_data %>%\n      mutate(\n           arrived_date = if_else(arrived_date < recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date < recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date > recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date > recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n## create new variables for start and end dates/causes\nsurvey_data <- survey_data %>% \n     ## choose earliest date entered in survey\n     ## from births, household arrivals, and camp arrivals \n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end   = \"recall_end\",\n                  datecol      = \"startdate\",\n                  datereason   = \"startcause\" \n                 ) %>%\n     ## choose earliest date entered in survey\n     ## from camp departures, death and end of the study\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end   = \"recall_end\",\n                datecol      = \"enddate\",\n                datereason   = \"endcause\" \n               )\n\n\n## label those that were present at the start/end (except births/deaths)\nsurvey_data <- survey_data %>% \n     mutate(\n       ## fill in start date to be the beginning of recall period (for those empty) \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## set the start cause to present at start if equal to recall period \n       ## unless it is equal to the birth date \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## fill in end date to be end of recall period (for those empty) \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## set the end cause to present at end if equall to recall end \n       ## unless it is equal to the death date\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## Define observation time in days\nsurvey_data <- survey_data %>% \n  mutate(obstime = as.numeric(enddate - startdate))"},{"path":"survey-analysis.html","id":"weighting","chapter":"26 Phân tích khảo sát","heading":"26.5 Weighting","text":"important drop erroneous observations adding survey weights.\nexample observations negative observation time, need\ncheck (can assert_positive_timespan() function\nsitrep.\nAnother thing want drop empty rows (e.g. drop_na(uid))\nremove duplicates (see handbook section [De-duplication]\ndetails).\nwithout consent need dropped .example filter cases want drop store separate\ndata frame - way can describe excluded survey.\nuse anti_join() function dplyr remove dropped cases\nsurvey data.DANGER: cant missing values weight variable, variables relevant survey design (e.g. age, sex, strata cluster variables).mentioned demonstrate add weights three different study\ndesigns (stratified, cluster stratified cluster). require information\nsource population /clusters surveyed.\nuse stratified cluster code example, use whichever \nappropriate study design.","code":"\n## store the cases that you drop so you can describe them (e.g. non-consenting \n## or wrong village/cluster)\ndropped <- survey_data %>% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## use the dropped cases to remove the unused rows from the survey data set  \nsurvey_data <- anti_join(survey_data, dropped, by = names(dropped))\n# stratified ------------------------------------------------------------------\n# create a variable called \"surv_weight_strata\"\n# contains weights for each individual - by age group, sex and health district\nsurvey_data <- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## cluster ---------------------------------------------------------------------\n\n# get the number of people of individuals interviewed per household\n# adds a variable with counts of the household (parent) index variable\nsurvey_data <- survey_data %>%\n  add_count(index, name = \"interviewed\")\n\n\n## create cluster weights\nsurvey_data <- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# stratified and cluster ------------------------------------------------------\n# create a survey weight for cluster and strata\nsurvey_data <- survey_data %>%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)"},{"path":"survey-analysis.html","id":"survey-design-objects","chapter":"26 Phân tích khảo sát","heading":"26.6 Survey design objects","text":"Create survey object according study design.\nUsed way data frames calculate weight proportions etc.\nMake sure necessary variables created .four options, comment use:\n- Simple random\n- Stratified\n- Cluster\n- Stratified clusterFor template - pretend cluster surveys two separate\nstrata (health districts B).\nget overall estimates need combined cluster strata weights.mentioned previously, two packages available . \nclassic one survey wrapper package called srvyr\nmakes tidyverse-friendly objects functions. demonstrate ,\nnote code chapter use srvyr based objects.\none exception gtsummary package accepts survey objects.","code":""},{"path":"survey-analysis.html","id":"survey-package","chapter":"26 Phân tích khảo sát","heading":"26.6.1 Survey package","text":"survey package effectively uses base R coding, \npossible use pipes (%>%) dplyr syntax.\nsurvey package use svydesign() function define survey\nobject appropriate clusters, weights strata.NOTE: need use tilde (~) front variables, package uses base R syntax assigning variables based formulae. ","code":"\n# simple random ---------------------------------------------------------------\nbase_survey_design_simple <- svydesign(ids = ~1, # 1 for no cluster ids\n                   weights = NULL,               # No weight added\n                   strata = NULL,                # sampling was simple (no strata)\n                   data = survey_data            # have to specify the dataset\n                  )\n\n## stratified ------------------------------------------------------------------\nbase_survey_design_strata <- svydesign(ids = ~1,  # 1 for no cluster ids\n                   weights = ~surv_weight_strata, # weight variable created above\n                   strata = ~health_district,     # sampling was stratified by district\n                   data = survey_data             # have to specify the dataset\n                  )\n\n# cluster ---------------------------------------------------------------------\nbase_survey_design_cluster <- svydesign(ids = ~village_name, # cluster ids\n                   weights = ~surv_weight_cluster, # weight variable created above\n                   strata = NULL,                 # sampling was simple (no strata)\n                   data = survey_data              # have to specify the dataset\n                  )\n\n# stratified cluster ----------------------------------------------------------\nbase_survey_design <- svydesign(ids = ~village_name,      # cluster ids\n                   weights = ~surv_weight_cluster_strata, # weight variable created above\n                   strata = ~health_district,             # sampling was stratified by district\n                   data = survey_data                     # have to specify the dataset\n                  )"},{"path":"survey-analysis.html","id":"srvyr-package","chapter":"26 Phân tích khảo sát","heading":"26.6.2 Srvyr package","text":"srvyr package can use as_survey_design() function, \narguments allows pipes (%>%), \nneed use tilde (~).","code":"\n## simple random ---------------------------------------------------------------\nsurvey_design_simple <- survey_data %>% \n  as_survey_design(ids = 1, # 1 for no cluster ids \n                   weights = NULL, # No weight added\n                   strata = NULL # sampling was simple (no strata)\n                  )\n## stratified ------------------------------------------------------------------\nsurvey_design_strata <- survey_data %>%\n  as_survey_design(ids = 1, # 1 for no cluster ids\n                   weights = surv_weight_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )\n## cluster ---------------------------------------------------------------------\nsurvey_design_cluster <- survey_data %>%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster, # weight variable created above\n                   strata = NULL # sampling was simple (no strata)\n                  )\n\n## stratified cluster ----------------------------------------------------------\nsurvey_design <- survey_data %>%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )"},{"path":"survey-analysis.html","id":"descriptive-analysis-2","chapter":"26 Phân tích khảo sát","heading":"26.7 Descriptive analysis","text":"Basic descriptive analysis visualisation covered extensively \nchapters handbook, dwell .\ndetails see chapters descriptive tables,\nstatistical tests,\ntables presentation,\nggplot basics \nR markdown reports.section focus investigate bias sample visualise .\nalso look visualising population flow survey setting using\nalluvial/sankey diagrams.general, consider including following descriptive analyses:Final number clusters, households individuals includedNumber excluded individuals reasons exclusionMedian (range) number households per cluster individuals per household","code":""},{"path":"survey-analysis.html","id":"sampling-bias","chapter":"26 Phân tích khảo sát","heading":"26.7.1 Sampling bias","text":"Compare proportions age group sample \nsource population.\nimportant able highlight potential sampling bias.\nsimilarly repeat looking distributions sex.Note p-values just indicative, descriptive discussion (\nvisualisation age-pyramids ) distributions study sample\ncompared source population important binomial test .\nincreasing sample size often lead \ndifferences may irrelevant weighting data.","code":"\n## counts and props of the study population\nag <- survey_data %>% \n  group_by(age_group) %>% \n  drop_na(age_group) %>% \n  tally() %>% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## counts and props of the source population\npropcount <- population %>% \n  group_by(age_group) %>%\n    tally(population) %>%\n    mutate(proportion = n / sum(n))\n\n## bind together the columns of two tables, group by age, and perform a \n## binomial test to see if n/total is significantly different from population\n## proportion.\n  ## suffix here adds to text to the end of columns in each of the two datasets\nleft_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %>%\n  group_by(age_group) %>%\n  ## broom::tidy(binom.test()) makes a data frame out of the binomial test and\n  ## will add the variables p.value, parameter, conf.low, conf.high, method, and\n  ## alternative. We will only use p.value here. You can include other\n  ## columns if you want to report confidence intervals\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %>%\n  unnest(cols = c(binom)) %>% # important for expanding the binom.test data frame\n  mutate(proportion_pop = proportion_pop * 100) %>%\n  ## Adjusting the p-values to correct for false positives \n  ## (because testing multiple age groups). This will only make \n  ## a difference if you have many age categories\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %>%\n                      \n  ## Only show p-values over 0.001 (those under report as <0.001)\n  mutate(p.value = ifelse(p.value < 0.001, \n                          \"<0.001\", \n                          as.character(round(p.value, 3)))) %>% \n  \n  ## rename the columns appropriately\n  select(\n    \"Age group\" = age_group,\n    \"Study population (n)\" = n,\n    \"Study population (%)\" = proportion,\n    \"Source population (n)\" = n_pop,\n    \"Source population (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )## # A tibble: 5 x 6\n## # Groups:   Age group [5]\n##   `Age group` `Study population ~ `Study population~ `Source populatio~ `Source populatio~\n##   <chr>                     <int>              <dbl>              <dbl>              <dbl>\n## 1 0-2                          12             0.0256               1360                6.8\n## 2 3-14                         42             0.0896               7244               36.2\n## 3 15-29                        64             0.136                5520               27.6\n## 4 30-44                        52             0.111                3232               16.2\n## 5 45+                         299             0.638                2644               13.2\n## # ... with 1 more variable: P-value <chr>"},{"path":"survey-analysis.html","id":"demographic-pyramids","chapter":"26 Phân tích khảo sát","heading":"26.7.2 Demographic pyramids","text":"Demographic (age-sex) pyramids easy way visualising distribution\nsurvey population. also worth considering creating\ndescriptive tables age\nsex survey strata.\ndemonstrate using apyramid package allows weighted\nproportions using survey design object created . options creating\ndemographic pyramids\ncovered extensively chapter handbook. also use \nwrapper function sitrep called plot_age_pyramid() saves lines\ncoding producing plot proportions.formal binomial test difference, seen sampling bias\nsection, interested visualising whether sampled population\nsubstantially different source population whether weighting corrects\ndifference. use patchwork package show \nggplot visualisations side--side; details see section \ncombining plots ggplot tips\nchapter handbook.\nvisualise source population, un-weighted survey population \nweighted survey population.\nmay also consider visualising strata survey - example\nusing argument stack_by  = \"health_district\"\n(see ?plot_age_pyramid details).NOTE: x y axes flipped pyramids ","code":"\n## define x-axis limits and labels ---------------------------------------------\n## (update these numbers to be the values for your graph)\nmax_prop <- 35      # choose the highest proportion you want to show \nstep <- 5           # choose the space you want beween labels \n\n## this part defines vector using the above numbers with axis breaks\nbreaks <- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## this part defines vector using the above numbers with axis limits\nlimits <- c(max_prop/100 * -1, max_prop/100)\n\n## this part defines vector using the above numbers with axis labels\nlabels <-  c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## create plots individually  --------------------------------------------------\n\n## plot the source population \n## nb: this needs to be collapsed for the overall population (i.e. removing health districts)\nsource_population <- population %>%\n  ## ensure that age and sex are factors\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %>% \n  group_by(age_group, sex) %>% \n  ## add the counts for each health district together \n  summarise(population = sum(population)) %>% \n  ## remove the grouping so can calculate overall proportion\n  ungroup() %>% \n  mutate(proportion = population / sum(population)) %>% \n  ## plot pyramid \n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## only show the y axis label (otherwise repeated in all three plots)\n  labs(title = \"Source population\", \n       y = \"\", \n       x = \"Age group (years)\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## plot the unweighted sample population \nsample_population <- plot_age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Unweighted sample population\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## plot the weighted sample population \nweighted_population <- survey_design %>% \n  ## make sure the variables are factors\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %>%\n  plot_age_pyramid(\n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Weighted sample population\", \n       y = \"\", \n       x = \"\")  + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## combine all three plots  ----------------------------------------------------\n## combine three plots next to eachother using + \nsource_population + sample_population + weighted_population + \n  ## only show one legend and define theme \n  ## note the use of & for combining theme with plot_layout()\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\",                    # move legend to bottom\n        legend.title = element_blank(),                # remove title\n        text = element_text(size = 18),                # change text size\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # turn x-axis text\n       )"},{"path":"survey-analysis.html","id":"alluvialsankey-diagram","chapter":"26 Phân tích khảo sát","heading":"26.7.3 Alluvial/sankey diagram","text":"Visualising starting points outcomes individuals can helpful \nget overview. quite obvious application mobile populations,\nhowever numerous applications cohorts situation\ntransitions states individuals. diagrams several\ndifferent names including alluvial, sankey parallel sets - details \nhandbook chapter diagrams charts.","code":"\n## summarize data\nflow_table <- survey_data %>%\n  count(startcause, endcause, sex) %>%  # get counts \n  gather_set_data(x = c(\"startcause\", \"endcause\")) %>%     # change format for plotting\n  mutate(x = fct_relevel(x, c(\"startcause\", \"endcause\")),  # set startcause as first level\n         x = fct_recode(x, \n                        \"Start \\n cause\" = \"startcause\",   # add line break (\\n) after start\n                        \"End \\n cause\"   = \"endcause\")\n        )\n\n\n## plot your dataset \n  ## on the x axis is the start and end causes\n  ## gather_set_data generates an ID for each possible combination\n  ## splitting by y gives the possible start/end combos\n  ## value as n gives it as counts (could also be changed to proportion)\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## colour lines by sex \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) +\n  ## fill in the label boxes grey\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") +\n  ## change text colour and angle (needs to be adjusted)\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) +\n  ## adjusted y and x axes (probably needs more vertical space)\n  scale_x_discrete(name = NULL, expand = c(0, 0.2)) + \n  ## remove axis labels\n  theme(\n    title = element_text(size = 26),\n    text = element_text(size = 26),\n    axis.line = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.y = element_blank(),\n    panel.background = element_blank(),\n    legend.position = \"bottom\",                    # move legend to bottom\n    legend.title = element_blank(),                # remove title\n  )"},{"path":"survey-analysis.html","id":"weighted-proportions","chapter":"26 Phân tích khảo sát","heading":"26.8 Weighted proportions","text":"section detail produce tables weighted counts proportions,\nassociated confidence intervals design effect.\nfour different options using functions following packages:\nsurvey, srvyr, sitrep gtsummary.\nminimal coding produce standard epidemiology style table, \nrecommend sitrep function - wrapper srvyr code; note\nhowever yet CRAN may change future.\nOtherwise, survey code likely stable long-term, whereas\nsrvyr fit nicely within tidyverse work-flows. gtsummary\nfunctions hold lot potential, appear experimental incomplete\ntime writing.","code":""},{"path":"survey-analysis.html","id":"survey-package-1","chapter":"26 Phân tích khảo sát","heading":"26.8.1 Survey package","text":"can use svyciprop() function survey get weighted proportions\naccompanying 95% confidence intervals. appropriate design effect can \nextracted using svymean() rather svyprop() function.\nworth noting svyprop() appears accept variables 0 \n1 (TRUE/FALSE), categorical variables work.NOTE: Functions survey also accept srvyr design objects, used survey design object just consistency can combine functions survey shown function \ndefine , called svy_prop; can use function\ntogether map() purrr package iterate several variables\ncreate table. See handbook iteration\nchapter details purrr.","code":"\n## produce weighted counts \nsvytable(~died, base_survey_design)## died\n##      FALSE       TRUE \n## 1406244.43   76213.01\n## produce weighted proportions\nsvyciprop(~died, base_survey_design, na.rm = T)##               2.5% 97.5%\n## died 0.0514 0.0208  0.12\n## get the design effect \nsvymean(~died, base_survey_design, na.rm = T, deff = T) %>% \n  deff()## diedFALSE  diedTRUE \n##  3.755508  3.755508\n# Define function to calculate weighted counts, proportions, CI and design effect\n# x is the variable in quotation marks \n# design is your survey design object\n\nsvy_prop <- function(design, x) {\n  \n  ## put the variable of interest in a formula \n  form <- as.formula(paste0( \"~\" , x))\n  ## only keep the TRUE column of counts from svytable\n  weighted_counts <- svytable(form, design)[[2]]\n  ## calculate proportions (multiply by 100 to get percentages)\n  weighted_props <- svyciprop(form, design, na.rm = TRUE) * 100\n  ## extract the confidence intervals and multiply to get percentages\n  weighted_confint <- confint(weighted_props) * 100\n  ## use svymean to calculate design effect and only keep the TRUE column\n  design_eff <- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## combine in to one data frame\n  full_table <- cbind(\n    \"Variable\"        = x,\n    \"Count\"           = weighted_counts,\n    \"Proportion\"      = weighted_props,\n    weighted_confint, \n    \"Design effect\"   = design_eff\n    )\n  \n  ## return table as a dataframe\n  full_table <- data.frame(full_table, \n             ## remove the variable names from rows (is a separate column now)\n             row.names = NULL)\n  \n  ## change numerics back to numeric\n  full_table[ , 2:6] <- as.numeric(full_table[, 2:6])\n  \n  ## return dataframe\n  full_table\n}\n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  svy_prop, design = base_survey_design) %>% \n  ## collapse list in to a single data frame\n  bind_rows() %>% \n  ## round \n  mutate(across(where(is.numeric), round, digits = 1))##   Variable    Count Proportion X2.5. X97.5. Design.effect\n## 1     left 701199.1       47.3  39.2   55.5           2.4\n## 2     died  76213.0        5.1   2.1   12.1           3.8\n## 3  arrived 761799.0       51.4  40.9   61.7           3.9"},{"path":"survey-analysis.html","id":"srvyr-package-1","chapter":"26 Phân tích khảo sát","heading":"26.8.2 Srvyr package","text":"srvyr can use dplyr syntax create table. Note \nsurvey_mean() function used proportion argument specified, \nalso function used calculate design effect. \nsrvyr wraps around survey package functions svyciprop() \nsvymean(), used section.NOTE: seem possible get proportions categorical variables using srvyr either, need check section using sitrep write function iterate multiple variables using\npurrr package.\nSee handbook iteration\nchapter details purrr.","code":"\n## use the srvyr design object\nsurvey_design %>% \n  summarise(\n    ## produce the weighted counts \n    counts = survey_total(died), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(died, deff = TRUE)) %>% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(counts, props, props_low, props_upp, deff_deff)##     counts    props props_low props_upp deff_deff\n## 1 76213.01 5.140991  2.082773  12.13328  3.755508\n# Define function to calculate weighted counts, proportions, CI and design effect\n# design is your survey design object\n# x is the variable in quotation marks \n\n\nsrvyr_prop <- function(design, x) {\n  \n  summarise(\n    ## using the survey design object\n    design, \n    ## produce the weighted counts \n    counts = survey_total(.data[[x]]), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(.data[[x]], deff = TRUE)) %>% \n  ## add in the variable name\n  mutate(variable = x) %>% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  ~srvyr_prop(.x, design = survey_design)) %>% \n  ## collapse list in to a single data frame\n  bind_rows()##   variable    counts     props props_low props_upp deff_deff\n## 1     left 701199.14 47.299782 39.235598  55.50736  2.379761\n## 2     died  76213.01  5.140991  2.082773  12.13328  3.755508\n## 3  arrived 761799.05 51.387583 40.927349  61.72766  3.925504"},{"path":"survey-analysis.html","id":"sitrep-package","chapter":"26 Phân tích khảo sát","heading":"26.8.3 Sitrep package","text":"tab_survey() function sitrep wrapper srvyr, allowing\ncreate weighted tables minimal coding. also allows calculate\nweighted proportions categorical variables.","code":"\n## using the survey design object\nsurvey_design %>% \n  ## pass the names of variables of interest unquoted\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE,   # calculate the design effect\n             pretty = TRUE  # merge the proportion and 95%CI\n             )## Warning: removing 257 missing value(s) from `education_level`## # A tibble: 9 x 5\n##   variable        value            n  deff ci                \n##   <chr>           <chr>        <dbl> <dbl> <chr>             \n## 1 arrived         TRUE       761799.  3.93 51.4% (40.9--61.7)\n## 2 arrived         FALSE      720658.  3.93 48.6% (38.3--59.1)\n## 3 left            TRUE       701199.  2.38 47.3% (39.2--55.5)\n## 4 left            FALSE      781258.  2.38 52.7% (44.5--60.8)\n## 5 died            TRUE        76213.  3.76 5.1% (2.1--12.1)  \n## 6 died            FALSE     1406244.  3.76 94.9% (87.9--97.9)\n## 7 education_level higher     171644.  4.70 42.4% (26.9--59.7)\n## 8 education_level primary    102609.  2.37 25.4% (16.2--37.3)\n## 9 education_level secondary  130201.  6.68 32.2% (16.5--53.3)"},{"path":"survey-analysis.html","id":"gtsummary-package","chapter":"26 Phân tích khảo sát","heading":"26.8.4 Gtsummary package","text":"gtsummary seem inbuilt functions yet add confidence\nintervals design effect.\nshow define function adding confidence intervals \nadd confidence intervals gtsummary table created using tbl_svysummary()\nfunction.\n          1\n          \n           \n          n (%)\n          ","code":"\nconfidence_intervals <- function(data, variable, by, ...) {\n  \n  ## extract the confidence intervals and multiply to get percentages\n  props <- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## extract the confidence intervals \n  as.numeric(confint(props) * 100) %>% ## make numeric and multiply for percentage\n    round(., digits = 1) %>%           ## round to one digit\n    c(.) %>%                           ## extract the numbers from matrix\n    paste0(., collapse = \"-\")          ## combine to single character\n}\n\n## using the survey package design object\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died),   ## define variables want to include\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %>% ## define stats of interest\n  add_n() %>%  ## add the weighted total \n  add_stat(fns = everything() ~ confidence_intervals) %>% ## add CIs\n  ## modify the column headers\n  modify_header(\n    list(\n      n ~ \"**Weighted total (N)**\",\n      stat_0 ~ \"**Weighted Count**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )"},{"path":"survey-analysis.html","id":"weighted-ratios","chapter":"26 Phân tích khảo sát","heading":"26.9 Weighted ratios","text":"Similarly weighted ratios (mortality ratios) can use \nsurvey srvyr package.\nsimilarly write functions (similar ) iterate \nseveral variables. also create function gtsummary \ncurrently inbuilt functionality.","code":""},{"path":"survey-analysis.html","id":"survey-package-2","chapter":"26 Phân tích khảo sát","heading":"26.9.1 Survey package","text":"","code":"\nratio <- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci <- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)##       obstime    2.5 %   97.5 %\n## died 5.981922 1.194294 10.76955"},{"path":"survey-analysis.html","id":"srvyr-package-2","chapter":"26 Phân tích khảo sát","heading":"26.9.2 Srvyr package","text":"","code":"\nsurvey_design %>% \n  ## survey ratio used to account for observation time \n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )##   mortality mortality_low mortality_upp\n## 1  5.981922     0.3490176      11.61483"},{"path":"survey-analysis.html","id":"resources-13","chapter":"26 Phân tích khảo sát","heading":"26.10 Resources","text":"UCLA stats pageAnalyze survey data freesrvyr packgegtsummary packageEPIET survey case studies","code":""},{"path":"survival-analysis.html","id":"survival-analysis","chapter":"27 Phân tích sống còn","heading":"27 Phân tích sống còn","text":"","code":""},{"path":"survival-analysis.html","id":"overview-4","chapter":"27 Phân tích sống còn","heading":"27.1 Overview","text":"Survival analysis focuses describing given individual group individuals, defined point event called failure (occurrence disease, cure disease, death, relapse response treatment…) occurs period time called failure time (follow-time cohort/population-based studies) individuals observed. determine failure time, necessary define time origin (can inclusion date, date diagnosis…).target inference survival analysis time origin event.\ncurrent medical research, widely used clinical studies assess effect treatment instance, cancer epidemiology assess large variety cancer survival measures.usually expressed survival probability probability event interest occurred duration t.Censoring: Censoring occurs end follow-, individuals event interest, thus true time event unknown. mostly focus right censoring details censoring survival analysis general, can see references.","code":""},{"path":"survival-analysis.html","id":"preparation-13","chapter":"27 Phân tích sống còn","heading":"27.2 Preparation","text":"","code":""},{"path":"survival-analysis.html","id":"load-packages-13","chapter":"27 Phân tích sống còn","heading":"Load packages","text":"run survival analyses R, one widely used package survival package. first install load well packages used section:handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.page explores survival analyses using linelist used previous pages apply changes proper survival data.","code":""},{"path":"survival-analysis.html","id":"import-dataset","chapter":"27 Phân tích sống còn","heading":"Import dataset","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).","code":"\n# import linelist\nlinelist_case_data <- rio::import(\"linelist_cleaned.rds\")"},{"path":"survival-analysis.html","id":"data-management-and-transformation","chapter":"27 Phân tích sống còn","heading":"Data management and transformation","text":"short, survival data can described following three characteristics:dependent variable response waiting time occurrence well-defined event,observations censored, sense units event interest occurred time data analyzed, andthere predictors explanatory variables whose effect waiting time wish assess control.Thus, create different variables needed respect structure run survival analysis.define:new data frame linelist_surv analysisour event interest “death” (hence survival probability probability alive certain time time origin),follow-time (futime) time time onset time outcome days,censored patients recovered final outcome known ie event “death” observed (event=0).CAUTION: Since real cohort study, information time origin end follow-known given individuals observed, remove observations date onset date outcome unknown. Also cases date onset later date outcome removed since considered wrong.TIP: Given filtering greater (>) less (<) date can remove rows missing values, applying filter wrong dates also remove rows missing dates.use case_when() create column age_cat_small 3 age categories.TIP: can verify new columns created summary futime cross-tabulation event outcome created. Besides verification good habit communicate median follow-time interpreting survival analysis results.Now cross-tabulate new age_cat_small var old age_cat col ensure correct assingmentsNow review 10 first observations linelist_surv data looking specific variables (including newly created).can also cross-tabulate columns age_cat_small gender details distribution new column gender. use tabyl() adorn functions janitor described [Descriptive tables] page.","code":"\n#create a new data called linelist_surv from the linelist_case_data\n\nlinelist_surv <-  linelist_case_data %>% \n     \n  dplyr::filter(\n       # remove observations with wrong or missing dates of onset or date of outcome\n       date_outcome > date_onset) %>% \n  \n  dplyr::mutate(\n       # create the event var which is 1 if the patient died and 0 if he was right censored\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # create the var on the follow-up time in days\n       futime = as.double(date_outcome - date_onset), \n    \n       # create a new age category variable with only 3 strata levels\n       age_cat_small = dplyr::case_when( \n            age_years < 5  ~ \"0-4\",\n            age_years >= 5 & age_years < 20 ~ \"5-19\",\n            age_years >= 20   ~ \"20+\"),\n       \n       # previous step created age_cat_small var as character.\n       # now convert it to factor and specify the levels.\n       # Note that the NA values remain NA's and are not put in a level \"unknown\" for example,\n       # since in the next analyses they have to be removed.\n       age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n       )\nsummary(linelist_surv$futime)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    1.00    6.00   10.00   11.98   16.00   64.00\n# cross tabulate the new event var and the outcome var from which it was created\n# to make sure the code did what it was intended to\nlinelist_surv %>% \n  tabyl(outcome, event)##  outcome    0    1\n##    Death    0 1952\n##  Recover 1547    0\n##     <NA> 1040    0\nlinelist_surv %>% \n  tabyl(age_cat_small, age_cat)##  age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n##            0-4 834   0     0     0     0     0     0   0   0\n##           5-19   0 852   717   575     0     0     0   0   0\n##            20+   0   0     0     0   862   554    69   5   0\n##           <NA>   0   0     0     0     0     0     0   0  71\nlinelist_surv %>% \n  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %>% \n  head(10)##    case_id age_cat_small date_onset date_outcome outcome event futime\n## 1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n## 2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n## 3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n## 4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n## 5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n## 6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n## 7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n## 8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n## 9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n## 10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\nlinelist_surv %>% \n  tabyl(gender, age_cat_small, show_na = F) %>% \n  adorn_totals(c(\"row\", \"col\")) %>% \n  adorn_percentages() %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\")##  gender         0-4         5-19          20+         Total\n##       f 482 (22.4%) 1184 (54.9%)  490 (22.7%) 2156 (100.0%)\n##       m 325 (15.0%)  880 (40.6%)  960 (44.3%) 2165 (100.0%)\n##   Total 807 (18.7%) 2064 (47.8%) 1450 (33.6%) 4321 (100.0%)"},{"path":"survival-analysis.html","id":"basics-of-survival-analysis","chapter":"27 Phân tích sống còn","heading":"27.3 Basics of survival analysis","text":"","code":""},{"path":"survival-analysis.html","id":"building-a-surv-type-object","chapter":"27 Phân tích sống còn","heading":"Building a surv-type object","text":"first use Surv() survival build survival object follow-time event columns.result step produce object type Surv condenses time information whether event interest (death) observed. object ultimately used right-hand side subsequent model formulae (see documentation).review, first 10 rows linelist_surv data, viewing important columns.first 10 elements survobj. prints essentially vector follow-time, “+” represent observation right-censored. See numbers align .","code":"\n# Use Suv() syntax for right-censored data\nsurvobj <- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\nlinelist_surv %>% \n  select(case_id, date_onset, date_outcome, futime, outcome, event) %>% \n  head(10)##    case_id date_onset date_outcome futime outcome event\n## 1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n## 2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n## 3   893f25 2014-05-21   2014-05-29      8 Recover     0\n## 4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n## 5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n## 6   369449 2014-06-02   2014-06-07      5   Death     1\n## 7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n## 8   1389ca 2014-06-05   2014-06-09      4   Death     1\n## 9   2978ac 2014-06-06   2014-06-15      9   Death     1\n## 10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n#print the 50 first elements of the vector to see how it presents\nhead(survobj, 10)##  [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+"},{"path":"survival-analysis.html","id":"running-initial-analyses","chapter":"27 Phân tích sống còn","heading":"Running initial analyses","text":"start analysis using survfit() function produce survfit object, fits default calculations Kaplan Meier (KM) estimates overall (marginal) survival curve, fact step function jumps observed event times. final survfit object contains one survival curves created using Surv object response variable model formula.NOTE: Kaplan-Meier estimate nonparametric maximum likelihood estimate (MLE) survival function. . (see resources information).summary survfit object give called life table. time step follow-(time) event happened (ascending order):number people risk developing event (people event yet censored: n.risk)develop event (n.event): probability developing event (probability dying, surviving past specific time)finally, standard error confidence interval probability derived displayedWe fit KM estimates using formula previously Surv object “survobj” response variable. “~ 1” precises run model overall survival.using summary() can add option times specify certain times want see survival informationWe can also use print() function. print.rmean = TRUE argument used obtain mean survival time standard error (se).NOTE: restricted mean survival time (RMST) specific survival measure used cancer survival analysis often defined area survival curve, given observe patients restricted time T (details Resources section).TIP: can create surv object directly survfit() function save line code. look like: linelistsurv_quick <-  survfit(Surv(futime, event) ~ 1, data=linelist_surv).","code":"\n# fit the KM estimates using a formula where the Surv object \"survobj\" is the response variable.\n# \"~ 1\" signifies that we run the model for the overall survival  \nlinelistsurv_fit <-  survival::survfit(survobj ~ 1)\n\n#print its summary for more details\nsummary(linelistsurv_fit)## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     1   4539      30    0.993 0.00120        0.991        0.996\n##     2   4500      69    0.978 0.00217        0.974        0.982\n##     3   4394     149    0.945 0.00340        0.938        0.952\n##     4   4176     194    0.901 0.00447        0.892        0.910\n##     5   3899     214    0.852 0.00535        0.841        0.862\n##     6   3592     210    0.802 0.00604        0.790        0.814\n##     7   3223     179    0.757 0.00656        0.745        0.770\n##     8   2899     167    0.714 0.00700        0.700        0.728\n##     9   2593     145    0.674 0.00735        0.660        0.688\n##    10   2311     109    0.642 0.00761        0.627        0.657\n##    11   2081     119    0.605 0.00788        0.590        0.621\n##    12   1843      89    0.576 0.00809        0.560        0.592\n##    13   1608      55    0.556 0.00823        0.540        0.573\n##    14   1448      43    0.540 0.00837        0.524        0.556\n##    15   1296      31    0.527 0.00848        0.511        0.544\n##    16   1152      48    0.505 0.00870        0.488        0.522\n##    17   1002      29    0.490 0.00886        0.473        0.508\n##    18    898      21    0.479 0.00900        0.462        0.497\n##    19    798       7    0.475 0.00906        0.457        0.493\n##    20    705       4    0.472 0.00911        0.454        0.490\n##    21    626      13    0.462 0.00932        0.444        0.481\n##    22    546       8    0.455 0.00948        0.437        0.474\n##    23    481       5    0.451 0.00962        0.432        0.470\n##    24    436       4    0.447 0.00975        0.428        0.466\n##    25    378       4    0.442 0.00993        0.423        0.462\n##    26    336       3    0.438 0.01010        0.419        0.458\n##    27    297       1    0.436 0.01017        0.417        0.457\n##    29    235       1    0.435 0.01030        0.415        0.455\n##    38     73       1    0.429 0.01175        0.406        0.452\n#print its summary at specific times\nsummary(linelistsurv_fit, times = c(5,10,20,30,60))## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     5   3899     656    0.852 0.00535        0.841        0.862\n##    10   2311     810    0.642 0.00761        0.627        0.657\n##    20    705     446    0.472 0.00911        0.454        0.490\n##    30    210      39    0.435 0.01030        0.415        0.455\n##    60      2       1    0.429 0.01175        0.406        0.452\n# print linelistsurv_fit object with mean survival time and its se. \nprint(linelistsurv_fit, print.rmean = TRUE)## Call: survfit(formula = survobj ~ 1)\n## \n##          n     events     *rmean *se(rmean)     median    0.95LCL    0.95UCL \n##   4539.000   1952.000     33.105      0.539     17.000     16.000     18.000 \n##     * restricted mean with upper limit =  64"},{"path":"survival-analysis.html","id":"cumulative-hazard","chapter":"27 Phân tích sống còn","heading":"Cumulative hazard","text":"Besides summary() function, can also use str() function gives details structure survfit() object. list 16 elements.Among elements important one: cumhaz, numeric vector. plotted allow show cumulative hazard, hazard instantaneous rate event occurrence (see references).","code":"\nstr(linelistsurv_fit)## List of 16\n##  $ n        : int 4539\n##  $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n##  $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n##  $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n##  $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n##  $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n##  $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n##  $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n##  $ type     : chr \"right\"\n##  $ logse    : logi TRUE\n##  $ conf.int : num 0.95\n##  $ conf.type: chr \"log\"\n##  $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n##  $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n##  $ call     : language survfit(formula = survobj ~ 1)\n##  - attr(*, \"class\")= chr \"survfit\""},{"path":"survival-analysis.html","id":"plotting-kaplan-meir-curves","chapter":"27 Phân tích sống còn","heading":"Plotting Kaplan-Meir curves","text":"KM estimates fitted, can visualize probability alive given time using basic plot() function draws “Kaplan-Meier curve”. words, curve conventional illustration survival experience whole patient group.can quickly verify follow-time min max curve.easy way interpret say time zero, participants still alive survival probability 100%. probability decreases time patients die. proportion participants surviving past 60 days follow-around 40%.confidence interval KM survival estimates also plotted default can dismissed adding option conf.int = FALSE plot() command.Since event interest “death”, drawing curve describing complements survival proportions lead drawing cumulative mortality proportions. can done lines(), adds information existing plot.","code":"\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\",    # x-axis label\n     ylab=\"Survival Probability\",   # y-axis label\n     main= \"Overall survival curve\" # figure title\n     )\n# original plot\nplot(\n  linelistsurv_fit,\n  xlab = \"Days of follow-up\",       \n  ylab = \"Survival Probability\",       \n  mark.time = TRUE,              # mark events on the curve: a \"+\" is printed at every event\n  conf.int = FALSE,              # do not plot the confidence interval\n  main = \"Overall survival curve and cumulative mortality\"\n  )\n\n# draw an additional curve to the previous plot\nlines(\n  linelistsurv_fit,\n  lty = 3,             # use different line type for clarity\n  fun = \"event\",       # draw the cumulative events instead of the survival \n  mark.time = FALSE,\n  conf.int = FALSE\n  )\n\n# add a legend to the plot\nlegend(\n  \"topright\",                               # position of legend\n  legend = c(\"Survival\", \"Cum. Mortality\"), # legend text \n  lty = c(1, 3),                            # line types to use in the legend\n  cex = .85,                                # parametes that defines size of legend text\n  bty = \"n\"                                 # no box type to be drawn for the legend\n  )"},{"path":"survival-analysis.html","id":"comparison-of-survival-curves","chapter":"27 Phân tích sống còn","heading":"27.4 Comparison of survival curves","text":"compare survival within different groups observed participants patients, might need first look respective survival curves run tests evaluate difference independent groups. comparison can concern groups based gender, age, treatment, comorbidity…","code":""},{"path":"survival-analysis.html","id":"log-rank-test","chapter":"27 Phân tích sống còn","heading":"Log rank test","text":"log rank test popular test compares entire survival experience two independent groups can thought test whether survival curves identical (overlapping) (null hypothesis difference survival groups). survdiff() function survival package allows running log-rank test specify rho = 0 (default). test results gives chi-square statistic along p-value since log rank statistic approximately distributed chi-square test statistic.first try compare survival curves gender group. , first try visualize (check whether two survival curves overlapping). new survfit object created slightly different formula. survdiff object created.supplying ~ gender right side formula, longer plot overall survival instead gender.Now can plot survival curves gender. look order strata levels gender column defining colors legend.now can compute test difference survival curves using survdiff()see survival curve women one men overlap log-rank test give evidence survival difference women men.R packages allow illustrating survival curves different groups testing difference . Using ggsurvplot() function survminer package, can also include curve printed risk tables group, well p-value log-rank test.CAUTION: survminer functions require specify survival object specify data used fit survival object. Remember avoid non-specific error messages. may also want test differences survival source infection (source contamination).case, Log rank test gives enough evidence difference survival probabilities alpha= 0.005. survival probabilities patients infected funerals higher survival probabilities patients got infected places, suggesting survival benefit.","code":"\n# create the new survfit object based on gender\nlinelistsurv_fit_sex <-  survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n# set colors\ncol_sex <- c(\"lightgreen\", \"darkgreen\")\n\n# create plot\nplot(\n  linelistsurv_fit_sex,\n  col = col_sex,\n  xlab = \"Days of follow-up\",\n  ylab = \"Survival Probability\")\n\n# add legend\nlegend(\n  \"topright\",\n  legend = c(\"Female\",\"Male\"),\n  col = col_sex,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n#compute the test of the difference between the survival curves\nsurvival::survdiff(\n  Surv(futime, event) ~ gender, \n  data = linelist_surv\n  )## Call:\n## survival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n## \n## n=4321, 218 observations deleted due to missingness.\n## \n##             N Observed Expected (O-E)^2/E (O-E)^2/V\n## gender=f 2156      924      909     0.255     0.524\n## gender=m 2165      929      944     0.245     0.524\n## \n##  Chisq= 0.5  on 1 degrees of freedom, p= 0.5\nsurvminer::ggsurvplot(\n    linelistsurv_fit_sex, \n    data = linelist_surv,          # again specify the data used to fit linelistsurv_fit_sex \n    conf.int = FALSE,              # do not show confidence interval of KM estimates\n    surv.scale = \"percent\",        # present probabilities in the y axis in %\n    break.time.by = 10,            # present the time axis with an increment of 10 days\n    xlab = \"Follow-up days\",\n    ylab = \"Survival Probability\",\n    pval = T,                      # print p-value of Log-rank test \n    pval.coord = c(40,.91),        # print p-value at these plot coordinates\n    risk.table = T,                # print the risk table at bottom \n    legend.title = \"Gender\",       # legend characteristics\n    legend.labs = c(\"Female\",\"Male\"),\n    font.legend = 10, \n    palette = \"Dark2\",             # specify color palette \n    surv.median.line = \"hv\",       # draw horizontal and vertical lines to the median survivals\n    ggtheme = theme_light()        # simplify plot background\n)\nlinelistsurv_fit_source <-  survfit(\n  Surv(futime, event) ~ source,\n  data = linelist_surv\n  )\n\n# plot\nggsurvplot( \n  linelistsurv_fit_source,\n  data = linelist_surv,\n  size = 1, linetype = \"strata\",   # line types\n  conf.int = T,\n  surv.scale = \"percent\",  \n  break.time.by = 10, \n  xlab = \"Follow-up days\",\n  ylab= \"Survival Probability\",\n  pval = T,\n  pval.coord = c(40,.91),\n  risk.table = T,\n  legend.title = \"Source of \\ninfection\",\n  legend.labs = c(\"Funeral\", \"Other\"),\n  font.legend = 10,\n  palette = c(\"#E7B800\",\"#3E606F\"),\n  surv.median.line = \"hv\", \n  ggtheme = theme_light()\n)## Warning: Vectorized input to `element_text()` is not officially supported.\n## Results may be unexpected or may change in future versions of ggplot2."},{"path":"survival-analysis.html","id":"cox-regression-analysis","chapter":"27 Phân tích sống còn","heading":"27.5 Cox regression analysis","text":"Cox proportional hazards regression one popular regression techniques survival analysis. models can also used since Cox model requires important assumptions need verified appropriate use proportional hazards assumption: see references.Cox proportional hazards regression model, measure effect hazard rate (HR), risk failure (risk death example), given participant survived specific time. Usually, interested comparing independent groups respect hazards, use hazard ratio, analogous odds ratio setting multiple logistic regression analysis. cox.ph() function survival package used fit model. function cox.zph() survival package may used test proportional hazards assumption Cox regression model fit.NOTE: probability must lie range 0 1. However, hazard represents expected number events per one unit time.hazard ratio predictor close 1 predictor affect survival,HR less 1, predictor protective (.e., associated improved survival),HR greater 1, predictor associated increased risk (decreased survival).","code":""},{"path":"survival-analysis.html","id":"fitting-a-cox-model","chapter":"27 Phân tích sống còn","heading":"Fitting a Cox model","text":"can first fit model assess effect age gender survival. just printing model, information :estimated regression coefficients coef quantifies association predictors outcome,exponential (interpretability, exp(coef)) produces hazard ratio,standard error se(coef),z-score: many standard errors estimated coefficient away 0,p-value: probability estimated coefficient 0.summary() function applied cox model object gives information, confidence interval estimated HR different test scores.effect first covariate gender presented first row. genderm (male) printed, implying first strata level (“f”), .e female group, reference group gender. Thus interpretation test parameter men compared women. p-value indicates enough evidence effect gender expected hazard association gender -cause mortality.lack evidence noted regarding age-group.interesting run model look results first look verify whether proportional hazards assumptions respected help saving time.NOTE: second argument called method can specified computing cox model, determines ties handled. default “efron”, options “breslow” “exact”.another model add risk factors source infection number days date onset admission. time, first verify proportional hazards assumption going forward.model, included continuous predictor (days_onset_hosp). case interpret parameter estimates increase expected log relative hazard one unit increase predictor, holding predictors constant. first verify proportional hazards assumption.graphical verification assumption may performed function ggcoxzph() survminer package.model results indicate negative association onset admission duration -cause mortality. expected hazard 0.9 times lower person one day later admitted another, holding gender constant. straightforward explanation, one unit increase duration onset admission associated 10.7% (coef *100) decrease risk death.Results show also positive association source infection -cause mortality. say increased risk death (1.21x) patients got source infection funerals.can verify relationship table:need consider investigate association exists data. One possible explanation patients live long enough admitted later less severe disease begin . Another perhaps likely explanation since used simulated fake dataset, pattern reflect reality!","code":"\n#fitting the cox model\nlinelistsurv_cox_sexage <-  survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#printing the model fitted\nlinelistsurv_cox_sexage## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##                       coef exp(coef) se(coef)      z     p\n## genderm           -0.03149   0.96900  0.04767 -0.661 0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n## \n## Likelihood ratio test=2.8  on 3 df, p=0.4243\n## n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n#summary of the model\nsummary(linelistsurv_cox_sexage)## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##   n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n## \n##                       coef exp(coef) se(coef)      z Pr(>|z|)\n## genderm           -0.03149   0.96900  0.04767 -0.661    0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n## \n##                   exp(coef) exp(-coef) lower .95 upper .95\n## genderm               0.969     1.0320    0.8826     1.064\n## age_cat_small5-19     1.099     0.9103    0.9680     1.247\n## age_cat_small20+      1.052     0.9509    0.9176     1.205\n## \n## Concordance= 0.514  (se = 0.007 )\n## Likelihood ratio test= 2.8  on 3 df,   p=0.4\n## Wald test            = 2.78  on 3 df,   p=0.4\n## Score (logrank) test = 2.78  on 3 df,   p=0.4\ntest_ph_sexage <- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage##               chisq df    p\n## gender        0.454  1 0.50\n## age_cat_small 0.838  2 0.66\n## GLOBAL        1.399  3 0.71\n#fit the model\nlinelistsurv_cox <-  coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#test the proportional hazard model\nlinelistsurv_ph_test <- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test##                    chisq df       p\n## gender           0.45062  1    0.50\n## age_years        0.00199  1    0.96\n## source           1.79622  1    0.18\n## days_onset_hosp 31.66167  1 1.8e-08\n## GLOBAL          34.08502  4 7.2e-07\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n#print the summary of the model\nsummary(linelistsurv_cox)## Call:\n## coxph(formula = Surv(futime, event) ~ gender + age_years + source + \n##     days_onset_hosp, data = linelist_surv)\n## \n##   n= 2772, number of events= 1180 \n##    (1767 observations deleted due to missingness)\n## \n##                      coef exp(coef)  se(coef)      z Pr(>|z|)    \n## genderm          0.004710  1.004721  0.060827  0.077   0.9383    \n## age_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \n## sourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \n## days_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                 exp(coef) exp(-coef) lower .95 upper .95\n## genderm            1.0047     0.9953    0.8918    1.1319\n## age_years          0.9978     1.0023    0.9930    1.0025\n## sourceother        1.1953     0.8366    1.0133    1.4100\n## days_onset_hosp    0.9012     1.1097    0.8764    0.9267\n## \n## Concordance= 0.566  (se = 0.009 )\n## Likelihood ratio test= 71.31  on 4 df,   p=1e-14\n## Wald test            = 59.22  on 4 df,   p=4e-12\n## Score (logrank) test = 59.54  on 4 df,   p=4e-12\nlinelist_case_data %>% \n  tabyl(days_onset_hosp, outcome) %>% \n  adorn_percentages() %>%  \n  adorn_pct_formatting()##  days_onset_hosp Death Recover   NA_\n##                0 44.3%   31.4% 24.3%\n##                1 46.6%   32.2% 21.2%\n##                2 43.0%   32.8% 24.2%\n##                3 45.0%   32.3% 22.7%\n##                4 41.5%   38.3% 20.2%\n##                5 40.0%   36.2% 23.8%\n##                6 32.2%   48.7% 19.1%\n##                7 31.8%   38.6% 29.5%\n##                8 29.8%   38.6% 31.6%\n##                9 30.3%   51.5% 18.2%\n##               10 16.7%   58.3% 25.0%\n##               11 36.4%   45.5% 18.2%\n##               12 18.8%   62.5% 18.8%\n##               13 10.0%   60.0% 30.0%\n##               14 10.0%   50.0% 40.0%\n##               15 28.6%   42.9% 28.6%\n##               16 20.0%   80.0%  0.0%\n##               17  0.0%  100.0%  0.0%\n##               18  0.0%  100.0%  0.0%\n##               22  0.0%  100.0%  0.0%\n##               NA 52.7%   31.2% 16.0%"},{"path":"survival-analysis.html","id":"forest-plots","chapter":"27 Phân tích sống còn","heading":"Forest plots","text":"can visualize results cox model using practical forest plots ggforest() function survminer package.","code":"\nggforest(linelistsurv_cox, data = linelist_surv)"},{"path":"survival-analysis.html","id":"time-dependent-covariates-in-survival-models","chapter":"27 Phân tích sống còn","heading":"27.6 Time-dependent covariates in survival models","text":"following sections adapted permission excellent introduction survival analysis R Dr. Emily ZaborIn last section covered using Cox regression examine associations covariates interest survival outcomes.analyses rely covariate measured baseline, , follow-time event begins.happens interested covariate measured follow-time begins? , covariate can change time?example, maybe working clinical data repeated measures hospital laboratory values can change time. example Time Dependent Covariate. order address need special setup, fortunately cox model flexible type data can also modeled tools survival package.","code":""},{"path":"survival-analysis.html","id":"time-dependent-covariate-setup","chapter":"27 Phân tích sống còn","heading":"Time-dependent covariate setup","text":"Analysis time-dependent covariates R requires setup special dataset. interested, see detailed paper author survival package Using Time Dependent Covariates Time Dependent Coefficients Cox Model., ’ll use new dataset SemiCompRisks package named BMT, includes data 137 bone marrow transplant patients. variables ’ll focus :T1 - time (days) death last follow-updelta1 - death indicator; 1-Dead, 0-AliveTA - time (days) acute graft-versus-host diseasedeltaA - acute graft-versus-host disease indicator;\n1 - Developed acute graft-versus-host disease\n0 - Never developed acute graft-versus-host disease\n1 - Developed acute graft-versus-host disease0 - Never developed acute graft-versus-host diseaseWe’ll load dataset survival package using base R command data(), can used loading data already included R package loaded. data frame BMT appear R environment.","code":"\ndata(BMT, package = \"SemiCompRisks\")"},{"path":"survival-analysis.html","id":"add-unique-patient-identifier","chapter":"27 Phân tích sống còn","heading":"Add unique patient identifier","text":"unique ID column BMT data, needed create type dataset want. use function rowid_to_column() tidyverse package tibble create new id column called my_id (adds column start data frame sequential row ids, starting 1). name data frame bmt.dataset now looks like :","code":"\nbmt <- rowid_to_column(BMT, \"my_id\")"},{"path":"survival-analysis.html","id":"expand-patient-rows","chapter":"27 Phân tích sống còn","heading":"Expand patient rows","text":"Next, ’ll use tmerge() function event() tdc() helper functions create restructured dataset. goal restructure dataset create separate row patient time interval different value deltaA. case, patient can two rows depending whether developed acute graft-versus-host disease data collection period. ’ll call new indicator development acute graft-versus-host disease agvhd.tmerge() creates long dataset multiple time intervals different covariate values patientevent() creates new event indicator go newly-created time intervalstdc() creates time-dependent covariate column, agvhd, go newly created time intervalsTo see , let’s look data first 5 individual patients.variables interest original data looked like :new dataset patients looks like :Now patients two rows dataset corresponding intervals different value new variable, agvhd. example, Patient 1 now two rows agvhd value zero time 0 time 67, value 1 time 67 time 2081.","code":"\ntd_dat <- \n  tmerge(\n    data1 = bmt %>% select(my_id, T1, delta1), \n    data2 = bmt %>% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\nbmt %>% \n  select(my_id, T1, delta1, TA, deltaA) %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1   TA deltaA\n## 1     1 2081      0   67      1\n## 2     2 1602      0 1602      0\n## 3     3 1496      0 1496      0\n## 4     4 1462      0   70      1\n## 5     5 1433      0 1433      0\ntd_dat %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1 id tstart tstop death agvhd\n## 1     1 2081      0  1      0    67     0     0\n## 2     1 2081      0  1     67  2081     0     1\n## 3     2 1602      0  2      0  1602     0     0\n## 4     3 1496      0  3      0  1496     0     0\n## 5     4 1462      0  4      0    70     0     0\n## 6     4 1462      0  4     70  1462     0     1\n## 7     5 1433      0  5      0  1433     0     0"},{"path":"survival-analysis.html","id":"cox-regression-with-time-dependent-covariates","chapter":"27 Phân tích sống còn","heading":"Cox regression with time-dependent covariates","text":"Now ’ve reshaped data added new time-dependent aghvd variable, let’s fit simple single variable cox regression model. can use coxph() function , just need change Surv() function specify start stop time interval using time1 = time2 = arguments., ’ll visualize cox model results using ggforest() function survminer package.:can see forest plot, confidence interval, p-value, appear strong association death acute graft-versus-host disease context simple model.","code":"\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)## Call:\n## coxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n##     agvhd, data = td_dat)\n## \n##   n= 163, number of events= 80 \n## \n##         coef exp(coef) se(coef)    z Pr(>|z|)\n## agvhd 0.3351    1.3980   0.2815 1.19    0.234\n## \n##       exp(coef) exp(-coef) lower .95 upper .95\n## agvhd     1.398     0.7153    0.8052     2.427\n## \n## Concordance= 0.535  (se = 0.024 )\n## Likelihood ratio test= 1.33  on 1 df,   p=0.2\n## Wald test            = 1.42  on 1 df,   p=0.2\n## Score (logrank) test = 1.43  on 1 df,   p=0.2\nggforest(bmt_td_model, data = td_dat)"},{"path":"survival-analysis.html","id":"resources-14","chapter":"27 Phân tích sống còn","heading":"27.7 Resources","text":"Survival Analysis Part : Basic concepts first analysesSurvival Analysis RSurvival analysis infectious disease research: Describing events timeChapter advanced survival models PrincetonUsing Time Dependent Covariates Time Dependent Coefficients Cox ModelSurvival analysis cheatsheet RSurvminer cheatsheetPaper different survival measures cancer registry data Rcode provided supplementary materials","code":""},{"path":"gis.html","id":"gis","chapter":"28 GIS cơ bản","heading":"28 GIS cơ bản","text":"","code":""},{"path":"gis.html","id":"overview-5","chapter":"28 GIS cơ bản","heading":"28.1 Overview","text":"Spatial aspects data can provide lot insights situation outbreak, answer questions :current disease hotspots?hotspots changed time?access health facilities? improvements needed?current focus GIS page address needs applied epidemiologists outbreak response. explore basic spatial data visualization methods using tmap ggplot2 packages. also walk basic spatial data management querying methods sf package. Lastly, briefly touch upon concepts spatial statistics spatial relationships, spatial autocorrelation, spatial regression using spdep package.","code":""},{"path":"gis.html","id":"key-terms","chapter":"28 GIS cơ bản","heading":"28.2 Key terms","text":"introduce key terminology. thorough introduction GIS spatial analysis, suggest review one longer tutorials courses listed References section.Geographic Information System (GIS) - GIS framework environment gathering, managing, analyzing, visualizing spatial data.","code":""},{"path":"gis.html","id":"gis-software","chapter":"28 GIS cơ bản","heading":"GIS software","text":"popular GIS software allow point--click interaction map development spatial analysis. tools comes advantages needing learn code ease manually selecting placing icons features map. two popular ones:ArcGIS - commercial GIS software developed company ESRI, popular quite expensiveQGIS - free open-source GIS software can almost anything ArcGIS can . can download QGIS hereUsing R GIS can seem intimidating first instead “point--click”, “command-line interface” (must code acquire desired outcome). However, major advantage need repetitively produce maps create analysis reproducible.","code":""},{"path":"gis.html","id":"spatial-data","chapter":"28 GIS cơ bản","heading":"Spatial data","text":"two primary forms spatial data used GIS vector raster data:Vector Data - common format spatial data used GIS, vector data comprised geometric features vertices paths. Vector spatial data can divided three widely-used types:Points - point consists coordinate pair (x,y) representing specific location coordinate system. Points basic form spatial data, may used denote case (.e. patient home) location (.e. hospital) map.Points - point consists coordinate pair (x,y) representing specific location coordinate system. Points basic form spatial data, may used denote case (.e. patient home) location (.e. hospital) map.Lines - line composed two connected points. Lines length, may used denote things like roads rivers.Lines - line composed two connected points. Lines length, may used denote things like roads rivers.Polygons - polygon composed least three line segments connected points. Polygon features length (.e. perimeter area) well area measurement. Polygons may used note area (.e. village) structure (.e. actual area hospital).Polygons - polygon composed least three line segments connected points. Polygon features length (.e. perimeter area) well area measurement. Polygons may used note area (.e. village) structure (.e. actual area hospital).Raster Data - alternative format spatial data, raster data matrix cells (e.g. pixels) cell containing information height, temperature, slope, forest cover, etc. often aerial photographs, satellite imagery, etc. Rasters can also used “base maps” vector data.","code":""},{"path":"gis.html","id":"visualizing-spatial-data","chapter":"28 GIS cơ bản","heading":"Visualizing spatial data","text":"visually represent spatial data map, GIS software requires provide sufficient information different features , relation one another. using vector data, true use cases, information typically stored shapefile:Shapefiles - shapefile common data format storing “vector” spatial data consisting lines, points, polygons. single shapefile actually collection least three files - .shp, .shx, .dbf. sub-component files must present given directory (folder) shapefile readable. associated files can compressed ZIP folder sent via email download website.shapefile contain information features , well locate Earth’s surface. important Earth globe, maps typically two-dimensional; choices “flatten” spatial data can big impact look interpretation resulting map.Coordinate Reference Systems (CRS) - CRS coordinate-based system used locate geographical features Earth’s surface. key components:Coordinate System - many many different coordinate systems, make sure know system coordinates . Degrees latitude/longitude common, also see UTM coordinates.Coordinate System - many many different coordinate systems, make sure know system coordinates . Degrees latitude/longitude common, also see UTM coordinates.Units - Know units coordinate system (e.g. decimal degrees, meters)Units - Know units coordinate system (e.g. decimal degrees, meters)Datum - particular modeled version Earth. revised years, ensure map layers using datum.Datum - particular modeled version Earth. revised years, ensure map layers using datum.Projection - reference mathematical equation used project truly round earth onto flat surface (map).Projection - reference mathematical equation used project truly round earth onto flat surface (map).Remember can summarise spatial data without using mapping tools shown . Sometimes simple table geography (e.g. district, country, etc.) needed!","code":""},{"path":"gis.html","id":"getting-started-with-gis","chapter":"28 GIS cơ bản","heading":"28.3 Getting started with GIS","text":"couple key items need think make map. include:dataset – can spatial data format (shapefiles, noted ) may spatial format (instance just csv).dataset – can spatial data format (shapefiles, noted ) may spatial format (instance just csv).dataset spatial format also need reference dataset. Reference data consists spatial representation data related attributes, include material containing location address information specific features.\nworking pre-defined geographic boundaries (example, administrative regions), reference shapefiles often freely available download government agency data sharing organization. doubt, good place start Google “[regions] shapefile”\naddress information, latitude longitude, may need use geocoding engine get spatial reference data records.\ndataset spatial format also need reference dataset. Reference data consists spatial representation data related attributes, include material containing location address information specific features.working pre-defined geographic boundaries (example, administrative regions), reference shapefiles often freely available download government agency data sharing organization. doubt, good place start Google “[regions] shapefile”working pre-defined geographic boundaries (example, administrative regions), reference shapefiles often freely available download government agency data sharing organization. doubt, good place start Google “[regions] shapefile”address information, latitude longitude, may need use geocoding engine get spatial reference data records.address information, latitude longitude, may need use geocoding engine get spatial reference data records.idea want present information datasets target audience. many different types maps, important think type map best fits needs.idea want present information datasets target audience. many different types maps, important think type map best fits needs.","code":""},{"path":"gis.html","id":"types-of-maps-for-visualizing-your-data","chapter":"28 GIS cơ bản","heading":"Types of maps for visualizing your data","text":"Choropleth map - type thematic map colors, shading, patterns used represent geographic regions relation value attribute. instance larger value indicated darker colour smaller value. type map particularly useful visualizing variable changes across defined regions geopolitical areas.Case density heatmap - type thematic map colours used represent intensity value, however, use defined regions geopolitical boundaries group data. type map typically used showing ‘hot spots’ areas high density concentration points.Dot density map - thematic map type uses dots represent attribute values data. type map best used visualize scatter data visually scan clusters.Proportional symbols map (graduated symbols map) - thematic map similar choropleth map, instead using colour indicate value attribute uses symbol (usually circle) relation value. instance larger value indicated larger symbol smaller value. type map best used want visualize size quantity data across geographic regions.can also combine several different types visualizations show complex geographic patterns. example, cases (dots) map colored according closest health facility (see legend). large red circles show health facility catchment areas certain radius, bright red case-dots outside catchment range:Note: primary focus GIS page based context field outbreak response. Therefore contents page cover basic spatial data manipulations, visualizations, analyses.","code":""},{"path":"gis.html","id":"preparation-14","chapter":"28 GIS cơ bản","heading":"28.4 Preparation","text":"","code":""},{"path":"gis.html","id":"load-packages-14","chapter":"28 GIS cơ bản","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.can see overview R packages deal spatial data CRAN “Spatial Task View”.","code":"\npacman::p_load(\n  rio,           # to import data\n  here,          # to locate files\n  tidyverse,     # to clean, handle, and plot the data (includes ggplot2 package)\n  sf,            # to manage spatial data using a Simple Feature format\n  tmap,          # to produce simple maps, works for both interactive and static maps\n  janitor,       # to clean column names\n  OpenStreetMap, # to add OSM basemap in ggplot map\n  spdep          # spatial statistics\n  ) "},{"path":"gis.html","id":"sample-case-data","chapter":"28 GIS cơ bản","heading":"Sample case data","text":"demonstration purposes, work random sample 1000 cases simulated Ebola epidemic linelist dataframe (computationally, working fewer cases easier display handbook). want follow along, click download “clean” linelist (.rds file).Since taking random sample cases, results may look slightly different demonstrated run codes .Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).Next select random sample 1000 rows using sample() base R.Now want convert linelist class dataframe, object class “sf” (spatial features). Given linelist two columns “lon” “lat” representing longitude latitude case’s residence, easy.use package sf (spatial features) function st_as_sf() create new object call linelist_sf. new object looks essentially linelist, columns lon lat designated coordinate columns, coordinate reference system (CRS) assigned points displayed. 4326 identifies coordinates based World Geodetic System 1984 (WGS84) - standard GPS coordinates.original linelist dataframe looks like. demonstration, use column date_onset geometry (constructed longitude latitude fields last column data frame).","code":"\n# import clean case linelist\nlinelist <- import(\"linelist_cleaned.rds\")  \n# generate 1000 random row numbers, from the number of rows in linelist\nsample_rows <- sample(nrow(linelist), 1000)\n\n# subset linelist to keep only the sample rows, and all columns\nlinelist <- linelist[sample_rows,]\n# Create sf object\nlinelist_sf <- linelist %>%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )"},{"path":"gis.html","id":"admin-boundary-shapefiles","chapter":"28 GIS cơ bản","heading":"Admin boundary shapefiles","text":"Sierra Leone: Admin boundary shapefilesIn advance, downloaded administrative boundaries Sierra Leone Humanitarian Data Exchange (HDX) website . Alternatively, can download example data handbook via R package, explained [Download handbook data] page.Now going following save Admin Level 3 shapefile R:Import shapefileClean column namesFilter rows keep areas interestTo import shapefile use read_sf() function sf. provided filepath via (). - case file within R project “data”, “gis”, “shp” subfolders, filename “sle_adm3.shp” (see pages [Import export] [R projects] information). need provide file path.Next use clean_names() janitor package standardize column names shapefile. also use filter() keep rows admin2name “Western Area Urban” “Western Area Rural”.can see shapefile looks import cleaning. Scroll right see columns admin level 0 (country), admin level 1, admin level 2, finally admin level 3. level character name unique identifier “pcode”. pcode expands increasing admin level e.g. SL (Sierra Leone) -> SL04 (Western) -> SL0410 (Western Area Rural) -> SL040101 (Koya Rural).","code":"\n# ADM3 level clean\nsle_adm3 <- sle_adm3_raw %>% \n  janitor::clean_names() %>% # standardize column names\n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filter to keep certain areas"},{"path":"gis.html","id":"population-data","chapter":"28 GIS cơ bản","heading":"Population data","text":"Sierra Leone: Population ADM3These data can downloaded HDX (link ) via epirhandbook R package explained [page][Download handbook data]. use import() load .csv file. also pass imported file clean_names() standardize column name syntax.population file looks like. Scroll right see jurisdiction columns male population, female populaton, total population, population break-columns age group.","code":"\n# Population by ADM3\nsle_adm3_pop <- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %>%\n  janitor::clean_names()"},{"path":"gis.html","id":"health-facilities","chapter":"28 GIS cơ bản","heading":"Health Facilities","text":"Sierra Leone: Health facility data OpenStreetMapAgain downloaded locations health facilities HDX via instructions [Download handbook data] page.import facility points shapefile read_sf(), clean column names, filter keep points tagged either “hospital”, “clinic”, “doctors”.resulting dataframe - scroll right see facility name geometry coordinates.","code":"\n# OSM health facility shapefile\nsle_hf <- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %>% \n  janitor::clean_names() %>%\n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))"},{"path":"gis.html","id":"plotting-coordinates","chapter":"28 GIS cơ bản","heading":"28.5 Plotting coordinates","text":"easiest way plot X-Y coordinates (longitude/latitude, points), case cases, draw points directly linelist_sf object created preparation section.package tmap offers simple mapping capabilities static (“plot” mode) interactive (“view” mode) just lines code. tmap syntax similar ggplot2, commands added +. Read detail vignette.Set tmap mode. case use “plot” mode, produces static outputs., points plotted alone.tm_shape() provided linelist_sf objects. add points via tm_dots(), specifying size color. linelist_sf sf object, already designated two columns contain lat/long coordinates coordinate reference system (CRS):Alone, points tell us much. also map administrative boundaries:use tm_shape() (see documentation) instead providing case points shapefile, provide administrative boundary shapefile (polygons).bbox = argument (bbox stands “bounding box”) can specify coordinate boundaries. First show map display without bbox, .now points polygons together:read good comparison mapping options R, see blog post.","code":"\ntmap_mode(\"plot\") # choose either \"view\" or \"plot\"\n# Just the cases (points)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n# Just the administrative boundaries (polygons)\ntm_shape(sle_adm3) +               # admin boundaries shapefile\n  tm_polygons(col = \"#F7F7F7\")+    # show polygons in light grey\n  tm_borders(col = \"#000000\",      # show borders with color and line weight\n             lwd = 2) +\n  tm_text(\"admin3name\")            # column text to display for each polygon\n\n\n# Same as above, but with zoom from bounding box\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # corner\n                  -13.2, 8.5)) +  # corner\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n# All together\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # give title to map"},{"path":"gis.html","id":"spatial-joins","chapter":"28 GIS cơ bản","heading":"28.6 Spatial joins","text":"may familiar joining data one dataset another one. Several methods discussed [Joining data] page handbook. spatial join serves similar purpose leverages spatial relationships. Instead relying common values columns correctly match observations, can utilize spatial relationships, one feature within another, nearest neighbor another, within buffer certain radius another, etc.sf package offers various methods spatial joins. See documentation st_join method spatial join types reference.","code":""},{"path":"gis.html","id":"points-in-polygon","chapter":"28 GIS cơ bản","heading":"Points in polygon","text":"Spatial assign administrative units casesHere interesting conundrum: case linelist contain information administrative units cases. Although ideal collect information initial data collection phase, can also assign administrative units individual cases based spatial relationships (.e. point intersects polygon)., spatially intersect case locations (points) ADM3 boundaries (polygons):Begin linelist (points)Spatial join boundaries, setting type join “st_intersects”Use select() keep certain new administrative boundary columnsAll columns sle_adms added linelist! case now columns detailing administrative levels falls within. example, want keep two new columns (admin level 3), select() old column names just two additional interest:, just display purposes can see first ten cases admin level 3 (ADM3) jurisdictions attached, based point spatially intersected polygon shapes.Now can describe cases administrative unit - something able spatial join!can also create bar plot case counts administrative unit.example, begin ggplot() linelist_adm, can apply factor functions like fct_infreq() orders bars frequency (see page [Factors] tips).","code":"\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects)\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects) %>% \n  \n  # Keep the old column names and two new admin ones of interest\n  select(names(linelist_sf), admin3name, admin3pcod)\n# Now you will see the ADM3 names attached to each case\nlinelist_adm %>% select(case_id, admin3name, admin3pcod)## Simple feature collection with 1000 features and 3 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -13.27276 ymin: 8.447961 xmax: -13.20636 ymax: 8.491748\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##      case_id     admin3name admin3pcod                   geometry\n## 1407  ec8ee4       West III   SL040208 POINT (-13.25785 8.451962)\n## 4530  e0b275        West II   SL040207 POINT (-13.24706 8.470411)\n## 2223  133f77 Mountain Rural   SL040102 POINT (-13.22366 8.478312)\n## 4405  b796bd        East II   SL040204 POINT (-13.21121 8.477168)\n## 3212  e88337 Mountain Rural   SL040102  POINT (-13.2226 8.463263)\n## 691   864934 Mountain Rural   SL040102 POINT (-13.20902 8.457891)\n## 1426  7fd086        West II   SL040207  POINT (-13.2353 8.468499)\n## 3211  da5dc9      Central I   SL040201 POINT (-13.23112 8.482114)\n## 502   683d70        West II   SL040207  POINT (-13.23872 8.47635)\n## 345   d24777 Mountain Rural   SL040102  POINT (-13.21593 8.46397)\n# Make new dataframe containing counts of cases by administrative unit\ncase_adm3 <- linelist_adm %>%          # begin with linelist with new admin cols\n  as_tibble() %>%                      # convert to tibble for better display\n  group_by(admin3pcod, admin3name) %>% # group by admin unit, both by name and pcode \n  summarise(cases = n()) %>%           # summarize and count rows\n  arrange(desc(cases))                     # arrange in descending order\n\ncase_adm3## # A tibble: 9 x 3\n## # Groups:   admin3pcod [9]\n##   admin3pcod admin3name     cases\n##   <chr>      <chr>          <int>\n## 1 SL040102   Mountain Rural   286\n## 2 SL040208   West III         245\n## 3 SL040207   West II          161\n## 4 SL040204   East II          110\n## 5 SL040201   Central I         59\n## 6 SL040203   East I            56\n## 7 SL040206   West I            42\n## 8 SL040205   East III          22\n## 9 SL040202   Central II        19\nggplot(\n    data = linelist_adm,                       # begin with linelist containing admin unit info\n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # x-axis is admin units, ordered by frequency (reversed)\n  geom_bar()+                                # create bars, height is number of rows\n  coord_flip()+                              # flip X and Y axes for easier reading of adm units\n  theme_classic()+                           # simplify background\n  labs(                                      # titles and labels\n    x = \"Admin level 3\",\n    y = \"Number of cases\",\n    title = \"Number of cases, by adminstative unit\",\n    caption = \"As determined by a spatial join, from 1000 randomly sampled cases from linelist\"\n  )"},{"path":"gis.html","id":"nearest-neighbor","chapter":"28 GIS cơ bản","heading":"Nearest neighbor","text":"Finding nearest health facility / catchment areaIt might useful know health facilities located relation disease hot spots.can use st_nearest_feature join method st_join() function (sf package) visualize closest health facility individual cases.begin shapefile linelist linelist_sfWe spatially join sle_hf, locations health facilities clinics (points)can see (first 50 rows) case now data nearest clinic/hospitalWe can see “Den Clinic” closest health facility ~30% cases.visualize results, can use tmap - time interactive mode easier viewing","code":"\n# Closest health facility to each case\nlinelist_sf_hf <- linelist_sf %>%                  # begin with linelist shapefile  \n  st_join(sle_hf, join = st_nearest_feature) %>%   # data from nearest clinic joined to case data \n  select(case_id, osm_id, name, amenity) %>%       # keep columns of interest, including id, name, type, and geometry of healthcare facility\n  rename(\"nearest_clinic\" = \"name\")                # re-name for clarity\n# Count cases by health facility\nhf_catchment <- linelist_sf_hf %>%   # begin with linelist including nearest clinic data\n  as.data.frame() %>%                # convert from shapefile to dataframe\n  count(nearest_clinic,              # count rows by \"name\" (of clinic)\n        name = \"case_n\") %>%         # assign new counts column as \"case_n\"\n  arrange(desc(case_n))              # arrange in descending order\n\nhf_catchment                         # print to console##                          nearest_clinic case_n\n## 1                            Den Clinic    371\n## 2       Shriners Hospitals for Children    312\n## 3         GINER HALL COMMUNITY HOSPITAL    168\n## 4                             panasonic     61\n## 5 Princess Christian Maternity Hospital     36\n## 6                     ARAB EGYPT CLINIC     24\n## 7                  MABELL HEALTH CENTER     18\n## 8                                  <NA>     10\ntmap_mode(\"view\")   # set tmap mode to interactive  \n\n# plot the cases and clinic points \ntm_shape(linelist_sf_hf) +            # plot cases\n  tm_dots(size=0.08,                  # cases colored by nearest clinic\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # plot clinic facilities in large black dots\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # overlay with name of facility\ntm_view(set.view = c(-13.2284, 8.4699, 13), # adjust zoom (center coords, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cases, colored by nearest clinic\")"},{"path":"gis.html","id":"buffers","chapter":"28 GIS cơ bản","heading":"Buffers","text":"can also explore many cases located within 2.5km (~30 mins) walking distance closest health facility.Note: accurate distance calculations, better re-project sf object respective local map projection system UTM (Earth projected onto planar surface). example, simplicity stick World Geodetic System (WGS84) Geograhpic coordinate system (Earth represented spherical / round surface, therefore units decimal degrees). use general conversion : 1 decimal degree = ~111km.See information map projections coordinate systems esri article. blog talks different types map projection one can choose suitable projection depending area interest context map / analysis.First, create circular buffer radius ~2.5km around health facility. done function st_buffer() tmap. unit map lat/long decimal degrees, “0.02” interpreted. map coordinate system meters, number must provided meters.plot buffer zones , :**Second, intersect buffers cases (points) using st_join() join type st_intersects*. , data buffers joined points intersect .Now can count results: nrow(linelist_sf_hf_2k[.na(linelist_sf_hf_2k$osm_id.y),]) 1000 cases intersect buffer (value missing), live 30 mins walk nearest health facility.can visualize results cases intersect buffer appear red.","code":"\nsle_hf_2k <- sle_hf %>%\n  st_buffer(dist=0.02)       # decimal degrees translating to approximately 2.5km \ntmap_mode(\"plot\")\n# Create circular buffers\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # plot clinic facilities in large red dots\n  tm_dots(size=0.3, col='black')      \n# Intersect the cases with the buffers\nlinelist_sf_hf_2k <- linelist_sf_hf %>%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %>%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %>%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n# Cases which did not get intersected with any of the health facility buffers\nlinelist_sf_hf_2k %>% \n  filter(is.na(osm_id.y)) %>%\n  nrow()## [1] 230\ntmap_mode(\"view\")\n\n# First display the cases in points\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# plot clinic facilities in large black dots\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# Then overlay the health facility buffers in polylines\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# Highlight cases that are not part of any health facility buffers\n# in red dots  \ntm_shape(linelist_sf_hf_2k %>%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# add title  \ntm_layout(title = \"Cases by clinic catchment area\")"},{"path":"gis.html","id":"other-spatial-joins","chapter":"28 GIS cơ bản","heading":"Other spatial joins","text":"Alternative values argument join include (documentation)st_contains_properlyst_containsst_covered_byst_coversst_crossesst_disjointst_equals_exactst_equalsst_is_within_distancest_nearest_featurest_overlapsst_touchesst_within","code":""},{"path":"gis.html","id":"choropleth-maps","chapter":"28 GIS cơ bản","heading":"28.7 Choropleth maps","text":"Choropleth maps can useful visualize data pre-defined area, usually administrative unit health area. outbreak response can help target resource allocation specific areas high incidence rates, example.Now administrative unit names assigned cases (see section spatial joins, ), can start mapping case counts area (choropleth maps).Since also population data ADM3, can add information case_adm3 table created previously.begin dataframe created previous step case_adm3, summary table administrative unit number cases.population data sle_adm3_pop joined using left_join() dplyr basis common values across column admin3pcod case_adm3 dataframe, column adm_pcode sle_adm3_pop dataframe. See page [Joining data]).select() applied new dataframe, keep useful columns - total total populationCases per 10,000 populaton calculated new column mutate()Join table ADM3 polygons shapefile mappingMapping resultsWe can also map incidence rates","code":"\n# Add population data and calculate cases per 10K population\ncase_adm3 <- case_adm3 %>% \n     left_join(sle_adm3_pop,                             # add columns from pop dataset\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %>%  # join based on common values across these two columns\n     select(names(case_adm3), total) %>%                 # keep only important columns, including total population\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # make new column with case rate per 10000, rounded to 3 decimals\n\ncase_adm3                                                # print to console for viewing## # A tibble: 9 x 5\n## # Groups:   admin3pcod [9]\n##   admin3pcod admin3name     cases  total case_10kpop\n##   <chr>      <chr>          <int>  <int>       <dbl>\n## 1 SL040102   Mountain Rural   286  33993       84.1 \n## 2 SL040208   West III         245 210252       11.7 \n## 3 SL040207   West II          161 145109       11.1 \n## 4 SL040204   East II          110  99821       11.0 \n## 5 SL040201   Central I         59  69683        8.47\n## 6 SL040203   East I            56  68284        8.20\n## 7 SL040206   West I            42  60186        6.98\n## 8 SL040205   East III          22 500134        0.44\n## 9 SL040202   Central II        19  23874        7.96\ncase_adm3_sf <- case_adm3 %>%                 # begin with cases & rate by admin unit\n  left_join(sle_adm3, by=\"admin3pcod\") %>%    # join to shapefile data by common column\n  select(objectid, admin3pcod,                # keep only certain columns of interest\n         admin3name = admin3name.x,           # clean name of one column\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %>%                        # keep geometry so polygons can be plotted\n  st_as_sf()                                  # convert to shapefile\n# tmap mode\ntmap_mode(\"plot\")               # view static map\n\n# plot polygons\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # color by number of cases column\n        tm_text(\"admin3name\")   # name display\n# Cases per 10K population\ntmap_mode(\"plot\")             # static viewing mode\n\n# plot\ntm_shape(case_adm3_sf) +                # plot polygons\n  tm_polygons(\"case_10kpop\",            # color by column containing case rate\n              breaks=c(0, 10, 50, 100), # define break points for colors\n              palette = \"Purples\"       # use a purple color palette\n              ) +\n  tm_text(\"admin3name\")                 # display text"},{"path":"gis.html","id":"mapping-with-ggplot2","chapter":"28 GIS cơ bản","heading":"28.8 Mapping with ggplot2","text":"already familiar using ggplot2, can use package instead create static maps data. geom_sf() function draw different objects based features (points, lines, polygons) data. example, can use geom_sf() ggplot() using sf data polygon geometry create choropleth map.illustrate works, can start ADM3 polygons shapefile used earlier. Recall Admin Level 3 regions Sierra Leone:can use left_join() function dplyr add data like map shapefile object. case, going use case_adm3 data frame created earlier summarize case counts administrative region; however, can use approach map data stored data frame.make column chart case counts region, using ggplot2, call geom_col() follows:want use ggplot2 instead make choropleth map case counts, can use similar syntax call geom_sf() function:can customize appearance map using grammar consistent across ggplot2, example:R users comfortable working ggplot2, geom_sf() offers simple direct implementation suitable basic map visualizations. learn , read geom_sf() vignette ggplot2 book.","code":"\nsle_adm3## Simple feature collection with 12 features and 19 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 12 x 20\n##    objectid admin3name  admin3pcod admin3ref_n admin2name admin2pcod admin1name admin1pcod\n##  *    <dbl> <chr>       <chr>      <chr>       <chr>      <chr>      <chr>      <chr>     \n##  1      155 Koya Rural  SL040101   Koya Rural  Western A~ SL0401     Western    SL04      \n##  2      156 Mountain R~ SL040102   Mountain R~ Western A~ SL0401     Western    SL04      \n##  3      157 Waterloo R~ SL040103   Waterloo R~ Western A~ SL0401     Western    SL04      \n##  4      158 York Rural  SL040104   York Rural  Western A~ SL0401     Western    SL04      \n##  5      159 Central I   SL040201   Central I   Western A~ SL0402     Western    SL04      \n##  6      160 East I      SL040203   East I      Western A~ SL0402     Western    SL04      \n##  7      161 East II     SL040204   East II     Western A~ SL0402     Western    SL04      \n##  8      162 Central II  SL040202   Central II  Western A~ SL0402     Western    SL04      \n##  9      163 West III    SL040208   West III    Western A~ SL0402     Western    SL04      \n## 10      164 West I      SL040206   West I      Western A~ SL0402     Western    SL04      \n## 11      165 West II     SL040207   West II     Western A~ SL0402     Western    SL04      \n## 12      167 East III    SL040205   East III    Western A~ SL0402     Western    SL04      \n## # ... with 12 more variables: admin0name <chr>, admin0pcod <chr>, date <date>,\n## #   valid_on <date>, valid_to <date>, shape_leng <dbl>, shape_area <dbl>,\n## #   rowcacode0 <chr>, rowcacode1 <chr>, rowcacode2 <chr>, rowcacode3 <chr>,\n## #   geometry <MULTIPOLYGON [°]>\nsle_adm3_dat <- sle_adm3 %>% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join = retain only if in both data objects\n\nselect(sle_adm3_dat, admin3name.x, cases) # print selected variables to console## Simple feature collection with 9 features and 2 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 9 x 3\n##   admin3name.x   cases                                                            geometry\n##   <chr>          <int>                                                  <MULTIPOLYGON [°]>\n## 1 Mountain Rural   286 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.474296, -13~\n## 2 Central I         59 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.489513, -13.~\n## 3 East I            56 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.494041, -13.~\n## 4 East II          110 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.49186, -13.~\n## 5 Central II        19 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.49146, -13.~\n## 6 West III         245 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.49621, -13.~\n## 7 West I            42 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.493132, -13.~\n## 8 West II          161 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.485505, -13~\n## 9 East III          22 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.485757, -13~\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # reorder x axis by descending 'cases'\n               y=cases)) +                                  # y axis is number of cases by region\n  theme_bw() +\n  labs(                                                     # set figure text\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # angle x-axis labels 45 degrees to fit better\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # set fill to vary by case count variable\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # change color gradient\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # set figure text\n       subtitle = \"Admin level 3\"\n  )"},{"path":"gis.html","id":"basemaps","chapter":"28 GIS cơ bản","heading":"28.9 Basemaps","text":"","code":""},{"path":"gis.html","id":"openstreetmap","chapter":"28 GIS cơ bản","heading":"OpenStreetMap","text":"describe achieve basemap ggplot2 map using OpenStreetMap features. Alternative methods include using ggmap requires free registration Google (details).OpenStreetMap collaborative project create free editable map world. underlying geolocation data (e.g. locations cities, roads, natural features, airports, schools, hospitals, roads etc) considered primary output project.First load OpenStreetMap package, get basemap., create object map, define using function openmap() OpenStreetMap package (documentation). provide following:upperLeft lowerRight Two coordinate pairs specifying limits basemap tile\ncase ’ve put max min linelist rows, map respond dynamically data\ncase ’ve put max min linelist rows, map respond dynamically datazoom = (null determined automatically)type = type basemap - listed several possibilities code currently using first one ([1]) “osm”mergeTiles = chose TRUE basetiles merged oneIf plot basemap right now, using autoplot.OpenStreetMap() OpenStreetMap package, see units axes latitude/longitude coordinates. using different coordinate system. correctly display case residences (stored lat/long), must changed.\nThus, want convert map latitude/longitude openproj() function OpenStreetMap package. provide basemap map also provide Coordinate Reference System (CRS) want. providing “proj.4” character string WGS 1984 projection, can provide CRS ways well. (see page better understand proj.4 string )Now create plot see along axes latitude longitude coordinate. coordinate system converted. Now cases plot correctly overlaid!See tutorials info.","code":"\n# load package\npacman::p_load(OpenStreetMap)\n\n# Fit basemap by range of lat/long coordinates. Choose tile type\nmap <- openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # limits of basemap tile\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\nautoplot.OpenStreetMap(map)\n# Projection WGS84\nmap_latlon <- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n# Plot map. Must use \"autoplot\" in order to work with ggplot\nautoplot.OpenStreetMap(map_latlon)"},{"path":"gis.html","id":"contoured-density-heatmaps","chapter":"28 GIS cơ bản","heading":"28.10 Contoured density heatmaps","text":"describe achieve contoured density heatmap cases, basemap, beginning linelist (one row per case).Create basemap tile OpenStreetMap, described abovePlot cases linelist using latitude longitude columnsConvert points density heatmap stat_density_2d() ggplot2,basemap lat/long coordinates, can plot cases top using lat/long coordinates residence.Building function autoplot.OpenStreetMap() create basemap, ggplot2 functions easily add top, shown geom_point() :\nmap might difficult interpret, especially points overlapping. can instead plot 2d density map using ggplot2 function stat_density_2d(). still using linelist lat/lon coordinates, 2D kernel density estimation performed results displayed contour lines - like topographical map. Read full documentation .","code":"\n# Plot map. Must be autoplotted to work with ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # begin with the basemap\n  geom_point(                                       # add xy points from linelist lon and lat columns \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # drop legend entirely\n  labs(x = \"Longitude\",                             # titles & labels\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")"},{"path":"gis.html","id":"time-series-heatmap","chapter":"28 GIS cơ bản","heading":"Time series heatmap","text":"density heatmap shows cumulative cases. can examine outbreak time space faceting heatmap based month symptom onset, derived linelist.begin linelist, creating new column Year Month onset. format() function base R changes date displayed. case want “YYYY-MM”.Now, simply introduce facetting via ggplot2 density heatmap. facet_wrap() applied, using new column rows. set number facet columns 3 clarity.","code":"\n# Extract month of onset\nlinelist <- linelist %>% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examine the values \ntable(linelist$date_onset_ym, useNA = \"always\")## \n## 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 2015-02 2015-03 \n##       9      15      44      79     196     182     136     101      74      45      54 \n## 2015-04    <NA> \n##      32      33\n# packages\npacman::p_load(OpenStreetMap, tidyverse)\n\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # facet the plot by month-year of onset\n  facet_wrap(~ date_onset_ym, ncol = 4)               "},{"path":"gis.html","id":"spatial-statistics","chapter":"28 GIS cơ bản","heading":"28.11 Spatial statistics","text":"discussion far focused visualization spatial data. cases, may also interested using spatial statistics quantify spatial relationships attributes data. section provide brief overview key concepts spatial statistics, suggest resources helpful explore wish comprehensive spatial analyses.","code":""},{"path":"gis.html","id":"spatial-relationships","chapter":"28 GIS cơ bản","heading":"Spatial relationships","text":"can calculate spatial statistics, need specify relationships features data. many ways conceptualize spatial relationships, simple commonly-applicable model use adjacency - specifically, expect geographic relationship areas share border “neighbour” one another.can quantify adjacency relationships administrative region polygons sle_adm3 data using spdep package. specify queen contiguity, means regions neighbors share least one point along borders. alternative rook contiguity, requires regions share edge - case, irregular polygons, distinction trivial, cases choice queen rook can influential.matrix printed shows relationships 9 regions sle_adm3 data. score 0 indicates two regions neighbors, value 0 indicates neighbor relationship. values matrix scaled region total row weight 1.better way visualize neighbor relationships plotting :used adjacency approach identify neighboring polygons; neighbors identified also sometimes called contiguity-based neighbors. just one way choosing regions expected geographic relationship. common alternative approaches identifying geographic relationships generate distance-based neighbors; briefly, :K-nearest neighbors - Based distance centroids (geographically-weighted center polygon region), select n closest regions neighbors. maximum-distance proximity threshold may also specified. spdep, can use knearneigh() (see documentation).K-nearest neighbors - Based distance centroids (geographically-weighted center polygon region), select n closest regions neighbors. maximum-distance proximity threshold may also specified. spdep, can use knearneigh() (see documentation).Distance threshold neighbors - Select neighbors within distance threshold. spdep, neighbor relationships can identified using dnearneigh() (see documentation).Distance threshold neighbors - Select neighbors within distance threshold. spdep, neighbor relationships can identified using dnearneigh() (see documentation).","code":"\nsle_nb <- spdep::poly2nb(sle_adm3_dat, queen=T) # create neighbors \nsle_adjmat <- spdep::nb2mat(sle_nb)    # create matrix summarizing neighbor relationships\nsle_listw <- spdep::nb2listw(sle_nb)   # create listw (list of weights) object -- we will need this later\n\nsle_nb## Neighbour list object:\n## Number of regions: 9 \n## Number of nonzero links: 30 \n## Percentage nonzero weights: 37.03704 \n## Average number of links: 3.333333\nround(sle_adjmat, digits = 2)##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n## 1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n## 2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n## 3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n## 4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n## 5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n## 6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n## 7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n## 8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n## 9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\n## attr(,\"call\")\n## spdep::nb2mat(neighbours = sle_nb)\nplot(sle_adm3_dat$geometry) +                                           # plot region boundaries\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # add neighbor relationships"},{"path":"gis.html","id":"spatial-autocorrelation","chapter":"28 GIS cơ bản","heading":"Spatial autocorrelation","text":"Tobler’s oft-cited first law geography states “everything related everything else, near things related distant things.” epidemiology, often means risk particular health outcome given region similar neighboring regions far away. concept formalized spatial autocorrelation - statistical property geographic features similar values clustered together space. Statistical measures spatial autocorrelation can used quantify extent spatial clustering data, locate clustering occurs, identify shared patterns spatial autocorrelation distinct variables data. section gives overview common measures spatial autocorrelation calculate R.Moran’s - global summary statistic correlation value variable one region, values variable neighboring regions. Moran’s statistic typically ranges -1 1. value 0 indicates pattern spatial correlation, values closer 1 -1 indicate stronger spatial autocorrelation (similar values close together) spatial dispersion (dissimilar values close together), respectively.example, calculate Moran’s statistic quantify spatial autocorrelation Ebola cases mapped earlier (remember, subset cases simulated epidemic linelist dataframe). spdep package function, moran.test, can calculation us:output moran.test() function shows us Moran statistic round(moran_i$estimate[1],2). indicates presence spatial autocorrelation data - specifically, regions similar numbers Ebola cases likely close together. p-value provided moran.test() generated comparison expectation null hypothesis spatial autocorrelation, can used need report results formal hypothesis test.Local Moran’s - can decompose (global) Moran’s statistic calculated identify localized spatial autocorrelation; , identify specific clusters data. statistic, sometimes called Local Indicator Spatial Association (LISA) statistic, summarizes extent spatial autocorrelation around individual region. can useful finding “hot” “cold” spots map.show example, can calculate map Local Moran’s Ebola case counts used , local_moran() function spdep:Getis-Ord Gi* - another statistic commonly used hotspot analysis; large part, popularity statistic relates use Hot Spot Analysis tool ArcGIS. based assumption typically, difference variable’s value neighboring regions follow normal distribution. uses z-score approach identify regions significantly higher (hot spot) significantly lower (cold spot) values specified variable, compared neighbors.can calculate map Gi* statistic using localG() function spdep:can see, map Getis-Ord Gi* looks slightly different map Local Moran’s produced earlier. reflects method used calculate two statistics slightly different; one use depends specific use case research question interest.Lee’s L test - statistical test bivariate spatial correlation. allows test whether spatial pattern given variable x similar spatial pattern another variable, y, hypothesized related spatially x.give example, let’s test whether spatial pattern Ebola cases simulated epidemic correlated spatial pattern population. start, need population variable sle_adm3 data. can use total variable sle_adm3_pop dataframe loaded earlier.can quickly visualize spatial patterns two variables side side, see whether look similar:Visually, patterns seem dissimilar. can use lee.test() function spdep test statistically whether pattern spatial autocorrelation two variables related. L statistic close 0 correlation patterns, close 1 strong positive correlation (.e. patterns similar), close -1 strong negative correlation (.e. patterns inverse).output shows Lee’s L statistic two variables round(lee_test$estimate[1],2), indicates weak negative correlation. confirms visual assessment pattern cases population related one another, provides evidence spatial pattern cases strictly result population density high-risk areas.Lee L statistic can useful making kinds inferences relationship spatially distributed variables; however, describe nature relationship two variables detail, adjust confounding, spatial regression techniques needed. described briefly following section.","code":"\nmoran_i <-spdep::moran.test(sle_adm3_dat$cases,    # numeric vector with variable of interest\n                            listw=sle_listw)       # listw object summarizing neighbor relationships\n\nmoran_i                                            # print results of Moran's I test## \n##  Moran I test under randomisation\n## \n## data:  sle_adm3_dat$cases  \n## weights: sle_listw    \n## \n## Moran I statistic standard deviate = 1.7437, p-value = 0.04061\n## alternative hypothesis: greater\n## sample estimates:\n## Moran I statistic       Expectation          Variance \n##        0.23541416       -0.12500000        0.04272474\n# calculate local Moran's I\nlocal_moran <- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # variable of interest\n  listw=sle_listw                                  # listw object with neighbor weights\n)\n\n# join results to sf data\nsle_adm3_dat<- cbind(sle_adm3_dat, local_moran)    \n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n# Perform local G analysis\ngetis_ord <- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# join results to sf data\nsle_adm3_dat$getis_ord <- getis_ord\n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\nsle_adm3_dat <- sle_adm3_dat %>% \n  rename(population = total)                          # rename 'total' to 'population'\ntmap_mode(\"plot\")\n\ncases_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + tm_layout(main.title=\"Cases\")\npop_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"population\") + tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # arrange into 2x1 facets\nlee_test <- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # variable 1 to compare\n  y=sle_adm3_dat$population,     # variable 2 to compare\n  listw=sle_listw                # listw object with neighbor weights\n)\n\nlee_test## \n##  Lee's L statistic randomisation\n## \n## data:  sle_adm3_dat$cases ,  sle_adm3_dat$population \n## weights: sle_listw  \n## \n## Lee's L statistic standard deviate = -0.86315, p-value = 0.806\n## alternative hypothesis: greater\n## sample estimates:\n## Lee's L statistic       Expectation          Variance \n##       -0.13346361       -0.03757913        0.01234022"},{"path":"gis.html","id":"spatial-regression","chapter":"28 GIS cơ bản","heading":"Spatial regression","text":"may wish make statistical inferences relationships variables spatial data. cases, useful consider spatial regression techniques - , approaches regression explicitly consider spatial organization units data. reasons may need consider spatial regression models, rather standard regression models GLMs, include:Standard regression models assume residuals independent one another. presence strong spatial autocorrelation, residuals standard regression model likely spatially autocorrelated well, thus violating assumption. can lead problems interpreting model results, case spatial model preferred.Standard regression models assume residuals independent one another. presence strong spatial autocorrelation, residuals standard regression model likely spatially autocorrelated well, thus violating assumption. can lead problems interpreting model results, case spatial model preferred.Regression models also typically assume effect variable x constant observations. case spatial heterogeneity, effects wish estimate may vary space, may interested quantifying differences. case, spatial regression models offer flexibility estimating interpreting effects.Regression models also typically assume effect variable x constant observations. case spatial heterogeneity, effects wish estimate may vary space, may interested quantifying differences. case, spatial regression models offer flexibility estimating interpreting effects.details spatial regression approaches beyond scope handbook. section instead provide overview common spatial regression models uses, refer references may use wish explore area .Spatial error models - models assume error terms across spatial units correlated, case data violate assumptions standard OLS model. Spatial error models also sometimes referred simultaneous autoregressive (SAR) models. can fit using errorsarlm() function spatialreg package (spatial regression functions used part spdep).Spatial lag models - models assume dependent variable region influenced value independent variables , also values variables regions neighboring . Like spatial error models, spatial lag models also sometimes described simultaneous autoregressive (SAR) models. can fit using lagsarlm() function spatialreg package.spdep package contains several useful diagnostic tests deciding standard OLS, spatial lag, spatial error models. tests, called Lagrange Multiplier diagnostics, can used identify type spatial dependence data choose model appropriate. function lm.LMtests() can used calculate Lagrange Multiplier tests. Anselin (1988) also provides useful flow chart tool decide spatial regression model use based results Lagrange Multiplier tests:Bayesian hierarchical models - Bayesian approaches commonly used applications spatial analysis, commonly disease mapping. preferred cases case data sparsely distributed (example, case rare outcome) statistically “noisy”, can used generate “smoothed” estimates disease risk accounting underlying latent spatial process. may improve quality estimates. also allow investigator pre-specification (via choice prior) complex spatial correlation patterns may exist data, can account spatially-dependent -independent variation independent dependent variables. R, Bayesian hierarchical models can fit using CARbayes package (see vignette) R-INLA (see website textbook). R can also used call external software Bayesian estimation, JAGS WinBUGS.","code":""},{"path":"gis.html","id":"resources-15","chapter":"28 GIS cơ bản","heading":"28.12 Resources","text":"R Simple Features sf package vignetteR Simple Features sf package vignetteR tmap package vignetteR tmap package vignetteggmap: Spatial Visualization ggplot2ggmap: Spatial Visualization ggplot2Intro making maps R, overview different packagesIntro making maps R, overview different packagesSpatial Data R (EarthLab course)Spatial Data R (EarthLab course)Applied Spatial Data Analysis R textbookApplied Spatial Data Analysis R textbookSpatialEpiApp - Shiny app downloadable R package, allowing provide data conduct mapping, cluster analysis, spatial statistics.SpatialEpiApp - Shiny app downloadable R package, allowing provide data conduct mapping, cluster analysis, spatial statistics.Introduction Spatial Econometrics R workshopAn Introduction Spatial Econometrics R workshop","code":""},{"path":"tables-presentation.html","id":"tables-presentation","chapter":"29 Trình bày bảng","heading":"29 Trình bày bảng","text":"HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Chương này sẽ trình bày cách chuyển đổi một bảng tóm tắt dữ liệu thành các bảng sẵn sàng cho mục đích trình bày với package flextable. Các bảng này có thể được chèn vào slide powerpoint, trang HTML, tài liệu PDF hoặc Word, v.v.Hãy hiểu rằng trước khi sử dụng flextable, bạn phải tạo bảng tóm tắt dữ liệu dưới dạng một data frame. Sử dụng các phương pháp trong các chương Bảng mô tả và Xoay trục dữ liệu như tạo bảng đơn, tạo bảng chéo, xoay trục, và tính toán các thống kê mô tả. Kết quả là một data frame sau đó có thể được chuyển đến flextable để định dạng hiển thị.Có nhiều các R packages khác có thể được sử dụng để tạo bảng cho mục đích trình bày - trong chương này chúng tôi nhấm mạnh vào package flextable. Một ví dụ sử dụng knitr package và hàm của nó kable() có thể được tìm thấy trong chương Truy vết tiếp xúc. Tương tự như vậy, package DT cũng được nhấn mạnh trong chương Dashboards với Shiny. Các package khác như GT và huxtable được đề cập trong chương Package đề xuất.","code":""},{"path":"tables-presentation.html","id":"chuẩn-bị-4","chapter":"29 Trình bày bảng","heading":"29.1 Chuẩn bị","text":"","code":""},{"path":"tables-presentation.html","id":"gọi-packages-3","chapter":"29 Trình bày bảng","heading":"Gọi packages","text":"Hãy cài đặt và gọi package flextable. Trong sổ tay này chúng tôi nhấn mạnh việc sử dụng hàm p_load() từ package pacman, giúp cài đặt package nếu cần thiết và gọi chúng ra để sử dụng. Bạn cũng có thể gọi package bằng lệnh library() từ base R. Xem thêm chương R cơ bản để biết thêm các thông tin về các package trong R.","code":"\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization"},{"path":"tables-presentation.html","id":"nhập-dữ-liệu-3","chapter":"29 Trình bày bảng","heading":"Nhập dữ liệu","text":"Để bắt đầu, chúng ta nhập bộ dữ liệu linelist đã được làm sạch về các ca bệnh Ebola mô phỏng. Để tiện theo dõi, bấm để tải dữ liệu linelist “đã làm sạch” (.rds file). Nhập dữ liệu bằng hàm import() từ package rio (chấp nhận nhiều loại tập tin như .xlsx, .csv, .rds - xem thêm chương Nhập xuất dữ liệu để biết thêm chi tiết).50 hàng đầu tiên của bộ dữ liệu linelist được hiển thị như dưới đây.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"tables-presentation.html","id":"chuẩn-bị-bảng","chapter":"29 Trình bày bảng","heading":"Chuẩn bị bảng","text":"Trước khi bắt đầu sử dụng flextable bạn cần phải tạo bảng của bạn dưới một data frame. Xem chương Bảng mô tả và Xoay trục dữ liệu để biết cách tạo một data frame sử dụng các packages như janitor và dplyr. Đầu tiên, bạn phải sắp xếp nội dung theo hàng và cột như cách bạn muốn nội dung hiển thị. Sau đó, data frame sẽ được chuyển đến flextable để hiển thị nó với màu sắc, tiêu đề, phông chữ, v.v.Dưới đây là một ví dụ trong chương Bảng mô tả về cách biến đổi các trường hợp bệnh trong linelist thành một data frame để tóm tắt các outcomes của bệnh nhân và giá trị CT theo bệnh viện, với hàng Tổng ở cuối bảng. Đầu ra được lưu dưới dạng table.","code":"\ntable <- linelist %>% \n  \n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known)                                    # Arrange rows from lowest to highest (Total row at bottom)\n\ntable  # print## # A tibble: 7 x 8\n## # Groups:   hospital [7]\n##   hospital N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death ct_value_Death\n##   <chr>      <int>     <int> <chr>                  <dbl>   <int> <chr>              <dbl>\n## 1 St. Mar~     325       126 38.8%                     22     199 61.2%                 22\n## 2 Central~     358       165 46.1%                     22     193 53.9%                 22\n## 3 Other        685       290 42.3%                     21     395 57.7%                 22\n## 4 Militar~     708       309 43.6%                     22     399 56.4%                 21\n## 5 Missing     1125       514 45.7%                     21     611 54.3%                 21\n## 6 Port Ho~    1364       579 42.4%                     21     785 57.6%                 22\n## 7 Total       3440      1469 42.7%                     22    1971 57.3%                 22"},{"path":"tables-presentation.html","id":"cơ-bản-về-flextable","chapter":"29 Trình bày bảng","heading":"29.2 Cơ bản về flextable","text":"","code":""},{"path":"tables-presentation.html","id":"tạo-một-flextable","chapter":"29 Trình bày bảng","heading":"Tạo một flextable","text":"Để tạo và quản lý các đối tượng của flextable, đầu tiên chúng ta đẩy data frame vào hàm flextable(), sau đó lưu kết quả là my_table.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Sau khi thực hiện việc này, chúng ta có thể pipe dần đối tượng my_table thông qua các hàm định dạng flextable khác.Trong trang này để rõ ràng, chúng tôi sẽ lưu bảng ở các bước trung gian vào đối tượng my_table, thêm các hàm flextable theo từng bước. Nếu bạn muốn xem tất cả code từ đầu đến cuối được viết trong một đoạn, hãy xem mục Kết hợp tất cả các code phía dưới đây.Cú pháp chung của mỗi dòng code flextable như sau:function(table, = X, j = X, part = \"X\"), :\n‘function’ có thể là một trong số rất nhiều hàm khác nhau, ví dụ như width() để xác định độ rộng cột, bg() để thiết lập màu nền, align() để điều chỉnh văn bản căn giữa / phải / trái, v.v.\ntable = tên của data frame, có thể bỏ qua nếu như data frame được piping vào trong hàm.\npart = đề cập đến phần nào của bảng mà hàm đang được áp dụng. Ví dụ. “tiêu đề”, “nội dung” hoặc “tất cả”.\n= chỉ định hàng mà hàm sẽ được áp dụng, trong đó ‘X’ là số thứ tự hàng. Nếu nhiều hàng được chọn, ví dụ: từ hàng đầu tiên đến hàng thứ ba, ta có thể viết: = c (1: 3). Lưu ý nếu chọn ‘body’, hàng đầu tiên bắt đầu từ bên dưới phần tiêu đề.\nj = chỉ định cột mà hàm sẽ được áp dụng, trong đó ‘X’ là số thứ tự cột hoặc tên cột. Nếu nhiều cột được chọn, ví dụ: từ hàng thứ năm đến hàng thứ sáu, ta có thể viết: j = c(5,6).\n‘function’ có thể là một trong số rất nhiều hàm khác nhau, ví dụ như width() để xác định độ rộng cột, bg() để thiết lập màu nền, align() để điều chỉnh văn bản căn giữa / phải / trái, v.v.table = tên của data frame, có thể bỏ qua nếu như data frame được piping vào trong hàm.part = đề cập đến phần nào của bảng mà hàm đang được áp dụng. Ví dụ. “tiêu đề”, “nội dung” hoặc “tất cả”.= chỉ định hàng mà hàm sẽ được áp dụng, trong đó ‘X’ là số thứ tự hàng. Nếu nhiều hàng được chọn, ví dụ: từ hàng đầu tiên đến hàng thứ ba, ta có thể viết: = c (1: 3). Lưu ý nếu chọn ‘body’, hàng đầu tiên bắt đầu từ bên dưới phần tiêu đề.j = chỉ định cột mà hàm sẽ được áp dụng, trong đó ‘X’ là số thứ tự cột hoặc tên cột. Nếu nhiều cột được chọn, ví dụ: từ hàng thứ năm đến hàng thứ sáu, ta có thể viết: j = c(5,6).Bạn có thể tìm thấy danh sách đầy đủ các hàm định dạng trong package flextable tại đây hoặc xem tài liệu hướng dẫn bằng cách gõ ?flextable.","code":"\nmy_table <- flextable(table) \nmy_table"},{"path":"tables-presentation.html","id":"độ-rộng-cột","chapter":"29 Trình bày bảng","heading":"Độ rộng cột","text":"Chúng ta có thể sử dụng hàm autofit() để điều chỉnh bảng sao cho mỗi ô chỉ có một hàng văn bản. Hàm qflextable() là một cách viết tắt thuận tiện cho flextable() và autofit().hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Tuy nhiên, điều này có thể không phải lúc nào cũng phù hợp, đặc biệt nếu có các giá trị rất dài trong các ô, nghĩa là bảng có thể không vừa trong độ rộng của trang.Thay vào đó, chúng ta có thể điều chỉnh độ rộng cột bằng hàm width(). Điều này có thể tốn một chút thời gian để tìm giá trị chiều rộng phù hợp cho các cột. Trong ví dụ dưới đây, chúng ta chỉ định các độ rộng khác nhau cho cột 1, cột 2 và cột 4 đến 8.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% autofit()\nmy_table <- my_table %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table"},{"path":"tables-presentation.html","id":"tiêu-đề-cột","chapter":"29 Trình bày bảng","heading":"Tiêu đề cột","text":"Một bảng có nhiều tiêu đề cột sẽ giúp giải thích nội dung bảng một cách dễ dàng hơn.Đối với bảng này, chúng ta cần thêm một lớp tiêu đề thứ hai để các cột bao gồm các nhóm con giống nhau có thể được nhóm lại với nhau. Chúng ta thực hiện điều này bằng hàm add_header_row() với top = TRUE. Chúng ta cung cấp tên mới của mỗi cột bằng values =, bỏ trống \"\" đối với các cột chúng ta dự định sẽ ghép lại với nhau sau này.Chúng ta cũng đổi tên các tên tiêu đề phụ ở hàng thứ hai bằng lệnh set_header_labels().Cuối cùng, chúng ta sử dụng hàm merge_at () để hợp nhất các tiêu đề cột trong hàng tiêu đề trên cùng.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  \n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %>% \n    \n  set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Horizontally merge columns 6 to 8 in new header row\n\nmy_table  # print"},{"path":"tables-presentation.html","id":"đường-viền-và-nền","chapter":"29 Trình bày bảng","heading":"Đường viền và nền","text":"Bạn có thể điều chỉnh đường viền, đường bên trong, v.v. bằng các hàm khác nhau trong flextable. Để dễ dàng, thông thường đầu tiên bạn cần loại bỏ hết các đường viền trong bảng bằng hàm border_remove().Sau đó, bạn có thể áp dụng các theme đường viền mặc định bằng cách đưa bảng tới hàm theme_box(), theme_booktabs(), hoặc theme_alafoli().Bạn có thể thêm các đường dọc và ngang bằng nhiều hàm khác nhau. hline() và vline() sẽ thêm các dòng vào một hàng hoặc cột cụ thể. Bên trong hàm, bạn cần chỉ định phần mà bảng sẽ áp dụng qua đối số part = với các tùy chọn “”, “body”, hoặc “header”. Đối với các đường dọc, ghi rõ cột được áp dụng với j =, đối với các đường ngang, ghi rõ hàng được áp dụng với =. Các hàm khác như vline_right(), vline_left(), hline_top(), và hline_bottom() chỉ thêm các đường viền ở bên ngoài.Bên trong tất cả các hàm này, kiểu đường phải được định nghĩa thông qua đối số border = và phải là đầu ra của một lệnh riêng biệt bằng cách sử dụng hàm fp_border() từ package officer. Hàm này giúp bạn xác định độ rộng và màu sắc của đường. Bạn có thể định nghĩa các thông tin này phía trên trước khi thực hiện các lệnh liên quan tới bảng, như được trình bày dưới đây:HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\n# define style for border line\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# add border lines to table\nmy_table <- my_table %>% \n\n  # Remove all existing borders\n  border_remove() %>%  \n  \n  # add horizontal lines via a pre-determined theme setting\n  theme_booktabs() %>% \n  \n  # add vertical lines to separate Recovered and Died sections\n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style)       # at column 5\n\nmy_table"},{"path":"tables-presentation.html","id":"phông-chữ-và-căn-chỉnh","chapter":"29 Trình bày bảng","heading":"Phông chữ và căn chỉnh","text":"Chúng ta căn giữa tất cả các cột ngoại trừ cột ngoài cùng bên trái với tên các bệnh viện, bằng cách sử dụng hàm align() từ flextable.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Ngoài ra, chúng ta có thể tăng kích thước phông chữ tiêu đề và sau đó thay đổi thành đậm. Chúng ta cũng có thể thay đổi hàng “Total” thành đậm.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Chúng ta cũng có thể thiết lập để các cột tỷ lệ chỉ hiển thị một chữ số thập phân bằng cách sử dụng hàm colformat_num(). Lưu ý rằng điều này cũng có thể được thực hiện ở giai đoạn quản lý dữ liệu với hàm round().HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\nmy_table <-  my_table %>%  \n  fontsize(i = 1, size = 12, part = \"header\") %>%   # adjust font size of header\n  bold(i = 1, bold = TRUE, part = \"header\") %>%     # adjust bold face of header\n  bold(i = 7, bold = TRUE, part = \"body\")           # adjust bold face of total row (row 7 of body)\n\nmy_table\nmy_table <- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table"},{"path":"tables-presentation.html","id":"hợp-nhất-ô","chapter":"29 Trình bày bảng","heading":"Hợp nhất ô","text":"Cũng giống như khi chúng ta hợp nhất các ô theo chiều ngang trong hàng tiêu đề, chúng ta cũng có thể hợp nhất các ô theo chiều dọc bằng cách sử dụng merge_at() và chỉ rõ các hàng () và cột (j). Ở đây chúng ta hợp nhất ô “Hospital” và “Total cases known outcome” theo chiều dọc để cung cấp thêm không gian cho chúng.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table"},{"path":"tables-presentation.html","id":"màu-nền","chapter":"29 Trình bày bảng","heading":"Màu nền","text":"Để phân biệt nội dung của bảng với các tiêu đề, chúng ta có thể muốn thêm định dạng bổ sung, ví dụ như thay đổi màu nền. Trong ví dụ này, chúng ta sẽ thay đổi nội dung bảng thành màu xám.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table "},{"path":"tables-presentation.html","id":"định-dạng-có-điều-kiện","chapter":"29 Trình bày bảng","heading":"29.3 Định dạng có điều kiện","text":"Chúng ta có thể highlight tất cả các giá trị trong một cột đáp ứng một quy tắc nhất định, ví dụ các ô có hơn 55% trường hợp tử vong. Đơn giản chỉ cần đặt điều kiện sánh vào trong đối số = hoặc j =, phía sau dấu ~. Bạn cần tham chiếu tới thứ tự cột cần highlight trong trong data frame, không phải tiêu đề cột.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Hoặc, chúng ta có thể highlight toàn bộ hàng đáp ứng một tiêu chí nhất định, chẳng hạn như tên một bệnh viện. Để làm điều này đơn giản chỉ cần không định danh thông số ở đối số (j), để các tiêu chí được áp dụng cho tất cả các cột.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% \n  bg(j = 7, i = ~ Pct_Death >= 55, part = \"body\", bg = \"red\") \nmy_table %>% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") "},{"path":"tables-presentation.html","id":"tbl_pres_all","chapter":"29 Trình bày bảng","heading":"29.4 Kết hợp tất cả các code","text":"Dưới đây, chúng tôi ghép tất cả code từ các phần trên lại với nhau.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization\n\ntable <- linelist %>% \n\n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known) %>%                                 # Arrange rows from lowest to highest (Total row at bottom)\n\n  # formatting\n  ############\n  flextable() %>%              # table is piped in from above\n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %>% \n    set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\") %>%  \n  border_remove() %>%  \n  theme_booktabs() %>% \n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style) %>%   # at column 5\n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\") %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1) %>% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %>% \n  bg(., part = \"body\", bg = \"gray95\")  %>% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %>% \n  colformat_num(., j = c(4,7), digits = 1) %>%\n  bold(i = 1, bold = TRUE, part = \"header\") %>% \n  bold(i = 7, bold = TRUE, part = \"body\")## `summarise()` has grouped output by 'hospital'. You can override using the `.groups` argument.\ntable"},{"path":"tables-presentation.html","id":"lưu-bảng-của-bạn","chapter":"29 Trình bày bảng","heading":"29.5 Lưu bảng của bạn","text":"Có nhiều cách khác nhau mà bảng có thể được tích hợp vào kết quả đầu ra của bạn.","code":""},{"path":"tables-presentation.html","id":"lưu-bảng-đơn","chapter":"29 Trình bày bảng","heading":"Lưu bảng đơn","text":"Bạn có thể xuất các bảng ra file Word, PowerPoint hoặc HTML hoặc dưới tệp tin ảnh (PNG). Để thực hiện điều này, hãy sử dụng một trong các hàm sau:save_as_docx()save_as_pptx()save_as_image()save_as_html()Ví dụ dưới đây, chúng ta sẽ lưu bảng dưới dạng tài liệu word. Lưu ý cú pháp của đối số đầu tiên - bạn chỉ có thể cung cấp tên của đối tượng flextable, ví dụ: my_table, hoặc bạn có thể gán một “tên” cho bảng (ví dụ đặt tên là “table”). Nếu đặt tên thì tên này sẽ xuất hiện dưới dạng tiêu đề của bảng trong Word. Code để lưu bảng dưới dạng ảnh PNG cũng được minh họa như dưới đây.Lưu ý là bạn cần cài đặt package webshot hoặc webshot2 để lưu bảng từ flextable dưới dạng ảnh. Hình ảnh xuất ra sẽ có nền trong suốt.Nếu bạn muốn xem thử kết quả đầu ra của bảng flextable , sử dụng lệnh print() và chỉ định định dạng muốn xem trước với preview =. Tài liệu sẽ được “mở lên” trên máy tính của bạn bằng phần mềm đã chỉ định, nhưng sẽ không được lưu. Điều này có thể hữu ích để kiểm tra xem bảng có vừa với một trang/slide hay không hoặc bạn có thể nhanh chóng copy kết quả sang một tài liệu khác. Bạn có thể sử dụng phương pháp này với đối số preview đặt là “pptx” hoặc “docx”.","code":"\n# Edit the 'my table' as needed for the title of table.  \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\nprint(my_table, preview = \"docx\") # Word document example\nprint(my_table, preview = \"pptx\") # Powerpoint example"},{"path":"tables-presentation.html","id":"in-bảng-trong-r-markdown","chapter":"29 Trình bày bảng","heading":"In bảng trong R markdown","text":"Bảng này có thể được tích hợp vào R markdown, một dạng báo cáo tự động của bạn, nếu đối tượng bảng được gọi trong phần code chunk của R markdown. Điều này có nghĩa là bảng có thể được cập nhật như một phần của báo cáo trong đó dữ liệu có thể thay đổi, đó, các con số có thể được làm mới.Xem thêm chi tiết trong chương Báo cáo với R Markdown của cuốn sổ tay này.","code":""},{"path":"tables-presentation.html","id":"nguồn-4","chapter":"29 Trình bày bảng","heading":"29.6 Nguồn","text":"Sách đầy đủ về flextable có thể xem ở đây: https://ardata-fr.github.io/flextable-book/\nTrang Github xem ở đây\nCó thể tìm thấy sách hướng dẫn về tất cả các hàm flextable ở đâyThư viên các ví dụ về mẫu bảng flextable cùng code có thể truy cập tại đây","code":""},{"path":"ggplot-basics.html","id":"ggplot-basics","chapter":"30 ggplot cơ bản","heading":"30 ggplot cơ bản","text":"ggplot2 popular data visualisation R package. ggplot() function core package, whole approach colloquially known “ggplot” resulting figures sometimes affectionately called “ggplots”. “gg” names reflects “grammar graphics” used construct figures. ggplot2 benefits wide variety supplementary R packages enhance functionality.syntax significantly different base R plotting, learning curve associated . Using ggplot2 generally requires user format data way highly tidyverse compatible, ultimately makes using packages together effective.page cover fundamentals plotting ggplot2. See page [ggplot tips] suggestions advanced techniques make plots really look nice.several extensive ggplot2 tutorials linked resources section. can also download data visualization ggplot cheatsheet RStudio website. want inspiration ways creatively visualise data, suggest reviewing websites like R graph gallery Data--viz.","code":""},{"path":"ggplot-basics.html","id":"preparation-15","chapter":"30 ggplot cơ bản","heading":"30.1 Preparation","text":"","code":""},{"path":"ggplot-basics.html","id":"load-packages-15","chapter":"30 ggplot cơ bản","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other data management tools\n  rio,            # import/export\n  here,           # file locator\n  stringr         # working with characters   \n)"},{"path":"ggplot-basics.html","id":"import-data-11","chapter":"30 ggplot cơ bản","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see [Import export] page details).first 50 rows linelist displayed . focus continuous variables age, wt_kg (weight kilos), ct_blood (CT values), days_onset_hosp (difference onset date hospitalisation).","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot-basics.html","id":"general-cleaning","chapter":"30 ggplot cơ bản","heading":"General cleaning","text":"preparing data plot, best make data adhere “tidy” data standards much possible. achieve expanded data management pages handbook, [Cleaning data core functions].simple ways can prepare data make better plotting can include making contents data better display - necessarily equate better data manipulation. example:Replace NA values character column character string “Unknown”Consider converting column class factor values prescribed ordinal levelsClean columns “data friendly” values underscores etc changed normal text title case (see [Characters strings])examples action:","code":"\n# make display version of columns with more friendly names\nlinelist <- linelist %>%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m to Male \n                            gender == \"f\" ~ \"Female\",      # f to Female,\n                            is.na(gender) ~ \"Unknown\"),    # NA to Unknown\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # replace NA outcome with \"unknown\"\n  )"},{"path":"ggplot-basics.html","id":"pivoting-longer","chapter":"30 ggplot cơ bản","heading":"Pivoting longer","text":"matter data structure, ggplot2 often also want pivot data longer formats. Read page [Pivoting data].example, say want plot data “wide” format, case linelist symptoms. create mini-linelist called symptoms_data contains case_id symptoms columns.first 50 rows mini-linelist look - see formatted “wide” symptom column:wanted plot number cases specific symptoms, limited fact symptom specific column. However, can pivot symptoms columns longer format like :first 50 rows. Note case 5 rows - one possible symptom. new columns symptom_name symptom_is_present result pivot. Note format may useful operations, useful plotting.","code":"\nsymptoms_data <- linelist %>% \n  select(c(case_id, fever, chills, cough, aches, vomit))\nsymptoms_data_long <- symptoms_data %>%    # begin with \"mini\" linelist called symptoms_data\n  \n  pivot_longer(\n    cols = -case_id,                       # pivot all columns except case_id (all the symptoms columns)\n    names_to = \"symptom_name\",             # assign name for new column that holds the symptoms\n    values_to = \"symptom_is_present\") %>%  # assign name for new column that holds the values (yes/no)\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # convert NA to \"unknown\""},{"path":"ggplot-basics.html","id":"basics-of-ggplot","chapter":"30 ggplot cơ bản","heading":"30.2 Basics of ggplot","text":"“Grammar graphics” - ggplot2Plotting ggplot2 based “adding” plot layers design elements top one another, command added previous ones plus symbol (+). result multi-layer plot object can saved, modified, printed, exported, etc.ggplot objects can highly complex, basic order layers usually look like :Begin baseline ggplot() command - “opens” ggplot allow subsequent functions added +. Typically dataset also specified commandAdd “geom” layers - functions visualize data geometries (shapes), e.g. bar graph, line plot, scatter plot, histogram (combination!). functions start geom_ prefix.Add design elements plot axis labels, title, fonts, sizes, color schemes, legends, axes rotationA simple example skeleton code follows. explain component sections .","code":"\n# plot data from my_data columns as red points\nggplot(data = my_data)+                   # use the dataset \"my_data\"\n  geom_point(                             # add a layer of points (dots)\n    mapping = aes(x = col1, y = col2),    # \"map\" data column to axes\n    color = \"red\")+                       # other specification for the geom\n  labs()+                                 # here you add titles, axes labels, etc.\n  theme()                                 # here you adjust color, font, size etc of non-data plot elements (axes, title, etc.) "},{"path":"ggplot-basics.html","id":"ggplot","chapter":"30 ggplot cơ bản","heading":"30.3 ggplot()","text":"opening command ggplot2 plot ggplot(). command simply creates blank canvas upon add layers. “opens” way layers added + symbol.Typically, command ggplot() includes data = argument plot. sets default dataset used subsequent layers plot.command end + closing parentheses. leaves command “open”. ggplot execute/appear full command includes final layer without + end.","code":"\n# This will create plot that is a blank canvas\nggplot(data = linelist)"},{"path":"ggplot-basics.html","id":"geoms","chapter":"30 ggplot cơ bản","heading":"30.4 Geoms","text":"blank canvas certainly sufficient - need create geometries (shapes) data (e.g. bar plots, histograms, scatter plots, box plots).done adding layers “geoms” initial ggplot() command. many ggplot2 functions create “geoms”. functions begins “geom_”, refer generically geom_XXXX(). 40 geoms ggplot2 many others created fans. View ggplot2 gallery. common geoms listed :Histograms - geom_histogram()Bar charts - geom_bar() geom_col() (see “Bar plot” section)Box plots - geom_boxplot()Points (e.g. scatter plots) - geom_point()Line graphs - geom_line() geom_path()Trend lines - geom_smooth()one plot can display one multiple geoms. added previous ggplot2 commands +, plotted sequentially later geoms plotted top previous ones.","code":""},{"path":"ggplot-basics.html","id":"ggplot_basics_mapping","chapter":"30 ggplot cơ bản","heading":"30.5 Mapping data to the plot","text":"geom functions must told use create shapes - must tell map (assign) columns data components plot like axes, shape colors, shape sizes, etc. geoms, essential components must mapped columns data x-axis, (necessary) y-axis.“mapping” occurs mapping = argument. mappings provide mapping must wrapped aes() function, write something like mapping = aes(x = col1, y = col2), shown ., ggplot() command data set case linelist. mapping = aes() argument column age mapped x-axis, column wt_kg mapped y-axis.+, plotting commands continue. shape created “geom” function geom_point(). geom inherits mappings ggplot() command - knows axis-column assignments proceeds visualize relationships points canvas.another example, following commands utilize data, slightly different mapping, different geom. geom_histogram() function requires column mapped x-axis, counts y-axis generated automatically.","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()"},{"path":"ggplot-basics.html","id":"plot-aesthetics","chapter":"30 ggplot cơ bản","heading":"Plot aesthetics","text":"ggplot terminology plot “aesthetic” specific meaning. refers visual property plotted data. Note “aesthetic” refers data plotted geoms/shapes - surrounding display titles, axis labels, background color, might associate word “aesthetics” common English. ggplot details called “themes” adjusted within theme() command (see section).Therefore, plot object aesthetics can colors, sizes, transparencies, placement, etc. plotted data. geoms aesthetic options, many can used geoms. examples:shape = Display point geom_point() dot, star, triangle, square…fill = interior color (e.g. bar boxplot)color = exterior line bar, boxplot, etc., point color using geom_point()size = Size (e.g. line thickness, point size)alpha = Transparency (1 = opaque, 0 = invisible)binwidth = Width histogram binswidth = Width “bar plot” columnslinetype = Line type (e.g. solid, dashed, dotted)plot object aesthetics can assigned values two ways:Assigned static value (e.g. color = \"blue\") apply across plotted observationsAssigned column data (e.g. color = hospital) display observation depends value column","code":""},{"path":"ggplot-basics.html","id":"set-to-a-static-value","chapter":"30 ggplot cơ bản","heading":"Set to a static value","text":"want plot object aesthetic static, - every observation data, write assignment within geom outside mapping = aes() statement. assignments look like size = 1 color = \"blue\". two examples:first example, mapping = aes() ggplot() command axes mapped age weight columns data. plot aesthetics color =, size =, alpha = (transparency) assigned static values. clarity, done geom_point() function, may add geoms afterward take different values plot aesthetics.second example, histogram requires x-axis mapped column. histogram binwidth =, color =, fill = (internal color), alpha = set within geom static values.","code":"\n# scatterplot\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # set data and axes mapping\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # set static point aesthetics\n\n# histogram\nggplot(data = linelist, mapping = aes(x = age))+       # set data and axes\n  geom_histogram(              # display histogram\n    binwidth = 7,                # width of bins\n    color = \"red\",               # bin line color\n    fill = \"blue\",               # bin interior color\n    alpha = 0.1)                 # bin transparency"},{"path":"ggplot-basics.html","id":"scaled-to-column-values","chapter":"30 ggplot cơ bản","heading":"Scaled to column values","text":"alternative scale plot object aesthetic values column. approach, display aesthetic depend observation’s value column data. column values continuous, display scale (legend) aesthetic continuous. column values discrete, legend display value plotted data appear distinctly “grouped” (read grouping section page).achieve , map plot aesthetic column name (quotes). must done within mapping = aes() function (note: several places code can make mapping assignments, discussed ).Two examples .first example, color = aesthetic (point) mapped column age - scale appeared legend! now just note scale exists - show modify later sections.second example two new plot aesthetics also mapped columns (color = size =), plot aesthetics shape = alpha = mapped static values outside mapping = aes() function.Note: Axes assignments always assigned columns data (static values), always done within mapping = aes().becomes important keep track plot layers aesthetics making complex plots - example plots multiple geoms. example , size = aesthetic assigned twice - geom_point() geom_smooth() - times static value.","code":"\n# scatterplot\nggplot(data = linelist,   # set data\n       mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age)\n       )+     # map color to age\n  geom_point()         # display data as points \n\n# scatterplot\nggplot(data = linelist,   # set data\n       mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age,       # map color to age\n         size = age))+      # map size to age\n  geom_point(             # display data as points\n    shape = \"diamond\",      # points display as diamonds\n    alpha = 0.3)            # point transparency at 30%\nggplot(data = linelist,\n       mapping = aes(           # map aesthetics to columns\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # add points for each row of data\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # add a trend line \n    method = \"lm\",              # with linear method\n    size = 2)                   # size (width of line) of 2"},{"path":"ggplot-basics.html","id":"ggplot_basics_map_loc","chapter":"30 ggplot cơ bản","heading":"Where to make mapping assignments","text":"Aesthetic mapping within mapping = aes() can written several places plotting commands can even written . can written top ggplot() command, /individual geom beneath. nuances include:Mapping assignments made top ggplot() command inherited defaults across geom , like x = y = inheritedMapping assignments made within one geom apply geomLikewise, data = specified top ggplot() apply default geom , also specify data geom (difficult).Thus, following commands create plot:","code":"\n# These commands will produce the exact same plot\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))"},{"path":"ggplot-basics.html","id":"ggplotgroups","chapter":"30 ggplot cơ bản","heading":"Groups","text":"can easily group data “plot group”. fact, already done !Assign “grouping” column appropriate plot aesthetic, within mapping = aes(). , demonstrated using continuous values assigned point size = column age. However works way discrete/categorical columns.example, want points displayed gender, set mapping = aes(color = gender). legend automatically appears. assignment can made within mapping = aes() top ggplot() command (inherited geom), set separate mapping = aes() within geom. approaches shown :Note depending geom, need use different arguments group data. geom_point() likely use color =, shape = size =. Whereas geom_bar() likely use fill =. just depends geom plot aesthetic want reflect groupings.information - basic way grouping data using group = argument within mapping = aes(). However, change colors, fill, shapes. create legend. Yet data grouped, statistical displays may affected.adjust order groups plot, see [ggplot tips] page page [Factors]. many examples grouped plots sections plotting continuous categorical data.","code":"\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n# This alternative code produces the same plot\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)"},{"path":"ggplot-basics.html","id":"ggplot_basics_facet","chapter":"30 ggplot cơ bản","heading":"30.6 Facets / Small-multiples","text":"Facets, “small-multiples”, used split one plot multi-panel figure, one panel (“facet”) per group data. type plot created multiple times, one using sub-group dataset.Faceting functionality comes ggplot2, legends axes facet “panels” automatically aligned. packages discussed [ggplot tips] page used combine completely different plots (cowplot patchwork) one figure.Faceting done one following ggplot2 functions:facet_wrap() show different panel level single variable. One example showing different epidemic curve hospital region. Facets ordered alphabetically, unless variable factor ordering defined.can invoke certain options determine layout facets, e.g. nrow = 1 ncol = 1 control number rows columns faceted plots arranged within.facet_grid() used want bring second variable faceting arrangement. panel grid shows intersection values two columns. example, epidemic curves hospital-age group combination hospitals along top (columns) age groups along sides (rows).nrow ncol relevant, subgroups presented gridEach functions accept formula syntax specify column(s) faceting. accept two columns, one side tilde ~.facet_wrap() often write one column preceded tilde ~ like facet_wrap(~hospital). However can write two columns facet_wrap(outcome ~ hospital) - unique combination display separate panel, arranged grid. headings show combined terms won’t specific logic columns vs. rows. providing one faceting variable, period . used placeholder side formula - see code examples.facet_wrap() often write one column preceded tilde ~ like facet_wrap(~hospital). However can write two columns facet_wrap(outcome ~ hospital) - unique combination display separate panel, arranged grid. headings show combined terms won’t specific logic columns vs. rows. providing one faceting variable, period . used placeholder side formula - see code examples.facet_grid() can also specify one two columns formula (grid rows ~ columns). want specify one, can place period . side tilde like facet_grid(. ~ hospital) facet_grid(hospital ~ .).facet_grid() can also specify one two columns formula (grid rows ~ columns). want specify one, can place period . side tilde like facet_grid(. ~ hospital) facet_grid(hospital ~ .).Facets can quickly contain overwhelming amount information - good ensure don’t many levels variable choose facet . quick examples malaria dataset (see [Download handbook data]) consists daily case counts malaria facilities, age group.import quick modifications simplicity:first 50 rows malaria data . Note column malaria_tot, also columns counts age group (used second, facet_grid() example).","code":"\n# These data are daily counts of malaria cases, by facility-day\nmalaria_data <- import(here(\"data\", \"malaria_facility_count_data.rds\")) %>%  # import\n  select(-submitted_date, -Province, -newid)                                 # remove unneeded columns"},{"path":"ggplot-basics.html","id":"facet_wrap","chapter":"30 ggplot cơ bản","heading":"facet_wrap()","text":"moment, let’s focus columns malaria_tot District. Ignore age-specific count columns now. plot epidemic curves geom_col(), produces column day specified y-axis height given column malaria_tot (data already daily counts, use geom_col() - see “Bar plot” section ).add command facet_wrap(), specify tilde column facet (District case). can place another column left side tilde, - create one facet combination - recommend facet_grid() instead. use case, one facet created unique value District.","code":"\n# A plot with facets by district\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # plot the count data as columns\n  theme_minimal()+                              # simplify the background panels\n  labs(                                         # add plot labels, title, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # the facets are created"},{"path":"ggplot-basics.html","id":"facet_grid","chapter":"30 ggplot cơ bản","heading":"facet_grid()","text":"can use facet_grid() approach cross two variables. Let’s say want cross District age. Well, need data transformations age columns get data ggplot-preferred “long” format. age groups columns - want single column called age_group another called num_cases. See page [Pivoting data] information process.Now first 50 rows data look like :pass two variables facet_grid(), easiest use formula notation (e.g. x ~ y) x rows y columns. plot, using facet_grid() show plots combination columns age_group District.","code":"\nmalaria_age <- malaria_data %>%\n  select(-malaria_tot) %>% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # choose columns to pivot longer\n    names_to = \"age_group\",      # column names become age group\n    values_to = \"num_cases\"      # values to a single column (num_cases)\n  ) %>%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district and age group\"\n  ) +\n  facet_grid(District ~ age_group)"},{"path":"ggplot-basics.html","id":"free-or-fixed-axes","chapter":"30 ggplot cơ bản","heading":"Free or fixed axes","text":"axes scales displayed faceting default (fixed) across facets. helpful cross-comparison, always appropriate.using facet_wrap() facet_grid(), can add scales = \"free_y\" “free” release y-axes panels scale appropriately data subset. particularly useful actual counts small one subcategories trends otherwise hard see. Instead “free_y” can also write “free_x” x-axis (e.g. dates) “free” axes. Note facet_grid, y scales facets row, x scales facets column.using facet_grid , can add space = \"free_y\" space = \"free_x\" actual height width facet weighted values figure within. works scales = \"free\" (y x) already applied.","code":"\n# Free y-axis\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # plot the count data as columns\n  theme_minimal()+                              # simplify the background panels\n  labs(                                         # add plot labels, title, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # the facets are created"},{"path":"ggplot-basics.html","id":"factor-level-order-in-facets","chapter":"30 ggplot cơ bản","heading":"Factor level order in facets","text":"See post re-order factor levels within facets.","code":""},{"path":"ggplot-basics.html","id":"storing-plots","chapter":"30 ggplot cơ bản","heading":"30.7 Storing plots","text":"","code":""},{"path":"ggplot-basics.html","id":"saving-plots","chapter":"30 ggplot cơ bản","heading":"Saving plots","text":"default run ggplot() command, plot printed Plots RStudio pane. However, can also save plot object using assignment operator <- giving name. print unless object name run. can also print wrapping plot name print(), necessary certain circumstances plot created inside loop used print multiple plots (see [Iteration, loops, lists] page).","code":"\n# define plot\nage_by_wt <- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# print\nage_by_wt    "},{"path":"ggplot-basics.html","id":"modifying-saved-plots","chapter":"30 ggplot cơ bản","heading":"Modifying saved plots","text":"One nice thing ggplot2 can define plot (), add layers starting name. repeat commands created original plot!example, modify plot age_by_wt defined , include vertical line age 50, just add + begin adding additional layers plot.","code":"\nage_by_wt+\n  geom_vline(xintercept = 50)"},{"path":"ggplot-basics.html","id":"exporting-plots","chapter":"30 ggplot cơ bản","heading":"Exporting plots","text":"Exporting ggplots made easy ggsave() function ggplot2. can work two ways, either:Specify name plot object, file path name extension\nexample: ggsave(my_plot, (\"plots\", \"my_plot.png\"))\nexample: ggsave(my_plot, (\"plots\", \"my_plot.png\"))Run command file path, save last plot printed\nexample: ggsave((\"plots\", \"my_plot.png\"))\nexample: ggsave((\"plots\", \"my_plot.png\"))can export png, pdf, jpeg, tiff, bmp, svg, several file types, specifying file extension file path.can also specify arguments width =, height =, units = (either “”, “cm”, “mm”). can also specify dpi = number plot resolution (e.g. 300). See function details entering ?ggsave reading documentation online.Remember can use () syntax provide desired file path. See [Import export] page information.","code":""},{"path":"ggplot-basics.html","id":"labels-1","chapter":"30 ggplot cơ bản","heading":"30.8 Labels","text":"Surely want add adjust plot’s labels. easily done within labs() function added plot + just geoms .Within labs() can provide character strings arguements:x = y = x-axis y-axis title (labels)title = main plot titlesubtitle = subtitle plot, smaller text titlecaption = caption plot, bottom-right defaultHere plot made earlier, nicer labels:Note caption assignment used str_glue() stringr package implant dynamic R code within string text. caption show “Data :” date reflects maximum hospitalization date linelist. Read page [Characters strings].note specifying legend title: one “legend title” argument, multiple scales legend. Within labs(), can write argument plot aesthetic used create legend, provide title way. example, assigned color = age create legend. Therefore, provide color = labs() assign legend title desired (“Age” capital ). create legend aes(fill = COLUMN), labs() write fill = adjust title legend. section color scales [ggplot tips] page provides details editing legends, alternative approach using scales_() functions.","code":"\nage_by_wt <- ggplot(\n  data = linelist,   # set data\n  mapping = aes(     # map aesthetics to column values\n         x = age,           # map x-axis to age            \n         y = wt_kg,         # map y-axis to weight\n         color = age))+     # map color to age\n  geom_point()+           # display data as points\n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt"},{"path":"ggplot-basics.html","id":"ggplot_basics_themes","chapter":"30 ggplot cơ bản","heading":"30.9 Themes","text":"One best parts ggplot2 amount control plot - can define anything! mentioned , design plot related data shapes/geometries adjusted within theme() function. example, plot background color, presence/absence gridlines, font/size/color/alignment text (titles, subtitles, captions, axis text…). adjustments can done one two ways:Add complete theme theme_() function make sweeping adjustments - include theme_classic(), theme_minimal(), theme_dark(), theme_light() theme_grey(), theme_bw() among othersAdjust tiny aspect plot individually within theme()","code":""},{"path":"ggplot-basics.html","id":"complete-themes","chapter":"30 ggplot cơ bản","heading":"Complete themes","text":"quite straight-forward, demonstrate complete theme functions describe . Note micro-adjustments theme() made use complete theme.Write empty parentheses.","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()"},{"path":"ggplot-basics.html","id":"modify-theme","chapter":"30 ggplot cơ bản","heading":"Modify theme","text":"theme() function can take large number arguments, edits specific aspect plot. way cover arguments, describe general pattern show find argument name need. basic syntax :Within theme() write argument name plot element want edit, like plot.title =Provide element_() function argumentMost often, use element_text(), others include element_rect() canvas background colors, element_blank() remove plot elementsWithin element_() function, write argument assignments make fine adjustments desireSo, description quite abstract, examples.plot looks quite silly, serves show variety ways can adjust plot.begin plot age_by_wt defined just add theme_classic()finer adjustments add theme() include one argument plot element adjustIt can nice organize arguments logical sections. describe just used :legend.position = unique accepts simple values like “bottom”, “top”, “left”, “right”. generally, text-related arguments require place details within element_text().Title size element_text(size = 30)caption horizontal alignment element_text(hjust = 0) (right left)subtitle italicized element_text(face = \"italic\")especially common theme() arguments. recognize patterns, appending .x .y apply change one axis.many theme arguments! remember ? worry - impossible remember . Luckily tools help :tidyverse documentation modifying theme, complete list.TIP: Run theme_get() ggplot2 print list 90+ theme() arguments console.TIP: ever want remove element plot, can also theme(). Just pass element_blank() argument disappear completely. legends, set legend.position = \"none\".","code":"\nage_by_wt + \n  theme_classic()+                                 # pre-defined theme adjustments\n  theme(\n    legend.position = \"bottom\",                    # move legend to bottom\n    \n    plot.title = element_text(size = 30),          # size of title to 30\n    plot.caption = element_text(hjust = 0),        # left-align caption\n    plot.subtitle = element_text(face = \"italic\"), # italicize subtitle\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # adjusts only x-axis text\n    axis.text.y = element_text(size = 15),         # adjusts only y-axis text\n    \n    axis.title = element_text(size = 20)           # adjusts both axes titles\n    )     "},{"path":"ggplot-basics.html","id":"colors","chapter":"30 ggplot cơ bản","heading":"30.10 Colors","text":"Please see section color scales ggplot tips page.","code":""},{"path":"ggplot-basics.html","id":"piping-into-ggplot2","chapter":"30 ggplot cơ bản","heading":"30.11 Piping into ggplot2","text":"using pipes clean transform data, easy pass transformed data ggplot().pipes pass dataset function--function transition + ggplot() function called. Note case, need specify data = argument, automatically defined piped-dataset.might look:","code":"\nlinelist %>%                                                     # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )"},{"path":"ggplot-basics.html","id":"plot-continuous-data","chapter":"30 ggplot cơ bản","heading":"30.12 Plot continuous data","text":"Throughout page, already seen many examples plotting continuous data. briefly consolidate present variations.\nVisualisations covered include:Plots one continuous variable:\nHistogram, classic graph present distribution continuous variable.\nBox plot (also called box whisker), show 25th, 50th, 75th percentiles, tail ends distribution, outliers (important limitations).\nJitter plot, show values points ‘jittered’ can (mostly) seen, even two value.\nViolin plot, show distribution continuous variable based symmetrical width ‘violin’.\nSina plot, combination jitter violin plots, individual points shown symmetrical shape distribution (via ggforce package).\nHistogram, classic graph present distribution continuous variable.Box plot (also called box whisker), show 25th, 50th, 75th percentiles, tail ends distribution, outliers (important limitations).Jitter plot, show values points ‘jittered’ can (mostly) seen, even two value.Violin plot, show distribution continuous variable based symmetrical width ‘violin’.Sina plot, combination jitter violin plots, individual points shown symmetrical shape distribution (via ggforce package).Scatter plot two continuous variables.Heat plots three continuous variables (linked [Heat plots] page)","code":""},{"path":"ggplot-basics.html","id":"histograms","chapter":"30 ggplot cơ bản","heading":"Histograms","text":"Histograms may look like bar charts, distinct measure distribution continuous variable. spaces “bars”, one column provided geom_histogram().code generating histograms, group continuous data ranges display adjacent bars varying height. done using geom_histogram(). See “Bar plot” section ggplot basics page understand difference geom_histogram(), geom_bar(), geom_col().show distribution ages cases. Within mapping = aes() specify column want see distribution . can assign column either x y axis.rows assigned “bins” based numeric age, bins graphically represented bars. specify number bins bins = plot aesthetic, break points evenly spaced minimum maximum values histogram. bins = unspecified, appropriate number bins guessed message displayed plot:want specify number bins bins =, alternatively specify binwidth = units axis. give examples showing different bins bin widths:get smoothed proportions, can use geom_density():get “stacked” histogram (continuous column data), can one following:Use geom_histogram() fill = argument within aes() assigned grouping column, orUse geom_freqpoly(), likely easier read (can still set binwidth =)see proportions values, set y = after_stat(density) (use syntax exactly - changed data). Note: proportions show per group.shown (*note use color = vs. fill = ):want fun, try geom_density_ridges ggridges package (vignette .Read detail histograms tidyverse page geom_histogram().","code":"## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n# A) Regular histogram\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) Fewer bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n\n# D) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# Stacked frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n# \"Stacked\" histogram\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# Frequency \nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# Frequency with proportion axis\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")"},{"path":"ggplot-basics.html","id":"box-plots","chapter":"30 ggplot cơ bản","heading":"Box plots","text":"Box plots common, important limitations. can obscure actual distribution - e.g. bi-modal distribution. See R graph gallery data--viz article details. However, nicely display inter-quartile range outliers - can overlaid top types plots show distribution detail.remind various components boxplot:using geom_boxplot() create box plot, generally map one axis (x y) within aes(). axis specified determines plots horizontal vertical.geoms, create plot per group mapping aesthetic like color = fill = column within aes(). However, box plots achieve assigning grouping column un-assigned axis (x y). code boxplot age values dataset, second code display one box plot (non-missing) gender dataset. Note NA (missing) values appear separate box plot unless removed. example also set fill column outcome plot different color - necessary.code add box plot edges scatter plot (“marginal” plots) see page [ggplot tips].","code":"\n# A) Overall boxplot\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # only y axis mapped (not x)\n  labs(title = \"A) Overall boxplot\")\n\n# B) Box plot by group\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # remove legend (redundant)\n  labs(title = \"B) Boxplot by gender\")      "},{"path":"ggplot-basics.html","id":"violin-jitter-and-sina-plots","chapter":"30 ggplot cơ bản","heading":"Violin, jitter, and sina plots","text":"code creating violin plots (geom_violin) jitter plots (geom_jitter) show distributions. can specify fill color also determined data, inserting options within aes().can combine two using geom_sina() function ggforce package. sina plots jitter points shape violin plot. overlaid violin plot (adjusting transparencies) can easier visually interpret.","code":"\n# A) Jitter plot by group\nggplot(data = linelist %>% drop_na(outcome),      # remove missing values\n       mapping = aes(y = age,                     # Continuous variable\n           x = outcome,                           # Grouping variable\n           color = outcome))+                     # Color variable\n  geom_jitter()+                                  # Create the violin plot\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# B) Violin plot by group\nggplot(data = linelist %>% drop_na(outcome),       # remove missing values\n       mapping = aes(y = age,                      # Continuous variable\n           x = outcome,                            # Grouping variable\n           fill = outcome))+                       # fill variable (color)\n  geom_violin()+                                   # create the violin plot\n  labs(title = \"B) violin plot by gender\")    \n# A) Sina plot by group\nggplot(\n  data = linelist %>% drop_na(outcome), \n  aes(y = age,           # numeric variable\n      x = outcome)) +    # group variable\n  geom_violin(\n    aes(fill = outcome), # fill (color of violin background)\n    color = \"white\",     # white outline\n    alpha = 0.2)+        # transparency\n  geom_sina(\n    size=1,                # Change the size of the jitter\n    aes(color = outcome))+ # color (color of dots)\n  scale_fill_manual(       # Define fill for violin background by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # Define colours for points by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # Remove the gray background\n  theme(legend.position = \"none\") +                # Remove unnecessary legend\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      "},{"path":"ggplot-basics.html","id":"two-continuous-variables","chapter":"30 ggplot cơ bản","heading":"Two continuous variables","text":"Following similar syntax, geom_point() allow plot two continuous variables scatter plot. useful showing actual values rather distributions. basic scatter plot age vs weight shown (). (B) use facet_grid() show relationship two continuous variables linelist.","code":"\n# Basic scatter plot of weight and age\nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Scatter plot of weight and age by gender and Ebola outcome\nggplot(data = linelist %>% drop_na(gender, outcome), # filter retains non-missing gender/outcome\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) "},{"path":"ggplot-basics.html","id":"three-continuous-variables","chapter":"30 ggplot cơ bản","heading":"Three continuous variables","text":"can display three continuous variables utilizing fill = argument create heat plot. color “cell” reflect value third continuous column data. See [ggplot tips] page page [Heat plots] details several examples.ways make 3D plots R, applied epidemiology often difficult interpret therefore less useful decision-making.","code":""},{"path":"ggplot-basics.html","id":"plot-categorical-data","chapter":"30 ggplot cơ bản","heading":"30.13 Plot categorical data","text":"Categorical data can character values, logical (TRUE/FALSE), factors (see [Factors] page).","code":""},{"path":"ggplot-basics.html","id":"preparation-16","chapter":"30 ggplot cơ bản","heading":"Preparation","text":"","code":""},{"path":"ggplot-basics.html","id":"data-structure","chapter":"30 ggplot cơ bản","heading":"Data structure","text":"first thing understand categorical data whether exists raw observations like linelist cases, summary aggregate data frame holds counts proportions. state data impact plotting function use:data raw observations one row per observation, likely use geom_bar()data already aggregated counts proportions, likely use geom_col()","code":""},{"path":"ggplot-basics.html","id":"column-class-and-value-ordering","chapter":"30 ggplot cơ bản","heading":"Column class and value ordering","text":"Next, examine class columns want plot. look hospital, first class() base R, tabyl() janitor.can see values within characters, hospital names, default ordered alphabetically. ‘’ ‘missing’ values, prefer last subcategories presenting breakdowns. change column factor re-order . covered detail [Factors] page.","code":"\n# View class of hospital column - we can see it is a character\nclass(linelist$hospital)## [1] \"character\"\n# Look at values and proportions within hospital column\nlinelist %>% \n  tabyl(hospital)##                              hospital    n    percent\n##                      Central Hospital  454 0.07710598\n##                     Military Hospital  896 0.15217391\n##                               Missing 1469 0.24949049\n##                                 Other  885 0.15030571\n##                         Port Hospital 1762 0.29925272\n##  St. Mark's Maternity Hospital (SMMH)  422 0.07167120\n# Convert to factor and define level order so \"Other\" and \"Missing\" are last\nlinelist <- linelist %>% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\nlevels(linelist$hospital)## [1] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [3] \"Central Hospital\"                     \"Military Hospital\"                   \n## [5] \"Other\"                                \"Missing\""},{"path":"ggplot-basics.html","id":"ggplot_basics_bars","chapter":"30 ggplot cơ bản","heading":"geom_bar()","text":"Use geom_bar() want bar height (height stacked bar components) reflect number relevant rows data. bars gaps , unless width = plot aesthetic adjusted.Provide one axis column assignment (typically x-axis). provide x y, get Error: stat_count() can x y aesthetic.can create stacked bars adding fill = column assignment within mapping = aes()opposite axis titled “count” default, represents number rowsBelow, assigned outcome y-axis, just easily x-axis. longer character values, can sometimes look better flip bars sideways put legend bottom. may impact factor levels ordered - case reverse fct_rev() put missing bottom.","code":"\n# A) Outcomes in all cases\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) Outcomes in all cases by hosptial\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")"},{"path":"ggplot-basics.html","id":"geom_col","chapter":"30 ggplot cơ bản","heading":"geom_col()","text":"Use geom_col() want bar height (height stacked bar components) reflect pre-calculated values exists data. Often, summary “aggregated” counts, proportions.Provide column assignments axes geom_col(). Typically x-axis column discrete y-axis column numeric.Let’s say dataset outcomes:code using geom_col creating simple bar charts show distribution Ebola patient outcomes. geom_col, x y need specified. x categorical variable along x axis, y generated proportions column proportion.show breakdowns hospital, need table contain information, “long” format. create table frequencies combined categories outcome hospital (see [Grouping data] page grouping tips).create ggplot added formatting:Axis flip: Swapped axis around coord_flip() can read hospital names.Columns side--side: Added position = \"dodge\" argument bars death recover presented side side rather stacked. Note stacked bars default.Column width: Specified ‘width’, columns half thin full possible width.Column order: Reversed order categories y axis ‘’ ‘Missing’ bottom, scale_x_discrete(limits=rev). Note used rather scale_y_discrete hospital stated x argument aes(), even visually y axis. Ggplot seems present categories backwards unless tell .details: Labels/titles colours added within labs scale_fill_color respectively.Note proportions binary, may prefer drop ‘recover’ just show proportion died. just illustration purposes.using geom_col() dates data (e.g. epicurve aggregated data) - want adjust width = argument remove “gap” lines bars. using daily data set width = 1. weekly, width = 7. Months possible month different number days.","code":"## # A tibble: 2 x 3\n##   outcome     n proportion\n##   <chr>   <int>      <dbl>\n## 1 Death    1022       56.2\n## 2 Recover   796       43.8\n# Outcomes in all cases\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\noutcomes2 <- linelist %>% \n  drop_na(outcome) %>% \n  count(hospital, outcome) %>%  # get counts by hospital and outcome\n  group_by(hospital) %>%        # Group so proportions are out of hospital total\n  mutate(proportion = n/sum(n)*100) # calculate proportions of hospital total\n\nhead(outcomes2) # Preview data## # A tibble: 6 x 4\n## # Groups:   hospital [3]\n##   hospital                             outcome     n proportion\n##   <fct>                                <chr>   <int>      <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n## 2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n## 3 Port Hospital                        Death     785       57.6\n## 4 Port Hospital                        Recover   579       42.4\n## 5 Central Hospital                     Death     193       53.9\n## 6 Central Hospital                     Recover   165       46.1\n# Outcomes in all cases by hospital\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # show pre-calculated proportion values\n      y = fct_rev(hospital),          # reverse level order so missing/other at bottom\n      fill = outcome),                # stacked by outcome\n    width = 0.5)+                    # thinner bars (out of 1)\n  theme_minimal() +                  # Minimal theme \n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # legend title\n       y = \"Count\",                  # y axis title\n       x = \"Hospital of admission\")+ # x axis title\n  scale_fill_manual(                 # adding colors manually\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) "},{"path":"ggplot-basics.html","id":"geom_histogram","chapter":"30 ggplot cơ bản","heading":"geom_histogram()","text":"Histograms may look like bar charts, distinct measure distribution continuous variable. spaces “bars”, one column provided geom_histogram(). arguments specific histograms bin_width = breaks = specify data binned. section continuous data page [Epidemic curves] provide additional detail.","code":""},{"path":"ggplot-basics.html","id":"resources-16","chapter":"30 ggplot cơ bản","heading":"30.14 Resources","text":"huge amount help online, especially ggplot. See:ggplot2 cheat sheetanother cheat sheettidyverse ggplot basics pageplotting continuous variablesR Data Science pages data visualizationgraphics communicaton","code":""},{"path":"ggplot-tips.html","id":"ggplot-tips","chapter":"31 Các tips với ggplot","heading":"31 Các tips với ggplot","text":"page cover tips tricks make ggplots sharp fancy. See page [ggplot basics] fundamentals.several extensive ggplot2 tutorials linked Resources section. can also download data visualization ggplot cheatsheet RStudio website. strongly recommend peruse inspiration R graph gallery Data--viz.","code":""},{"path":"ggplot-tips.html","id":"preparation-17","chapter":"31 Các tips với ggplot","heading":"31.1 Preparation","text":"","code":""},{"path":"ggplot-tips.html","id":"load-packages-16","chapter":"31 Các tips với ggplot","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other\n  rio,            # import/export\n  here,           # file locator\n  stringr,        # working with characters   \n  scales,         # transform numbers\n  ggrepel,        # smartly-placed labels\n  gghighlight,    # highlight one part of plot\n  RColorBrewer    # color scales\n)"},{"path":"ggplot-tips.html","id":"import-data-12","chapter":"31 Các tips với ggplot","heading":"Import data","text":"page, import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot-tips.html","id":"ggplot_tips_colors","chapter":"31 Các tips với ggplot","heading":"31.2 Scales for color, fill, axes, etc.","text":"ggplot2, aesthetics plotted data (e.g. size, color, shape, fill, plot axis) mapped columns data, exact display can adjusted corresponding “scale” command. section explain common scale adjustments.","code":""},{"path":"ggplot-tips.html","id":"color-schemes","chapter":"31 Các tips với ggplot","heading":"31.2.1 Color schemes","text":"One thing can initially difficult understand ggplot2 control color schemes. Note section discusses color plot objects (geoms/shapes) points, bars, lines, tiles, etc. adjust color accessory text, titles, background color see Themes section [ggplot basics] page.control “color” plot objects adjusting either color = aesthetic (exterior color) fill = aesthetic (interior color). One exception pattern geom_point(), really get control color =, controls color point (interior exterior).setting colour fill can use colour names recognized R like \"red\" (see complete list enter ?colors), specific hex colour \"#ff0505\".explained [ggplot basics] section mapping data plot, aesthetics fill = color = can defined either outside mapping = aes() statement inside one. outside aes(), assigned value static (e.g. color = \"blue\") apply data plotted geom. inside, aesthetic mapped column, like color = hospital, expression vary value row data. examples:","code":"\n# histogram - \nggplot(data = linelist, mapping = aes(x = age))+       # set data and axes\n  geom_histogram(              # display histogram\n    binwidth = 7,                # width of bins\n    color = \"red\",               # bin line color\n    fill = \"lightblue\")          # bin interior color (fill) \n# Static color for points and for line\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# Color mapped to continuous column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# Color mapped to discrete column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# bar plot, fill to discrete column, color to static value\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")"},{"path":"ggplot-tips.html","id":"ggplot_tips_scales","chapter":"31 Các tips với ggplot","heading":"Scales","text":"map column plot aesthetic (e.g. x =, y =, fill =, color =…), plot gain scale/legend. See scale can continuous, discrete, date, etc. values depending class assigned column. multiple aesthetics mapped columns, plot multiple scales.can control scales appropriate scales_() function. scale functions ggplot() 3 parts written like : scale_AESTHETIC_METHOD().first part, scale_(), fixed.second part, AESTHETIC, aesthetic want adjust scale (_fill_, _shape_, _color_, _size_, _alpha_…) - options also include _x_ _y_.third part, METHOD, either _discrete(), continuous(), _date(), _gradient(), _manual() depending class column want control . others, -often used.sure use correct function scale! Otherwise scale command appear change anything. multiple scales, may use multiple scale functions adjust ! example:","code":""},{"path":"ggplot-tips.html","id":"scale-arguments","chapter":"31 Các tips với ggplot","heading":"Scale arguments","text":"kind scale arguments, though overlap. Query function like ?scale_color_discrete R console see function argument documentation.continuous scales, use breaks = provide sequence values seq() (take =, =, = shown example . Set expand = c(0,0) eliminate padding space around axes (can used _x_ _y_ scale.discrete scales, can adjust order level appearance breaks =, values display labels = argument. Provide character vector (see example ). can also drop NA easily setting na.translate = FALSE.nuances date scales covered extensively [Epidemic curves] page.","code":""},{"path":"ggplot-tips.html","id":"manual-adjustments","chapter":"31 Các tips với ggplot","heading":"Manual adjustments","text":"One useful tricks using “manual” scaling functions explicitly assign colors desire. functions syntax scale_xxx_manual() (e.g. scale_colour_manual() scale_fill_manual()). arguments demonstrated code example .Assign colors data values values = argumentSpecify color NA na.value =Change values written legend labels = argumentChange legend title name =, create bar plot show appears default, three scales adjusted - continuous y-axis scale, discrete x-axis scale, manual adjustment fill (interior bar color).","code":"\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n# SCALES ADJUSTED\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # simplify background\n  \n  scale_y_continuous(                # continuous scale for y-axis (counts)\n    expand = c(0,0),                 # no padding\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # discrete scale for x-axis (gender)\n    expand = c(0,0),                  # no padding\n    drop = FALSE,                     # show all factor levels (even if not in data)\n    na.translate = FALSE,             # remove NA outcomes from plot\n    labels = c(\"Died\", \"Recovered\"))+ # Change display of values\n    \n  \n  scale_fill_manual(                  # Manually specify fill (bar interior color)\n    values = c(\"m\" = \"violetred\",     # reference values in data to assign colors\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          # re-label the legend (use \"=\" assignment to avoid mistakes)\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # title of legend\n    na.value = \"grey\"                 # assign a color for missing values\n  )+\n  labs(title = \"Adjustment of scales\") # Adjust the title of the fill legend"},{"path":"ggplot-tips.html","id":"continuous-axes-scales","chapter":"31 Các tips với ggplot","heading":"Continuous axes scales","text":"data mapping plot axes, can adjusted scales commands. common example adjusting display axis (e.g. y-axis) mapped column continuous data.may want adjust breaks display values ggplot using scale_y_continuous(). noted , use argument breaks = provide sequence values serve “breaks” along scale. values numbers display. argument, can provide c() vector containing desired break values, can provide regular sequence numbers using base R function seq(). seq() function accepts =, =, =.","code":"\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")"},{"path":"ggplot-tips.html","id":"display-percents","chapter":"31 Các tips với ggplot","heading":"Display percents","text":"original data values proportions, can easily display percents “%” providing labels = scales::percent scales command, shown .alternative convert values character add “%” character end, approach cause complications data longer continuous numeric values.","code":"\n# Original y-axis proportions\n#############################\nlinelist %>%                                   # start with linelist\n  group_by(hospital) %>%                       # group data by hospital\n  summarise(                                   # create summary columns\n    n = n(),                                     # total number of rows in group\n    deaths = sum(outcome == \"Death\", na.rm=T),   # number of deaths in group\n    prop_death = deaths/n) %>%                   # proportion deaths in group\n  ggplot(                                      # begin plotting\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# Display y-axis proportions as percents\n########################################\nlinelist %>%         \n  group_by(hospital) %>% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %>% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # display proportions as percents\n  )"},{"path":"ggplot-tips.html","id":"log-scale","chapter":"31 Các tips với ggplot","heading":"Log scale","text":"transform continuous axis log scale, add trans = \"log2\" scale command. purposes example, create data frame regions respective preparedness_index cumulative cases values.cumulative cases region “” dramatically greater regions. circumstances like , may elect display y-axis using log scale reader can see differences regions fewer cumulative cases.","code":"\nplot_data <- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data##   region preparedness_index cases_cumulative\n## 1      A                8.8               15\n## 2      B                7.5               45\n## 3      C                3.4               80\n## 4      D                3.6               20\n## 5      E                2.1               21\n## 6      F                7.9                7\n## 7      G                7.0               51\n## 8      H                5.6               30\n## 9      I                1.0             1442\n# Original y-axis\npreparedness_plot <- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # points for each region \n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # add text labels\n  theme_minimal()\n\npreparedness_plot                  # print original plot\n\n\n# print with y-axis transformed\npreparedness_plot+                   # begin with plot saved above\n  scale_y_continuous(trans = \"log2\") # add transformation for y-axis"},{"path":"ggplot-tips.html","id":"gradient-scales","chapter":"31 Các tips với ggplot","heading":"Gradient scales","text":"Fill gradient scales can involve additional nuance. defaults usually quite pleasing, may want adjust values, cutoffs, etc.demonstrate adjust continuous color scale, ’ll use data set [Contact tracing] page contains ages cases source cases., produce “raster” heat tile density plot. won’t elaborate (see link paragraph ) focus can adjust color scale. Read stat_density2d() ggplot2 function . Note fill scale continuous.Now show variations fill scale:Now show examples actually adjusting break points scale:scale_fill_gradient() accepts two colors (high/low)scale_fill_gradientn() accepts vector length colors values = (intermediate values interpolated)Use scales::rescale() adjust colors positioned along gradient; rescales vector positions 0 1.","code":"\ncase_source_relationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_age, target_age) \ntrans_matrix <- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\ntrans_matrix + \n  scale_fill_gradient(     # 2-sided gradient scale\n    low = \"aquamarine\",    # low value\n    high = \"purple\",       # high value\n    na.value = \"grey\",     # value for NA\n    name = \"Density\")+     # Legend title\n  labs(title = \"Manually specify high/low colors\")\n\n# 3+ colors to scale\ntrans_matrix + \n  scale_fill_gradientn(    # 3-color scale (low/mid/high)\n    colors = c(\"blue\", \"yellow\",\"red\") # provide colors in vector\n  )+\n  labs(title = \"3-color scale\")\n\n# Use of rescale() to adjust placement of colors along scale\ntrans_matrix + \n  scale_fill_gradientn(    # provide any number of colors\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # positions for colors are rescaled between 0 and 1\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# use of limits to cut-off values that get fill color\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")"},{"path":"ggplot-tips.html","id":"palettes","chapter":"31 Các tips với ggplot","heading":"Palettes","text":"","code":""},{"path":"ggplot-tips.html","id":"colorbrewer-and-viridis","chapter":"31 Các tips với ggplot","heading":"Colorbrewer and Viridis","text":"generally, want predefined palettes, can use scale_xxx_brewer scale_xxx_viridis_y functions.‘brewer’ functions can draw colorbrewer.org palettes.‘viridis’ functions draw viridis (colourblind friendly!) palettes, “provide colour maps perceptually uniform colour black--white. also designed perceived viewers common forms colour blindness.” (read ). Define palette discrete, continuous, binned specifying end function (e.g. discrete scale_xxx_viridis_d).advised test plot color blindness simulator. red/green color scheme, try “hot-cold” (red-blue) scheme instead described hereHere example [ggplot basics] page, using various color schemes.","code":"\nsymp_plot <- linelist %>%                                         # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  # print with default colors\n\n#################################\n# print with manually-specified colors\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # explicitly define colours\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # order the factors correctly\n    name = \"\"                           # set legend to no title\n\n  ) \n\n#################################\n# print with viridis discrete colors\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )"},{"path":"ggplot-tips.html","id":"change-order-of-discrete-variables","chapter":"31 Các tips với ggplot","heading":"31.3 Change order of discrete variables","text":"Changing order discrete variables appear often difficult understand people new ggplot2 graphs. ’s easy understand however understand ggplot2 handles discrete variables hood. Generally speaking, discrete varaible used, automatically converted factor type - orders factors alphabetical order default. handle , simply reorder factor levels reflect order like appear chart. detailed information reorder factor objects, see factor section guide.can look common example using age groups - default 5-9 age group placed middle age groups (given alphanumeric order), can move behind 0-4 age group chart releveling factors.","code":"\nggplot(\n  data = linelist %>% drop_na(age_cat5),                         # remove rows where age_cat5 is missing\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # relevel factor\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()"},{"path":"ggplot-tips.html","id":"ggthemr","chapter":"31 Các tips với ggplot","heading":"31.3.0.1 ggthemr","text":"Also consider using ggthemr package. can download package Github using instructions . offers palettes aesthetically pleasing, aware typically maximum number values can limiting want 7 8 colors.","code":""},{"path":"ggplot-tips.html","id":"contour-lines","chapter":"31 Các tips với ggplot","heading":"31.4 Contour lines","text":"Contour plots helpful many points might cover (“overplotting”). case-source data used plotted, simply using stat_density2d() stat_density2d_filled() produce discrete contour levels - like topographical map. Read statistics .","code":"\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")"},{"path":"ggplot-tips.html","id":"marginal-distributions","chapter":"31 Các tips với ggplot","heading":"31.5 Marginal distributions","text":"show distributions edges geom_point() scatterplot, can use ggExtra package function ggMarginal(). Save original ggplot object, pass ggMarginal() shown . key arguments:must specify type = either “histogram”, “density” “boxplot”, “violin”, “densigram”.default, marginal plots appear axes. can set margins = “x” “y” want one.optional arguments include fill = (bar color), color = (line color), size = (plot size relative margin size, larger number makes marginal plot smaller).can provide axis-specific arguments xparams = yparams =. example, different histogram bin sizes, shown .can marginal plots reflect groups (columns assigned color = ggplot() mapped aesthetics). case, set ggMarginal() argument groupColour = groupFill = TRUE, shown .Read vignette, R Graph Gallery function R documentation ?ggMarginal.add marginal histograms use type = \"histogram\". can optionally set groupFill = TRUE get stacked histograms.Marginal density plot grouped/colored values:Set size = arguemnt adjust relative size marginal plot. Smaller number makes larger marginal plot. also set color =. marginal boxplot, demonstration margins = argument appears one axis:","code":"\n# Install/load ggExtra\npacman::p_load(ggExtra)\n\n# Basic scatter plot of weight and age\nscatter_plot <- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n# with histograms\nggMarginal(\n  scatter_plot,                     # add marginal histograms\n  type = \"histogram\",               # specify histograms\n  fill = \"lightblue\",               # bar fill\n  xparams = list(binwidth = 10),    # other parameters for x-axis marginal\n  yparams = list(binwidth = 5))     # other parameters for y-axis marginal\n# Scatter plot, colored by outcome\n# Outcome column is assigned as color in ggplot. groupFill in ggMarginal set to TRUE\nscatter_plot_color <- ggplot(data = linelist %>% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n# with boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # only show x-axis marginal plot\n  type = \"boxplot\")   "},{"path":"ggplot-tips.html","id":"smart-labeling","chapter":"31 Các tips với ggplot","heading":"31.6 Smart Labeling","text":"ggplot2, also possible add text plots. However, comes notable limitation text labels often clash data points plot, making look messy hard read. ideal way deal base package, ggplot2 add-, known ggrepel makes dealing simple!ggrepel package provides two new functions, geom_label_repel() geom_text_repel(), replace geom_label() geom_text(). Simply use functions instead base functions produce neat labels. Within function, map aesthetics aes() always, include argument label = provide column name containing values want display (e.g. patient id, name, etc.). can make complex labels combining columns newlines (\\n) within str_glue() shown .tips:Use min.segment.length = 0 always draw line segments, min.segment.length = Inf never draw themUse size = outside aes() set text sizeUse force = change degree repulsion labels respective points (default 1)Include fill = within aes() label colored value\nletter “” may appear legend - add guides(fill = guide_legend(override.aes = aes(color = NA)))+ remove \nletter “” may appear legend - add guides(fill = guide_legend(override.aes = aes(color = NA)))+ remove itSee -depth tutorial .can label subset data points - using standard ggplot() syntax provide different data = geom layer plot. , cases plotted, labeled.","code":"\npacman::p_load(ggrepel)\n\nlinelist %>%                                               # start with linelist\n  group_by(hospital) %>%                                   # group by hospital\n  summarise(                                               # create new dataset with summary values per hospital\n    n_cases = n(),                                           # number of cases per hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # mean delay per hospital\n  ) %>% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # send data frame to ggplot\n  geom_point(size = 2)+                                    # add points\n  geom_label_repel(                                        # add point labels\n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # how label displays\n      ), \n    size = 3,                                              # text size in labels\n    min.segment.length = 0)+                               # show all line segments                \n  labs(                                                    # add axes labels\n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\nggplot()+\n  # All points in grey\n  geom_point(\n    data = linelist,                                   # all data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # grey and semi-transparent\n  \n  # Few points in black\n  geom_point(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filtered data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # default black and not transparent\n  \n  # point labels for few points\n  geom_label_repel(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filter the data for the labels\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # label color by outcome\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # label created with str_glue()\n    min.segment.length = 0) +                                  # show line segments for all\n  \n  # remove letter \"a\" from inside legend boxes\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # axis labels\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")"},{"path":"ggplot-tips.html","id":"time-axes","chapter":"31 Các tips với ggplot","heading":"31.7 Time axes","text":"Working time axes ggplot can seem daunting, made easy key functions. Remember working time date ensure correct variables formatted date datetime class - see Working dates page information , [Epidemic curves] page (ggplot section) examples.single useful set functions working dates ggplot2 scale functions (scale_x_date(), scale_x_datetime(), cognate y-axis functions). functions let define often axis labels, format axis labels. find format dates, see working dates section ! can use date_breaks date_labels arguments specify dates look:date_breaks allows specify often axis breaks occur - can pass string (e.g. \"3 months\", \"2 days\")date_breaks allows specify often axis breaks occur - can pass string (e.g. \"3 months\", \"2 days\")date_labels allows define format dates shown . can pass date format string arguments (e.g. \"%b-%d-%Y\"):date_labels allows define format dates shown . can pass date format string arguments (e.g. \"%b-%d-%Y\"):","code":"\n# make epi curve by date of onset when available\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # 1 break every 1 month\n    date_breaks = \"1 months\",\n    # labels should show month then date\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()"},{"path":"ggplot-tips.html","id":"highlighting","chapter":"31 Các tips với ggplot","heading":"31.8 Highlighting","text":"Highlighting specific elements chart useful way draw attention specific instance variable also providing information dispersion full dataset. easily done base ggplot2, external package can help known gghighlight. easy use within ggplot syntax.gghighlight package uses gghighlight() function achieve effect. use function, supply logical statement function - can quite flexible outcomes, ’ll show example age distribution cases linelist, highlighting outcome.also works well faceting functions - allows user produce facet plots background data highlighted doesn’t apply facet! count cases week plot epidemic curves hospital (color = facet_wrap() set hospital column).","code":"\n# load gghighlight\nlibrary(gghighlight)\n\n# replace NA values with unknown in the outcome variable\nlinelist <- linelist %>%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produce a histogram of all cases by age\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # highlight instances where the patient has died.\n# produce a histogram of all cases by age\nlinelist %>% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %>% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # highlight instances where the patient has died\n  facet_wrap(~hospital)                              # make facets by outcome"},{"path":"ggplot-tips.html","id":"plotting-multiple-datasets","chapter":"31 Các tips với ggplot","heading":"31.9 Plotting multiple datasets","text":"Note properly aligning axes plot multiple datasets plot can difficult. Consider one following strategies:Merge data prior plotting, convert “long” format column reflecting datasetUse cowplot similar package combine two plots (see )","code":""},{"path":"ggplot-tips.html","id":"combine-plots","chapter":"31 Các tips với ggplot","heading":"31.10 Combine plots","text":"Two packages useful combining plots cowplot patchwork. page mostly focus cowplot, occassional use patchwork.online introduction cowplot. can read extensive documentation function online . cover common use cases functions .cowplot package works tandem ggplot2 - essentially, use arrange combine ggplots legends compound figures. can also accept base R graphics.faceting (described [ggplot basics] page) convenient approach plotting, sometimes possible get results want relatively restrictive approach. , may choose combine plots sticking together larger plot. three well known packages great - cowplot, gridExtra, patchwork. However, packages largely things, ’ll focus cowplot section.","code":"\npacman::p_load(\n  tidyverse,      # data manipulation and visualisation\n  cowplot,        # combine plots\n  patchwork       # combine plots\n)"},{"path":"ggplot-tips.html","id":"plot_grid","chapter":"31 Các tips với ggplot","heading":"plot_grid()","text":"cowplot package fairly wide range functions, easiest use can achieved use plot_grid(). effectively way arrange predefined plots grid formation. can work another example malaria dataset - can plot total cases district, also show epidemic curve time.","code":"\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# bar chart of total cases by district\np1 <- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# epidemic curve over time\np2 <- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 column and two rows - stacked on top of each other\n                   ncol = 1,\n                   nrow = 2,\n                   # top plot is 2/3 as tall as second\n                   rel_heights = c(2, 3))"},{"path":"ggplot-tips.html","id":"combine-legends","chapter":"31 Các tips với ggplot","heading":"Combine legends","text":"plots legend, combining relatively straight-forward. Simple use cowplot approach combine plots, remove legend one (de-duplicate).plots different legends, must use alternative approach:Create save plots without legends using theme(legend.position = \"none\")Extract legends plot using get_legend() shown - extract legends plots modified actually show legendCombine legends legends panelCombine plots legends panelFor demonstration show two plots separately, arranged grid legends showing (ugly inefficient use space):two plots look combined using plot_grid() without combining legends:now show combine legends. Essentially define plot without legend (theme(legend.position = \"none\"), define plot’s legend separately, using get_legend() function cowplot. extract legend saved plot, need add + legend back , including specifying placement (“right”) smaller adjustments alignment legends titles. , combine legends together vertically, combine two plots newly-combined legends. Voila!solution learned post minor fix align legends post.TIP: Fun note - “cow” cowplot comes creator’s name - Claus O. Wilke.","code":"\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n# Define plot 1 without legend\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# Define plot 2 without legend\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# extract legend from p1 (from p1 + legend)\nleg_p1 <- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # extract vertical legend\n                                      legend.justification = c(0,0.5))+ # so legends  align\n                                labs(fill = \"Outcome\"))                 # title of legend\n# extract legend from p2 (from p2 + legend)\nleg_p2 <- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # extract vertical legend   \n                                      legend.justification = c(0,0.5))+  # so legends align\n                                labs(fill = \"Age Category\"))             # title of legend\n\n# create a blank plot for legend alignment\n#blank_p <- patchwork::plot_spacer() + theme_void()\n\n# create legends panel, can be one on top of the other (or use spacer commented above)\nlegends <- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# combine two plots and the combined legends panel\ncombined <- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # print"},{"path":"ggplot-tips.html","id":"inset-plots","chapter":"31 Các tips với ggplot","heading":"Inset plots","text":"can inset one plot another using cowplot. things aware :Define main plot theme_half_open() cowplot; may best legend either top bottomDefine inset plot. Best plot need legend. can remove plot theme elements element_blank() shown .Combine applying ggdraw() main plot, adding draw_plot() inset plot specifying coordinates (x y lower left corner), height width proportion whole main plot.technique explained two vignettes:Wilke labdraw_plot() documentation","code":"\n# Define main plot\nmain_plot <- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# Define inset plot\ninset_plot <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# Combine main with inset\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)"},{"path":"ggplot-tips.html","id":"dual-axes","chapter":"31 Các tips với ggplot","heading":"31.11 Dual axes","text":"secondary y-axis often requested addition ggplot2 graph. robust debate validity graphs data visualization community, often recommended, manager may still want . , present one method achieve : using cowplot package combine two separate plots.approach involves creating two separate plots - one y-axis left, y-axis right. use specific theme_cowplot() must x-axis. third command two plots aligned overlaid top . functionalities cowplot, one, described depth site.demonstrate technique overlay epidemic curve line weekly percent patients died. use example alignment dates x-axis complex say, aligning bar chart another plot. things note:epicurve line aggregated weeks prior plotting date_breaks date_labels identical - x-axes two plots overlaid.y-axis moved right-side plot 2 position = argument scale_y_continuous().plots make use theme_cowplot()Note another example technique [Epidemic curves] page - overlaying cumulative incidence top epicurve.Make plot 1\nessentially epicurve. use geom_area() just demonstrate use (area line, default)Make plot 2\nCreate second plot showing line weekly percent cases died.Now align plot using function align_plots(), specifying horizontal vertical alignment (“hv”, also “h”, “v”, “none”). specify alignment axes well (top, bottom, left, right) “tblr”. output class list (2 elements).draw two plots together using ggdraw() (cowplot) referencing two parts aligned_plots object.","code":"\npacman::p_load(cowplot)            # load/install cowplot\n\np1 <- linelist %>%                 # save plot as object\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # view plot \np2 <- linelist %>%         # save plot as object\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %>% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # view plot\naligned_plots <- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # align the two plots and save them as list\naligned_plotted <- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # overlay them and save the visual plot\naligned_plotted                                                                # print the overlayed plots"},{"path":"ggplot-tips.html","id":"packages-to-help-you","chapter":"31 Các tips với ggplot","heading":"31.12 Packages to help you","text":"really neat R packages specifically designed help navigate ggplot2:","code":""},{"path":"ggplot-tips.html","id":"point-and-click-ggplot2-with-equisse","chapter":"31 Các tips với ggplot","heading":"Point-and-click ggplot2 with equisse","text":"“addin allows interactively explore data visualizing ggplot2 package. allows draw bar plots, curves, scatter plots, histograms, boxplot sf objects, export graph retrieve code reproduce graph.”Install launch addin via RStudio menu esquisse::esquisser().See Github pageDocumentation","code":""},{"path":"ggplot-tips.html","id":"miscellaneous","chapter":"31 Các tips với ggplot","heading":"31.13 Miscellaneous","text":"","code":""},{"path":"ggplot-tips.html","id":"numeric-display","chapter":"31 Các tips với ggplot","heading":"Numeric display","text":"can disable scientific notation running command prior plotting.apply number_format() scales package specific value column, shown .Use functions package scales easily adjust numbers displayed. can applied columns data frame, shown individual numbers purpose example.","code":"\noptions(scipen=999)\nscales::number(6.2e5)## [1] \"620 000\"\nscales::number(1506800.62,  accuracy = 0.1,)## [1] \"1 506 800.6\"\nscales::comma(1506800.62, accuracy = 0.01)## [1] \"1,506,800.62\"\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")## [1] \"1.506.800,62\"\nscales::percent(0.1)## [1] \"10%\"\nscales::dollar(56)## [1] \"$56\"\nscales::scientific(100000)## [1] \"1e+05\""},{"path":"ggplot-tips.html","id":"resources-17","chapter":"31 Các tips với ggplot","heading":"31.14 Resources","text":"Inspiration\nggplot graph galleryPresentation data\nEuropean Centre Disease Prevention Control Guidelines presentation surveillance dataFacets labellers\nUsing labellers facet strips\nLabellersAdjusting order factors\nfct_reorderfct_inorderHow reorder boxplotReorder variable ggplot2R Data Science - FactorsLegendsAdjust legend orderCaptions\nCaption alignmentLabelsggrepelCheatsheetsBeautiful plotting ggplot2","code":""},{"path":"epicurves.html","id":"epicurves","chapter":"32 Đường cong dịch bệnh","heading":"32 Đường cong dịch bệnh","text":"epidemic curve (also known “epi curve”) core epidemiological chart typically used visualize temporal pattern illness onset among cluster epidemic cases.Analysis epicurve can reveal temporal trends, outliers, magnitude outbreak, likely time period exposure, time intervals case generations, can even help identify mode transmission unidentified disease (e.g. point source, continuous common source, person--person propagation). One online lesson interpretation epi curves can found website US CDC.page demonstrate two approaches producing epicurves R:incidence2 package, can produce epi curve simple commandsThe ggplot2 package, allows advanced customizability via complex commandsAlso addressed specific use-cases :Plotting aggregated count dataFaceting producing small-multiplesApplying moving averagesShowing data “tentative” subject reporting delaysOverlaying cumulative case incidence using second axis","code":""},{"path":"epicurves.html","id":"preparation-18","chapter":"32 Đường cong dịch bệnh","heading":"32.1 Preparation","text":"","code":""},{"path":"epicurves.html","id":"packages-3","chapter":"32 Đường cong dịch bệnh","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,          # file import/export\n  here,         # relative filepaths \n  lubridate,    # working with dates/epiweeks\n  aweek,        # alternative package for working with dates/epiweeks\n  incidence2,   # epicurves of linelist data\n  i2extras,     # supplement to incidence2\n  stringr,      # search and manipulate character strings\n  forcats,      # working with factors\n  RColorBrewer, # Color palettes from colorbrewer2.org\n  tidyverse     # data management + ggplot2 graphics\n) "},{"path":"epicurves.html","id":"import-data-13","chapter":"32 Đường cong dịch bệnh","heading":"Import data","text":"Two example datasets used section:Linelist individual cases simulated epidemicAggregated counts hospital simulated epidemicThe datasets imported using import() function rio package. See page [Import export] various ways import data.Case linelistWe import dataset cases simulated Ebola epidemic. want download data follow step--step, see instruction [Download handbook data] page. assume file working directory sub-folders specified file path.first 50 rows displayed .Case counts aggregated hospitalFor purposes handbook, dataset weekly aggregated counts hospital created linelist following code.first 50 rows displayed :","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")\n# import the counts data into R\ncount_data <- linelist %>% \n  group_by(hospital, date_hospitalisation) %>% \n  summarize(n_cases = dplyr::n()) %>% \n  filter(date_hospitalisation > as.Date(\"2013-06-01\")) %>% \n  ungroup()"},{"path":"epicurves.html","id":"set-parameters","chapter":"32 Đường cong dịch bệnh","heading":"Set parameters","text":"production report, may want set editable parameters date data current (“data date”). can reference object data_date code applying filters dynamic captions.","code":"\n## set the report date for the report\n## note: can be set to Sys.Date() for the current date\ndata_date <- as.Date(\"2015-05-15\")"},{"path":"epicurves.html","id":"verify-dates","chapter":"32 Đường cong dịch bệnh","heading":"Verify dates","text":"Verify relevant date column class Date appropriate range values. can simply using hist() histograms, range() na.rm=TRUE, ggplot() .","code":"\n# check range of onset dates\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))"},{"path":"epicurves.html","id":"epicurves-with-incidence2-package","chapter":"32 Đường cong dịch bệnh","heading":"32.2 Epicurves with incidence2 package","text":"demonstrate make epicurves using incidence2 package. authors package tried allow user create modify epicurves without needing know ggplot2 syntax. Much page adapted package vignettes, can found incidence2 github page.","code":""},{"path":"epicurves.html","id":"simple-example","chapter":"32 Đường cong dịch bệnh","heading":"Simple example","text":"2 steps required plot epidemic curve incidence2 package:Create incidence object (using function incidence())\nProvide data\nSpecify date column date_index =\nSpecify interval = cases aggregated (daily, weekly, monthly..)\nSpecify grouping columns (e.g. gender, hospital, outcome)\nProvide dataSpecify date column date_index =Specify interval = cases aggregated (daily, weekly, monthly..)Specify grouping columns (e.g. gender, hospital, outcome)Plot incidence object\nSpecify labels, colors, titles, etc.\nSpecify labels, colors, titles, etc., load incidence2 package, create incidence object linelist column date_onset aggregated cases day. print summary incidence object.incidence2 object looks like tibble (like data frame) can printed manipulated like data frame.looks like printed. date_index column count column.can also print summary object:plot incidence object, use plot() name incidence object. background, function plot.incidence2() called, read incidence2-specific documentation run ?plot.incidence2.notice lots tiny white vertical lines, try adjust size image. example, export plot ggsave(), can provide numbers width = height =. widen plot lines may disappear.","code":"\n# load incidence2 package\npacman::p_load(incidence2)\n\n# create the incidence object, aggregating cases by day\nepi_day <- incidence(       # create incidence object\n  x = linelist,             # dataset\n  date_index = date_onset,  # date column\n  interval = \"day\"          # date grouping interval\n  )\nclass(epi_day)## [1] \"incidence2\" \"tbl_df\"     \"tbl\"        \"data.frame\"\nepi_day## An incidence2 object: 367 x 2\n## 5632 cases from 2014-04-07 to 2015-04-30\n## interval: 1 day\n## cumulative: FALSE\n## \n##    date_index count\n##    <date>     <int>\n##  1 2014-04-07     1\n##  2 2014-04-15     1\n##  3 2014-04-21     2\n##  4 2014-04-25     1\n##  5 2014-04-26     1\n##  6 2014-04-27     1\n##  7 2014-05-01     2\n##  8 2014-05-03     1\n##  9 2014-05-04     1\n## 10 2014-05-05     1\n## # ... with 357 more rows\n# print summary of the incidence object\nsummary(epi_day)## An incidence2 object: 367 x 2\n## 5632 cases from 2014-04-07 to 2015-04-30\n## interval: 1 day\n## cumulative: FALSE\n## timespan: 389 days\n# plot the incidence object\nplot(epi_day)"},{"path":"epicurves.html","id":"change-time-interval-of-case-aggregation","chapter":"32 Đường cong dịch bệnh","heading":"Change time interval of case aggregation","text":"interval = argument incidence() defines observations grouped vertical bars.Specify intervalincidence2 provides flexibility understandable syntax specifying want aggregate cases epicurve bars. Provide value like ones interval = argument. can write plural (e.g. “weeks”), can add numbers (e.g. “3 months”).examples different intervals look applied linelist. Note default format frequency date labels x-axis change date interval changes.First dateYou can optionally specify value class Date (e.g. .Date(\"2016-05-01\")) firstdate = incidence() command. given, data trimmed range intervals begin date.","code":"\n# Create the incidence objects (with different intervals)\n##############################\n# Weekly (Monday week by default)\nepi_wk      <- incidence(linelist, date_onset, interval = \"Monday week\")\n\n# Sunday week\nepi_Sun_wk  <- incidence(linelist, date_onset, interval = \"Sunday week\")\n\n# Three weeks (Monday weeks by default)\nepi_2wk     <- incidence(linelist, date_onset, interval = \"2 weeks\")\n\n# Monthly\nepi_month   <- incidence(linelist, date_onset, interval = \"month\")\n\n# Quarterly\nepi_quarter   <- incidence(linelist, date_onset, interval = \"quarter\")\n\n# Years\nepi_year   <- incidence(linelist, date_onset, interval = \"year\")\n\n\n# Plot the incidence objects (+ titles for clarity)\n############################\nplot(epi_wk)+      labs(title = \"Monday weeks\")\nplot(epi_Sun_wk)+  labs(title = \"Sunday weeks\")\nplot(epi_2wk)+     labs(title = \"2 (Monday) weeks\")\nplot(epi_month)+   labs(title = \"Months\")\nplot(epi_quarter)+ labs(title = \"Quarters\")\nplot(epi_year)+    labs(title = \"Years\")"},{"path":"epicurves.html","id":"groups","chapter":"32 Đường cong dịch bệnh","heading":"Groups","text":"Groups specified incidence() command, can used color bars facet data. specify groups data provide column name(s) groups = argument incidence() command (quotes around column name). specifying multiple columns, put names within c().can specify cases missing values grouping columns listed distinct NA group setting na_as_group = TRUE. Otherwise, excluded plot.color bars grouping column, must provide column name fill = plot() command.color bars grouping column, must provide column name fill = plot() command.facet based grouping column, see section facets incidence2.facet based grouping column, see section facets incidence2.example , cases whole outbreak grouped age category. Missing values included group. epicurve interval weeks.TIP: Change title legend adding + ggplot2 command labs(fill = \"title\") incidence2 plot.can also grouped bars display side--side setting stack = FALSE plot(), shown :can set na_as_group = argument FALSE incidence() command remove rows missing values plot.","code":"\n# Create incidence object, with data grouped by age category\nage_outbreak <- incidence(\n  linelist,                # dataset\n  date_index = date_onset, # date column\n  interval = \"week\",       # Monday weekly aggregation of cases\n  groups = age_cat,        # age_cat is set as a group\n  na_as_group = TRUE)      # missing values assigned their own group\n\n# plot the grouped incidence object\nplot(\n  age_outbreak,             # incidence object with age_cat as group\n  fill = age_cat)+          # age_cat is used for bar fill color (must have been set as a groups column above)\nlabs(fill = \"Age Category\") # change legend title from default \"age_cat\" (this is a ggplot2 modification)\n# Make incidence object of monthly counts. \nmonthly_gender <- incidence(\n linelist,\n date_index = date_onset,\n interval = \"month\",\n groups = gender            # set gender as grouping column\n)\n\nplot(\n  monthly_gender,   # incidence object\n  fill = gender,    # display bars colored by gender\n  stack = FALSE)    # side-by-side (not stacked)"},{"path":"epicurves.html","id":"filtered-data","chapter":"32 Đường cong dịch bệnh","heading":"Filtered data","text":"plot epicurve subset data:Filter linelist dataProvide filtered data incidence() commandPlot incidence objectThe example uses data filtered show cases Central Hospital.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(central_data, date_index = date_onset, interval = \"week\")\n\n# plot the incidence object\nplot(central_outbreak, title = \"Weekly case incidence at Central Hospital\")"},{"path":"epicurves.html","id":"aggregated-counts","chapter":"32 Đường cong dịch bệnh","heading":"Aggregated counts","text":"original data aggregated (counts), provide name column contains case counts count = argument creating incidence object incidence().example, data frame count_data linelist aggregated daily counts hospital. first 50 rows look like :beginning analysis daily count data like dataset , incidence() command convert weekly epicurve hospital look like :","code":"\nepi_counts <- incidence(              # create weekly incidence object\n  count_data,                         # dataset with counts aggregated by day\n  date_index = date_hospitalisation,  # column with dates\n  count = n_cases,                    # column with counts\n  interval = \"week\",                  # aggregate daily counts up to weeks\n  groups = hospital                   # group by hospital\n  )\n\n# plot the weekly incidence epi curve, with stacked bars by hospital\nplot(epi_counts,                      # incidence object\n     fill = hospital)                 # color the bars by hospital"},{"path":"epicurves.html","id":"facetssmall-multiples","chapter":"32 Đường cong dịch bệnh","heading":"Facets/small multiples","text":"facet data group (.e. produce “small multiples”):Specify faceting column groups = create incidence objectUse facet_plot() command instead plot()Specify grouping columns use fill = use facets =, set columns hospital outcome grouping columns incidence() command. , facet_plot() plot epicurve, specifying want different epicurve hospital within epicurve bars stacked colored outcome.Note package ggtree (used displaying phylogenetic trees) also function facet_plot() - specified incidence2::facet_plot() .","code":"\nepi_wks_hosp_out <- incidence(\n  linelist,                      # dataset\n  date_index = date_onset,       # date column\n  interval = \"month\",            # monthly bars  \n  groups = c(outcome, hospital)  # both outcome and hospital are given as grouping columns\n  )\n\n# plot\nincidence2::facet_plot(\n  epi_wks_hosp_out,      # incidence object\n  facets = hospital,     # facet column\n  fill = outcome)        # fill column"},{"path":"epicurves.html","id":"modifications-with-plot","chapter":"32 Đường cong dịch bệnh","heading":"Modifications with plot()","text":"epicurve produced incidence2 can modified via arguments within plot() function.plot() arguments modify appearance bars:plot() arguments modify date axis:Note date_breaks = argument works centre_dates = FALSE. Provide character value quotation marks using strptime syntax , detailed Working dates page. can use \\n “newline”.%d = Day number month (5, 17, 28, etc.)\n%j = Day number year (Julian day 001-366)\n%= Abbreviated weekday (Mon, Tue, Wed, etc.)\n%= Full weekday (Monday, Tuesday, etc.)\n%w = Weekday number (0-6, Sunday 0)\n%u = Weekday number (1-7, Monday 1)\n%W = Week number (00-53, Monday week start)\n%U = Week number (01-53, Sunday week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds\n%z = offset GMT\n%Z = Time zone (character)plot() arguments modify plot labels:example using many arguments:adjust plot appearance, see section modifications ggplot().","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = outcome)\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  alpha = 0.7,                          # transparency \n  border = \"grey\",                      # box border\n  angle = 30,                           # angle of date labels\n  centre_dates = FALSE,                 # date labels at edge of bar\n  date_format = \"%a %d %b %Y\\n(Week %W)\" # adjust how dates are displayed\n  )"},{"path":"epicurves.html","id":"modifications-with-ggplot2","chapter":"32 Đường cong dịch bệnh","heading":"Modifications with ggplot2","text":"can modify incidence2 plot adding ggplot2 modifications + close incidence plot() function, demonstrated ., incidence2 plot finishes ggplot2 commands used modify axes, add caption, adjust bold font text size.Note add scale_x_date(), date formatting plot() overwritten. See ggplot() epicurves section Handbook page [ggplot tips] options.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = c(outcome))\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  alpha = 0.7,                          # transparency \n  border = \"grey\",                      # box border\n  centre_dates = FALSE,                   \n  date_format = \"%a %d %b\\n%Y (Week %W)\", \n  angle = 30                           # angle of date labels\n  )+\n  \n  scale_y_continuous(\n    breaks = seq(from = 0, to = 30, by = 5),  # specify y-axis increments by 5\n    expand = c(0,0))+                         # remove excess space below 0 on y-axis\n  \n  # add dynamic caption\n  labs(\n    fill = \"Patient outcome\",                               # Legend title\n    caption = stringr::str_glue(                            # dynamic caption - see page on characters and strings for details\n      \"n = {central_cases} from Central Hospital\n      Case onsets range from {earliest_date} to {latest_date}. {missing_onset} cases are missing date of onset and not shown\",\n      central_cases = nrow(central_data),\n      earliest_date = format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),\n      latest_date = format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),      \n      missing_onset = nrow(central_data %>% filter(is.na(date_onset)))))+\n  \n  # adjust bold face, and caption position\n  theme(\n    axis.title = element_text(size = 12, face = \"bold\"),    # axis titles larger and bold\n    axis.text = element_text(size = 10, face = \"bold\"),     # axis text size and bold\n    plot.caption = element_text(hjust = 0, face = \"italic\") # move caption to left\n  )"},{"path":"epicurves.html","id":"change-colors","chapter":"32 Đường cong dịch bệnh","heading":"Change colors","text":"","code":""},{"path":"epicurves.html","id":"specify-a-palette","chapter":"32 Đường cong dịch bệnh","heading":"Specify a palette","text":"Provide name pre-defined palette col_pal = argument plot(). incidence2 package comes 2 pre-defined paletted: “vibrant” “muted”. “vibrant” first 6 colors distinct “muted” first 9 colors distinct. numbers, colors interpolations/intermediaries colors. pre-defined palettes can found website. palettes exclude grey, reserved missing data (use na_color = change default).can also use one base R palettes (put name palette without quotes).can also add color palette viridis package RColorBrewer package. First packages must loaded, add respective scale_fill_*() functions +, shown .","code":"\n# Create incidence object, with data grouped by age category  \nage_outbreak <- incidence(\n  linelist,\n  date_index = date_onset,   # date of onset for x-axis\n  interval = \"week\",         # weekly aggregation of cases\n  groups = age_cat)\n\n# plot the epicurve with default palette\nplot(age_outbreak, fill = age_cat, title = \"'vibrant' default incidence2 palette\")\n\n# plot with different color palette\n#plot(age_outbreak, fill = age_cat, col_pal = muted, title = \"'muted' incidence2 palette\")\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = heat.colors, title = \"base R heat.colors palette\")\n\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = rainbow, title = \"base R rainbow palette\")\npacman::p_load(RColorBrewer, viridis)\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"Viridis palette\")+\n  scale_fill_viridis_d(\n    option = \"inferno\",     # color scheme, try also \"plasma\" or the default\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"RColorBrewer palette\")+\n  scale_fill_brewer(\n    palette = \"Dark2\",      # color palette, try also Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values"},{"path":"epicurves.html","id":"specify-manually","chapter":"32 Đường cong dịch bệnh","heading":"Specify manually","text":"specify colors manually, add ggplot2 function scale_fill_manual() plot() + provide vector colors names HEX codes argument values =. number colors listed must equal number groups. aware whether missing values group - can converted character value like “Missing” data preparation function fct_explicit_na() explained page [Factors].mentioned [ggplot tips] page, can create palettes using colorRampPalette() vector colors specifying number colors want return. good way get many colors ramp specifying .","code":"\n# manual colors\nplot(age_outbreak, fill = age_cat, title = \"Manually-specified colors\")+\n  scale_fill_manual(\n    values = c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\", \"red\", \"lightblue\"),  # colors\n    name = \"Age Category\")      # Name for legend\nmy_cols <- c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\")\nmy_palette <- colorRampPalette(my_cols)(12)  # expand the 6 colors above to 12 colors\nmy_palette##  [1] \"#006400\" \"#00363F\" \"#00097E\" \"#3A0BAF\" \"#821ADD\" \"#A84BE2\" \"#B592CB\" \"#C9C99B\"\n##  [9] \"#E7E745\" \"#FFF600\" \"#FFCD00\" \"#FFA500\""},{"path":"epicurves.html","id":"adjust-level-order","chapter":"32 Đường cong dịch bệnh","heading":"Adjust level order","text":"adjust order group appearance (plot legend), grouping column must class Factor. See page [Factors] information.First, let’s see weekly epicurve hospital default ordering:Now, adjust order “Missing” “” top epicurve can following:Load package forcats, work factorsAdjust dataset - case ’ll define new dataset (plot_data) :\ngender column defined factor order levels set fct_relevel() “” “Missing” first, appear top bars\ngender column defined factor order levels set fct_relevel() “” “Missing” first, appear top barsThe incidence object created plotted beforeWe add ggplot2 modifications\nscale_fill_manual() manually assign colors “Missing” grey “” beige\nscale_fill_manual() manually assign colors “Missing” grey “” beigeTIP: want reverse order legend , add ggplot2 command guides(fill = guide_legend(reverse = TRUE)).","code":"\n# ORIGINAL - hospital NOT as factor\n###################################\n\n# create weekly incidence object, rows grouped by hospital and week\nhospital_outbreak <- incidence(\n  linelist,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak, fill = hospital, title = \"ORIGINAL - hospital not a factor\")\n# MODIFIED - hospital as factor\n###############################\n\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Convert hospital column to factor and adjust levels\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Set \"Missing\" and \"Other\" as top levels\n\n\n# Create weekly incidence object, grouped by hospital and week\nhospital_outbreak_mod <- incidence(\n  plot_data,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak_mod, fill = hospital)+\n  \n  # manual specify colors\n  scale_fill_manual(values = c(\"grey\", \"beige\", \"darkgreen\", \"green2\", \"orange\", \"red\", \"pink\"))+                      \n\n  # labels added via ggplot\n  labs(\n      title = \"MODIFIED - hospital as factor\",   # plot title\n      subtitle = \"Other & Missing at top of epicurve\",\n      y = \"Weekly case incidence\",               # y axis title  \n      x = \"Week of symptom onset\",               # x axis title\n      fill = \"Hospital\")                         # title of legend     "},{"path":"epicurves.html","id":"vertical-gridlines","chapter":"32 Đường cong dịch bệnh","heading":"Vertical gridlines","text":"plot default incidence2 settings, may notice vertical gridlines appear date label date label. can result gridlines intersecting top bars.can remove gridlines adding ggplot2 command theme_classic().Note however, using weeks, date_breaks date_minor_breaks arguments work Monday weeks. weeks another day week need manually provide vector dates breaks = minor_breaks = arguments instead. See ggplot2 section examples using seq.Date().","code":"\n# make incidence object\na <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"Monday weeks\"\n)\n\n# Default gridlines\nplot(a, title = \"Default lines\")\n\n# Specified gridline intervals\n# NOT WORKING WITH INCIDENCE2 1.0.0\n# plot(a, title = \"Weekly lines\")+\n#   scale_x_date(\n#     date_breaks = \"4 weeks\",      # major vertical lines align on weeks\n#     date_minor_breaks = \"weeks\",  # minor vertical lines every week\n#     date_labels = \"%a\\n%d\\n%b\")   # format of date labels\n\n# No gridlines\nplot(a, title = \"No lines\")+\n  theme_classic()                 # remove all gridlines"},{"path":"epicurves.html","id":"cumulative-incidence","chapter":"32 Đường cong dịch bệnh","heading":"Cumulative incidence","text":"can easily produce plot cumulative incidence passing incidence object incidence2 command cumulate() plot(). also works facet_plot().See section farther page alternative method plot cumulative incidence ggplot2 - example overlay cumulative incidence line epicurve.","code":"\n# make weekly incidence object\nwkly_inci <- incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"week\"\n)## 256 missing observations were removed.\n# plot cumulative incidence\nwkly_inci %>% \n  cumulate() %>% \n  plot()"},{"path":"epicurves.html","id":"rolling-average","chapter":"32 Đường cong dịch bệnh","heading":"Rolling average","text":"can add rolling average incidence2 plot easily add_rolling_average() i2extras package. Pass incidence2 object function, plot(). Set = number previous days want included rolling average (default 2). data grouped, rolling average calculated per group.learn apply rolling averages generally data, see Handbook page Moving averages.","code":"\nrolling_avg <- incidence(                    # make incidence object\n  linelist,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = gender) %>% \n  \n  i2extras::add_rolling_average(before = 6)  # add rolling averages (in this case, by gender)\n\n# plot\nplot(rolling_avg, n.breaks = 3) # faceted automatically because rolling average on groups"},{"path":"epicurves.html","id":"epicurves-with-ggplot2","chapter":"32 Đường cong dịch bệnh","heading":"32.3 Epicurves with ggplot2","text":"Using ggplot() build epicurve allows flexibility customization, requires effort understanding ggplot() works.Unlike using incidence2 package, must manually control aggregation cases time (weeks, months, etc) intervals labels date axis. must carefully managed.examples use subset linelist dataset - cases Central Hospital.produce epicurve ggplot() three main elements:histogram, linelist cases aggregated “bins” distinguished specific “break” pointsScales axes labelsThemes plot appearance, including titles, labels, captions, etc.","code":"\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")"},{"path":"epicurves.html","id":"specify-case-bins","chapter":"32 Đường cong dịch bệnh","heading":"Specify case bins","text":"show specify cases aggregated histogram bins (“bars”). important recognize aggregation cases histogram bins necessarily intervals dates appear x-axis.perhaps simple code produce daily weekly epicurves.-arching ggplot() command dataset provided data =. Onto foundation, geometry histogram added +. Within geom_histogram(), map aesthetics column date_onset mapped x-axis. Also within geom_histogram() within aes() set binwidth = histogram bins, days. ggplot2 syntax confusing, review page [ggplot basics].CAUTION: Plotting weekly cases using binwidth = 7 starts first 7-day bin first case, day week! create specific weeks, see section .Let us note first case Central Hospital dataset symptom onset :manually specify histogram bin breaks, use binwidth = argument, instead supply vector dates breaks =.Create vector dates base R function seq.Date(). function expects arguments =, =, =. example, command returns monthly dates starting Jan 15 ending June 28.vector can provided geom_histogram() breaks =:simple weekly date sequence can returned setting = \"week\". example:alternative supplying specific start end dates write dynamic code weekly bins begin Monday first case. use date vectors throughout examples .Let’s unpack rather daunting code :“” value (earliest date sequence) created follows: minimum date value (min() na.rm=TRUE) column date_onset fed floor_date() lubridate package. floor_date() set “week” returns start date cases’s “week”, given start day week Monday (week_start = 1).Likewise, “” value (end date sequence) created using inverse function ceiling_date() return Monday last case.“” argument seq.Date() can set number days, weeks, months.Use week_start = 7 Sunday weeksAs use date vectors throughout page, also define one whole outbreak (Central Hospital ).seq.Date() outputs can used create histogram bin breaks, also breaks date labels, may independent bins. Read date labels later sections.TIP: simple ggplot() command, save bin breaks date label breaks named vectors advance, simply provide names breaks =.","code":"\n# daily \nggplot(data = central_data) +          # set data\n  geom_histogram(                      # add histogram\n    mapping = aes(x = date_onset),     # map date column to x-axis\n    binwidth = 1)+                     # cases binned by 1 day \n  labs(title = \"Central Hospital - Daily\")                # title\n\n# weekly\nggplot(data = central_data) +          # set data \n  geom_histogram(                      # add histogram\n      mapping = aes(x = date_onset),   # map date column to x-axis\n      binwidth = 7)+                   # cases binned every 7 days, starting from first case (!) \n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # title\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")## [1] \"Thursday 01 May, 2014\"\nmonthly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks   # print##  [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\" \"2014-07-01\"\n##  [7] \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\" \"2014-12-01\" \"2015-01-01\"\n## [13] \"2015-02-01\" \"2015-03-01\" \"2015-04-01\" \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n# monthly \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # provide the pre-defined vector of breaks                    \n  labs(title = \"Monthly case bins\")   # title\nweekly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n# Sequence of weekly Monday dates for CENTRAL HOSPITAL\nweekly_breaks_central <- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")\n# Sequence for the entire outbreak\nweekly_breaks_all <- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")"},{"path":"epicurves.html","id":"weekly-epicurve-example","chapter":"32 Đường cong dịch bệnh","heading":"Weekly epicurve example","text":"detailed example code produce weekly epicurves Monday weeks, aligned bars, date labels, vertical gridlines. section user needs code quickly. understand aspect (themes, date labels, etc.) -depth, continue subsequent sections. note:histogram bin breaks defined seq.Date() explained begin Monday earliest case end Monday last caseThe interval date labels specified date_breaks = within scale_x_date()interval minor vertical gridlines date labels specified date_minor_breaks =expand = c(0,0) x y scales removes excess space side axes, also ensures date labels begin first bar.","code":"\n# TOTAL MONDAY WEEK ALIGNMENT\n#############################\n# Define sequence of weekly breaks\nweekly_breaks_central <- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # Monday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # Monday after last case\n      by   = \"week\")    # bins are 7-days \n\n\nggplot(data = central_data) + \n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    \n    # mapping aesthetics\n    mapping = aes(x = date_onset),  # date column mapped to x-axis\n    \n    # histogram bin breaks\n    breaks = weekly_breaks_central, # histogram bin breaks defined previously\n    \n    # bars\n    color = \"darkblue\",     # color of lines around bars\n    fill = \"lightblue\"      # color of fill within bars\n  )+ \n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"4 weeks\",        # date labels and major vertical gridlines appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # minor vertical lines appear every Monday week\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+             # remove excess y-axis space below 0 (align histogram flush with x-axis)\n  \n  # aesthetic themes\n  theme_minimal()+                # simplify plot background\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # caption on left side\n                                face = \"italic\"), # caption in italics\n    axis.title = element_text(face = \"bold\"))+    # axis titles in bold\n  \n  # labels including dynamic caption\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epicurves.html","id":"sunday-weeks","chapter":"32 Đường cong dịch bệnh","heading":"Sunday weeks","text":"achieve plot Sunday weeks modifications needed, date_breaks = \"weeks\" work Monday weeks.break points histogram bins must set Sundays (week_start = 7)Within scale_x_date(), similar date breaks provided breaks = minor_breaks = ensure date labels vertical gridlines align Sundays.example, scale_x_date() command Sunday weeks look like :","code":"scale_x_date(\n    expand = c(0,0),\n    \n    # specify interval of date labels and major vertical gridlines\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"4 weeks\"),\n    \n    # specify interval of minor vertical gridline \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"week\"),\n   \n    # date label format\n    date_labels = \"%a\\n%d %b\\n%Y\")+         # day, above month abbrev., above 2-digit year"},{"path":"epicurves.html","id":"groupcolor-by-value","chapter":"32 Đường cong dịch bệnh","heading":"Group/color by value","text":"histogram bars can colored group “stacked”. designate grouping column, make following changes. See [ggplot basics] page details.Within histogram aesthetic mapping aes(), map column name group = fill = argumentsRemove fill = argument outside aes(), override one insideArguments inside aes() apply group, whereas outside apply bars (e.g. may still want color = outside, bar border)aes() command look like group color bars gender:applied:","code":"\naes(x = date_onset, group = gender, fill = gender)\nggplot(data = linelist) +     # begin with linelist (many hospitals)\n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # set data to be grouped by hospital\n      fill = hospital),       # bar fill (inside color) by hospital\n    \n    # bin breaks are Monday weeks\n    breaks = weekly_breaks_all,   # sequence of weekly Monday bin breaks for whole outbreak, defined in previous code       \n    \n    # Color around bars\n    color = \"black\")"},{"path":"epicurves.html","id":"adjust-colors","chapter":"32 Đường cong dịch bệnh","heading":"Adjust colors","text":"manually set fill group, use scale_fill_manual() (note: scale_color_manual() different!).\nUse values = argument apply vector colors.\nUse na.value = specify color NA values.\nUse labels = argument change text legend items. safe, provide named vector like c(\"old\" = \"new\", \"old\" = \"new\") adjust values data .\nUse name = give proper title legend\nUse values = argument apply vector colors.Use na.value = specify color NA values.Use labels = argument change text legend items. safe, provide named vector like c(\"old\" = \"new\", \"old\" = \"new\") adjust values data .Use name = give proper title legendFor tips color scales palettes, see page [ggplot basics].","code":"\nggplot(data = linelist)+           # begin with linelist (many hospitals)\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # cases grouped by hospital\n        fill = hospital),          # bar fill by hospital\n    \n    # bin breaks\n    breaks = weekly_breaks_all,        # sequence of weekly Monday bin breaks, defined in previous code\n    \n    # Color around bars\n    color = \"black\")+              # border color of each bar\n  \n  # manual specification of colors\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\") # specify fill colors (\"values\") - attention to order!"},{"path":"epicurves.html","id":"adjust-level-order-1","chapter":"32 Đường cong dịch bệnh","heading":"Adjust level order","text":"order grouped bars stacked best adjusted classifying grouping column class Factor. can designate factor level order (display labels). See page [Factors] [ggplot tips] details.making plot, use fct_relevel() function forcats package convert grouping column class factor manually adjust level order, detailed page [Factors].plot, differences previous column hospital consolidated , use guides() reverse legend order, “Missing” bottom legend.TIP: reverse order legend , add ggplot2 command: guides(fill = guide_legend(reverse = TRUE)).","code":"\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Define new dataset with hospital as factor\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convert to factor and set \"Missing\" and \"Other\" as top levels to appear on epicurve top\n\nlevels(plot_data$hospital) # print levels in order## [1] \"Missing\"                              \"Other\"                               \n## [3] \"Central Hospital\"                     \"Military Hospital\"                   \n## [5] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\nggplot(plot_data) +                     # Use NEW dataset with hospital as re-ordered factor\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # cases grouped by hospital\n        fill = hospital),               # bar fill (color) by hospital\n    \n    breaks = weekly_breaks_all,         # sequence of weekly Monday bin breaks for whole outbreak, defined at top of ggplot section\n    \n    color = \"black\")+                   # border color around each bar\n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space before and after case bars\n    date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n    date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n    date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+                   # remove excess y-axis space below 0\n  \n  # manual specification of colors, ! attention to order\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\")+ \n  \n  # aesthetic themes\n  theme_minimal()+                      # simplify plot background\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # caption on left side in italics\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # axis titles in bold\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\")"},{"path":"epicurves.html","id":"adjust-legend","chapter":"32 Đường cong dịch bệnh","heading":"Adjust legend","text":"Read legends scales [ggplot tips] page. highlights:Edit legend title either scale function labs(fill = \"Legend title\") (using color = aesthetic, use labs(color = \"\"))theme(legend.title = element_blank()) legend titletheme(legend.position = \"top\") (“bottom”, “left”, “right”, “none” remove legend)theme(legend.direction = \"horizontal\") horizontal legendguides(fill = guide_legend(reverse = TRUE)) reverse order legend","code":""},{"path":"epicurves.html","id":"bars-side-by-side","chapter":"32 Đường cong dịch bệnh","heading":"Bars side-by-side","text":"Side--side display group bars (opposed stacked) specified within geom_histogram() position = \"dodge\" placed outside aes().two value groups, can become difficult read. Consider instead using faceted plot (small multiples). improve readability example, missing gender values removed.","code":"\nggplot(central_data %>% drop_na(gender))+   # begin with Central Hospital cases dropping missing gender\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # cases grouped by gender\n          fill = gender),         # bars filled by gender\n        \n        # histogram bin breaks\n        breaks = weekly_breaks_central,   # sequence of weekly dates for Central outbreak - defined at top of ggplot section\n        \n        color = \"black\",          # bar edge color\n        \n        position = \"dodge\")+      # SIDE-BY-SIDE bars\n                      \n  \n  # The labels on the x-axis\n  scale_x_date(expand            = c(0,0),         # remove excess x-axis space below and after case bars\n               date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n               date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n               date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+             # removes excess y-axis space between bottom of bars and the labels\n  \n  #scale of colors and legend labels\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # specify fill colors (\"values\") - attention to order!\n                    na.value = \"grey\" )+     \n\n  # aesthetic themes\n  theme_minimal()+                                               # a set of themes to simplify plot\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n        axis.title = element_text(face = \"bold\"))+               # axis titles in bold\n  \n  # labels\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")"},{"path":"epicurves.html","id":"axis-limits","chapter":"32 Đường cong dịch bệnh","heading":"Axis limits","text":"two ways limit extent axis values.Generally preferred way use command coord_cartesian(), accepts xlim = c(min, max) ylim = c(min, max) (provide min max values). acts “zoom” without actually removing data, important statistics summary measures.Alternatively, can set maximum minimum date values using limits = c() within scale_x_date(). example:Likewise, want x-axis extend specific date (e.g. current date), even new cases reported, can use:DANGER: cautious setting y-axis scale breaks limits (e.g. 0 30 5: seq(0, 30, 5)). static numbers can cut-plot short data changes exceed limit!.","code":"\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # sets a minimum date but leaves the maximum open.  scale_x_date(limits = c(NA, Sys.Date()) # ensures date axis will extend until current date  "},{"path":"epicurves.html","id":"date-axis-labelsgridlines","chapter":"32 Đường cong dịch bệnh","heading":"Date-axis labels/gridlines","text":"TIP: Remember date-axis labels independent aggregation data bars, visually can important align bins, date labels, vertical grid lines.modify date labels grid lines, use scale_x_date() one ways:histogram bins days, Monday weeks, months, years:\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)\nUse date_minor_breaks = specify interval minor vertical gridlines (date labels)\nAdd expand = c(0,0) begin labels first bar\nUse date_labels = specify format date labels - see Dates page tips (use \\n new line)\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)Use date_minor_breaks = specify interval minor vertical gridlines (date labels)Add expand = c(0,0) begin labels first barUse date_labels = specify format date labels - see Dates page tips (use \\n new line)histogram bins Sunday weeks:\nUse breaks = minor_breaks = providing sequence date breaks \ncan still use date_labels = expand = formatting described \nUse breaks = minor_breaks = providing sequence date breaks eachYou can still use date_labels = expand = formatting described aboveSome notes:See opening ggplot section instructions create sequence dates using seq.Date().See page Working dates page tips creating date labels.","code":""},{"path":"epicurves.html","id":"demonstrations","chapter":"32 Đường cong dịch bệnh","heading":"Demonstrations","text":"demonstration plots bins plot labels/grid lines aligned aligned:","code":"\n# 7-day bins + Monday labels\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # 7-day bins with start at first case\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),               # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",       # Monday every 3 weeks\n    date_minor_breaks = \"week\",    # Monday weeks\n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # remove excess space under x-axis, make flush\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# 7-day bins + Months\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                  # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",           # 1st of month\n    date_minor_breaks = \"week\",       # Monday weeks\n    date_labels = \"%a\\n%d %b\\n%Y\")+    # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# TOTAL MONDAY ALIGNMENT: specify manual bin breaks to be mondays\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"4 weeks\",           # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%a\\n%d %b\\n%Y\")+      # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# TOTAL MONDAY ALIGNMENT WITH MONTHS LABELS:\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,            # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",            # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%b\\n%Y\")+          # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  theme(panel.grid.major = element_blank())+  # Remove major gridlines (fall on 1st of month)\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# TOTAL SUNDAY ALIGNMENT: specify manual bin breaks AND labels to be Sundays\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"7 days\"),\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # date label breaks and major gridlines set to every 3 weeks beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"3 weeks\"),\n    \n    # minor gridlines set to weekly beginning Sunday before first case\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by   = \"7 days\"),\n    \n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")"},{"path":"epicurves.html","id":"aggregated-data","chapter":"32 Đường cong dịch bệnh","heading":"Aggregated data","text":"Often instead linelist, begin aggregated counts facilities, districts, etc. can make epicurve ggplot() code slightly different. section utilize count_data dataset imported earlier, data preparation section. dataset linelist aggregated day-hospital counts. first 50 rows displayed .","code":""},{"path":"epicurves.html","id":"plotting-daily-counts","chapter":"32 Đường cong dịch bệnh","heading":"Plotting daily counts","text":"can plot daily epicurve daily counts. differences code:Within aesthetic mapping aes(), specify y = counts column (case, column name n_cases)Add argument stat = \"identity\" within geom_histogram(), specifies bar height y = value, number rows defaultAdd argument width = avoid vertical white lines bars. daily data set 1. weekly count data set 7. monthly count data, white lines issue (month different number days) - consider transforming x-axis categorical ordered factor (months) using geom_col().","code":"\nggplot(data = count_data)+\n  geom_histogram(\n   mapping = aes(x = date_hospitalisation, y = n_cases),\n   stat = \"identity\",\n   width = 1)+                # for daily counts, set width = 1 to avoid white space between bars\n  labs(\n    x = \"Date of report\", \n    y = \"Number of cases\",\n    title = \"Daily case incidence, from daily count data\")"},{"path":"epicurves.html","id":"plotting-weekly-counts","chapter":"32 Đường cong dịch bệnh","heading":"Plotting weekly counts","text":"data already case counts week, might look like dataset (called count_data_weekly):first 50 rows count_data_weekly displayed . can see counts aggregated weeks. week displayed first day week (Monday default).Now plot x = epiweek column. Remember add y = counts column aesthetic mapping, add stat = \"identity\" explained .","code":"\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # x-axis is epiweek (as class Date)\n      y = n_cases_weekly,    # y-axis height in the weekly case counts\n      group = hospital,      # we are grouping the bars and coloring by hospital\n      fill = hospital),\n    stat = \"identity\")+      # this is also required when plotting count data\n     \n  # labels for x-axis\n  scale_x_date(\n    date_breaks = \"2 months\",      # labels every 2 months \n    date_minor_breaks = \"1 month\", # gridlines every month\n    date_labels = '%b\\n%Y')+       #labeled by month with year below\n     \n  # Choose color palette (uses RColorBrewer package)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")"},{"path":"epicurves.html","id":"moving-averages","chapter":"32 Đường cong dịch bệnh","heading":"Moving averages","text":"See page Moving averages detailed description several options. one option calculating moving averages package slider. approach, moving average calculated dataset prior plotting:Aggregate data counts necessary (daily, weekly, etc.) (see [Grouping data] page)Create new column hold moving average, created slide_index() slider packagePlot moving average geom_line() top () epicurve histogramSee helpful online vignette slider package","code":"\n# load package\npacman::p_load(slider)  # slider used to calculate rolling averages\n\n# make dataset of daily counts and 7-day moving average\n#######################################################\nll_counts_7day <- linelist %>%    # begin with linelist\n  \n  ## count cases by date\n  count(date_onset, name = \"new_cases\") %>%   # name new column with counts as \"new_cases\"\n  drop_na(date_onset) %>%                     # remove cases with missing date_onset\n  \n  ## calculate the average number of cases in 7-day window\n  mutate(\n    avg_7day = slider::slide_index(    # create new column\n      new_cases,                       # calculate based on value in new_cases column\n      .i = date_onset,                 # index is date_onset col, so non-present dates are included in window \n      .f = ~mean(.x, na.rm = TRUE),    # function is mean() with missing values removed\n      .before = 6,                     # window is the day and 6-days before\n      .complete = FALSE),              # must be FALSE for unlist() to work in next step\n    avg_7day = unlist(avg_7day))       # convert class list to class numeric\n\n\n# plot\n######\nggplot(data = ll_counts_7day) +  # begin with new dataset defined above \n    geom_histogram(              # create epicurve histogram\n      mapping = aes(\n        x = date_onset,          # date column as x-axis\n        y = new_cases),          # height is number of daily new cases\n        stat = \"identity\",       # height is y value\n        fill=\"#92a8d1\",          # cool color for bars\n        colour = \"#92a8d1\",      # same color for bar border\n        )+ \n    geom_line(                   # make line for rolling average\n      mapping = aes(\n        x = date_onset,          # date column for x-axis\n        y = avg_7day,            # y-value set to rolling average column\n        lty = \"7-day \\nrolling avg\"), # name of line in legend\n      color=\"red\",               # color of line\n      size = 1) +                # width of line\n    scale_x_date(                # date scale\n      date_breaks = \"1 month\",\n      date_labels = '%d/%m',\n      expand = c(0,0)) +\n    scale_y_continuous(          # y-axis scale\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # removes title of legend"},{"path":"epicurves.html","id":"facetingsmall-multiples","chapter":"32 Đường cong dịch bệnh","heading":"Faceting/small-multiples","text":"ggplots, can create facetted plots (“small multiples”). explained [ggplot tips] page handbook, can use either facet_wrap() facet_grid(). demonstrate facet_wrap(). epicurves, facet_wrap() typically easier likely need facet one column.general syntax facet_wrap(rows ~ cols), left tilde (~) name column spread across “rows” facetted plot, right tilde name column spread across “columns” facetted plot. simply, just use one column name, right tilde: facet_wrap(~age_cat).Free axes\nneed decide whether scales axes facet “fixed” dimensions (default), “free” (meaning change based data within facet). scales = argument within facet_wrap() specifying “free_x” “free_y”, “free”.Number cols rows facets\ncan specified ncol = nrow = within facet_wrap().Order panels\nchange order appearance, change underlying order levels factor column used create facets.Aesthetics\nFont size face, strip color, etc. can modified theme() arguments like:strip.text = element_text() (size, colour, face, angle…)strip.background = element_rect() (e.g. element_rect(fill=“grey”))strip.position = (position strip “bottom”, “top”, “left”, “right”)Strip labels\nLabels facet plots can modified “labels” column factor, use “labeller”.Make labeller like , using function as_labeller() ggplot2. provide labeller labeller = argument facet_wrap() shown .example facetted plot - facetted column age_cat.See link information labellers.","code":"\nmy_labels <- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n# make plot\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # arguments inside aes() apply by group\n      \n    color = \"black\",      # arguments outside aes() apply to all data\n        \n    # histogram breaks\n    breaks = weekly_breaks_central)+  # pre-defined date vector (see earlier in this page)\n                      \n  # The labels on the x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+                       # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epicurves.html","id":"total-epidemic-in-facet-background","chapter":"32 Đường cong dịch bệnh","heading":"Total epidemic in facet background","text":"show total epidemic background facet, add function gghighlight() empty parentheses ggplot. package gghighlight. Note y-axis maximum facets now based peak entire epidemic. examples package [ggplot tips] page.","code":"\nggplot(central_data) + \n  \n  # epicurves by group\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # arguments inside aes() apply by group\n    \n    color = \"black\",    # arguments outside aes() apply to all data\n    \n    # histogram breaks\n    breaks = weekly_breaks_central)+     # pre-defined date vector (see top of ggplot section)                \n  \n  # add grey epidemic in background to each facet\n  gghighlight::gghighlight()+\n  \n  # labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space below 0\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,                          # each plot is one value of age_cat\n    ncol = 4,                          # number of columns\n    strip.position = \"top\",            # position of the facet title/strip\n    labeller = my_labels)+             # labeller defines above\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epicurves.html","id":"one-facet-with-data","chapter":"32 Đường cong dịch bệnh","heading":"One facet with data","text":"want one facet box contains data, duplicate entire dataset treat duplicates one faceting value. “helper” function CreateAllFacet() can assist (thanks blog post). run, number rows doubles new column called facet duplicated rows value “”, original rows original value faceting colum. Now just facet facet column.helper function. Run available .Now apply helper function dataset, column age_cat:Notable changes ggplot() command :data used now central_data2 (double rows, new column “facet”)Labeller need updated, usedOptional: achieve vertically stacked facets: facet column moved rows side equation right replaced “.” (facet_wrap(facet~.)), ncol = 1. may also need adjust width height saved png plot image (see ggsave() [ggplot tips]).","code":"\n# Define helper function\nCreateAllFacet <- function(df, col){\n     df$facet <- df[[col]]\n     temp <- df\n     temp$facet <- \"all\"\n     merged <-rbind(temp, df)\n     \n     # ensure the facet value is a factor\n     merged[[col]] <- as.factor(merged[[col]])\n     \n     return(merged)\n}\n# Create dataset that is duplicated and with new column \"facet\" to show \"all\" age categories as another facet level\ncentral_data2 <- CreateAllFacet(central_data, col = \"age_cat\") %>%\n  \n  # set factor levels\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))## Warning: Unknown levels in `f`: 70+\n# check levels\ntable(central_data2$facet, useNA = \"always\")## \n##   all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  <NA> \n##   454    84    84    82    58    73    57     7     9\nggplot(central_data2) + \n  \n  # actual epicurves by group\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # arguments inside aes() apply by group\n        color = \"black\",    # arguments outside aes() apply to all data\n        \n        # histogram breaks\n        breaks = weekly_breaks_central)+    # pre-defined date vector (see top of ggplot section)\n                     \n  # Labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # create facets\n  facet_wrap(facet~. ,                            # each plot is one value of facet\n             ncol = 1)+            \n\n  # labels\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epicurves.html","id":"tentative-data","chapter":"32 Đường cong dịch bệnh","heading":"32.4 Tentative data","text":"recent data shown epicurves often marked tentative, subject reporting delays. can done adding vertical line /rectangle specified number days. two options:Use annotate():\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.\nrectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.rectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.Group data tentative status color bars differentlyCAUTION: might try geom_rect() draw rectangle, adjusting transparency work linelist context. function overlays one rectangle observation/row!. Use either low alpha (e.g. 0.01), another approach. ","code":""},{"path":"epicurves.html","id":"using-annotate","chapter":"32 Đường cong dịch bệnh","heading":"Using annotate()","text":"Within annotate(geom = \"rect\"), xmin xmax arguments must given inputs class Date.Note data aggregated weekly bars, last bar extends Monday last data point, shaded region may appear cover 4 weeksHere annotate() online exampleThe black vertical line can achieved code , using geom_vline() lose ability control height:","code":"\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"1 month\",           # 1st of month\n    date_minor_breaks = \"1 month\",     # 1st of month\n    date_labels = \"%b\\n'%y\")+          # label format\n  \n  # labels and theme\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # add semi-transparent red rectangle to tentative data\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # note must be wrapped in as.Date()\n    xmax  = as.Date(Inf),                                          # note must be wrapped in as.Date()\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # alpha easy and intuitive to adjust using annotate()\n    fill  = \"red\")+\n  \n  # add black vertical line on top of other layers\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 days before last data\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # line begins at y = 0\n    yend  = Inf,       # line to top of plot\n    size  = 2,         # line size\n    color = \"black\",\n    lty   = \"solid\")+   # linetype e.g. \"solid\", \"dashed\"\n\n  # add text in rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")"},{"path":"epicurves.html","id":"bars-color","chapter":"32 Đường cong dịch bệnh","heading":"Bars color","text":"alternative approach adjust color display tentative bars data . create new column data preparation stage use group data, aes(fill = ) tentative data can different color alpha bars.","code":"\n# add column\n############\nplot_data <- central_data %>% \n  mutate(tentative = case_when(\n    date_onset >= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative if in last 7 days\n    TRUE                                       ~ \"Reliable\")) # all else reliable\n\n# plot\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogram\n  geom_histogram(\n    breaks = weekly_breaks_central,   # pre-defined data vector, see top of ggplot page\n    color = \"black\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",           # Monday every 3 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%d\\n%b\\n'%y\")+      # label format\n  \n  # labels and theme\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # remove title of legend"},{"path":"epicurves.html","id":"multi-level-date-labels","chapter":"32 Đường cong dịch bệnh","heading":"32.5 Multi-level date labels","text":"want multi-level date labels (e.g. month year) without duplicating lower label levels, consider one approaches :Remember - can can use tools like \\n within date_labels labels arguments put parts label new line . However, code helps take years months (example) lower line . notes code :Case counts aggregated weeks aesthetic reasons. See Epicurves page (aggregated data tab) details.geom_area() line used instead histogram, faceting approach work well histograms.Aggregate weekly countsMake plotsThe techniques adapted post stackoverflow.com.","code":"\n# Create dataset of case counts by week\n#######################################\ncentral_weekly <- linelist %>%\n  filter(hospital == \"Central Hospital\") %>%   # filter linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %>%  \n  count(week) %>%                              # summarize weekly case counts\n  drop_na(week) %>%                            # remove cases with missing onset_date\n  complete(                                    # fill-in all weeks with no cases reported\n    week = seq.Date(\n      from = min(week),   \n      to   = max(week),\n      by   = \"week\"),\n    fill = list(n = 0))                        # convert new NA values to 0 counts\n# plot with box border on year\n##############################\nggplot(central_weekly) +\n  geom_area(aes(x = week, y = n),    # make line, specify x and y\n            stat = \"identity\") +             # because line height is count number\n  scale_x_date(date_labels=\"%b\",             # date label format show month \n               date_breaks=\"month\",          # date labels on 1st of each month\n               expand=c(0,0)) +              # remove excess space on each end\n  scale_y_continuous(\n    expand  = c(0,0))+                       # remove excess space below x-axis\n  facet_grid(~lubridate::year(week), # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",                # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                   # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",         # facet labels placement\n        strip.background = element_rect(fill = NA, # facet labels no fill grey border\n                                        colour = \"grey50\"),\n        panel.spacing = unit(0, \"cm\"))+      # no space between facet panels\n  labs(title = \"Nested year labels, grey label border\")\n# plot with no box border on year\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # establish x and y for entire plot\n  geom_line(stat = \"identity\",              # make line, line height is count number\n            color = \"#69b3a2\") +            # line color\n  geom_point(size=1, color=\"#69b3a2\") +     # make points at the weekly data points\n  geom_area(fill = \"#69b3a2\",               # fill area below line\n            alpha = 0.4)+                   # fill transparency\n  scale_x_date(date_labels=\"%b\",            # date label format show month \n               date_breaks=\"month\",         # date labels on 1st of each month\n               expand=c(0,0)) +             # remove excess space\n  scale_y_continuous(\n    expand  = c(0,0))+                      # remove excess space below x-axis\n  facet_grid(~lubridate::year(week),        # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",               # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                  # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",                     # facet label placement\n          strip.background = element_blank(),            # no facet lable background\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_rect(colour=\"grey40\"),  # grey border to facet PANEL\n          panel.spacing=unit(0,\"cm\"))+                   # No space between facet panels\n  labs(title = \"Nested year labels - points, shaded, no label border\")"},{"path":"epicurves.html","id":"dual-axis","chapter":"32 Đường cong dịch bệnh","heading":"32.6 Dual-axis","text":"Although fierce discussions validity dual axes within data visualization community, many epi supervisors still want see epicurve similar chart percent overlaid second axis. discussed extensively [ggplot tips] page, one example using cowplot method shown :Two distinct plots made, combined cowplot package.plots must exact x-axis (set limits) else data labels alignEach uses theme_cowplot() one y-axis moved right side plotNow use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\n#######################################\nplot_cases <- linelist %>% \n  \n  # plot cases per week\n  ggplot()+\n  \n  # create histogram  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks every week beginning monday before first case, going to monday after last case\n    breaks = weekly_breaks_all)+  # pre-defined vector of weekly dates (see top of ggplot section)\n        \n  # specify beginning and end of date axis to align with other plot\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  # labels\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# make second plot of percent died per week\n###########################################\nplot_deaths <- linelist %>%                        # begin with linelist\n  group_by(week = floor_date(date_onset, \"week\")) %>%  # create week column\n  \n  # summarise to get weekly percent of cases who died\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %>% \n  \n  # begin plot\n  ggplot()+\n  \n  # line of weekly percent who died\n  geom_line(                                # create line of percent died\n    mapping = aes(x = week, y = pct_died),  # specify y-height as pct_died column\n    stat = \"identity\",                      # set line height to the value in pct_death column, not the number of rows (which is default)\n    size = 2,\n    color = \"black\")+\n  \n  # Same date-axis limits as the other plot - perfect alignment\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  \n  # y-axis adjustments\n  scale_y_continuous(                # adjust y-axis\n    breaks = seq(0,100, 10),         # set break intervals of percent axis\n    limits = c(0, 100),              # set extent of percent axis\n    position = \"right\")+             # move percent axis to the right\n  \n  # Y-axis label, no x-axis label\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # percent axis label\n  \n  theme_cowplot()                   # add this to make the two plots merge together nicely\naligned_plots <- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epicurves.html","id":"cumulative-incidence-1","chapter":"32 Đường cong dịch bệnh","heading":"32.7 Cumulative Incidence","text":"Note: using incidence2, see section can produce cumulative incidence simple function. page address calculate cumulative incidence plot ggplot().beginning case linelist, create new column containing cumulative number cases per day outbreak using cumsum() base R:first 10 rows shown :cumulative column can plotted date_onset, using geom_line():can also overlaid onto epicurve, dual-axis using cowplot method described [ggplot tips] page:Now use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\ncumulative_case_counts <- linelist %>% \n  count(date_onset) %>%                # count of rows per day (returned in column \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n)       # new column of the cumulative number of rows at each date\n    )\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\nplot_cases <- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# make second plot of cumulative cases line\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\naligned_plots <- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epicurves.html","id":"resources-18","chapter":"32 Đường cong dịch bệnh","heading":"32.8 Resources","text":"","code":""},{"path":"age-pyramid.html","id":"age-pyramid","chapter":"33 Tháp dân số và thang đo Likert","heading":"33 Tháp dân số và thang đo Likert","text":"Kim tự tháp nhân khẩu học rất hữu ích khi bạn muốn hiển thị sự phân bố về độ tuổi và giới tính. Code tương tự cũng có thể được sử dụng để trực quan hóa kết quả của các câu hỏi khảo sát kiểu Likert (ví dụ: “Hoàn toàn đồng ý”, “Đồng ý”, “Trung lập”, “Không đồng ý”, “Hoàn toàn không đồng ý”). Trong chương này, chúng tôi đề cập đến những điều sauTạo một tháp dân số nhanh & dễ dàng với package apyramidTùy biến tháp dân số với ggplot()Hiển thị dữ liệu nhân khẩu học “nền” trong tháp dân sốSử dụng các biểu đồ kiểu kim tự tháp để hiển thị các loại dữ liệu khác (ví dụ: câu trả lời cho các câu hỏi khảo sát kiểu Likert)","code":""},{"path":"age-pyramid.html","id":"chuẩn-bị-5","chapter":"33 Tháp dân số và thang đo Likert","heading":"33.1 Chuẩn bị","text":"","code":""},{"path":"age-pyramid.html","id":"gọi-package","chapter":"33 Tháp dân số và thang đo Likert","heading":"Gọi package","text":"Đoạn code này hiển thị việc gọi các package cần thiết cho các phân tích. Trong cuốn sách này, chúng tôi nhấn mạnh việc sử dụng hàm p_load() từ package pacman, giúp cài đặt các package cần thiết và gọi chúng ra để sử dụng. Bạn cũng có thể gọi các packages đã cài đặt với hàm library() của base R. Xem thêm chương R cơ bản để có thêm thông tin về các packages trong R.","code":"\npacman::p_load(rio,       # to import data\n               here,      # to locate files\n               tidyverse, # to clean, handle, and plot the data (includes ggplot2 package)\n               apyramid,  # a package dedicated to creating age pyramids\n               janitor,   # tables and cleaning data\n               stringr)   # working with strings for titles, captions, etc."},{"path":"age-pyramid.html","id":"nhập-dữ-liệu-4","chapter":"33 Tháp dân số và thang đo Likert","heading":"Nhập dữ liệu","text":"Để bắt đầu, chúng ta nhập bộ dữ liệu có tên linelist đã làm sạch bao gồm các trường hợp từ vụ dịch Ebola mô phỏng. Để tiện theo dõi, bấm để tải dữ liệu linelist “đã được làm sạch”  (dưới dạng tệp .rds). Nhập dữ liệu bằng hàm import() từ package rio (nó xử lý nhiều loại tệp như .xlsx, .csv, .rds - xem thêm chương Nhập xuất dữ liệu để biết thêm chi tiết.50 hàng đầu tiên của bộ dữ liệu được hiển thị như bên dưới.","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"age-pyramid.html","id":"làm-sạch","chapter":"33 Tháp dân số và thang đo Likert","heading":"Làm sạch","text":"Để tạo tháp nhân khẩu học theo độ tuổi/giới tính truyền thống, trước tiên dữ liệu phải được làm sạch theo những cách sau:Cột gender phải được làm sạch.Tùy thuộc vào phương pháp của bạn, độ tuổi phải được lưu trữ dưới dạng số hoặc trong cột age category.Nếu sử dụng nhóm tuổi, các giá trị trong cột phải được sắp xếp thứ tự, hoặc là thứ tự chữ-số mặc định hoặc được đặt có chủ ý bằng cách chuyển đổi thành kiểu factor.Sau đây chúng ta sử dụng hàm tabyl() từ package janitor để khảo sát hai cột gender và age_cat5.Chúng ta có thể vẽ biểu đồ histogram đối với cột age để chắc chắn rằng nó đã được làm sạch và phân loại chính xác:","code":"\nlinelist %>% \n  tabyl(age_cat5, gender)##  age_cat5   f   m NA_\n##       0-4 640 416  39\n##       5-9 641 412  42\n##     10-14 518 383  40\n##     15-19 359 364  20\n##     20-24 305 316  17\n##     25-29 163 259  13\n##     30-34 104 213   9\n##     35-39  42 157   3\n##     40-44  25 107   1\n##     45-49   8  80   5\n##     50-54   2  37   1\n##     55-59   0  30   0\n##     60-64   0  12   0\n##     65-69   0  12   1\n##     70-74   0   4   0\n##     75-79   0   0   1\n##     80-84   0   1   0\n##       85+   0   0   0\n##      <NA>   0   0  86\nhist(linelist$age)"},{"path":"age-pyramid.html","id":"apyramid-package","chapter":"33 Tháp dân số và thang đo Likert","heading":"33.2 apyramid package","text":"Package apyramid là một sản phẩm của dự án R4Epis. Bạn có thể đọc thêm về package này tại đây. Nó cho phép bạn nhanh chóng tạo một tháp tuổi. Để tùy biến đẹp hơn, xem mục sử dụng ggplot(). Bạn có thể đọc thêm về package apyramid tại trang Help bằng cách nhập ?age_pyramid vào R console.","code":""},{"path":"age-pyramid.html","id":"dữ-liệu-linelist-1","chapter":"33 Tháp dân số và thang đo Likert","heading":"Dữ liệu Linelist","text":"Sử dụng dữ liệu linelist đã làm sạch, chúng ta có thể tạo một tháp tuổi chỉ với một lệnh age_pyramid() cơ bản. Trong lệnh này:Đối số data = sử dụng bộ dữ liệu linelistĐối số age_group = (trục y) lấy thông tin từ cột nhóm tuổi (trong ngoặc kép)Đối số split_by = (trục x) lấy thông tin từ cột giớiTháp có thể hiện thị phần trăm của tất cả các trường hợp trên trục x, thay vì chỉ số lượng, bằng cách thêm proportional = TRUE.Khi sử dụng package agepyramid, nếu cột được phân chia split_by là nhị phân (vd. nam/nữ, hoặc có/không), thì kết quả sẽ xuất hiện dưới dạng một kim tự tháp. Tuy nhiên nếu có nhiều hơn hai giá trị trong cột được phân chia split_by (không bao gồm NA), kim tự tháp sẽ xuất hiện dưới dạng nhiều biểu đồ cột ngang với các thanh màu xám trong “background” cho biết phạm vi của dữ liệu không có mặt cho nhóm tuổi đó. Trong trường hợp này, giá trị của split_by = sẽ xuất hiện dưới dạng nhãn ở đỉnh mỗi biểu đồ. Chẳng hạn, bên dưới là những gì xảy ra nếu split_by = được chỉ định tới cột hospital.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  "},{"path":"age-pyramid.html","id":"giá-trị-missing-1","chapter":"33 Tháp dân số và thang đo Likert","heading":"Giá trị Missing","text":"Các hàng chứa giá trị missing NA của các cột split_by = hoặc age_group =, nếu được mã hóa là NA, sẽ không tự động kích hoạt việc phân chia biểu đồ như được hiển thị ở trên. Mặc định những hàng này không được hiển thị. Tuy nhiên, bạn có thể chỉ định các giá trị missing hiển thị, trong một biểu đồ liền kề và dưới dạng một nhóm tuổi riêng biệt, bằng cách chỉ định na.rm = FALSE.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # show patients missing age or gender"},{"path":"age-pyramid.html","id":"tỷ-lệ-màu-sắc-thẩm-mỹ","chapter":"33 Tháp dân số và thang đo Likert","heading":"Tỷ lệ, màu sắc, & thẩm mỹ","text":"Theo mặc định, các cột hiển thị số lượng (không phải %), đường gạch ngang giữa cho mỗi nhóm được hiển thị và màu sắc là xanh lục/tím. Các thông số này có thể được điều chỉnh, như được trình bày dưới đây:Bạn cũng có thể thêm các lệnh ggplot() vào biểu đồ bằng cách sử dụng các cú pháp chuẩn của ggplot() “+” , chẳng hạn như chủ đề trang trí và điều chỉnh nhãn:","code":"\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # show percents, not counts\n  show_midpoint = FALSE,            # remove bar mid-point line\n  #pal = c(\"orange\", \"purple\")      # can specify alt. colors here (but not labels)\n  )+                 \n  \n  # additional ggplot commands\n  theme_minimal()+                               # simplfy background\n  scale_fill_manual(                             # specify colors AND labels\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # note x and y labs are switched\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # legend to bottom\n    axis.text = element_text(size = 10, face = \"bold\"),  # fonts/sizes\n    axis.title = element_text(size = 12, face = \"bold\"))"},{"path":"age-pyramid.html","id":"dữ-liệu-được-tổng-hợp","chapter":"33 Tháp dân số và thang đo Likert","heading":"Dữ liệu được tổng hợp","text":"Ví dụ bên trên giả định rằng dữ liệu của bạn có định dạng mỗi hàng cho một quan sát. Nếu dữ liệu của bạn đã được tổng hợp thành số lượng theo nhóm tuổi, bạn vẫn có thể sử dụng package apyramid, như được trình bày dưới đây.Để minh họa, chúng ta sẽ tổng hợp dữ liệu linelist theo số lượng đối với nhóm tuổi và giới, dưới định dạng “ngang”. Việc này sẽ mô phỏng như thể dữ liệu ban đầu của bạn đang được trình bày dưới dạng số lượng. Tìm hiểu thêm về Nhóm dữ liệu và Xoay trục dữ liệu ở các chương tương ứng.…lệnh trên sẽ khiến bộ dữ liệu trông như thế này: bao gồm các cột nhóm tuổi, số lượng nam, nữ, và missing.Để thiết lập chủ đề cho tháp tuổi, chúng ta sẽ xoay trục dữ liệu sang dạng “dọc” bằng hàm pivot_longer() trong package dplyr. Đó là bởi vì ggplot() thường thích dữ liệu được bố trí ở dạng “dọc”, và package apyramid đang sử dụng ggplot().Sau đó sử dụng các đối số split_by = và count = của hàm age_pyramid() để chỉ định các cột tương ứng trong bộ dữ liệu:Lưu ý rằng ở trên, thứ tự của “m” và “f” là khác nhau (tháp bị đảo ngược). Để điều chỉnh thự tự, bạn phải định nghĩa lại cột giới trong dữ liệu được tổng hợp thành kiểu Factor và sắp xếp thứ tự như mong muốn. Xem chương [Factors].","code":"\ndemo_agg <- linelist %>% \n  count(age_cat5, gender, name = \"cases\") %>% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %>% \n  rename(`missing_gender` = `NA`)\n# pivot the aggregated data into long format\ndemo_agg_long <- demo_agg %>% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # cols to elongate\n    names_to = \"gender\",                # name for new col of categories\n    values_to = \"counts\") %>%           # name for new col of counts\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # convert \"missing_gender\" to NA\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# column name for age category\n                      split_by = \"gender\",   # column name for gender\n                      count = \"counts\")      # column name for case counts"},{"path":"age-pyramid.html","id":"demo_pyr_gg","chapter":"33 Tháp dân số và thang đo Likert","heading":"33.3 ggplot()","text":"Sử dụng ggplot() cho phép bạn xây dựng tháp tuổi một cách linh hoạt hơn, nhưng đòi hỏi nhiều nỗ lực và hiểu biết hơn về cách hoạt động của ggplot(). Việc vô tình mắc sai lầm cũng dễ dàng hơn.Để sử dụng ggplot() tạo tháp nhân khẩu học, bạn tạo hai biểu đồ cột (cho từng giới tính), chuyển đổi các giá trị trong một biểu đồ thành âm và cuối cùng lật các trục x và y để hiển thị các biểu đồ cột theo chiều dọc, xuất phát điểm của chúng gặp nhau ở chính giữa biểu đồ.","code":""},{"path":"age-pyramid.html","id":"chuẩn-bị-6","chapter":"33 Tháp dân số và thang đo Likert","heading":"Chuẩn bị","text":"Cách tiếp cận này sử dụng cột tuổi ở dạng numeric, không phải cột nhóm tuổi age_cat5 dạng categorical. Vì vậy, chúng ta cần kiểm tra để đảm bảo rằng kiểu của cột này thực sự là dạng số.Bạn có thể sử dụng logic tương tự như dưới đây để xây dựng một kim tự tháp từ dữ liệu dạng danh mục sử dụng geom_col() thay vì geom_histogram().","code":"\nclass(linelist$age)## [1] \"numeric\""},{"path":"age-pyramid.html","id":"xây-dựng-biểu-đồ","chapter":"33 Tháp dân số và thang đo Likert","heading":"Xây dựng biểu đồ","text":"Trước tiên, hãy hiểu rằng để tạo một kim tự tháp như vậy bằng cách sử dụng ggplot(), cách tiếp cận sẽ là như sau:Bên trong hàm ggplot(), tạo hai biểu đồ histograms sử dụng cột tuổi dạng numeric, tương ứng cho hai nhóm (trong trường hợp này là giới nam và nữ). Để thực hiện việc này, dữ liệu cho mỗi biểu đồ được chỉ định trong các lệnh geom_histogram() tương ứng của chúng, với các bộ lọc tương ứng được áp dụng cho bộ dữ liệu linelist.Bên trong hàm ggplot(), tạo hai biểu đồ histograms sử dụng cột tuổi dạng numeric, tương ứng cho hai nhóm (trong trường hợp này là giới nam và nữ). Để thực hiện việc này, dữ liệu cho mỗi biểu đồ được chỉ định trong các lệnh geom_histogram() tương ứng của chúng, với các bộ lọc tương ứng được áp dụng cho bộ dữ liệu linelist.Một biểu đồ sẽ có các giá trị dương, trong khi biểu đồ kia sẽ có các giá trị được chuyển thành giá trị âm - điều này tạo ra “kim tự tháp” với giá trị 0 ở giữa biểu đồ. Các giá trị âm được tạo bằng cách sử dụng thuật ngữ đặc biệt của ggplot2 là ..count.. và nhân với -1.Một biểu đồ sẽ có các giá trị dương, trong khi biểu đồ kia sẽ có các giá trị được chuyển thành giá trị âm - điều này tạo ra “kim tự tháp” với giá trị 0 ở giữa biểu đồ. Các giá trị âm được tạo bằng cách sử dụng thuật ngữ đặc biệt của ggplot2 là ..count.. và nhân với -1.Lệnh coord_flip() chuyển trục X và Y, dẫn đến các đồ thị quay dọc và tạo ra hình kim tự tháp.Lệnh coord_flip() chuyển trục X và Y, dẫn đến các đồ thị quay dọc và tạo ra hình kim tự tháp.Cuối cùng, các nhãn giá trị trục đếm phải được thay đổi để chúng xuất hiện dưới dạng số “dương” trên cả hai mặt của kim tự tháp (mặc dù các giá trị thực tế ở một mặt là âm).Cuối cùng, các nhãn giá trị trục đếm phải được thay đổi để chúng xuất hiện dưới dạng số “dương” trên cả hai mặt của kim tự tháp (mặc dù các giá trị thực tế ở một mặt là âm).Một phiên bản đơn giản của biểu đồ, sử dụng hàm geom_histogram(), như dưới đây:NGUY HIỂM: Nếu như giới hạn của trục counts được thiết lập quá nhỏ, và cột số lượng vượt quá giá trị đó, cột sẽ biến mất hoàn toàn hoặc bị rút ngắn một cách không tự nhiên! Hãy chú ý điều này nếu dữ liệu phân tích thường xuyên được cập nhật. Có thể ngăn chặn điều này bằng cách tự động điều chỉnh các giới hạn trục count cho phù hợp với dữ liệu của bạn, như dưới đây.Có nhiều thứ bạn có thể thay đổi/thêm vào phiên bản đơn giản này, bao gồm:Tự động điều chỉnh tỷ lệ trục count cho dữ liệu của bạn (tránh các lỗi được thảo luận trong cảnh báo bên dưới)Chỉ định màu sắc và nhãn chú giải một cách thủ côngChuyển đổi số lượng thành tỷ lệ phần trămĐể chuyển đổi số lượng thành phần trăm (của tổng số), hãy thực hiện điều này với dữ liệu của bạn trước khi vẽ biểu đồ. Dưới đây, chúng ta lấy số lượng của age-gender, sau đó ungroup(), và tiếp tục mutate() để tạo cột phần trăm mới. Nếu bạn muốn phần trăm theo giới tính, hãy bỏ qua bước hủy nhóm.Quan trọng là, chúng ta lưu các giá trị lớn nhất vầ nhỏ nhất để chúng ta biết giới hạn của thang đo. Chúng sẽ được sử dụng trong lệnh ggplot() dưới đây.Cuối cùng, chúng ta dùng hàm ggplot() trên dữ liệu phần trăm. Chúng ta chỉ rõ scale_y_continuous() để mở rộng độ dài được xác định trước theo mỗi hướng (dương và “âm”). Chúng ta sử dụng hàm floor() vả ceiling() để làm tròn số thập phân theo cách thích hợp (làm tròn xuống hoặc lên).","code":"\n  # begin ggplot\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # female histogram\n  geom_histogram(data = linelist %>% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # male histogram (values converted to negative)\n  geom_histogram(data = linelist %>% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # flip the X and Y axes\n  coord_flip() +\n  \n  # adjust counts-axis scale\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n# create dataset with proportion of total\npyramid_data <- linelist %>%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %>% \n  ungroup() %>%                 # ungroup so percents are not by group\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,     # convert male to negative\n            TRUE          ~ NA_real_))    # NA val must by numeric as well\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n\nmax_per## [1] 10.9\nmin_per## [1] -7.1\n# begin ggplot\n  ggplot()+  # default x-axis is age in years;\n\n  # case data graph\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # white around each bar\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n\n  # adjust the axes scales\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # sequence of values, by 2s\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # sequence of absolute values, by 2s, with \"%\"\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # label values (remember X and Y flipped now)\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # display themes\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )"},{"path":"age-pyramid.html","id":"so-sánh-với-đường-cơ-sở","chapter":"33 Tháp dân số và thang đo Likert","heading":"So sánh với đường cơ sở","text":"flexibility ggplot(), can second layer bars background represent “true” “baseline” population pyramid. can provide nice visualization compare observed baseline.Với sự linh hoạt của ggplot(), bạn có thể có lớp thanh thứ hai trong nền đại diện cho tháp dân số “chuẩn” hoặc “đường cơ sở”. Điều này có thể cung cấp khả năng trực quan hóa tốt để sánh những gì quan sát được với đường cơ sở.Nhập và xem dữ liệu dân số (xem chương Tải sách và dữ liệu):Đầu tiên là một số bước quản lý dữ liệu:Ở đây chúng ta sắp xếp lại thứ tự của các danh mục tuổi mà chúng ta muốn chúng xuất hiện. một số điểm khác biệt trong cách thực thi ggplot(), trong trường hợp cụ thể này, dễ dàng nhất là lưu trữ chúng dưới dạng vectơ ký tự và sử dụng chúng sau này trong hàm vẽ đồ thị.Kết hợp dữ liệu quần thể và dữ liệu trường hợp thông qua hàm bind_rows() của package dplyr:Trước tiên, hãy đảm bảo hai bộ dữ liệu có tên cột giống nhau, các giá trị nhóm tuổi và giá trị giới tínhLàm cho chúng có cấu trúc dữ liệu giống nhau: cột nhóm tuổi, giới tính, số lượng và phần trăm tổng sốGắn chúng lại với nhau, một bộ dữ liệu này ở trên bộ dữ liệu kia (bind_rows())Xem lại bộ dữ liệu dân số đã thay đổiBây giờ thực hiện tương tự cho bộ linelist. Sẽ hơi khác một chút bởi vì nó bắt đầu với các trường hợp theo hàng, không phải số lượng.Xem lại bộ dữ liệu trường hợp đã thay đổiBây giờ hai data frame sẽ được kết hợp, cái này ở trên cái kia (chúng có cùng tên cột). Chúng ta có thể “đặt tên” cho từng data frame, và sử dụng đối số .id = để tạo một cột mới “data_source” sẽ cho biết dữ liệu có nguồn gốc từ data frame nào. Chúng tôi có thể sử dụng cột này để lọc với hàm ggplot().Lưu trữ các giá trị phần trăm tối đa và tối thiểu, được sử dụng trong hàm vẽ biểu đồ để xác định phạm vi của biểu đồ (và không cắt ngắn bất kỳ cột nào!)Bây giờ biểu đồ được tạo bởi ggplot() có:Một biểu đồ cột ngang của dữ liệu dan số (rộng hơn, trong suốt)Một biểu đồ cột ngang của dữ liệu các trường hợp (nhỏ hơn, đậm hơn)","code":"\n# import the population demographics data\npop <- rio::import(\"country_demographics.csv\")\n# record correct age cat levels\nage_levels <- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n# create/transform populaton data, with percent of total\n########################################################\npop_data <- pop %>% \n  pivot_longer(      # pivot gender columns longer\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %>% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % of total\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent,               # if male, convert % to negative\n     TRUE          ~ NA_real_))\n# create case data by age/gender, with percent of total\n#######################################################\ncase_data <- linelist %>%\n  count(age_cat5, gender, name = \"counts\") %>%  # counts by age-gender groups\n  ungroup() %>% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculate % of total for age-gender groups\n    percent = case_when(                                     # convert % to negative if male\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent,\n      TRUE          ~ NA_real_))\n# combine case and population data (same column names, age_cat values, and gender values)\npyramid_data <- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n# Define extent of percent axis, used for plot limits\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n# begin ggplot\n##############\nggplot()+  # default x-axis is age in years;\n\n  # population data graph\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # black color around bars\n    alpha = 0.2,                                    # more transparent\n    width = 1)+                                     # full width\n  \n  # case data graph\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # age categories as original X axis\n      y = percent,                                # % as original Y-axis\n      fill = gender),                             # fill of bars by gender\n    colour = \"black\",                               # black color around bars\n    alpha = 1,                                      # not transparent \n    width = 0.3)+                                   # half width\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n  # manually ensure that age-axis is ordered correctly\n  scale_x_discrete(limits = age_levels)+     # defined in chunk above\n  \n  # set percent-axis \n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # min and max defined above\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # from min% to max% by 2 \n    labels = paste0(                                                       # for the labels, paste together... \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # assign colors to values in the data\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # change labels that appear in legend, note order\n  ) +\n\n  # plot labels, titles, caption    \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # optional aesthetic themes\n  theme(\n    legend.position = \"bottom\",                             # move legend to bottom\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))"},{"path":"age-pyramid.html","id":"thang-đo-likert","chapter":"33 Tháp dân số và thang đo Likert","heading":"33.4 Thang đo Likert","text":"Các kỹ thuật được sử dụng để tạo tháp dân số với ggplot() cũng có thể được sử dụng để lập các biểu đồ của dữ liệu khảo sát từ thang đo Likert.Nhập dữ liệu (xem chương Tải sách và dữ liệu nếu cần).Bắt đầu với dữ liệu giống như sau, với một biến phân loại từng người trả lời (status) và câu trả lời của họ cho 8 câu hỏi trên thang điểm Likert 4 mức độ (“Rất kém”, “Kém”, “Tốt”, “Rất tốt”).Đầu tiên là một vài bước quản lý số liệu:Xoay trục dữ liệu dài hơnTạo cột mới direction tùy thuộc vào việc phản hồi “tích cực” hay “tiêu cực”Thiết lập thứ bậc kiểu factor cho cột status và cột ResponseLưu trữ giá trị đếm tối đa để các giới hạn của biểu đồ là phù hợpBây giờ hãy cùng vẽ biểu đồ. Tương tự các tháp tuổi ở trên, chúng ta đang tạo hai biểu đồ thanh và đảo các giá trị của một trong số chúng thành âm.Chúng ta sử dụng hàm geom_bar() bởi vì dữ liệu của chúng ta mỗi quan sát nằm trên một hàng, không phải là số lượng tổng hợp. Chúng ta sử dụng thuật ngữ đặc biệt của ggplot2 là ..count.. ở một biểu đồ thanh để đảo ngược các giá trị thành âm(*-1), sau đó chúng ta thiết lập position = \"stack\" để các giá trị xếp chồng lên nhau.","code":"\n# import the likert survey response data\nlikert_data <- rio::import(\"likert_data.csv\")\nmelted <- likert_data %>% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %>% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # must reverse 'Very Poor' and 'Poor' for ordering to work\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# get largest value for scale limits\nmelted_max <- melted %>% \n  count(status, Question) %>% # get counts\n  pull(n) %>%                 # column 'n'\n  max(na.rm=T)                # get max\n# make plot\nggplot()+\n     \n  # bar graph of the \"negative\" responses \n     geom_bar(\n       data = melted %>% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # counts inverted to negative\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # bar graph of the \"positive responses\n     geom_bar(\n       data = melted %>% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # flip the X and Y axes\n     coord_flip()+\n  \n     # Black vertical line at 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # convert labels to all positive numbers\n    scale_y_continuous(\n      \n      # limits of the x-axis scale\n      limits = c(-ceiling(melted_max/10)*11,    # seq from neg to pos by 10, edges rounded outward to nearest 5\n                 ceiling(melted_max/10)*10),   \n      \n      # values of the x-axis scale\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # labels of the x-axis scale\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # color scales manually assigned \n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # assigns colors\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # orders the legend\n     \n    \n     \n    # facet the entire plot so each question is a sub-plot\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # labels, titles, caption\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # display adjustments \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # facet sub-titles\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # black box around each facet"},{"path":"age-pyramid.html","id":"nguồn-5","chapter":"33 Tháp dân số và thang đo Likert","heading":"33.5 Nguồn","text":"apyramid documentation","code":""},{"path":"heatmaps.html","id":"heatmaps","chapter":"34 Biểu đồ nhiệt","heading":"34 Biểu đồ nhiệt","text":"Heat plots, also known “heat maps” “heat tiles”, can useful visualizations trying display 3 variables (x-axis, y-axis, fill). demonstrate two examples:visual matrix transmission events age (“infected ”)Tracking reporting metrics across many facilities/jurisdictions time","code":""},{"path":"heatmaps.html","id":"preparation-19","chapter":"34 Biểu đồ nhiệt","heading":"34.1 Preparation","text":"","code":""},{"path":"heatmaps.html","id":"load-packages-17","chapter":"34 Biểu đồ nhiệt","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.DatasetsThis page utilizes case linelist simulated outbreak transmission matrix section, separate dataset daily malaria case counts facility metrics tracking section. loaded cleaned individual sections.","code":"\npacman::p_load(\n  tidyverse,       # data manipulation and visualization\n  rio,             # importing data \n  lubridate        # working with dates\n  )"},{"path":"heatmaps.html","id":"transmission-matrix","chapter":"34 Biểu đồ nhiệt","heading":"34.2 Transmission matrix","text":"Heat tiles can useful visualize matrices. One example display “-infected-” outbreak. assumes information transmission events.Note [Contact tracing] page contains another example making heat tile contact matrix, using different (perhaps simple) dataset ages cases sources neatly aligned row data frame. data used make density map [ggplot tips] page. example begins case linelist involves considerable data manipulation prior achieving plotable data frame. many scenarios chose …begin case linelist simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (accepts many file types like .xlsx, .rds, .csv - see [Import export] page details).first 50 rows linelist shown demonstration:linelist:one row per case, identified case_idThere later column infector contains case_id infector, also case linelist","code":"\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"heatmaps.html","id":"data-preparation","chapter":"34 Biểu đồ nhiệt","heading":"Data preparation","text":"Objective: need achieve “long”-style data frame contains one row per possible age--age transmission route, numeric column containing row’s proportion observed transmission events linelist.take several data manuipulation steps achieve:","code":""},{"path":"heatmaps.html","id":"make-cases-data-frame","chapter":"34 Biểu đồ nhiệt","heading":"Make cases data frame","text":"begin, create data frame cases, ages, infectors - call data frame case_ages. first 50 rows displayed .","code":"\ncase_ages <- linelist %>% \n  select(case_id, infector, age_cat) %>% \n  rename(\"case_age_cat\" = \"age_cat\")"},{"path":"heatmaps.html","id":"make-infectors-data-frame","chapter":"34 Biểu đồ nhiệt","heading":"Make infectors data frame","text":"Next, create data frame infectors - moment consists single column. infector IDs linelist. every case known infector, remove missing values. first 50 rows displayed .Next, use joins procure ages infectors. simple, linelist, infector’s ages listed . achieve result joining case linelist infectors. begin infectors, left_join() (add) case linelist infector id column left-side “baseline” data frame joins case_id column right-side linelist data frame.Thus, data infector’s case record linelist (including age) added infector row. 50 first rows displayed ., combine cases ages infectors ages. data frame column infector, used join. first rows displayed :, simple cross-tabulation counts case infector age groups. Labels added clarity.can convert table data frame data.frame() base R, also automatically converts “long” format, desired ggplot(). first rows shown .Now , apply prop.table() base R table instead counts get proportions total. first 50 rows shown .","code":"\ninfectors <- linelist %>% \n  select(infector) %>% \n  drop_na(infector)\ninfector_ages <- infectors %>%             # begin with infectors\n  left_join(                               # add the linelist data to each infector  \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %>%    # match infector to their information as a case\n  select(infector, age_cat) %>%            # keep only columns of interest\n  rename(\"infector_age_cat\" = \"age_cat\")   # rename for clarity\nages_complete <- case_ages %>%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %>%        # each has the column infector\n  drop_na()                     # drop rows with any missing data\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)##        infectors\n## cases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n##   0-4   105 156   105   114   143   117    13   0\n##   5-9   102 132   110   102   117    96    12   5\n##   10-14 104 109    91    79   120    80    12   4\n##   15-19  85 105    82    39    75    69     7   5\n##   20-29 101 127   109    80   143   107    22   4\n##   30-49  72  97    56    54    98    61     4   5\n##   50-69   5   6    15     9     7     5     2   0\n##   70+     1   0     2     0     0     0     0   0\nlong_counts <- data.frame(table(\n    cases     = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\nlong_prop <- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))"},{"path":"heatmaps.html","id":"create-heat-plot","chapter":"34 Biểu đồ nhiệt","heading":"Create heat plot","text":"Now finally can create heat plot ggplot2 package, using geom_tile() function. See [ggplot tips] page learn extensively color/fill scales, especially scale_fill_gradient() function.aesthetics aes() geom_tile() set x y case age infector ageAlso aes() set argument fill = Freq column - value converted tile colorSet scale color scale_fill_gradient() - can specify high/low colors\nNote scale_color_gradient() different! case want fill\nNote scale_color_gradient() different! case want fillBecause color made via “fill”, can use fill = argument labs() change legend title","code":"\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = cases,         # x-axis is case age\n      y = infectors,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  labs(                         # labels\n    x = \"Case age\",\n    y = \"Infector age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"heatmaps.html","id":"reporting-metrics-over-time","chapter":"34 Biểu đồ nhiệt","heading":"34.3 Reporting metrics over time","text":"Often public health, one objective assess trends time many entities (facilities, jurisdictions, etc.). One way visualize trends time heat plot x-axis time y-axis many entities.","code":""},{"path":"heatmaps.html","id":"data-preparation-1","chapter":"34 Biểu đồ nhiệt","heading":"Data preparation","text":"begin importing dataset daily malaria reports many facilities. reports contain date, province, district, malaria counts. See page [Download handbook data] information download data. first 30 rows:","code":"\nfacility_count_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"heatmaps.html","id":"aggregate-and-summarize","chapter":"34 Biểu đồ nhiệt","heading":"Aggregate and summarize","text":"objective example transform daily facility total malaria case counts (seen previous tab) weekly summary statistics facility reporting performance - case proportion days per week facility reported data. example show data Spring District.achieve following data management steps:Filter data appropriate (place, date)Create week column using floor_date() package lubridate\nfunction returns start-date given date’s week, using specified start date week (e.g. “Mondays”)\nfunction returns start-date given date’s week, using specified start date week (e.g. “Mondays”)data grouped columns “location” “week” create analysis units “facility-week”function summarise() creates new columns reflecting summary statistics per facility-week group:\nNumber days per week (7 - static value)\nNumber reports received facility-week (7!)\nSum malaria cases reported facility-week (just interest)\nNumber unique days facility-week data reported\nPercent 7 days per facility-week data reported\nNumber days per week (7 - static value)Number reports received facility-week (7!)Sum malaria cases reported facility-week (just interest)Number unique days facility-week data reportedPercent 7 days per facility-week data reportedThe data frame joined right_join() comprehensive list possible facility-week combinations, make dataset complete. matrix possible combinations created applying expand() two columns data frame moment pipe chain (represented .). right_join() used, rows expand() data frame kept, added agg_weeks necessary. new rows appear NA (missing) summarized values.demonstrate step--step:Now dataset nrow(agg_weeks) rows, previously nrow(facility_count_data).Next create week column reflecting start date week record. achieved lubridate package function floor_date(), set “week” weeks begin Mondays (day 1 week - Sundays 7). top rows shown .new week column can seen far right data frameNow group data facility-weeks summarise produce statistics per facility-week. See page [Descriptive tables] tips. grouping doesn’t change data frame, impacts subsequent summary statistics calculated.top rows shown . Note columns completely changed reflect desired summary statistics. row reflects one facility-week.Finally, run command ensure possible facility-weeks present data, even missing .using right_join() (dataset represented “.”) expanded include possible combinations columns week location_name. See documentation expand() function page [Pivoting]. running code dataset contains nrow(agg_weeks) rows.expanded_weeks:running code, agg_weeks contains nrow(agg_weeks) rows.running code, agg_weeks contains nrow(agg_weeks) rows.","code":"\n# Create weekly summary dataset\nagg_weeks <- facility_count_data %>% \n  \n  # filter the data as appropriate\n  filter(\n    District == \"Spring\",\n    data_date < as.Date(\"2020-08-01\")) \nagg_weeks <- agg_weeks %>% \n  # Create week column from data_date\n  mutate(\n    week = lubridate::floor_date(                     # create new column of weeks\n      data_date,                                      # date column\n      unit = \"week\",                                  # give start of the week\n      week_start = 1))                                # weeks to start on Mondays \nagg_weeks <- agg_weeks %>%   \n\n  # Group into facility-weeks\n  group_by(location_name, week) %>%\n  \n  # Create summary statistics columns on the grouped data\n  summarize(\n    n_days          = 7,                                          # 7 days per week           \n    n_reports       = dplyr::n(),                                 # number of reports received per week (could be >7)\n    malaria_tot     = sum(malaria_tot, na.rm = T),                # total malaria cases reported\n    n_days_reported = length(unique(data_date)),                  # number of unique days reporting per week\n    p_days_reported = round(100*(n_days_reported / n_days)))      # percent of days reporting\n# Create data frame of every possible facility-week\nexpanded_weeks <- agg_weeks %>% \n  mutate(week = as.factor(week)) %>%         # convert date to a factor so expand() works correctly\n  tidyr::expand(., week, location_name) %>%  # expand data frame to include all possible facility-week combinations\n                                             # note: \".\" represents the dataset at that moment in the pipe chain\n  mutate(week = as.Date(week))               # re-convert week to class Date so the subsequent right_join works\n# Use a right-join with the expanded facility-week list to fill-in the missing gaps in the data\nagg_weeks <- agg_weeks %>%      \n  right_join(expanded_weeks) %>%                            # Ensure every possible facility-week combination appears in the data\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # convert missing values to 0                           ## Joining, by = c(\"location_name\", \"week\")"},{"path":"heatmaps.html","id":"create-heat-plot-1","chapter":"34 Biểu đồ nhiệt","heading":"Create heat plot","text":"ggplot() made using geom_tile() ggplot2 package:Weeks x-axis transformed dates, allowing use scale_x_date()location_name y-axis show facility namesThe fill p_days_reported, performance facility-week (numeric)scale_fill_gradient() used numeric fill, specifying colors high, low, NAscale_x_date() used x-axis specifying labels every 2 weeks formatDisplay themes labels can adjusted necessary","code":""},{"path":"heatmaps.html","id":"basic","chapter":"34 Biểu đồ nhiệt","heading":"Basic","text":"basic heat plot produced , using default colors, scales, etc. explained , within aes() geom_tile() must provide x-axis column, y-axis column, column fill =. fill numeric value presents tile color.","code":"\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))"},{"path":"heatmaps.html","id":"cleaned-plot","chapter":"34 Biểu đồ nhiệt","heading":"Cleaned plot","text":"can make plot look better adding additional ggplot2 functions, shown . See page [ggplot tips] details.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heatmaps.html","id":"ordered-y-axis","chapter":"34 Biểu đồ nhiệt","heading":"Ordered y-axis","text":"Currently, facilities ordered “alpha-numerically” bottom top. want adjust order y-axis facilities, convert class factor provide order. See page [Factors] tips.Since many facilities don’t want write , try another approach - ordering facilities data frame using resulting column names factor level order. , column location_name converted factor, order levels set based total number reporting days filed facility across whole time-span., create data frame represents total number reports per facility, arranged ascending order. can use vector order factor levels plot.See data frame :Now use column data frame (facility_order$location_name) order factor levels location_name data frame agg_weeks:now data re-plotted, location_name ordered factor:","code":"\nfacility_order <- agg_weeks %>% \n  group_by(location_name) %>% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %>% \n  arrange(tot_reports) # ascending order\n# load package \npacman::p_load(forcats)\n\n# create factor and define levels manually\nagg_weeks <- agg_weeks %>% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heatmaps.html","id":"display-values","chapter":"34 Biểu đồ nhiệt","heading":"Display values","text":"can add geom_text() layer top tiles, display actual numbers tile. aware may look pretty many small tiles!following code added: geom_text(aes(label = p_days_reported)). adds text onto every tile. text displayed value assigned argument label =, case set numeric column p_days_reported also used create color gradient.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  # text\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+      # add text on top of tile\n  \n  # fill scale\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                    # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heatmaps.html","id":"resources-19","chapter":"34 Biểu đồ nhiệt","heading":"34.4 Resources","text":"scale_fill_gradient()R graph gallery - heatmap","code":""},{"path":"diagrams.html","id":"diagrams","chapter":"35 Sơ đồ và biểu đồ","heading":"35 Sơ đồ và biểu đồ","text":"page covers code produce:Flow diagrams using DiagrammeR DOT languageAlluvial/Sankey diagramsEvent timelines","code":""},{"path":"diagrams.html","id":"preparation-20","chapter":"35 Sơ đồ và biểu đồ","heading":"35.1 Preparation","text":"","code":""},{"path":"diagrams.html","id":"load-packages-18","chapter":"35 Sơ đồ và biểu đồ","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  DiagrammeR,     # for flow diagrams\n  networkD3,      # For alluvial/Sankey diagrams\n  tidyverse)      # data management and visualization"},{"path":"diagrams.html","id":"import-data-14","chapter":"35 Sơ đồ và biểu đồ","heading":"Import data","text":"content page require dataset. However, Sankey diagram section, use case linelist simulated Ebola epidemic. want follow along part, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"diagrams.html","id":"flow-diagrams","chapter":"35 Sơ đồ và biểu đồ","heading":"35.2 Flow diagrams","text":"One can use R package DiagrammeR create charts/flow charts. can static, can adjust somewhat dynamically based changes dataset.ToolsThe function grViz() used create “Graphviz” diagram. function accepts character string input containing instructions making diagram. Within string, instructions written different language, called DOT - quite easy learn basics.Basic structureOpen instructions grViz(\"Specify directionality name graph, open brackets, e.g. digraph my_flow_chart {Graph statement (layout, rank direction)Nodes statements (create nodes)Edges statements (gives links nodes)Close instructions }\")","code":""},{"path":"diagrams.html","id":"simple-examples","chapter":"35 Sơ đồ và biểu đồ","heading":"Simple examples","text":"two simple examplesA minimal example:example perhaps bit applied public health context:","code":"\n# A minimal plot\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -> b -> c\n}\")\ngrViz(\"                           # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  # nodes\n  #######\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]               # width of circles\n  \n  Primary                         # names of nodes\n  Secondary\n  Tertiary\n\n  # edges\n  #######\n  Primary   -> Secondary [label = ' case transfer']\n  Secondary -> Tertiary [label = ' case transfer']\n}\n\")"},{"path":"diagrams.html","id":"syntax","chapter":"35 Sơ đồ và biểu đồ","heading":"Syntax","text":"Basic syntaxNode names, edge statements, can separated spaces, semicolons, newlines.Rank directionA plot can re-oriented move left--right adjusting rankdir argument within graph statement. default TB (top--bottom), can LR (left--right), RL, BT.Node namesNode names can single words, simple example . use multi-word names special characters (e.g. parentheses, dashes), put node name within single quotes (’ ’). may easier short node name, assign label, shown within brackets [ ]. want newline within node’s name, must via label - use \\n node label within single quotes, shown .Subgroups\nWithin edge statements, subgroups can created either side edge curly brackets ({ }). edge applies nodes bracket - shorthand.Layoutsdot (set rankdir either TB, LR, RL, BT, )neatotwopicircoNodes - editable attributeslabel (text, single quotes multi-word)fillcolor (many possible colors)fontcoloralpha (transparency 0-1)shape (ellipse, oval, diamond, egg, plaintext, point, square, triangle)stylesidesperipheriesfixedsize (h x w)heightwidthdistortionpenwidth (width shape border)x (displacement left/right)y (displacement /)fontnamefontsizeiconEdges - editable attributesarrowsizearrowhead (normal, box, crow, curve, diamond, dot, inv, none, tee, vee)arrowtaildir (direction, )style (dashed, …)coloralphaheadport (text front arrowhead)tailport (text behind arrowtail)fontnamefontsizefontcolorpenwidth (width arrow)minlen (minimum length)Color names: hexadecimal values ‘X11’ color names, see X11 details","code":""},{"path":"diagrams.html","id":"complex-examples","chapter":"35 Sơ đồ và biểu đồ","heading":"Complex examples","text":"example expands surveillance_diagram, adding complex node names, grouped edges, colors stylingSub-graph clustersTo group nodes boxed clusters, put within named subgraph (subgraph name {}). subgraph identified within bounding box, begin name subgraph “cluster”, shown 4 boxes .Node shapesThe example , borrowed tutorial, shows applied node shapes shorthand serial edge connections","code":"DiagrammeR::grViz(\"               # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            # layout top-to-bottom\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary   [label = 'Primary\\nFacility'] \n  Secondary [label = 'Secondary\\nFacility'] \n  Tertiary  [label = 'Tertiary\\nFacility'] \n  SC        [label = 'Surveillance\\nCoordination',\n             fontcolor = darkgreen] \n  \n  # edges\n  #######\n  Primary   -> Secondary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  Secondary -> Tertiary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  \n  # grouped edge\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting',\n                                      fontcolor = darkgreen,\n                                      color = darkgreen,\n                                      style = dashed]\n}\n\")DiagrammeR::grViz(\"             # All instructions are within a large character string\ndigraph surveillance_diagram {  # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,                  # shape = circle\n       fixedsize = true\n       width = 1.3]                      # width of circles\n  \n  subgraph cluster_passive {\n    Primary   [label = 'Primary\\nFacility'] \n    Secondary [label = 'Secondary\\nFacility'] \n    Tertiary  [label = 'Tertiary\\nFacility'] \n    SC        [label = 'Surveillance\\nCoordination',\n               fontcolor = darkgreen] \n  }\n  \n  # nodes (boxes)\n  ###############\n  node [shape = box,                     # node shape\n        fontname = Helvetica]            # text font in node\n  \n  subgraph cluster_active {\n    Active [label = 'Active\\nSurveillance'] \n    HCF_active [label = 'HCF\\nActive Search']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'Event-Based\\nSurveillance (EBS)'] \n    'Social Media'\n    Radio\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = 'Community-Based\\nSurveillance (CBS)']\n    RECOs\n  }\n\n  \n  # edges\n  #######\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting']\n\n  Primary   -> Secondary [label = 'case transfer',\n                          fontcolor = red]\n  Secondary -> Tertiary [label = 'case transfer',\n                          fontcolor = red]\n  \n  HCF_active -> Active\n  \n  {'Social Media' Radio} -> EBS\n  \n  RECOs -> CBS\n}\n\")\n\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n# define the global styles of the nodes. We can override these in box if we wish\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataset 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataset 2', shape = folder, fillcolor = Beige]\nprocess [label =  'Process \\n Data']\nstatistical [label = 'Statistical \\n Analysis']\nresults [label= 'Results']\n\n# edge definitions with the node IDs\n{data1 data2}  -> process -> statistical -> results\n}\")"},{"path":"diagrams.html","id":"outputs","chapter":"35 Sơ đồ và biểu đồ","heading":"Outputs","text":"handle save outputsOutputs appear RStudio’s Viewer pane, default lower-right alongside Files, Plots, Packages, Help.export can “Save image” “Copy clipboard” Viewer. graphic adjust specified size.","code":""},{"path":"diagrams.html","id":"parameterized-figures","chapter":"35 Sơ đồ và biểu đồ","heading":"Parameterized figures","text":"quote tutorial: https://mikeyharper.uk/flowcharts--r-using-diagrammer/“Parameterized figures: great benefit designing figures within R able connect figures directly analysis reading R values directly flowcharts. example, suppose created filtering process removes values stage process, can figure show number values left dataset stage process. , can use @@X symbol directly within figure, refer footer plot using [X]:, X unique numeric index.”encourage review tutorial parameterization something interested .","code":""},{"path":"diagrams.html","id":"alluvialsankey-diagrams","chapter":"35 Sơ đồ và biểu đồ","heading":"35.3 Alluvial/Sankey Diagrams","text":"","code":""},{"path":"diagrams.html","id":"load-packages-19","chapter":"35 Sơ đồ và biểu đồ","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.load networkD3 package produce diagram, also tidyverse data preparation steps.","code":"\npacman::p_load(\n  networkD3,\n  tidyverse)"},{"path":"diagrams.html","id":"plotting-from-dataset","chapter":"35 Sơ đồ và biểu đồ","heading":"Plotting from dataset","text":"Plotting connections dataset. demonstrate using package case linelist. online tutorial.begin getting case counts unique age category hospital combination. ’ve removed values missing age category clarity. also re-label hospital age_cat columns source target respectively. two sides alluvial diagram.dataset now look like :Now create data frame diagram nodes, column name. consists values hospital age_cat. Note ensure class Character combining . adjust ID columns numbers instead labels:edit links data frame, created count(). add two numeric columns IDsource IDtarget actually reflect/create links nodes. columns hold rownumbers (position) source target nodes. 1 subtracted position numbers begin 0 (1).links dataset now looks like :Now plot Sankey diagram sankeyNetwork(). can read argument running ?sankeyNetwork console. Note unless set iterations = 0 order nodes may expected.example patient Outcome included well. Note data preparation step calculate counts cases age hospital, separately hospital outcome - bind counts together bind_rows().https://www.displayr.com/sankey-diagrams-r/","code":"\n# counts by hospital and age category\nlinks <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = hospital,\n         target = age_cat)\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\nnodes  # print##                                    name\n## 1                      Central Hospital\n## 2                     Military Hospital\n## 3                               Missing\n## 4                                 Other\n## 5                         Port Hospital\n## 6  St. Mark's Maternity Hospital (SMMH)\n## 7                                   0-4\n## 8                                   5-9\n## 9                                 10-14\n## 10                                15-19\n## 11                                20-29\n## 12                                30-49\n## 13                                50-69\n## 14                                  70+\n# match to numbers, not names\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n# plot\n######\np <- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0)        # ensure node order is as in data\np\n# counts by hospital and age category\nage_hosp_links <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = age_cat,          # re-name\n         target = hospital)\n\nhosp_out_links <- linelist %>% \n    drop_na(age_cat) %>% \n    select(hospital, outcome) %>% \n    count(hospital, outcome) %>% \n    rename(source = hospital,       # re-name\n           target = outcome)\n\n# combine links\nlinks <- bind_rows(age_hosp_links, hosp_out_links)\n\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\n# Create id numbers\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n\n# plot\n######\np <- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np"},{"path":"diagrams.html","id":"event-timelines","chapter":"35 Sơ đồ và biểu đồ","heading":"35.4 Event timelines","text":"make timeline showing specific events, can use vistime package.See vignetteHere events dataset begin :","code":"\n# load package\npacman::p_load(vistime,  # make the timeline\n               plotly    # for interactive visualization\n               )\np <- vistime(data)    # apply vistime\n\nlibrary(plotly)\n\n# step 1: transform into a list\npp <- plotly_build(p)## Warning: `arrange_()` was deprecated in dplyr 0.7.0.\n## Please use `arrange()` instead.\n## See vignette('programming') for more help\n# step 2: Marker size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size <- 10\n}\n\n# step 3: text size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size <- 10\n}\n\n\n# step 4: text position\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition <- \"right\"\n}\n\n#print\npp"},{"path":"diagrams.html","id":"dags","chapter":"35 Sơ đồ và biểu đồ","heading":"35.5 DAGs","text":"can build DAG manually using DiagammeR package DOT language described .Alternatively, packages like ggdag daggityIntroduction DAGs ggdag vignetteCausal inference dags R","code":""},{"path":"diagrams.html","id":"resources-20","chapter":"35 Sơ đồ và biểu đồ","heading":"35.6 Resources","text":"Much regarding DOT language adapted tutorial siteAnother -depth tutorial DiagammeRThis page Sankey diagrams","code":""},{"path":"combination-analysis.html","id":"combination-analysis","chapter":"36 Biểu đồ kết hợp","heading":"36 Biểu đồ kết hợp","text":"Phân tích này vẽ biểu đồ tần suất của các kết hợp giá trị/phản hồi khác nhau. Trong ví dụ này, chúng ta sẽ vẽ biểu đồ tần suất các trường hợp có biểu hiện kết hợp nhiều triệu chứng khác nhau.Phân tích này còn thường được gọi bằng những tên khác như:“Phân tích nhiều lựa chọn”“Phân tích các bộ (sets)”“Phân tích kết hợp”Trong biểu đồ minh họa bên trên, năm triệu chứng được trình bày. Bên dưới mỗi thanh dọc là một đường và dấu chấm biểu thị sự kết hợp của các triệu chứng được phản ánh bởi thanh ở trên. Ở bên trái, các thanh ngang phản ánh tần suất của từng triệu chứng riêng lẻ.Phương pháp đầu tiên chúng tôi sẽ trình bày sử dụng package ggupset, phương pháp thứ hai sử dụng package UpSetR.","code":""},{"path":"combination-analysis.html","id":"chuẩn-bị-7","chapter":"36 Biểu đồ kết hợp","heading":"36.1 Chuẩn bị","text":"","code":""},{"path":"combination-analysis.html","id":"gọi-package-1","chapter":"36 Biểu đồ kết hợp","heading":"Gọi package","text":"Đoạn code này hiển thị việc gọi các gói cần thiết cho các phân tích. Trong cuốn sách này, chúng tôi nhấn mạnh việc sử dụng hàm p_load() từ package pacman, giúp cài đặt các package nếu cần thiết và gọi chúng ra để sử dụng. Bạn cũng có thể gọi các packages đã cài đặt với hàm library() của base R. Xem thêm chương R cơ bản để có thêm thông tin về các packages trong R.","code":"\npacman::p_load(\n  tidyverse,     # data management and visualization\n  UpSetR,        # special package for combination plots\n  ggupset)       # special package for combination plots"},{"path":"combination-analysis.html","id":"nhập-dữ-liệu-5","chapter":"36 Biểu đồ kết hợp","heading":"Nhập dữ liệu","text":"Để bắt đầu, chúng ta nhập bộ dữ liệu có tên linelist đã làm sạch bao gồm các trường hợp từ vụ dịch Ebola mô phỏng. Để tiện theo dõi, bấm để tải dữ liệu linelist “đã được làm sạch”  (dưới dạng tệp .rds). Nhập dữ liệu bằng hàm import() từ package rio (nó xử lý nhiều loại tệp như .xlsx, .csv, .rds - xem thêm chương Nhập xuất dữ liệu để biết thêm chi tiết.Bộ số liệu linelist bao gồm năm biến “có/không” về các triệu chứng được ghi nhận. Chúng ta sẽ cần phải biến đổi các biến số này một chút trước khi sử dụng package ggupset để tạo biểu đồ. Xem dữ liệu (cuộn sang phải để xem các biến triệu chứng).","code":"\n# import case linelist \nlinelist_sym <- import(\"linelist_cleaned.rds\")"},{"path":"combination-analysis.html","id":"định-dạng-lại-giá-trị","chapter":"36 Biểu đồ kết hợp","heading":"Định dạng lại giá trị","text":"Để tương đồng với định dạng của package ggupset, chúng ta cần đổi giá trị “yes” và “” thành tên các triệu chứng thực tế, sử dụng hàm case_when() từ package dplyr. Nếu giá trị là “”, chúng ta sẽ bỏ trống, nghĩa là biến mới sẽ có giá trị hoặc là NA hoặc là triệu chứng.Bây giờ chúng ta tạo hai cột cuối cùng:Kết hợp (ghép lại với nhau) tất cả các triệu chứng của bệnh nhân (thành một cột ký tự)Chuyển đổi định dạng cột bên trên thành kiểu danh sách để được chấp nhận bởi package ggupset khi vẽ biểu đồXem thêm chương Ký tự và chuỗi để biết thêm về hàm unite() trong package stringrBây giờ chúng ta cùng xem dữ liệu mới. Lưu ý hai cột ở cuối bên phải - các giá trị kết hợp được ghép và danh sách","code":"\n# create column with the symptoms named, separated by semicolons\nlinelist_sym_1 <- linelist_sym %>% \n  \n  # convert the \"yes\" and \"no\" values into the symptom name itself\n  mutate(\n    fever = case_when(\n      fever == \"yes\" ~ \"fever\",          # if old value is \"yes\", new value is \"fever\"\n      TRUE           ~ NA_character_),   # if old value is anything other than \"yes\", the new value is NA\n         \n    chills = case_when(\n       chills == \"yes\" ~ \"chills\",\n       TRUE           ~ NA_character_),\n    \n    cough = case_when(\n      cough == \"yes\" ~ \"cough\",\n      TRUE           ~ NA_character_),\n         \n    aches = case_when(\n      aches == \"yes\" ~ \"aches\",\n      TRUE           ~ NA_character_),\n         \n    vomit = case_when(\n      vomit == \"yes\" ~ \"vomit\",\n      TRUE           ~ NA_character_)\n    )\nlinelist_sym_1 <- linelist_sym_1 %>% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \"; \",\n        remove = TRUE,\n        na.rm = TRUE) %>% \n  mutate(\n    # make a copy of all_symptoms column, but of class \"list\" (which is required to use ggupset() in next step)\n    all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n    )"},{"path":"combination-analysis.html","id":"ggupset","chapter":"36 Biểu đồ kết hợp","heading":"36.2 ggupset","text":"Gọi packageVẽ biểu đồ. Chúng ta bắt đầu bằng hàm ggplot() và geom_bar(), nhưng sau đó chúng ta thêm hàm đặc biệt scale_x_upset() từ package ggupset.Bạn có thể đọc thêm về package ggupset ở tài liệu online này hoặc trong tài liệu trợ giúp của package bằng cách gõ vào cửa RStudio Help lệnh ?ggupset.","code":"\npacman::p_load(ggupset)\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signs & symptoms\",\n  subtitle = \"10 most frequent combinations of signs and symptoms\",\n  caption = \"Caption here.\",\n  x = \"Symptom combination\",\n  y = \"Frequency in dataset\")"},{"path":"combination-analysis.html","id":"upsetr","chapter":"36 Biểu đồ kết hợp","heading":"36.3 UpSetR","text":"Package UpSetR cho phép tùy chỉnh biểu đồ sâu hơn, nhưng nó cũng khó thực hiện hơn:Gọi packageLàm sạch dữ liệuChúng ta phải chuyển đổi các triệu chứng trong bộ dữ liệu linelist thành các giá trị 1 / 0.Bây giờ chúng ta hãy vẽ biểu đồ bằng hàm tùy chỉnh upset() - chỉ sử dụng các cột triệu chứng. Bạn phải chỉ định “bộ” nào để sánh (tên của các cột triệu chứng). Một cách khác, sử dụng nsets = và order.= \"freq\" để chỉ hiện thị X các sự kết hợp nhiều nhất.","code":"\npacman::p_load(UpSetR)\n# Make using upSetR\n\nlinelist_sym_2 <- linelist_sym %>% \n  \n  # convert the \"yes\" and \"no\" values into the symptom name itself\n  mutate(\n    fever = case_when(\n      fever == \"yes\" ~ 1,    # if old value is \"yes\", new value is 1\n      TRUE           ~ 0),   # if old value is anything other than \"yes\", the new value is 0\n         \n    chills = case_when(\n      chills == \"yes\" ~ 1,\n      TRUE           ~ 0),\n         \n    cough = case_when(\n      cough == \"yes\" ~ 1,\n      TRUE           ~ 0),\n         \n    aches = case_when(\n      aches == \"yes\" ~ 1,\n      TRUE           ~ 0),\n         \n    vomit = case_when(\n      vomit == \"yes\" ~ 1,\n      TRUE           ~ 0)\n    )\n# Make the plot\nUpSetR::upset(\n  select(linelist_sym_2, fever, chills, cough, aches, vomit),\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n  order.by = \"freq\",\n  sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n  empty.intersections = \"on\",\n  # nsets = 3,\n  number.angles = 0,\n  point.size = 3.5,\n  line.size = 2, \n  mainbar.y.label = \"Symptoms Combinations\",\n  sets.x.label = \"Patients with Symptom\")"},{"path":"combination-analysis.html","id":"nguồn-6","chapter":"36 Biểu đồ kết hợp","heading":"36.4 Nguồn","text":"github page UpSetRA Shiny App version - can upload data*documentation - difficult interpret","code":""},{"path":"transmission-chains.html","id":"transmission-chains","chapter":"37 Chuỗi lây nhiễm","heading":"37 Chuỗi lây nhiễm","text":"","code":""},{"path":"transmission-chains.html","id":"overview-6","chapter":"37 Chuỗi lây nhiễm","heading":"37.1 Overview","text":"primary tool handle, analyse visualise transmission chains contact\ntracing data package epicontacts, developed folks \nRECON. Try interactive plot hovering nodes \ninformation, dragging move clicking highlight downstream cases.","code":""},{"path":"transmission-chains.html","id":"preparation-21","chapter":"37 Chuỗi lây nhiễm","heading":"37.2 Preparation","text":"","code":""},{"path":"transmission-chains.html","id":"load-packages-20","chapter":"37 Chuỗi lây nhiễm","heading":"Load packages","text":"First load standard packages required data import manipulation. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page [R basics] information R packages.require development version epicontacts, can \ninstalled github using p_install_github() function pacman. need run command\n, every time use package (thereafter, can use p_load() usual).","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   remotes       # Package installation from github\n)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")"},{"path":"transmission-chains.html","id":"import-data-15","chapter":"37 Chuỗi lây nhiễm","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions [Download handbook data] page. dataset imported using import() function rio package. See page [Import export] various ways import data.first 50 rows linelist displayed . particular interest columns case_id, generation, infector, source.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"transmission-chains.html","id":"creating-an-epicontacts-object","chapter":"37 Chuỗi lây nhiễm","heading":"Creating an epicontacts object","text":"need create epicontacts object, requires two types \ndata:linelist documenting cases columns variables rows correspond unique casesa list edges defining links cases basis unique IDs (can contacts,\ntransmission events, etc.)already linelist, just need create list edges \ncases, specifically IDs. can extract transmission links \nlinelist linking infector column case_id column. point can also add “edge\nproperties”, mean variable describing link two\ncases, cases . illustration, add location\nvariable describing location transmission event, duration\nvariable describing duration contact days.code , dplyr function transmute similar mutate, except keeps\ncolumns specified within function. drop_na function \nfilter rows specified columns NA value; \ncase, want keep rows infector known.can now create epicontacts object using make_epicontacts\nfunction. need specify column linelist points unique case\nidentifier, well columns contacts point unique\nidentifiers cases involved link. links directional \ninfection going infector case, need specify\narguments accordingly. therefore also set directed\nargument TRUE, affect future operations.Upon examining epicontacts objects, can see case_id column\nlinelist renamed id case_id infector\ncolumns contacts renamed . ensures\nconsistency subsequent handling, visualisation analysis operations.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %>%\n  drop_na(infector)\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n## view epicontacts object\nepic## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 5,888 cases in linelist; 3,800 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 5,888 x 30\n##    id    generation date_infection date_onset date_hospitalis~ date_outcome outcome gender\n##    <chr>      <dbl> <date>         <date>     <date>           <date>       <chr>   <chr> \n##  1 5fe5~          4 2014-05-08     2014-05-13 2014-05-15       NA           <NA>    m     \n##  2 8689~          4 NA             2014-05-13 2014-05-14       2014-05-18   Recover f     \n##  3 11f8~          2 NA             2014-05-16 2014-05-18       2014-05-30   Recover m     \n##  4 b881~          3 2014-05-04     2014-05-18 2014-05-20       NA           <NA>    f     \n##  5 893f~          3 2014-05-18     2014-05-21 2014-05-22       2014-05-29   Recover m     \n##  6 be99~          3 2014-05-03     2014-05-22 2014-05-23       2014-05-24   Recover f     \n##  7 07e3~          4 2014-05-22     2014-05-27 2014-05-29       2014-06-01   Recover f     \n##  8 3694~          4 2014-05-28     2014-06-02 2014-06-03       2014-06-07   Death   f     \n##  9 f393~          4 NA             2014-06-05 2014-06-06       2014-06-18   Recover m     \n## 10 1389~          4 NA             2014-06-05 2014-06-07       2014-06-09   Death   f     \n## # ... with 5,878 more rows, and 22 more variables: age <dbl>, age_unit <chr>,\n## #   age_years <dbl>, age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>, lat <dbl>,\n## #   infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>,\n## #   chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\n## \n##   // contacts\n## \n## # A tibble: 3,800 x 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 f547d6 5fe599 Community         4\n##  2 f90f5f b8812a Community         2\n##  3 11f8ea 893f25 Nosocomial        5\n##  4 aec8ec be99c8 Nosocomial        5\n##  5 893f25 07e3e8 Nosocomial        9\n##  6 133ee7 369449 Nosocomial        2\n##  7 996f3a 2978ac Nosocomial        4\n##  8 133ee7 57a565 Community         8\n##  9 37a6f6 fc15ef Community         9\n## 10 9f6884 2eaa9a Community         5\n## # ... with 3,790 more rows"},{"path":"transmission-chains.html","id":"handling","chapter":"37 Chuỗi lây nhiễm","heading":"37.3 Handling","text":"","code":""},{"path":"transmission-chains.html","id":"subsetting","chapter":"37 Chuỗi lây nhiễm","heading":"Subsetting","text":"subset() method epicontacts objects allows , among things,\nfiltering networks based properties linelist (“node attributes”) contacts\ndatabase (“edge attributes”). values must passed named lists \nrespective argument. example, code keeping \nmale cases linelist infection date April \nJuly 2014 (dates specified ranges), transmission links occured\nhospital.can use thin function either filter linelist include cases\nfound contacts setting argument = \"linelist\", \nfilter contacts include cases found linelist setting\nargument = \"contacts\". code , filtering \nepicontacts object keep transmission links involving male cases\ninfected April July filtered . can see \ntwo known transmission links fit specification.addition subsetting node edge attributes, networks can pruned \ninclude components connected certain nodes. cluster_id\nargument takes vector case IDs returns linelist individuals \nlinked, directly indirectly, IDs. code , can see\ntotal 13 linelist cases involved clusters containing\n2ae019 71577a.subset() method epicontacts objects also allows filtering cluster\nsize using cs, cs_min cs_max arguments. code , \nkeeping cases linked clusters 10 cases larger, can see \n271 linelist cases involved clusters.","code":"\nsub_attributes <- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 69 cases in linelist; 1,925 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 69 x 30\n##    id    generation date_infection date_onset date_hospitalis~ date_outcome outcome gender\n##    <chr>      <dbl> <date>         <date>     <date>           <date>       <chr>   <chr> \n##  1 5fe5~          4 2014-05-08     2014-05-13 2014-05-15       NA           <NA>    m     \n##  2 893f~          3 2014-05-18     2014-05-21 2014-05-22       2014-05-29   Recover m     \n##  3 2978~          4 2014-05-30     2014-06-06 2014-06-08       2014-06-15   Death   m     \n##  4 57a5~          4 2014-05-28     2014-06-13 2014-06-15       NA           Death   m     \n##  5 fc15~          6 2014-06-14     2014-06-16 2014-06-17       2014-07-09   Recover m     \n##  6 99e8~          7 2014-06-24     2014-06-28 2014-06-29       2014-07-09   Recover m     \n##  7 f327~          6 2014-06-14     2014-07-12 2014-07-13       2014-07-14   Death   m     \n##  8 90e5~          5 2014-06-18     2014-07-13 2014-07-14       2014-07-16   <NA>    m     \n##  9 a475~          5 2014-06-13     2014-07-17 2014-07-18       2014-07-26   Death   m     \n## 10 da8e~          5 2014-06-20     2014-07-18 2014-07-20       2014-08-01   <NA>    m     \n## # ... with 59 more rows, and 22 more variables: age <dbl>, age_unit <chr>,\n## #   age_years <dbl>, age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>, lat <dbl>,\n## #   infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>,\n## #   chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\n## \n##   // contacts\n## \n## # A tibble: 1,925 x 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 11f8ea 893f25 Nosocomial        5\n##  2 aec8ec be99c8 Nosocomial        5\n##  3 893f25 07e3e8 Nosocomial        9\n##  4 133ee7 369449 Nosocomial        2\n##  5 996f3a 2978ac Nosocomial        4\n##  6 4802b1 bbfa93 Nosocomial       10\n##  7 ab634e 99e8fa Nosocomial        4\n##  8 b799eb bc2adf Nosocomial        6\n##  9 a15e13 f327be Nosocomial        9\n## 10 ea3740 90e5fe Nosocomial        3\n## # ... with 1,915 more rows\nsub_attributes <- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)## [1] 2\nsub_id <- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)## [1] 13\nsub_cs <- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)## [1] 271"},{"path":"transmission-chains.html","id":"accessing-ids","chapter":"37 Chuỗi lây nhiễm","heading":"Accessing IDs","text":"get_id() function retrieves information case IDs \ndataset, can parameterized follows:linelist: IDs line list datacontacts: IDs contact dataset (“” “” combined): IDs “” column contact datsetto IDs “” column contact datasetall: IDs appear anywhere either datasetcommon: IDs appear contacts dataset line listFor example, first ten IDs contacts dataset?many IDs found linelist contacts?","code":"\ncontacts_ids <- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)##  [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\" \"9f6884\"\n## [10] \"4802b1\"\nlength(get_id(epic, \"common\"))## [1] 4352"},{"path":"transmission-chains.html","id":"visualization","chapter":"37 Chuỗi lây nhiễm","heading":"37.4 Visualization","text":"","code":""},{"path":"transmission-chains.html","id":"basic-plotting","chapter":"37 Chuỗi lây nhiễm","heading":"Basic plotting","text":"visualisations epicontacts objects handled plot\nfunction. first filter epicontacts object include \ncases onset dates June 2014 using subset function, \ninclude contacts linked cases using thin function.can create basic, interactive plot simply follows:can move nodes around dragging , hover \ninformation click highlight connected cases.large number arguments modify plot. cover\nmain ones , check documentation via ?vis_epicontacts (\nfunction called using plot epicontacts object) get full\ndescription function arguments.","code":"\n## subset epicontacts object\nsub <- epic %>%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %>%\n thin(\"contacts\")\n## plot epicontacts object\nplot(\n  sub,\n  width = 700,\n  height = 700\n)"},{"path":"transmission-chains.html","id":"visualising-node-attributes","chapter":"37 Chuỗi lây nhiễm","heading":"Visualising node attributes","text":"Node color, node shape node size can mapped given column linelist\nusing node_color, node_shape node_size arguments. similar\naes syntax may recognise ggplot2.specific colors, shapes sizes nodes can specified follows:Colors via col_pal argument, either providing name list manual\nspecification color done , providing color palette\nfunction colorRampPalette(c(\"black\", \"red\", \"orange\")), \nprovide gradient colours ones specified.Colors via col_pal argument, either providing name list manual\nspecification color done , providing color palette\nfunction colorRampPalette(c(\"black\", \"red\", \"orange\")), \nprovide gradient colours ones specified.Shapes passing named list shapes argument, specifying one shape\nunique element linelist column specified node_shape\nargument. See codeawesome available shapes.Shapes passing named list shapes argument, specifying one shape\nunique element linelist column specified node_shape\nargument. See codeawesome available shapes.Size passing size range nodes size_range argument.Size passing size range nodes size_range argument.example, color represents outcome, shape gender size\nage:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"visualising-edge-attributes","chapter":"37 Chuỗi lây nhiễm","heading":"Visualising edge attributes","text":"Edge color, width linetype can mapped given column contacts\ndataframe using edge_color, edge_width edge_linetype\narguments. specific colors widths edges can specified follows:Colors via edge_col_pal argument, manner used col_pal.Colors via edge_col_pal argument, manner used col_pal.Widths passing size range nodes width_range argument.Widths passing size range nodes width_range argument.example:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"temporal-axis","chapter":"37 Chuỗi lây nhiễm","heading":"Temporal axis","text":"can also visualise network along temporal axis mapping x_axis\nargument column linelist. example , x-axis\nrepresents date symptom onset. also specified arrow_size\nargument ensure arrows large, set label = FALSE make\nfigure less cluttered.large number additional arguments futher specify \nnetwork visualised along temporal axis, can check \nvia ?vis_temporal_interactive (function called using plot \nepicontacts object x_axis specified). ’ll go \n.","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"specifying-transmission-tree-shape","chapter":"37 Chuỗi lây nhiễm","heading":"Specifying transmission tree shape","text":"two main shapes transmission tree can assume, specified using\nnetwork_shape argument. first branching shape shown ,\nstraight edge connects two nodes. intuitive\nrepresentation, however can result overlapping edges densely connected\nnetwork. second shape rectangle, produces tree resembling \nphylogeny. example:case node can assigned unique vertical position toggling \nposition_dodge argument. position unconnected cases (.e. \nreported contacts) specified using unlinked_pos argument.position parent node relative children nodes can \nspecified using parent_pos argument. default option place \nparent node middle, however can placed bottom (parent_pos = 'bottom') top (parent_pos = 'top').","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"saving-plots-and-figures","chapter":"37 Chuỗi lây nhiễm","heading":"Saving plots and figures","text":"can save plot interactive, self-contained html file \nvisSave function VisNetwork package:Saving network outputs image unfortunately less easy requires\nsave file html take screenshot file using\nwebshot package. code , converting html file saved\nPNG:","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %>%\n  visNetwork::visSave(\"network.html\")\nwebshot(url = \"network.html\", file = \"network.png\")"},{"path":"transmission-chains.html","id":"timelines","chapter":"37 Chuỗi lây nhiễm","heading":"Timelines","text":"can also case timelines network, represented x-axis\ncase. can used visualise case locations, example, time\noutcome. generate timeline, need create data.frame least\nthree columns indicating case ID, start date “event” end\ndate “event”. can also add number columns can\nmapped node edge properties timeline. code ,\ngenerate timeline going date symptom onset date \noutcome, keep outcome hospital variables use define \nnode shape colour. Note can one timeline row/event\nper case, example case transferred multiple hospitals.pass timeline element timeline argument. can map\ntimeline attributes timeline node colours, shapes sizes way\ndefined previous sections, except two nodes: start end\nnode timeline, seperate arguments. example,\ntl_start_node_color defines timeline column mapped colour \nstart node, tl_end_node_shape defines timeline column \nmapped shape end node. can also map colour, width, linetype \nlabels timeline edge via tl_edge_* arguments.See ?vis_temporal_interactive (function called plotting \nepicontacts object) detailed documentation arguments. argument\nannotated code :","code":"\n## generate timeline\ntimeline <- linelist %>%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n## define shapes\nshapes <- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## define colours\ncolours <- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## make plot\nplot(\n  sub,\n  ## max x coordinate to date of onset\n  x_axis = \"date_onset\",\n  ## use rectangular network shape\n  network_shape = \"rectangle\",\n  ## mape case node shapes to gender column\n  node_shape = \"gender\",\n  ## we don't want to map node colour to any columns - this is important as the\n  ## default value is to map to node id, which will mess up the colour scheme\n  node_color = NULL,\n  ## set case node size to 30 (as this is not a character, node_size is not\n  ## mapped to a column but instead interpreted as the actual node size)\n  node_size = 30,\n  ## set transmission link width to 4 (as this is not a character, edge_width is\n  ## not mapped to a column but instead interpreted as the actual edge width)\n  edge_width = 4,\n  ## provide the timeline object\n  timeline = timeline,\n  ## map the shape of the end node to the outcome column in the timeline object\n  tl_end_node_shape = \"outcome\",\n  ## set the size of the end node to 15 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## node size)\n  tl_end_node_size = 15,\n  ## map the colour of the timeline edge to the hospital column\n  tl_edge_color = \"hospital\",\n  ## set the width of the timeline edge to 2 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## edge width)\n  tl_edge_width = 2,\n  ## map edge labels to the hospital variable\n  tl_edge_label = \"hospital\",\n  ## specify the shape for everyone node attribute (defined above)\n  shapes = shapes,\n  ## specify the colour palette (defined above)\n  col_pal = colours,\n  ## set the size of the arrow to 0.5\n  arrow_size = 0.5,\n  ## use two columns in the legend\n  legend_ncol = 2,\n  ## set font size\n  font_size = 15,\n  ## define formatting for dates\n  date_labels = c(\"%d %b %Y\"),\n  ## don't plot the ID labels below nodes\n  label = FALSE,\n  ## specify height\n  height = 1000,\n  ## specify width\n  width = 1200,\n  ## ensure each case node has a unique y-coordinate - this is very important\n  ## when using timelines, otherwise you will have overlapping timelines from\n  ## different cases\n  position_dodge = TRUE\n)## Warning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed as ID not\n## found in linelist or start/end date is NA"},{"path":"transmission-chains.html","id":"analysis","chapter":"37 Chuỗi lây nhiễm","heading":"37.5 Analysis","text":"","code":""},{"path":"transmission-chains.html","id":"summarising","chapter":"37 Chuỗi lây nhiễm","heading":"Summarising","text":"can get overview network properties using \nsummary function.example, can see 57% contacts cases \nlinelist; means linelist data significant\nnumber cases involved transmission chains.","code":"\n## summarise epicontacts object\nsummary(epic)## \n## /// Overview //\n##   // number of unique IDs in linelist: 5888\n##   // number of unique IDs in contacts: 5511\n##   // number of unique IDs in both: 4352\n##   // number of contacts: 3800\n##   // contacts with both cases in linelist: 56.868 %\n## \n## /// Degrees of the network //\n##   // in-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n## \n##   // out-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n## \n##   // in and out degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   1.000   1.000   1.078   1.000   7.000 \n## \n## /// Attributes //\n##   // attributes in linelist:\n##  generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n## \n##   // attributes in contacts:\n##  location duration"},{"path":"transmission-chains.html","id":"pairwise-characteristics","chapter":"37 Chuỗi lây nhiễm","heading":"Pairwise characteristics","text":"get_pairwise() function allows processing variable(s) line list\naccording pair contact dataset. following example, date\nonset disease extracted line list order compute \ndifference disease date onset pair. value \nproduced comparison represents serial interval (si).get_pairwise() interpret class column used \ncomparison, adjust method comparing values accordingly. \nnumbers dates (like si example ), function subtract\nvalues. applied columns characters categorical,\nget_pairwise() paste values together. function also allows\narbitrary processing (see “f” argument), discrete combinations can \neasily tabulated analyzed., see significant association transmission links gender.","code":"\nsi <- get_pairwise(epic, \"date_onset\")   \nsummary(si)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    5.00    9.00   11.01   15.00   99.00    1820\ntibble(si = si) %>%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 1820 rows containing non-finite values (stat_bin).\nhead(get_pairwise(epic, \"gender\"), n = 10)##  [1] \"f -> m\" NA       \"m -> m\" NA       \"m -> f\" \"f -> f\" NA       \"f -> m\" NA      \n## [10] \"m -> f\"\nget_pairwise(epic, \"gender\", f = table)##            values.to\n## values.from   f   m\n##           f 464 516\n##           m 510 468\nfisher.test(get_pairwise(epic, \"gender\", f = table))## \n##  Fisher's Exact Test for Count Data\n## \n## data:  get_pairwise(epic, \"gender\", f = table)\n## p-value = 0.03758\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  0.6882761 0.9892811\n## sample estimates:\n## odds ratio \n##  0.8252575"},{"path":"transmission-chains.html","id":"identifying-clusters","chapter":"37 Chuỗi lây nhiễm","heading":"Identifying clusters","text":"get_clusters() function can used identify connected components\nepicontacts object. First, use retrieve data.frame\ncontaining cluster information:Let us look largest clusters. , add cluster information \nepicontacts object subset keep largest clusters:","code":"\nclust <- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)## \n##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n## 1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\nepic <- get_clusters(epic)\nmax_size <- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))"},{"path":"transmission-chains.html","id":"calculating-degrees","chapter":"37 Chuỗi lây nhiễm","heading":"Calculating degrees","text":"degree node corresponds number edges connections \nnodes. get_degree() provides easy method calculating value \nepicontacts networks. high degree context indicates individual\ncontact many others. type argument indicates want\ncount -degree -degree, only_linelist argument\nindicates want calculate degree cases linelist.individuals ten contacts?mean number contacts?","code":"\ndeg_both <- get_degree(epic, type = \"both\", only_linelist = TRUE)\nhead(sort(deg_both, decreasing = TRUE), 10)## 916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n##      7      6      6      6      5      5      5      5      5      5\nmean(deg_both)## [1] 1.078473"},{"path":"transmission-chains.html","id":"resources-21","chapter":"37 Chuỗi lây nhiễm","heading":"37.6 Resources","text":"\nepicontacts page\nprovides overview package functions includes -depth\nvignettes.github page can used raise\nissues request features.","code":""},{"path":"phylogenetic-trees.html","id":"phylogenetic-trees","chapter":"38 Cây phả hệ","heading":"38 Cây phả hệ","text":"","code":""},{"path":"phylogenetic-trees.html","id":"overview-7","chapter":"38 Cây phả hệ","heading":"38.1 Overview","text":"Phylogenetic trees used visualize describe relatedness evolution organisms based sequence genetic code.can constructed genetic sequences using distance-based methods (neighbor-joining method) character-based methods (maximum likelihood Bayesian Markov Chain Monte Carlo method). Next-generation sequencing (NGS) become affordable becoming widely used public health describe pathogens causing infectious diseases. Portable sequencing devices decrease turn around time hold promises make data available support outbreak investigation real-time. NGS data can used identify origin source outbreak strain propagation, well determine presence antimicrobial resistance genes. visualize genetic relatedness samples phylogenetic tree constructed.page learn use ggtree package, allows combined visualization phylogenetic trees additional sample data form dataframe. enable us observe patterns improve understanding outbreak dynamic.","code":""},{"path":"phylogenetic-trees.html","id":"preparation-22","chapter":"38 Cây phả hệ","heading":"38.2 Preparation","text":"","code":""},{"path":"phylogenetic-trees.html","id":"load-packages-21","chapter":"38 Cây phả hệ","heading":"Load packages","text":"code chunk shows loading required packages. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,             # import/export\n  here,            # relative file paths\n  tidyverse,       # general data management and visualization\n  ape,             # to import and export phylogenetic files\n  ggtree,          # to visualize phylogenetic files\n  treeio,          # to visualize phylogenetic files\n  ggnewscale)      # to add additional layers of color schemes"},{"path":"phylogenetic-trees.html","id":"import-data-16","chapter":"38 Cây phả hệ","heading":"Import data","text":"data page can downloaded instructions [Download handbook data] page.several different formats phylogenetic tree can stored (eg. Newick, NEXUS, Phylip). common one Newick file format (.nwk), standard representing trees computer-readable form. means entire tree can expressed string format “((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59);”, listing nodes tips relationship (branch length) .Note: important understand phylogenetic tree file contain sequencing data, merely result genetic distances sequences. therefore extract sequencing data tree file.First, use read.tree() function ape package import Newick phylogenetic tree file .txt format, store list object class “phylo”. necessary, use () function package specify relative file path.Note: case newick tree saved .txt file easier handling downloading Github.inspect tree object see contains 299 tips (samples) 236 nodes.Second, import table stored .csv file additional information sequenced sample, gender, country origin attributes antimicrobial resistance, using import() function rio package:first 50 rows data:","code":"\ntree <- ape::read.tree(\"Shigella_tree.txt\")\ntree## \n## Phylogenetic tree with 299 tips and 236 internal nodes.\n## \n## Tip labels:\n##   SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\n## Node labels:\n##   17, 29, 100, 67, 100, 100, ...\n## \n## Rooted; includes branch lengths.\nsample_data <- import(\"sample_data_Shigella_tree.csv\")"},{"path":"phylogenetic-trees.html","id":"clean-and-inspect","chapter":"38 Cây phả hệ","heading":"Clean and inspect","text":"clean inspect data: order assign correct sample data phylogenetic tree, values column Sample_ID sample_data data frame need match tip.labels values tree file:check formatting tip.labels tree file looking first 6 entries using head() base R.also make sure first column sample_data data frame Sample_ID. look column names dataframe using colnames() base R.look Sample_IDs data frame make sure formatting tip.label (eg. letters capitals, extra underscores _ letters numbers, etc.)can also compare samples present tree file vice versa generating logical vector TRUE FALSE match. printed , simplicity.can use vectors show sample IDs tree (none).Upon inspection can see format Sample_ID dataframe corresponds format sample names tip.labels. sorted order matched.ready go!","code":"\nhead(tree$tip.label) ## [1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\" \"S17BD05939\"\ncolnames(sample_data)   ##  [1] \"Sample_ID\"                  \"serotype\"                  \n##  [3] \"Country\"                    \"Continent\"                 \n##  [5] \"Travel_history\"             \"Year\"                      \n##  [7] \"Belgium\"                    \"Source\"                    \n##  [9] \"Gender\"                     \"gyrA_mutations\"            \n## [11] \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n## [13] \"MIC_CIP\"\nhead(sample_data$Sample_ID) # we again inspect only the first 6 using head()## [1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\" \"S18BD02657\"\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]## character(0)"},{"path":"phylogenetic-trees.html","id":"simple-tree-visualization","chapter":"38 Cây phả hệ","heading":"38.3 Simple tree visualization","text":"","code":""},{"path":"phylogenetic-trees.html","id":"different-tree-layouts","chapter":"38 Cây phả hệ","heading":"Different tree layouts","text":"ggtree offers many different layout formats may suitable specific purpose others. demonstrations. options see online book.example tree layouts:","code":"\nggtree(tree)                                            # simple linear tree\nggtree(tree,  branch.length = \"none\")                   # simple linear tree with all tips aligned\nggtree(tree, layout=\"circular\")                         # simple circular tree\nggtree(tree, layout=\"circular\", branch.length = \"none\") # simple circular tree with all tips aligned"},{"path":"phylogenetic-trees.html","id":"simple-tree-plus-sample-data","chapter":"38 Cây phả hệ","heading":"Simple tree plus sample data","text":"%<+% operator used connect sample_data data frame tree file.\neasy annotation tree addition sample names tips, well coloring tip points desired branches:example circular tree:can export tree plot ggsave() ggplot object. Written way, ggsave() saves last image produced file path specify. Remember can use () relative file paths easily save subfolders, etc.","code":"\nggtree(tree, layout = \"circular\", branch.length = 'none') %<+% sample_data + # %<+% adds dataframe with sample data to tree\n  aes(color = I(Belgium))+                       # color the branches according to a variable in your dataframe\n  scale_color_manual(\n    name = \"Sample Origin\",                      # name of your color scheme (will show up in the legend like this)\n    breaks = c(\"Yes\", \"No\"),                     # the different options in your variable\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # how you want the different options named in your legend, allows for formatting\n    values = c(\"blue\", \"black\"),                  # the color you want to assign to the variable \n    na.value = \"black\") +                        # color NA values in black as well\n  new_scale_color()+                             # allows to add an additional color scheme for another variable\n    geom_tippoint(\n      mapping = aes(color = Continent),          # tip color by continent. You may change shape adding \"shape = \"\n      size = 1.5)+                               # define the size of the point at the tip\n  scale_color_brewer(\n    name = \"Continent\",                    # name of your color scheme (will show up in the legend like this)\n    palette = \"Set1\",                      # we choose a set of colors coming with the brewer package\n    na.value = \"grey\") +                    # for the NA values we choose the color grey\n  geom_tiplab(                             # adds name of sample to tip of its branch \n    color = 'black',                       # (add as many text lines as you wish with + , but you may need to adjust offset value to place them next to each other)\n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    align = TRUE)+    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # title of your graph\n  theme(\n    axis.title.x = element_blank(), # removes x-axis title\n    axis.title.y = element_blank(), # removes y-axis title\n    legend.title = element_text(    # defines font size and format of the legend title\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # defines font size and format of the legend text\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # defines font size and format of the plot title\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # defines placement of the legend\n    legend.box = \"vertical\",        # defines placement of the legend\n    legend.margin = margin())   \nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)"},{"path":"phylogenetic-trees.html","id":"tree-manipulation","chapter":"38 Cây phả hệ","heading":"38.4 Tree manipulation","text":"Sometimes may large phylogenetic tree interested one part tree. example, produced tree including historical international samples get large overview dataset might fit bigger picture. look closer data want inspect portion bigger tree.Since phylogenetic tree file just output sequencing data analysis, can manipulate order nodes branches file . already determined previous analysis raw NGS data. able though zoom parts, hide parts even subset part tree.","code":""},{"path":"phylogenetic-trees.html","id":"zoom-in","chapter":"38 Cây phả hệ","heading":"Zoom in","text":"don’t want “cut” tree, inspect part closely can zoom view specific part.First, plot entire tree linear format add numeric labels node tree.zoom one particular branch (sticking right), use viewClade() ggtree object p provide node number get closer look:","code":"\np <- ggtree(tree,) %<+% sample_data +\n  geom_tiplab(size = 1.5) +                # labels the tips of all branches with the sample name in the tree file\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # labels all the nodes in the tree\n\np  # print\nviewClade(p, node = 452)"},{"path":"phylogenetic-trees.html","id":"collapsing-branches","chapter":"38 Cây phả hệ","heading":"Collapsing branches","text":"However, may want ignore branch can collapse node (node nr. 452) using collapse(). tree defined p_collapsed.clarity, print p_collapsed, add geom_point2() (blue diamond) node collapsed branch.","code":"\np_collapsed <- collapse(p, node = 452)\np_collapsed\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # we assign a symbol to the collapsed node\n            size = 5,                     # define the size of the symbol\n            shape = 23,                   # define the shape of the symbol\n            fill = \"steelblue\")           # define the color of the symbol"},{"path":"phylogenetic-trees.html","id":"subsetting-a-tree","chapter":"38 Cây phả hệ","heading":"Subsetting a tree","text":"want make permanent change create new, reduced tree work can subset part tree_subset(). can save new newick tree file .txt file.First, inspect tree nodes tip labels order decide subset.Now, say decided subset tree node 528 (keep tips within branch node 528) save new sub_tree1 object:Lets look subset tree 1:can also subset based one particular sample, specifying many nodes “backwards” want include. Let’s subset part tree based sample, case S17BD07692, going back 9 nodes save new sub_tree2 object:Lets look subset tree 2:can also save new tree either Newick type even text file using write.tree() function ape package:","code":"\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %<+% sample_data +               # we add the asmple data using the %<+% operator\n  geom_tiplab(size = 1)+                                # label tips of all branches with sample name in tree file\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # labels all the nodes in the tree\n theme(\n   legend.position = \"none\",                            # removes the legend all together\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\nsub_tree1 <- tree_subset(\n  tree,\n  node = 528)                                            # we subset the tree at node 528\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\nsub_tree2 <- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels back defines how many nodes backwards from the sample tip you want to go\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n# to save in .nwk format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# to save in .txt format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')"},{"path":"phylogenetic-trees.html","id":"rotating-nodes-in-a-tree","chapter":"38 Cây phả hệ","heading":"Rotating nodes in a tree","text":"mentioned change order tips nodes tree, based genetic relatedness subject visual manipulation. can rote branches around nodes eases visualization.First, plot new subset tree 2 node labels choose node want manipulate store ggtree plot object p.can manipulate nodes applying ggtree::rotate() ggtree::flip():\nNote: illustrate nodes manipulating first apply geom_hilight() function ggtree highlight samples nodes interested store ggtree plot object new object p1.Now can rotate node 37 object p1 samples node 38 move top. store rotated tree new object p2.can use flip command rotate node 36 object p1 switch node 37 top node 39 bottom. store flipped tree new object p3.","code":"\np <- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # labels all the nodes in the tree\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\np1 <- p + geom_hilight(  # highlights node 39 in blue, \"extend =\" allows us to define the length of the color block\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # highlights the node 37 in yellow\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # print\np2 <- rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # print\np3 <-  flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # print"},{"path":"phylogenetic-trees.html","id":"example-subtree-with-sample-data-annotation","chapter":"38 Cây phả hệ","heading":"Example subtree with sample data annotation","text":"Lets say investigating cluster cases clonal expansion occurred 2017 2018 node 39 sub-tree. add year strain isolation well travel history color country see origin closely related strains:observation points towards import event strains Asia, circulated Belgium years seem caused latest outbreak.","code":"\nggtree(sub_tree2) %<+% sample_data +     # we use th %<+% operator to link to the sample_data\n  geom_tiplab(                          # labels the tips of all branches with the sample name in the tree file\n    size = 2.5,\n    offset = 0.001,\n    align = TRUE) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # set the x-axis limits of our tree\n  geom_tippoint(aes(color=Country),     # color the tip point by continent\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                          # add isolation year as a text label at the tips\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    align = TRUE)+ \n  geom_tiplab(                          # add travel history as a text label at the tips, in red color\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    align = TRUE)+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # add plot title\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                    # add a label to the x-axis \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))"},{"path":"phylogenetic-trees.html","id":"more-complex-trees-adding-heatmaps-of-sample-data","chapter":"38 Cây phả hệ","heading":"More complex trees: adding heatmaps of sample data","text":"can add complex information, categorical presence antimicrobial resistance genes numeric values actually measured resistance antimicrobials form heatmap using ggtree::gheatmap() function.First need plot tree (can either linear circular) store new ggtree plot object p: use sub_tree part 3.)Second, prepare data. visualize different variables new color schemes, subset dataframe desired variable. important add Sample_ID rownames otherwise match data tree tip.labels:example want look gender mutations confer resistance Ciprofloxacin, important first line antibiotic used treat Shigella infections.create dataframe gender:create dataframe mutations gyrA gene, confer Ciprofloxacin resistance:create dataframe measured minimum inhibitory concentration (MIC) Ciprofloxacin laboratory:create first plot adding binary heatmap gender phylogenetic tree storing new ggtree plot object h1:add information mutations gyrA gene, confer resistance Ciprofloxacin:Note: presence chromosomal point mutations WGS data prior determined using PointFinder tool developed Zankari et al. (see reference additional references section)First, assign new color scheme existing plot object h1 store now object h2. enables us define change colors second variable heatmap.add second heatmap layer h2 store combined plots new object h3:repeat process, first adding new color scale layer existing object h3, adding continuous data minimum inhibitory concentration (MIC) Ciprofloxacin strain resulting object h4 produce final object h5:can exercise linear tree:First add gender:add Ciprofloxacin resistance mutations adding another color scheme layer:add minimum inhibitory concentration determined laboratory (MIC):","code":"\np <- ggtree(sub_tree2, branch.length='none', layout='circular') %<+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\ngender <- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) <- sample_data$Sample_ID\ncipR <- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) <- sample_data$Sample_ID\nMIC_Cip <- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) <- sample_data$Sample_ID\nh1 <-  gheatmap(p, gender,                                 # we add a heatmap layer of the gender dataframe to our tree plot\n                offset = 10,                               # offset shifts the heatmap to the right,\n                width = 0.10,                              # width defines the width of the heatmap column,\n                color = NULL,                              # color defines the boarder of the heatmap columns\n         colnames = FALSE) +                               # hides column names for the heatmap\n  scale_fill_manual(name = \"Gender\",                       # define the coloring scheme and legend for gender\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for 'y' is already present. Adding another scale for 'y', which will replace the\n## existing scale.## Scale for 'fill' is already present. Adding another scale for 'fill', which will\n## replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill() \nh3 <- gheatmap(h2, cipR,         # adds the second row of heatmap describing Ciprofloxacin resistance mutations\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for 'y' is already present. Adding another scale for 'y', which will replace the\n## existing scale.## Scale for 'fill' is already present. Adding another scale for 'fill', which will\n## replace the existing scale.\nh3\n# First we add the new coloring scheme:\nh4 <- h3 + new_scale_fill()\n\n# then we combine the two into a new plot:\nh5 <- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # here we define a gradient color scheme for the continuous variable of MIC\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for 'y' is already present. Adding another scale for 'y', which will replace the\n## existing scale.## Scale for 'fill' is already present. Adding another scale for 'fill', which will\n## replace the existing scale.\nh5\np <- ggtree(sub_tree2) %<+% sample_data +\n  geom_tiplab(size = 3) + # labels the tips\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\nh1 <-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for 'y' is already present. Adding another scale for 'y', which will replace the\n## existing scale.## Scale for 'fill' is already present. Adding another scale for 'fill', which will\n## replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill()\nh3 <- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for 'y' is already present. Adding another scale for 'y', which will replace the\n## existing scale.## Scale for 'fill' is already present. Adding another scale for 'fill', which will\n## replace the existing scale.\n h3\nh4 <- h3 + new_scale_fill()\nh5 <- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))## Scale for 'y' is already present. Adding another scale for 'y', which will replace the\n## existing scale.## Scale for 'fill' is already present. Adding another scale for 'fill', which will\n## replace the existing scale.\nh5"},{"path":"phylogenetic-trees.html","id":"resources-22","chapter":"38 Cây phả hệ","heading":"38.5 Resources","text":"http://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors\nhttps://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\nhttps://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html\nhttps://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.htmlEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: novel web tool WGS-based detection antimicrobial resistance associated chromosomal point mutations bacterial pathogens, Journal Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764–2768, https://doi.org/10.1093/jac/dkx217","code":""},{"path":"interactive-plots.html","id":"interactive-plots","chapter":"39 Biểu đồ tương tác","heading":"39 Biểu đồ tương tác","text":"Data visualisation increasingly required interrogable audience. Consequently, becoming common create interactive plots. several ways include two common plotly shiny.page focus converting existing ggplot() plot interactive plot plotly. can read shiny [Dashboards Shiny] page. worth mentioning interactive plots useable HTML format R markdown documents, PDF Word documents.basic epicurve transformed interactive using integration ggplot2 plotly (hover mouse plot, zoom , click items legend).","code":""},{"path":"interactive-plots.html","id":"preparation-23","chapter":"39 Biểu đồ tương tác","heading":"39.1 Preparation","text":"","code":""},{"path":"interactive-plots.html","id":"load-packages-22","chapter":"39 Biểu đồ tương tác","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,       # import/export\n  here,      # filepaths\n  lubridate, # working with dates\n  plotly,    # interactive plots\n  scales,    # quick percents\n  tidyverse  # data management and visualization\n  ) "},{"path":"interactive-plots.html","id":"start-with-a-ggplot","chapter":"39 Biểu đồ tương tác","heading":"Start with a ggplot()","text":"page assume beginning ggplot() plot want convert interactive. build several plots page, using case linelist used many pages handbook.","code":""},{"path":"interactive-plots.html","id":"import-data-17","chapter":"39 Biểu đồ tương tác","heading":"Import data","text":"begin, import cleaned linelist cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"interactive-plots.html","id":"plot-with-ggplotly","chapter":"39 Biểu đồ tương tác","heading":"39.2 Plot with ggplotly()","text":"function ggplotly() plotly package makes easy convert ggplot() interactive. Simply save ggplot() pipe ggplotly() function., plot simple line representing proportion cases died given week:begin creating summary dataset epidemiological week, percent cases known outcome died.first 50 rows weekly_deaths dataset.create plot ggplot2, using geom_line().can make interactive simply passing plot ggplotly(), . Hover mouse line show x y values. can zoom plot, drag around. can also see icons upper-right plot. order, allow :Download current view PNG imageZoom select box“Pan”, move across plot clicking dragging plotZoom , zoom , return default zoomReset axes defaultsToggle /“spike lines” dotted lines interactive point extending x y axesAdjustments whether data show hovering lineGrouped data work ggplotly() well. , weekly epicurve made, grouped outcome. stacked bars interactive. Try clicking different items legend (appear/disappear).","code":"\nweekly_deaths <- linelist %>%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %>%  # create and group data by epiweek column\n  summarise(                                              # create new summary data frame:\n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # number of cases per group with known outcome\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # number of cases per group who died\n    pct_death = 100*(n_death / n_known_outcome)           # percent of cases with known outcome who died\n  )\ndeaths_plot <- ggplot(data = weekly_deaths)+            # begin with weekly deaths data\n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # make line \n\ndeaths_plot   # print\ndeaths_plot %>% plotly::ggplotly()\n# Make epidemic curve with incidence2 pacakge\np <- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %>% plot(fill = outcome)\n# Plot interactively  \np %>% plotly::ggplotly()"},{"path":"interactive-plots.html","id":"modifications","chapter":"39 Biểu đồ tương tác","heading":"39.3 Modifications","text":"","code":""},{"path":"interactive-plots.html","id":"file-size","chapter":"39 Biểu đồ tương tác","heading":"File size","text":"exporting R Markdown generated HTML (like book!) want make plot small data size possible (negative side effects cases). , just pipe interactive plot partial_bundle(), also plotly.","code":"\np <- p %>% \n  plotly::ggplotly() %>%\n  plotly::partial_bundle()"},{"path":"interactive-plots.html","id":"buttons","chapter":"39 Biểu đồ tương tác","heading":"Buttons","text":"buttons standard plotly superfluous can distracting, can remove . can simply piping output config() plotly specifying buttons remove. example specify advance names buttons remove, provide argument modeBarButtonsToRemove =. also set displaylogo = FALSE remove plotly logo.","code":"\n## these buttons are distracting and we want to remove them\nplotly_buttons_remove <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np <- p %>%          # re-define interactive plot without these buttons\n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"heat-tiles","chapter":"39 Biểu đồ tương tác","heading":"39.4 Heat tiles","text":"can make almost ggplot() plot interactive, including heat tiles. page [Heat plots] can read make plot, displays proportion days per week certain facilities reported data province.code, although describe depth ., make interactive modify simple buttons file size.–>\n","code":"\n# import data\nfacility_count_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# aggregate data into Weeks for Spring district\nagg_weeks <- facility_count_data %>% \n  filter(District == \"Spring\",\n         data_date < as.Date(\"2020-08-01\")) %>% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %>% \n  group_by(location_name, week, .drop = F) %>%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %>% \n  right_join(tidyr::expand(., week, location_name)) %>% \n  mutate(week = aweek::week2date(week))\n\n# create plot\nmetrics_plot <- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\nmetrics_plot # print\nmetrics_plot %>% \n  plotly::ggplotly() %>% \n  plotly::partial_bundle() %>% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"resources-23","chapter":"39 Biểu đồ tương tác","heading":"39.5 Resources","text":"Plotly just R, also works well Python (really data science language ’s built JavaScript). can read plotly website","code":""},{"path":"rmarkdown.html","id":"rmarkdown","chapter":"40 Báo cáo với R Markdown","heading":"40 Báo cáo với R Markdown","text":"R Markdown là một công cụ được sử dụng rộng rãi nhằm tạo ra tài liệu tự động, tái lập và chia sẻ được, như các báo cáo. Nó có thể tạo ra kết quả thống kê hoặc tương tác, ở định dạng Word, pdf, html, powerpoint, và các định dạng khác.Một R Markdown script chứa xen kẽ các code R và văn bản khiến script này thật sự trở thành một tài liệu đầu ra của bạn. Bạn có thể tạo ra một tài liệu đã được định dạng toàn bộ, gồm có văn bản thuần túy (có thể thay đổi dựa trên số liệu của bạn), bảng, biểu đồ, đầu mục/số, thư mục, v.v.Những tài liệu như vậy có thể được cập nhật thường xuyên (ví dụ: báo cáo giám sát hàng ngày) và/hoặc chạy một tập dữ liệu (ví dụ: báo cáo cho mỗi jurisdiction-quyền xét xử).Những chương khác trong cuốn sách này mở rộng các chủ đề khác:Chương Tổ chức báo cáo định kỳ trình bày cách tự động hóa các báo cáo sản phẩm với các tập tin tự tạo kèm theo thời gian.Chương Dashboards với R Markdown giải thích cách định dạng một báo cáo R Markdown dưới dạng một dashboard.Một lưu ý là dự án R4Epis đã tạo ra các mẫu R Markdown script cho những đợt dịch và trường hợp khảo sát phổ biến ở vị trí dự án MSF.","code":""},{"path":"rmarkdown.html","id":"chuẩn-bị-8","chapter":"40 Báo cáo với R Markdown","heading":"40.1 Chuẩn bị","text":"Nền tảng về R MarkdownNhằm giải thích một số khái niệm và packages cần thiết:Markdown là một “ngôn ngữ” cho phép bạn soạn tài liệu bằng chữ thuần túy, sau đó có thể chuyển đổi sang html và các định dạng khác. Nó không dành riêng cho R. Các tệp được viết trong Markdown có đuôi ‘.md’.R Markdown: là một biến thể trên markdown chỉ dành riêng cho R - nó cho phép bạn soạn một tài liệu sử dụng markdown để tạo chữ cũng như nhúng code R và hiển thị kết quả đầu ra. Các tệp R Markdown có đuôi ‘.Rmd’.Package rmarkdown: Package được R sử dụng để chuyển tệp .Rmd thành đầu ra mong muốn. Nó tập trung vào việc chuyển cú pháp markdown (chữ), vì vậy chúng ta cũng cần tới…knitr: Package R này sẽ đọc các đoạn code, thực thi chúng, và ‘knit’ (kết hợp) chúng vào lại tài liệu. Đây là cách bảng, biểu đồ được thêm vào văn bản.Pandoc: Cuối cùng, pandoc thật sự chuyển đổi kết quả đầu ra thành word/pdf/powerpoint, v.v. Nó là một phần mềm tách biệt khỏi R nhưng được cài đặt tự động cùng với RStudio.Tổng kết lại, quá trình được tiến hành trong nền (bạn không cần biết tới tất cả những bước này!), gồm chuyển tệp .Rmd tới knitr để thực thi các đoạn code R và tạo một tệp .md (markdown) mới bao gồm cả code R lẫn kết quả đầu ra đã được chuyển đổi. Các tệp .md này sau đó được pandoc chạy để tạo ra sản phẩm hoàn thiện như là một tài liệu Microsoft Word, tệp HTML, tài liệu powerpoint, pdf, v.v.(Nguồn: https://rmarkdown.rstudio.com/authoring_quick_tour.html):Cài đặtĐể tạo một kết quả đầu ra của R Markdown, bạn cần phải cài đặt:Package rmarkdown (knitr cũng sẽ được cài đặt tự động)Pandoc sẽ được cài đặt cùng với RStudio. Nếu bạn không dùng RStudio, bạn có thể tải Pandoc tại đây: http://pandoc.org.Nếu bạn muốn tạo đầu ra là tệp PDF (phức tạp hơn một chút), bạn sẽ cần cài đặt LaTex. Với những người dùng R Markdown chưa cài đặt LaTex trước đó, các bạn có thể cài đặt TinyTeX (https://yihui.name/tinytex/). Bạn có thể sử dụng lệnh sau để cài đặt:","code":"\npacman::p_load(tinytex)     # install tinytex package\ntinytex::install_tinytex()  # R command to install TinyTeX software "},{"path":"rmarkdown.html","id":"bắt-đầu","chapter":"40 Báo cáo với R Markdown","heading":"40.2 Bắt đầu","text":"","code":""},{"path":"rmarkdown.html","id":"cài-đặt-package-rmarkdown","chapter":"40 Báo cáo với R Markdown","heading":"Cài đặt package rmarkdown","text":"Cài đặt R package rmarkdown. Trong quyển sổ tay này chúng tôi nhấn mạnh việc sử dụng hàm p_load() từ package pacman, giúp cài đặt package nếu cần và gọi ra để sử dụng. Bạn cũng có thể cài đặt package với library() từ base R. Xem thêm ở chương R cơ bản để biết thêm thông tin về R packages.","code":"\npacman::p_load(rmarkdown)"},{"path":"rmarkdown.html","id":"bắt-đầu-một-tệp-rmd-mới","chapter":"40 Báo cáo với R Markdown","heading":"Bắt đầu một tệp Rmd mới","text":"Trong RStudio, để mở một tệp R markdown mới, bắt đầu với ‘File’, rồi ‘New file’, rồi ‘R markdown…’.R Studio sẽ đưa ra cho bạn một số lựa chọn kết quả đầu ra. Trong ví dụ bên dưới, chúng tôi chọn “HTML” bởi chúng tôi muốn tạo ra một văn bản html. Tiêu đề và tên các tác giả không quan trọng. Nếu loại tài liệu đầu ra bạn muốn không có, đừng lo - bạn có thể chọn bất kỳ loại nào và thay đổi trong script sau đó.Như vậy sẽ mở ra một script .Rmd mới.","code":""},{"path":"rmarkdown.html","id":"điều-quan-trọng-cần-phải-biết","chapter":"40 Báo cáo với R Markdown","heading":"Điều quan trọng cần phải biết","text":"Thư mục làm việcThư mục làm việc của một tệp markdown là ở bất kỳ vị trí nào tệp được lưu. Ví dụ, nếu R project nằm trong ~/Documents/projectX và tệp Rmd được lưu ở thư mục con ~/Documents/projectX/markdownfiles/markdown.Rmd, thì lệnh read.csv(“data.csv”) trong markdown sẽ tìm tệp csv trong thư mục markdownfiles, mà không phải là ở thư mục gốc nơi mà scripts trong projects sẽ thường tự động tìm kiếm.Để tìm kiếm các tệp này ở chỗ khác, bạn sẽ vừa cần sử dụng cả đường dẫn tệp đầy đủ và sử dụng package . Package cài đặt thư mục làm việc tới thư mục gốc của R project và sẽ được giải thích chi tiết trong các chương Dự án R và Nhập xuất dữ liệu của sổ tay này. Ví dụ, để nhập một tệp tên “data.csv” từ trong thư mục projectX, code sẽ là import((“data.csv”)).Lưu ý rằng không nên sử dụng setwd() trong R Markdown scripts - nó chỉ dùng cho các đoạn code được viết trong đó.Làm việc với ổ cứng mạng với trên máy tính của bạnVì R Markdown có thể gặp các vấn đề với pandoc khi chạy trên một ổ cứng mạng được chia sẻ, thư mục của bạn nên nằm ở ở cứng vật lý, ví dụ trong dự án thuộc ‘Documents’. Nếu bạn dùng Git (rất khuyến khích!), nó sẽ thân thuộc hơn. Để biết thêm chi tiết, xem thêm chương R trên ổ cứng mạng và Các lỗi thường gặp.","code":""},{"path":"rmarkdown.html","id":"các-cấu-phần-của-r-markdown","chapter":"40 Báo cáo với R Markdown","heading":"40.3 Các cấu phần của R Markdown","text":"Một tài liệu R Markdown có thể chỉnh sửa trong RStudio giống như một R script tiêu chuẩn. Khi bạn tạo một R Markdown script mới, RStudio vô cùng hữu ích bằng cách đưa ra một mẫu có các phần khác nhau của một tệp R Markdown script.Dưới đây là khung hiển thị khi bắt đầu một Rmd script mới có kết quả đầu ra là html (như phần trước)Như bạn có thể thấy, một tệp Rmd gồm có 3 cấu phần: YAML, chữ Markdown, và đoạn code R.Chúng sẽ tạo ra và trở thành tài liệu đầu ra của bạn. Xem biểu đồ bên dưới:","code":""},{"path":"rmarkdown.html","id":"yaml-metadata","chapter":"40 Báo cáo với R Markdown","heading":"YAML metadata","text":"‘YAML metadata’ hoặc chỉ ‘YAML’ nằm ở trên cùng trong tài liệu R Markdown. Phần này của script sẽ cho tệp Rmd của bạn biết cần tạo loại kết quả đầu ra nào, định dạng mong muốn, và metadata khác như tiêu đề tài liệu, tác giả, và ngày. Có những công dụng khác không được nhắc ở đây (nhưng được nhắc tới trong ‘Tạo kết quả đầu ra’). Lưu ý rằng có sự thụt đầu dòng, nhưng chỉ chấp nhận spaces chứ không nhận tabs.Phần này phải được bắt đầu với với một dòng gồm có 3 dấu gạch ngang --- và phải kết thúc với một dòng chỉ có 3 dấu gạch ngang ---. Tham số của YAML ở dạng cặp key:value. Dấu hai chấm trong YAML có vị trí quan trọng - cặp key:value được tách ra bởi dấu hai chấm (không phải dấu bằng!)YAML nên bắt đầu với metadata cho tài liệu. Thứ tự của những tham số YAML chính (không thụt lề) không quan trọng. Ví dụ:Bạn có thể sử dụng code R trong giá trị YAML bằng cách viết nó như code tại dòng (mở đầu bằng r trong dấu back-ticks/nháy đơn ngược) nhưng nằm trong trích dẫn (xem tại ví dụ phía trên với date:).Trong hình ảnh phía trên, vì chúng ta ấn vào kết quả đầu ra mặc định là tệp html, chúng ta có thể thấy rằng YAML hiện output: html_document. Tuy nhiên, chúng ta cũng có thể thay đổi thành powerpoint_presentation hoặc word_document hoặc cả pdf_document.","code":"title: \"My document\"\nauthor: \"Me\"\ndate: \"2021-07-12\""},{"path":"rmarkdown.html","id":"văn-bản","chapter":"40 Báo cáo với R Markdown","heading":"Văn bản","text":"Đây là phần diễn giải trong tài liệu của bạn, gồm các tiêu đề và đề mục. Nó được viết bằng ngôn ngữ “markdown”, được sử dụng trên nhiều phần mềm khác nhau.Dưới đây là những cách cốt lõi để viết văn bản định dạng này. Xem thêm tài liệu mở rộng có sẵn trên R Markdown “cheatsheet” tại Trang web RStudio.","code":""},{"path":"rmarkdown.html","id":"dòng-mới","chapter":"40 Báo cáo với R Markdown","heading":"Dòng mới","text":"Duy nhất trong R Markdown, để bắt đầu một dòng mới, nhập *hai dấu cách** vào cuối dòng trước đó và ấn Enter/Return.","code":""},{"path":"rmarkdown.html","id":"định-dạng","chapter":"40 Báo cáo với R Markdown","heading":"Định dạng","text":"Đặt các chữ bình thường bên trong các kí tự sau để thay đổi định dạng của chúng ở đầu ra.Gạch dưới (_chữ_) hoặc dấu hoa thị đơn (*chữ*) để nghiêngDấu hoa thị kép (**chữ**) để đậmDấu nháy đơn ngược (chữ) để hiển thị chữ như codePhông chữ hiển thị thực tế có thể được đặt bằng cách sử dụng các mẫu cụ thể (được chỉ định trong YAML metadata; xem các tab ví dụ).","code":""},{"path":"rmarkdown.html","id":"màu-sắc","chapter":"40 Báo cáo với R Markdown","heading":"Màu sắc","text":"Không có cơ chế đơn giản nào để thay đổi màu chữ trong R Markdown. Một giải pháp khác, NẾU đầu ra của bạn là tệp HTML, là thêm một dòng HTML vào văn bản markdown. Đoạn mã HTML dưới đây sẽ ra một dòng văn bản có màu đỏ đậm.DANGER: warning.","code":"<span style=\"color: red;\">**_DANGER:_** This is a warning.<\/span>  "},{"path":"rmarkdown.html","id":"tiêu-đề-và-đầu-mục","chapter":"40 Báo cáo với R Markdown","heading":"Tiêu đề và đầu mục","text":"Dấu thăng trong phần văn bản của một script R Markdown tạo ra đầu mục. Điều này khác với một đoạn code R trong script, trong đó ký hiệu thăng là cơ chế nhận xét/chú thích/hủy kích hoạt, như trong R script bình thường.Các mức tiêu đề khác nhau được thiết lập với số lượng ký hiệu thăng khác nhau khi bắt đầu một dòng mới. Một ký hiệu thăng là tiêu đề hoặc đầu mục chính. Hai ký hiệu thăng là một đầu mục cấp hai. Các đầu mục cấp ba và cấp bốn có thể được tạo bằng các ký hiệu thăng liên tiếp.","code":"# Đầu mục cấp một / Tiêu đề\n\n## Đầu mục cấp hai\n\n### Đầu mục cấp ba"},{"path":"rmarkdown.html","id":"dấu-đầu-dòng-và-đánh-số","chapter":"40 Báo cáo với R Markdown","heading":"Dấu đầu dòng và đánh số","text":"Sử dụng dấu hoa thị (*) để tạo danh sách gạch đầu dòng. Kết thúc câu trước, nhập hai dấu cách, Enter/Return hai lần, và bắt đầu tạo gạch đầu dòng. Thêm một dấu cách vào giữa dấu hoa thị và chữ đầu dòng. Sau mỗi đầu dòng nhập hai dấu cách và Enter/Return. Gạch đầu dòng phụ được tạo tương tự nhưng được thụt vào. Các số cũng hoạt động tương tự nhưng thay vì dấu hoa thị, viết 1), 2), v.v. Dưới đây là cách văn bản R Markdown script của bạn trông như thế nào.","code":"Đây là gạch đầu dòng của tôi (có hai dấu cách sau dấu hai chấm này):  \n\n* Gạch đầu dòng 1 (theo sau là 2 dấu cách và Enter/Return)  \n* Gạch đầu dòng 2 (theo sau là 2 dấu cách và Enter/Return)  \n  * Gạch đầu dòng phụ 1 (theo sau là 2 dấu cách và Enter/Return)  \n  * Gạch đầu dòng phụ 2 (theo sau là 2 dấu cách và Enter/Return)  \n  "},{"path":"rmarkdown.html","id":"chữ-chú-giải","chapter":"40 Báo cáo với R Markdown","heading":"Chữ chú giải","text":"Bạn có thể “chú giải” văn bản R Markdown giống như bạn sử dụng “#” để chú giải một dòng code R trong một đoạn code R. Chỉ cần đánh dấu văn bản và nhấn Ctrl+Shift+c (Cmd+Shift+c cho Mac). Văn bản sẽ được bao quanh bởi các mũi tên và chuyển sang màu xanh lục. Nó sẽ không xuất hiện trong kết quả đầu ra của bạn.","code":""},{"path":"rmarkdown.html","id":"đoạn-code","chapter":"40 Báo cáo với R Markdown","heading":"Đoạn Code","text":"Các phần của script dành riêng để chạy code R được gọi là “chunk - đoạn”. Đây là nơi bạn có thể tải các package, nhập dữ liệu và thực hiện quản lý và trực quan hóa dữ liệu thực tế. Có thể có nhiều đoạn code, vì vậy chúng có thể giúp bạn tổ chức code R của mình thành các phần, có thể xen kẽ với văn bản. Cần lưu ý:\nNhững ‘đoạn’ này sẽ có màu nền hơi khác với phần diễn giải của tài liệu.Mỗi đoạn code được mở với một dòng bắt đầu với 3 dấu nháy đơn ngược, và ngoặc nhọn chứa các tham số cho đoạn ({ }). Đoạn code kết thúc với 3 dấu nháy đơn ngược.Bạn có thể tạo một đoạn code mới bằng cách tự gõ nó ra, hoặc bằng cách sử dụng phím tắt “Ctrl + Alt + ” (hoặc Cmd + Shift + r trong Mac), hoặc bằng cách nhấp vào biểu tượng ‘insert new code chunk’ màu xanh lục ở đầu trình chỉnh sửa script của bạn.Một số lưu ý về nội dung bên trong dấu ngoặc nhọn { }:Chúng bắt đầu bằng ‘r’ để chỉ ra rằng tên ngôn ngữ trong đoạn này là RSau chữ r, bạn có thể tùy ý viết “tên” đoạn - việc này không cần thiết nhưng có thể giúp bạn sắp xếp công việc của mình tốt hơn. Lưu ý rằng nếu bạn đặt tên cho các phần của mình, bạn phải LUÔN sử dụng các tên độc nhất, nếu không R sẽ báo lỗi khi bạn cố gắng kết xuất.Dấu ngoặc nhọn cũng có thể bao gồm các tùy chọn khác, được viết dưới dạng tag = value, chẳng hạn như:eval = FALSE để không chạy code Recho = FALSE để không hiển thị mã nguồn code R của đoạn trong kết quả đầu rawarning = FALSE để không hiển thị cảnh báo được tạo bởi code Rmessage = FALSE để không hiển thị bất kỳ thông báo nào được tạo bởi code Rinclude = TRUE/FALSE có bao gồm đầu ra đoạn code (ví dụ: các đồ thị) trong tài liệu hay khôngout.width = và .height = - cung cấp theo kiểu .width = \"75%\"fig.align = \"center\" điều chỉnh cách một hình được căn trên trangfig.show='hold' nếu đoạn code của bạn hiển thị nhiều biểu đồ và bạn muốn chúng hiển thị cạnh nhau (cùng với .width = c(\"33%\", \"67%\"). Có thể đặt là fig.show='asis' để hiển thị chúng dưới code tạo chúng, 'hide' để ẩn, hoặc 'animate' để nối nhiều cái thành một ảnh động.Tiêu đề đoạn phải được viết trên một dòngCố gắng tránh dấu chấm, dấu gạch dưới và dấu cách. Sử dụng dấu gạch ngang ( - ) thay thế nếu bạn cần dấu ngăn cách.Đọc kĩ hơn về các tùy chọn knitr tại đây.Một số tùy chọn ở trên có thể được định cấu hình với trỏ và nhấp bằng cách sử dụng các nút cài đặt ở trên cùng bên phải của đoạn. Tại đây, bạn có thể chỉ định những phần nào của đoạn mà bạn muốn tài liệu được kết xuất bao gồm cụ thể là code, kết quả đầu ra và cảnh báo. Điều này sẽ xuất hiện dưới dạng tùy chọn được viết trong dấu ngoặc nhọn, ví dụ echo = FALSE nếu bạn muốn ‘Chỉ hiển thị đầu ra’.Ngoài ra còn có hai mũi tên ở trên cùng bên phải của mỗi đoạn code. Chúng rất hữu ích để chạy code trong một đoạn hoặc tất cả code trong các đoạn trước. Di chuột lên chúng để xem chúng làm gì.Để các tùy chọn toàn cục được áp dụng cho tất cả các đoạn trong tập lệnh, bạn có thể thiết lập điều này trong đoạn code R đầu tiên của mình trong tập lệnh. Ví dụ, để chỉ các kết quả đầu ra được hiển thị cho mỗi đoạn code chứ không phải bản thân code, bạn có thể đưa lệnh này vào đoạn code R:","code":"\nknitr::opts_chunk$set(echo = FALSE) "},{"path":"rmarkdown.html","id":"code-r-trong-văn-bản","chapter":"40 Báo cáo với R Markdown","heading":"Code R trong văn bản","text":"Bạn cũng có thể bao gồm code R đơn giản trong dấu nháy đơn ngược. Trong dấu nháy đơn ngược, hãy bắt đầu mã bằng “r” và một dấu cách, để RStudio biết đánh giá code đó là code R. Xem ví dụ bên dưới.Ví dụ bên dưới hiển thị nhiều cấp tiêu đề, dấu đầu dòng và sử dụng code R cho ngày hiện tại (Sys.Date ()) để chuyển thành ngày .Phía trên là một ví dụ đơn giản (hiển thị ngày hiện tại), nhưng sử dụng cùng một cú pháp, bạn có thể hiển thị các giá trị được tạo bởi code R phức tạp hơn (ví dụ: để tính toán giá trị nhỏ nhất, trung bình, giá trị lớn nhất của một cột). Bạn cũng có thể tích hợp các đối tượng hoặc giá trị R đã được tạo trong các đoạn code R trước đó trong script.Ví dụ, script dưới đây tính toán tỷ lệ các trường hợp dưới 18 tuổi, sử dụng các hàm tidyverse và tạo các đối tượng less18,total và less18prop. Giá trị động này được chèn vào văn bản tiếp theo. Chúng ta thấy nó trông như thế nào khi được knit vào một tài liệu word.","code":""},{"path":"rmarkdown.html","id":"ảnh","chapter":"40 Báo cáo với R Markdown","heading":"Ảnh","text":"Bạn có thể đưa hình ảnh vào R Markdown của mình theo một trong hai cách:Nếu cách trên không được, thử dùng knitr::include_graphics()(hãy nhớ rằng, đường dẫn tệp của bạn có thể được viết bằng cách sử dụng package )","code":"![](\"path/to/image.png\")  \nknitr::include_graphics(\"path/to/image.png\")\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))"},{"path":"rmarkdown.html","id":"bảng","chapter":"40 Báo cáo với R Markdown","heading":"Bảng","text":"Tạo bảng bằng dấu gạch ngang ( - ) và dấu thanh ( | ). Số lượng dấu gạch nối trước/giữa các thanh cho phép số lượng khoảng trắng trong ô trước khi văn bản bắt đầu được bao lại.Code trên tạo ra bảng ở dưới:","code":"Cột 1    |Cột  2    |Cột 3\n---------|----------|--------\nÔ A      |Ô B       |Ô C\nÔ D      |Ô E       |Ô F"},{"path":"rmarkdown.html","id":"các-phần-được-chia-thẻ","chapter":"40 Báo cáo với R Markdown","heading":"Các phần được chia thẻ","text":"Đối với đầu ra là tệp HTML, bạn có thể sắp xếp các phần thành các “tab - thẻ”. Chỉ cần thêm .tabset vào trong dấu ngoặc nhọn{}được đặt sau đề mục. Bất kỳ đề mục phụ nào bên dưới tiêu đề đó (cho đến khi tiêu đề khác cùng cấp) sẽ xuất hiện dưới dạng các tab mà người dùng có thể nhấp qua. Đọc thêm tại đâyBạn có thể thêm một tùy chọn bổ sung .tabset-pills sau .tabset để tạo cho các thẻ có giao diện “được tô màu”. Lưu ý rằng khi xem đầu ra HTML theo thẻ, chức năng tìm kiếm Ctrl+f sẽ chỉ tìm kiếm các tab “đang hoạt động” chứ không phải các thẻ ẩn.","code":""},{"path":"rmarkdown.html","id":"cấu-trúc-tệp","chapter":"40 Báo cáo với R Markdown","heading":"40.4 Cấu trúc tệp","text":"Có nhiều cách để tổ chức R Markdown của bạn và bất kỳ script R nào liên quan. Mỗi cách đều có cả ưu điểm và nhược điểm:R Markdown khép kín - mọi thứ cần thiết cho báo cáo đều được nhập hoặc tạo trong R Markdown\nNguồn từ các tệp khác - Bạn có thể chạy các script R bên ngoài bằng lệnh source () và sử dụng đầu ra của chúng trong Rmd\nScipt con - một cơ chế thay thế cho source()\nNguồn từ các tệp khác - Bạn có thể chạy các script R bên ngoài bằng lệnh source () và sử dụng đầu ra của chúng trong RmdScipt con - một cơ chế thay thế cho source()Sử dụng “runfile” - Chạy các lệnh trong script R trước khi kết xuất tệp R Markdown","code":""},{"path":"rmarkdown.html","id":"rmd-khép-kín","chapter":"40 Báo cáo với R Markdown","heading":"Rmd khép kín","text":"Đối với một báo cáo tương đối đơn giản, bạn có thể chọn tổ chức tập lệnh R Markdown của mình sao cho nó “khép kín” và không liên quan đến bất kỳ tập lệnh bên ngoài nào.Mọi thứ bạn cần để chạy R markdown đều được nhập hoặc tạo trong tệp Rmd, bao gồm tất cả các đoạn code và package. Cách tiếp cận “khép kín” này phù hợp khi bạn không cần xử lý nhiều dữ liệu (ví dụ: nó mang đến một tệp dữ liệu sạch hoặc gần sạch) và việc kết xuất R Markdown sẽ không mất quá nhiều thời gian.Trong trường hợp này, một cấu trúc hợp lý của script R Markdown có thể là:Thiết lập các tùy chọn knitr chungTải packagesNhập dữ liệuXử lý dữ liệuTạo kết quả đầu ra (bảng, đồ thị, etc.)Lưu kết quả đầu ra nếu cần (.csv, .png, v.v.)","code":""},{"path":"rmarkdown.html","id":"nguồn-từ-các-tệp-khác","chapter":"40 Báo cáo với R Markdown","heading":"Nguồn từ các tệp khác","text":"Một biến thể của cách tiếp cận “khép kín” là có các đoạn code R Markdown “nguồn” (chạy) chạy các script R khác. Điều này có thể làm cho tập lệnh R Markdown của bạn ít lộn xộn hơn, đơn giản hơn và dễ tổ chức hơn. Nó cũng có thể hữu ích nếu bạn muốn hiển thị số liệu cuối cùng ở đầu báo cáo. Theo cách tiếp cận này, script R Markdown cuối cùng chỉ đơn giản là kết hợp các đầu ra được xử lý trước thành một tài liệu.Một cách để làm điều này là cung cấp script R (đường dẫn tệp và tên có phần mở rộng) cho lệnh R base source().Lưu ý rằng khi sử dụng source () trong R Markdown, các tệp bên ngoài sẽ vẫn được chạy trong quá trình kết xuất tệp Rmd của bạn. đó, mỗi tập lệnh được chạy mỗi lần bạn kết xuất báo cáo. đó, việc có các lệnh source () này trong R Markdown không tăng tốc thời gian chạy của bạn, cũng như không hỗ trợ nhiều cho việc gỡ lỗi, vì lỗi vẫn được hiển thị khi tạo R Markdown.Một giải pháp thay thế là sử dụng tùy chọn child = của knitr. GIẢI THÍCH THÊM ĐỂ LÀMBạn phải để ý các môi trường R khác nhau. Các đối tượng được tạo trong một môi trường sẽ không nhất thiết phải có sẵn cho môi trường được R Markdown sử dụng.","code":"\nsource(\"your-script.R\", local = knitr::knit_global())\n# or sys.source(\"your-script.R\", envir = knitr::knit_global())"},{"path":"rmarkdown.html","id":"runfile","chapter":"40 Báo cáo với R Markdown","heading":"Runfile","text":"Cách tiếp cận này liên quan đến việc sử dụng R script có chứa (các) lệnh render () để xử lý trước các đối tượng đưa vào R markdown.Ví dụ, bạn có thể tải các package, tải và làm sạch dữ liệu, và thậm chí tạo các biểu đồ trước khi render(). Các bước này có thể xảy ra trong R script hoặc trong các script khác được lưu nguồn. Miễn là các lệnh này diễn ra trong cùng một phiên RStudio và các đối tượng được lưu vào môi trường, các đối tượng sau đó có thể được gọi trong nội dung Rmd. Sau đó, bản thân R markdown sẽ chỉ được sử dụng cho bước cuối cùng - để tạo ra kết quả với tất cả các đối tượng được xử lý trước. Điều này dễ dàng hơn để gỡ lỗi nếu có sự cố.Cách tiếp cận này hữu ích vì những lý sau:Thông báo lỗi mang nhiều thông tin hơn - những thông báo này sẽ được tạo từ R script, không phải R Markdown. Lỗi R Markdown có xu hướng cho bạn biết đoạn nào có vấn đề, nhưng sẽ không cho bạn biết dòng nào.Thông báo lỗi mang nhiều thông tin hơn - những thông báo này sẽ được tạo từ R script, không phải R Markdown. Lỗi R Markdown có xu hướng cho bạn biết đoạn nào có vấn đề, nhưng sẽ không cho bạn biết dòng nào.Nếu có thể, bạn có thể chạy các bước xử lý dài trước lệnh render () - chúng sẽ chỉ chạy một lần.Nếu có thể, bạn có thể chạy các bước xử lý dài trước lệnh render () - chúng sẽ chỉ chạy một lần.Trong ví dụ bên dưới, chúng ta có một R script riêng biệt, trong đó chúng tôi xử lý trước một đối tượng data vào Môi trường R và sau đó kết xuất “create_output.Rmd” bằng cách sử dụng render().","code":"\ndata <- import(\"datafile.csv\") %>%       # Load data and save to environment\n  select(age, hospital, weight)          # Select limited columns\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Create Rmd file"},{"path":"rmarkdown.html","id":"cấu-trúc-thư-mục","chapter":"40 Báo cáo với R Markdown","heading":"Cấu trúc thư mục","text":"Quy trình làm việc cũng liên quan đến cấu trúc thư mục tổng thể, chẳng hạn như có thư mục ‘đầu ra’ cho các tài liệu và số liệu đã tạo và thư mục ‘dữ liệu’ hoặc ‘đầu vào’ cho dữ liệu đã được làm sạch. Chúng tôi không đi sâu vào chi tiết ở đây, nhưng hãy xem chương Tổ chức báo cáo định kỳ.","code":""},{"path":"rmarkdown.html","id":"tạo-tài-liệu","chapter":"40 Báo cáo với R Markdown","heading":"40.5 Tạo tài liệu","text":"Bạn có thể tạo tài liệu theo những cách sau:Thủ công bằng cách nhấn nút “Knit” ở đầu trình chỉnh sửa script RStudio (nhanh chóng và dễ dàng)Chạy lệnh render() (được thực thi bên ngoài R Markdown script)","code":""},{"path":"rmarkdown.html","id":"cách-1-nút-knit","chapter":"40 Báo cáo với R Markdown","heading":"Cách 1: Nút “Knit”","text":"Khi bạn mở tệp Rmd, hãy nhấn vào biểu tượng/nút ‘Knit’ ở đầu tệp.R Studio sẽ cho bạn thấy tiến trình trong tab ‘R Markdown’ gần R console của bạn. Tài liệu sẽ tự động mở khi hoàn tất.Tài liệu sẽ được lưu trong cùng một thư mục với R markdown script của bạn và có cùng tên tệp (ngoại trừ phần mở rộng). Điều này rõ ràng không phải là lý tưởng cho việc kiểm soát phiên bản (nó sẽ bị ghi đè lên mỗi lần bạn knit, trừ khi được di chuyển theo cách thủ công), như sau đó bạn có thể cần phải tự đổi tên tệp (ví dụ: thêm ngày).Đây là nút tắt của RStudio cho hàm render () từ rmarkdown. Cách tiếp cận này chỉ tương thích với R markdown khép kín, nơi tất cả các thành phần cần thiết tồn tại hoặc có nguồn trong tệp.","code":""},{"path":"rmarkdown.html","id":"cách-2-lệnh-render","chapter":"40 Báo cáo với R Markdown","heading":"Cách 2: Lệnh render()","text":"Một cách khác để tạo đầu ra R Markdown của bạn là chạy hàm render () (từ package rmarkdown). Bạn phải thực hiện lệnh này bên ngoài R Markdown script - vì vậy hoặc trong một tập lệnh R riêng biệt (thường được gọi là “run file”) hoặc dưới dạng lệnh độc lập trong R Console.Như với “knit”, cài đặt mặc định sẽ lưu đầu ra Rmd vào cùng thư mục với Rmd script, với cùng tên tệp (ngoài phần mở rộng tệp). Ví dụ: “my_report.Rmd” khi được knit sẽ tạo ra “my_report.docx” nếu bạn đang knit vào một tài liệu word. Tuy nhiên, bằng cách sử dụng render (), bạn có tùy chọn sử dụng các cài đặt khác nhau. render () có thể chấp nhận các đối số bao gồm:output_format = Đây là định dạng đầu ra để chuyển đổi (e.g. \"html_document\", \"pdf_document\", \"word_document\", hoặc \"\"). Bạn cũng có thể chỉ định điều này trong YAML bên trong R Markdown script.output_file = Đây là tên của tệp đầu ra (và đường dẫn tệp). Điều này có thể được tạo thông qua các hàm R như () hoặc str_glue() như minh họa bên dưới.output_dir = Đây là thư mục đầu ra (thư mục) để lưu tệp. Điều này cho phép bạn chọn một thư mục khác với thư mục mà tệp Rmd được lưu vào.output_options = Bạn có thể cung cấp một danh sách các tùy chọn sẽ ghi đè các tùy chọn đó trong script YAML (ví dụ, )output_yaml = Bạn có thể cung cấp đường dẫn đến tệp .yml chứa thông số kỹ thuật YAMLparams = Xem phần thông số bên dướiXem danh sách đầy đủ tại đâyVí dụ, để cải thiện kiểm soát phiên bản, lệnh sau sẽ lưu tệp đầu ra trong thư mục con ‘đầu ra’, với ngày hiện tại trong tên tệp. Để tạo tên tệp, hàm str_glue () từ package stringr được sử dụng để ‘dán’ các chuỗi tĩnh lại với nhau (được viết đơn giản) với code R động (được viết trong dấu ngoặc nhọn). Ví dụ: nếu đó là ngày 10 tháng 4 năm 2021, tên tệp từ bên dưới sẽ là “Report_2021-04-10.docx”. Xem chương Ký tự và chuỗi để biết thêm chi tiết về str_glue ().Khi file đang kết xuất, RStudio Console sẽ cho bạn thấy quá trình kết xuất tới 100%, và một thông báo cuối để báo rằng quá trình kết xuất đã hoàn thành.","code":"\nrmarkdown::render(input = \"my_report.Rmd\")\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) "},{"path":"rmarkdown.html","id":"cách-3-reportfactory-package","chapter":"40 Báo cáo với R Markdown","heading":"Cách 3: reportfactory package","text":"R package reportfactory cung cấp một phương pháp thay thế để tổ chức và soạn báo cáo R Markdown phù hợp với các tình huống mà bạn chạy báo cáo thường xuyên (ví dụ hàng ngày, hàng tuần …). Nó giúp giảm bớt việc soạn nhiều tệp R Markdown và tổ chức đầu ra của chúng. Về bản chất, nó cung cấp một “nhà máy” mà từ đó bạn có thể chạy báo cáo R Markdown, nhận các thư mục được đánh dấu ngày tháng và thời gian tự động cho kết quả đầu ra và có cách kiểm soát phiên bản “nhẹ nhàng”.Đọc thêm về quy trình công việc này trong chương về Tổ chức báo cáo định kỳ.","code":""},{"path":"rmarkdown.html","id":"báo-cáo-được-tham-số-hóa","chapter":"40 Báo cáo với R Markdown","heading":"40.6 Báo cáo được tham số hóa","text":"Bạn có thể sử dụng tham số hóa để tạo báo cáo động, sao cho báo cáo có thể được chạy với cài đặt cụ thể (ví dụ: ngày hoặc địa điểm cụ thể hoặc với các tùy chọn knit nhất định). Dưới đây, chúng tôi tập trung vào những điều cơ bản, nhưng có thêm các tài liệu chi tiết trực tuyến về các báo cáo được tham số hóa.Sử dụng bộ dữ liệu Ebola có tên linelist làm ví dụ, giả sử chúng ta muốn chạy một báo cáo giám sát tiêu chuẩn cho từng bệnh viện mỗi ngày. Chúng ta chỉ ra cách người ta có thể làm điều này bằng cách sử dụng các tham số.Quan trọng: các báo cáo động cũng có thể thực hiện được mà không có cấu trúc tham số chính thức (không có params:), bằng cách sử dụng các đối tượng R đơn giản trong R script liền kề. Điều này được giải thích ở cuối phần này.","code":""},{"path":"rmarkdown.html","id":"cài-đặt-tham-số","chapter":"40 Báo cáo với R Markdown","heading":"Cài đặt tham số","text":"Bạn có nhiều cách để chỉ định giá trị tham số cho đầu ra R Markdown của mình.","code":""},{"path":"rmarkdown.html","id":"cách-1-đặt-tham-số-trong-yaml","chapter":"40 Báo cáo với R Markdown","heading":"Cách 1: Đặt tham số trong YAML","text":"Chỉnh sửa YAML để bao gồm tùy chọn params:, với các biểu thức được thụt lề cho mỗi tham số bạn muốn xác định. Trong ví dụ này, chúng tôi tạo các tham số date vàhospital, với các giá trị mà chúng tôi chỉ định. Các giá trị này có thể thay đổi mỗi khi chạy báo cáo. Nếu bạn sử dụng nút “Knit” để tạo ra đầu ra, các tham số sẽ có các giá trị mặc định này. Tương tự như vậy, nếu bạn sử dụng render (), các tham số sẽ có các giá trị mặc định này trừ khi được chỉ định khác trong lệnh render ().Ở chế độ nền, các giá trị tham số này được chứa trong danh sách chỉ đọc được gọi là params. đó, bạn có thể chèn các giá trị tham số trong code R như cách bạn làm với một đối tượng/giá trị R khác trong môi trường của bạn. Chỉ cần gõ params $ theo sau là tên tham số. Ví dụ: params $ Hospital để đại diện cho tên bệnh viện (“Central Hospital” theo mặc định).Lưu ý rằng các tham số cũng có thể giữ các giá trị true hoặc false, và vì vậy chúng có thể được đưa vào các tùy chọn knitr của bạn trong một đoạn code R. Ví dụ: bạn có thể đặt {r, eval=params$run} thay vì {r, eval=FALSE}, và bây giờ việc đoạn code chạy hay không phụ thuộc vào giá trị của tham số run:.Lưu ý rằng đối với các tham số là ngày tháng, chúng sẽ được nhập dưới dạng một chuỗi. Vì vậy, để params$date được diễn giải trong code R, nó có thể sẽ cần được bao bọc bằng .Date() hoặc một hàm tương tự để chuyển đổi thành lớp Date.","code":"---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Central Hospital\n---"},{"path":"rmarkdown.html","id":"cách-2-đặt-tham-số-trong-render","chapter":"40 Báo cáo với R Markdown","heading":"Cách 2: Đặt tham số trong render()","text":"Như đã đề cập ở trên, thay thế cho việc nhấn nút “Knit” để tạo đầu ra là thực thi hàm render() từ một script riêng biệt. Trong trường hợp sau này, bạn có thể chỉ định các tham số được sử dụng trong việc hiển thị đó cho đối số params = của render ().Lưu ý rằng bất kỳ giá trị tham số nào được cung cấp ở đây sẽ ghi đè các giá trị mặc định của chúng nếu được viết trong YAML. Chúng tôi viết các giá trị trong dấu ngoặc kép vì trong trường hợp này chúng phải được định nghĩa là giá trị ký tự/chuỗi.Lệnh dưới đây kết xuất tệp “surveillance_report.Rmd”, chỉ định tên và thư mục tệp đầu ra động, đồng thời cung cấp một list() gồm hai tham số và giá trị của chúng cho đối số params =.","code":"\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))"},{"path":"rmarkdown.html","id":"cách-3-đặt-tham-số-sử-giao-diện-người-dùng-gui","chapter":"40 Báo cáo với R Markdown","heading":"Cách 3: Đặt tham số sử Giao diện Người dùng (GUI)","text":"Để có cảm giác tương tác hơn, bạn cũng có thể sử dụng Giao diện Người dùng (Graphical User Interface - GUI) để chọn thủ công các giá trị cho các tham số. Để thực hiện việc này, chúng ta có thể nhấp vào menu thả xuống bên cạnh nút ‘Knit’ và chọn ‘Knit parameter’.Một cửa sổ bật lên sẽ xuất hiện cho phép bạn nhập các giá trị cho các tham số được thiết lập trong YAML của tài liệu.Bạn có thể đạt được điều tương tự thông qua lệnh render() bằng cách chỉ định params = \"ask\", như được minh họa bên dưới.Tuy nhiên, việc nhập giá trị vào cửa sổ bật lên này có thể xảy ra lỗi và lỗi chính tả. Bạn có thể chọn thêm các hạn chế cho các giá trị có thể được nhập thông qua menu thả xuống. Bạn có thể làm điều này bằng cách thêm vào YAML một số thông số kỹ thuật cho mỗi mục nhập params:.label: là cách tiêu đề cho menu thả xuống cụ thể đóvalue: là giá trị mặc định (bắt đầu)input: đặt thành select cho menu thả xuốngchoices: cung cấp các giá trị đủ điều kiện trong menu thả xuốngDưới đây, các thông số kỹ thuật này được viết cho tham số hospital.Khi knit (thông qua nút ‘knit parameters’ hoặc bằng cách render()), cửa sổ bật lên sẽ có các tùy chọn thả xuống để bạn lựa chọn.","code":"rmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = “ask”)---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: “Town:”\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---"},{"path":"rmarkdown.html","id":"ví-dụ-tham-số-hóa","chapter":"40 Báo cáo với R Markdown","heading":"Ví dụ tham số hóa","text":"Đoạn mã sau đây tạo các tham số cho date và hospital, được sử dụng trong R Markdown tương ứng là params$date và params$hospital.Trong kết quả đầu ra của báo cáo, hãy xem cách dữ liệu được lọc cho bệnh viện cụ thể và tiêu đề biểu đồ đề cập đến bệnh viện và ngày chính xác. Chúng tôi sử dụng tệp “linelist_cleaned.rds” ở đây, nhưng nó sẽ đặc biệt thích hợp nếu bản thân tệp linelist cũng có một dấu ngày tháng bên trong nó để căn chỉnh với ngày được tham số hóa.Knit sẽ tạo ra kết quả cuối cùng với phông chữ và bố cục mặc định.","code":""},{"path":"rmarkdown.html","id":"tham-số-hóa-không-có-params","chapter":"40 Báo cáo với R Markdown","heading":"Tham số hóa không có params","text":"Nếu bạn đang kết xuất tệp R Markdown với render () từ một script riêng biệt, bạn thực sự có thể tạo ra tác động của tham số hóa mà không cần sử dụng chức năng params:.Ví dụ, trong R script có chứa lệnh render (), bạn có thể chỉ cần xác định hospital và date là hai đối tượng R (giá trị) trước lệnh render (). Trong R Markdown, bạn sẽ không cần phải có phần params: trong YAML, và chúng tôi sẽ đề cập đến đối tượng date hơn là params$date và hospital hơn là params$hospital.Làm theo cách này có nghĩa là bạn không thể “knit với các tham số”, sử dụng GUI hoặc bao gồm các tùy chọn knit trong các tham số. Tuy nhiên, điều này có thể có ích vì nó cho phép code đơn giản hơn.","code":"\n# This is a R script that is separate from the R Markdown\n\n# define R objects\nhospital <- \"Central Hospital\"\ndate <- \"2021-04-10\"\n\n# Render the R markdown\nrmarkdown::render(input = \"create_output.Rmd\") "},{"path":"rmarkdown.html","id":"tạo-vòng-lặp-nhiều-báo-cáo","chapter":"40 Báo cáo với R Markdown","heading":"40.7 Tạo vòng lặp nhiều báo cáo","text":"Chúng ta có thể muốn chạy một báo cáo nhiều lần, thay đổi các thông số đầu vào, để tạo ra một báo cáo cho từng khu vực pháp lý/đơn vị. Điều này có thể được thực hiện bằng cách sử dụng các công cụ cho việc lặp lại, được giải thích chi tiết trong chương về [Lặp, vòng lặp và danh sách]. Các tùy chọn bao gồm package purrr hoặc sử dụng vòng lặp như được giải thích bên dưới.Dưới đây, chúng tôi sử dụng vòng lặp đơn giản để tạo báo cáo giám sát cho tất cả các bệnh viện được chọn. Điều này được thực hiện bằng một lệnh (thay vì thay đổi từng thông số bệnh viện theo cách thủ công). Lệnh kết xuất báo cáo phải tồn tại trong một script riêng biệt bên ngoài báo cáo Rmd. Script này cũng sẽ chứa các đối tượng được xác định để “lặp qua” - ngày hôm nay và một vectơ tên bệnh viện để lặp qua.Sau đó, chúng tôi cung cấp từng giá trị này vào lệnh render() bằng cách sử dụng một vòng lặp, lệnh này chạy lệnh một lần cho mỗi giá trị trong vectơ hospitals. Chữ cái đại diện cho vị trí chỉ mục (từ 1 đến 4) của bệnh viện hiện đang được sử dụng trong lần lặp đó, như vậy hospital_list[1] sẽ là “Central Hospital”. Thông tin này được cung cấp ở hai nơi trong lệnh render():Đối với tên tệp, sao cho tên tệp của lần lặp đầu tiên nếu được tạo vào ngày 10 tháng 4 năm 2021 sẽ là “Report_Central Hospital_2021-04-10.docx”, được lưu trong thư mục con ‘output’ của thư mục làm việc.Với params = sao cho Rmd sử dụng tên bệnh viện trong nội bộ bất cứ khi nào giá trị params$hospital được gọi (ví dụ: chỉ để lọc tập dữ liệu cho bệnh viện cụ thể). Trong ví dụ này, bốn tệp sẽ được tạo - mỗi tệp cho một bệnh viện.","code":"\nhospitals <- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}       "},{"path":"rmarkdown.html","id":"mẫu","chapter":"40 Báo cáo với R Markdown","heading":"40.8 Mẫu","text":"Bằng cách sử dụng tài liệu mẫu có chứa bất kỳ định dạng mong muốn nào, bạn có thể điều chỉnh tính thẩm mỹ của đầu ra Rmd sẽ trông như thế nào. Ví dụ, bạn có thể tạo tệp MS Word hoặc Powerpoint chứa các trang/trang trình bày với kích thước, hình đóng dấu, hình nền và phông chữ mong muốn.","code":""},{"path":"rmarkdown.html","id":"tài-liệu-word","chapter":"40 Báo cáo với R Markdown","heading":"Tài liệu Word","text":"Để tạo một mẫu, hãy bắt đầu một tài liệu word mới (hoặc sử dụng đầu ra hiện có với định dạng phù hợp với bạn) và chỉnh sửa phông chữ bằng cách xác định Kiểu. Trong Kiểu, Đầu mục 1, 2 và 3 đề cập đến các cấp đề mục markdown khác nhau (tương ứng #Đề mục 1, ##Đề mục 2 và ### Đề mục 3). Nhấp chuột phải vào kiểu và nhấp vào ‘sửa đổi’ để thay đổi định dạng phông chữ cũng như đoạn văn (ví dụ: bạn có thể giới thiệu các ngắt trang trước các kiểu nhất định có thể giúp giãn cách). Các khía cạnh khác của tài liệu word như lề, kích thước trang, đề mục, v.v., có thể được thay đổi giống như một tài liệu word thông thường mà bạn đang làm việc trực tiếp bên trong.","code":""},{"path":"rmarkdown.html","id":"tài-liệu-powerpoint","chapter":"40 Báo cáo với R Markdown","heading":"Tài liệu Powerpoint","text":"Như trên, hãy tạo một slide mới hoặc sử dụng một file powerpoint hiện có với định dạng mong muốn. Để chỉnh sửa thêm, hãy nhấp vào ‘View’ và ‘Slide Master’. Từ đây, bạn có thể thay đổi giao diện trang chiếu ‘master’ bằng cách chỉnh sửa định dạng văn bản trong các hộp văn bản, cũng như kích thước nền/trang cho trang tổng thể.Thật không may, việc chỉnh sửa tệp powerpoint hơi kém linh hoạt:Đề mục cấp đầu tiên (# Đề mục 1) sẽ tự động trở thành tiêu đề của trang trình bày mới,Chữ ## Đề mục 2 sẽ không xuất hiện dưới dạng phụ đề mà là chữ trong hộp văn bản chính của trang chiếu (trừ khi bạn tìm được cách để làm rộng chế độ xem Master).Các ô và bảng đã xuất sẽ tự động chuyển sang các trang trình bày mới. Bạn sẽ cần kết hợp chúng, chẳng hạn như hàm patchwork để kết hợp các ggplots, để chúng hiển thị trên cùng một trang. Xem bài đăng trên blog về cách sử dụng package patchwork để đặt nhiều hình ảnh trên một trang chiếu.Xem officer package để biết công cụ làm việc chuyên sâu hơn với các bài thuyết trình powerpoint.","code":""},{"path":"rmarkdown.html","id":"tích-hợp-các-mẫu-vào-yaml","chapter":"40 Báo cáo với R Markdown","heading":"Tích hợp các mẫu vào YAML","text":"Khi một mẫu được chuẩn bị, chi tiết của mẫu này có thể được thêm vào YAML của Rmd bên dưới dòng ‘đầu ra’ và bên dưới nơi loại tài liệu được chỉ định (chính nó sẽ đi đến một dòng riêng). Lưu ý reference_doc có thể được sử dụng cho các mẫu slide powerpoint.Dễ dàng nhất là lưu mẫu trong cùng một thư mục với nơi chứa tệp Rmd (như trong ví dụ bên dưới) hoặc trong một thư mục con bên trong.","code":"---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---"},{"path":"rmarkdown.html","id":"định-dạng-tệp-html","chapter":"40 Báo cáo với R Markdown","heading":"Định dạng tệp HTML","text":"Các tệp HTML không sử dụng các mẫu, nhưng có thể có các kiểu được định cấu hình trong YAML. HTML là tài liệu tương tác và đặc biệt linh hoạt. Chúng tôi đề cập đến một số tùy chọn cơ bản ở đây.Mục lục: Chúng ta có thể thêm mục lục với toc: true bên dưới, và cũng chỉ định rằng nó vẫn có thể xem được (“float”) khi bạn cuộn, vớitoc_float: true.Mục lục: Chúng ta có thể thêm mục lục với toc: true bên dưới, và cũng chỉ định rằng nó vẫn có thể xem được (“float”) khi bạn cuộn, vớitoc_float: true.Chủ đề: Chúng ta có thể tham khảo một số chủ đề được tạo sẵn, lấy từ thư viện chủ đề của Bootswatch. Trong ví dụ dưới đây, chúng tôi sử dụng cerulean. Các tùy chọn khác bao gồm: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, và yeti.Chủ đề: Chúng ta có thể tham khảo một số chủ đề được tạo sẵn, lấy từ thư viện chủ đề của Bootswatch. Trong ví dụ dưới đây, chúng tôi sử dụng cerulean. Các tùy chọn khác bao gồm: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, và yeti.Đánh dấu: Định cấu hình này sẽ thay đổi giao diện của chữ được đánh dấu (ví dụ: code trong các đoạn được hiển thị). Các kiểu được hỗ trợ bao gồm mặc định, tango, pygments, kate, monochrome, espresso, zenburn, hasdock, breezedark và textmate.Đánh dấu: Định cấu hình này sẽ thay đổi giao diện của chữ được đánh dấu (ví dụ: code trong các đoạn được hiển thị). Các kiểu được hỗ trợ bao gồm mặc định, tango, pygments, kate, monochrome, espresso, zenburn, hasdock, breezedark và textmate.Đây là một ví dụ về cách tích hợp các tùy chọn trên vào YAML.Dưới đây là hai ví dụ về kết quả đầu ra HTML, cả hai đều có mục lục nổi, nhưng chủ đề và kiểu đánh dấu khác nhau được chọn:","code":"---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---"},{"path":"rmarkdown.html","id":"nội-dung-động","chapter":"40 Báo cáo với R Markdown","heading":"40.9 Nội dung động","text":"Trong đầu ra HTML, nội dung báo cáo của bạn có thể là động. Dưới đây là một số ví dụ:","code":""},{"path":"rmarkdown.html","id":"bảng-1","chapter":"40 Báo cáo với R Markdown","heading":"Bảng","text":"Trong báo cáo HTML, bạn có thể khung/ô dữ liệu sao cho nội dung là động, với các bộ lọc và thanh cuộn. Có một số packages cung cấp khả năng này.Để thực hiện việc này với package DT, như được sử dụng trong cuốn sổ tay này, bạn có thể chèn một đoạn code như sau:Hàm datatable() sẽ khung dữ liệu đã cung cấp dưới dạng bảng động cho trình đọc. Bạn có thể đặt rownames = FALSE để đơn giản hóa phần ngoài cùng bên trái của bảng. filter = \"top\" cung cấp một bộ lọc trên mỗi cột. Trong đối số option() cung cấp danh sách các thông số kỹ thuật khác. Dưới đây, chúng tôi bao gồm hai đối số: pageLength = 5 đặt số hàng xuất hiện là 5 (các hàng còn lại có thể được xem bằng cách phân trang thông qua các mũi tên) vàscrollX = TRUE bật thanh cuộn ở cuối bảng (đối với cột mở rộng quá xa sang bên phải).Nếu tập dữ liệu của bạn rất lớn, hãy xem xét chỉ hiển thị X hàng trên cùng bằng cách gói khung dữ liệu trong head().","code":""},{"path":"rmarkdown.html","id":"tiện-ích-html","chapter":"40 Báo cáo với R Markdown","heading":"Tiện ích HTML","text":"Tiện ích HTML cho R là một lớp packages R đặc biệt cho phép tăng tính tương tác bằng cách sử dụng các thư viện JavaScript. Bạn có thể nhúng chúng vào các đầu ra HTML R Markdown.Một số ví dụ phổ biến về các tiện ích này bao gồm:Plotly (được sử dụng trong chương sổ tay này và trong chương Biểu đồ tương tác)visNetwork (được sử dụng trong chương Chuỗi lây nhiễm của sổ tay này)Leaflet (được sử dụng trong chương GIS Cơ bản của sổ tay này)dygraphs ( hữu ích để hiển thị dữ liệu chuỗi thời gian tương tác)DT (datatable()) (được sử dụng để hiển thị các bảng động với bộ lọc, sắp xếp, v.v.)Hàm ggplotly() từ plotly đặc biệt dễ sử dụng. Xem chương Biểu đồ tương tác.","code":""},{"path":"rmarkdown.html","id":"tài-nguyên","chapter":"40 Báo cáo với R Markdown","heading":"40.10 Tài nguyên","text":"Tìm thêm thông tin tại:https://bookdown.org/yihui/rmarkdown/https://rmarkdown.rstudio.com/articles_intro.htmlMột giải thích tốt về sánh giữa markdown, knitr và Rmarkdown ở đây: https://stackoverflow.com/questions/40563479/relationship--r-markdown-knitr-pandoc--bookdown","code":""},{"path":"reportfactory.html","id":"reportfactory","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41 Tổ chức báo cáo định kỳ","text":"page covers reportfactory package, accompaniment using R Markdown reports.scenarios run reports routinely (daily, weekly, etc.), eases compilation multiple R Markdown files organization outputs. essence, provides “factory” can run R Markdown reports, get automatically date- time-stamped folders outputs, “light” version control.reportfactory one packages developed RECON (R Epidemics Consortium). website Github.","code":""},{"path":"reportfactory.html","id":"preparation-24","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41.1 Preparation","text":"","code":""},{"path":"reportfactory.html","id":"load-packages-23","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Load packages","text":"within RStudio, install latest version reportfactory package Github.can via pacman package p_load_current_gh() force intall latest version Github. Provide character string “reconverse/reportfactory”, specifies Github organization (reconverse) repository (reportfactory). can also use install_github() remotes package, alternative.","code":"\n# Install and load the latest version of the package from Github\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # alternative"},{"path":"reportfactory.html","id":"new-factory","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41.2 New factory","text":"create new factory, run function new_factory(). create new self-contained R project folder. default:factory added working directoryThe name factory R project called “new_factory.Rproj”RStudio session “move ” R projectLooking inside factory, can see sub-folders files created automatically.report_sources folder hold R Markdown scripts, generate reportsThe outputs folder hold report outputs (e.g. HTML, Word, PDF, etc.)scripts folder can used store R scripts (e.g. sourced Rmd scripts)data folder can used hold data (“raw” “clean” subfolders included).file, can use package call files sub-folders relation root folder (see [R projects] page details)gitignore file created case link R project Github repository (see [Version control collaboration Github])empty README file, use Github repositoryCAUTION: depending computer’s setting, files “.” may exist invisible.default settings, several might want adjust within new_factory() command:factory = - Provide name factory folder (default “new_factory”)path = - Designate file path new factory (default working directory)report_sources = Provide alternate name subfolder holds R Markdown scripts (default “report_sources”)outputs = Provide alternate name folder holds report outputs (default “outputs”)See ?new_factory complete list arguments.create new factory, R session transferred new R project, load reportfactory package.Now can run factory_overview() command see internal structure (folders files) factory.following “tree” factory’s folders files printed R console. Note “data” folder sub-folders “raw” “clean” data, example CSV data. also “example_report.Rmd” “report_sources” folder.","code":"\n# This will create the factory in the working directory\nnew_factory()\npacman::p_load(reportfactory)\nfactory_overview()            # print overview of the factory to console"},{"path":"reportfactory.html","id":"create-a-report","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41.3 Create a report","text":"within factory R project, create R Markdown report just normally, save “report_sources” folder. See [R Markdown][Reports R Markdown] page instructions. purposes example, added following factory:new R markdown script entitled “daily_sitrep.Rmd”, saved within “report_sources” folderData report (“linelist_cleaned.rds”), saved “clean” sub-folder within “data” folderWe can see using factory_overview() R Markdown “report_sources” folder data file “clean” data folder (highlighted):screenshot beginning R Markdown “daily_sitrep.Rmd”. can see output format set HTML, via YAML header output: html_document.simple script, commands :Load necessary packagesImport linelist data using filepath package (read page [Import export])Print summary table cases, export export() .csv filePrint epicurve, export ggsave() .png fileYou can review just list R Markdown reports “report_sources” folder command:","code":"\nlinelist <- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\nlist_reports()"},{"path":"reportfactory.html","id":"compile","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41.4 Compile","text":"report factory, “compile” R Markdown report means .Rmd script run output produced (specified script YAML e.g. HTML, Word, PDF, etc).factory automatically create date- time-stamped folder outputs “outputs” folder.report exported files produced script (e.g. csv, png, xlsx) saved folder. addition, Rmd script saved folder, record version script.contrasts normal behavior “knitted” R Markdown, saves outputs location Rmd script. default behavior can result crowded, messy folders. factory aims improve organization one needs run reports frequently.","code":""},{"path":"reportfactory.html","id":"compile-by-name","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Compile by name","text":"can compile specific report running compile_reports() providing Rmd script name (without .Rmd extension) reports =. simplicity, can skip reports = just write R Markdown name quotes, .command compile “daily_sitrep.Rmd” report, saving HTML report, .csv table .png epicurve exports date- time-stamped sub-folder specific report, within “outputs” folder.Note choose provide .Rmd extension, must correctly type extension saved file name (.rmd vs. .Rmd).Also note compile, may see several files temporarily appear “report_sources” folder - soon disappear transferred correct “outputs” folder.","code":""},{"path":"reportfactory.html","id":"compile-by-number","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Compile by number","text":"can also specify Rmd script compile providing number vector numbers reports =. numbers must align order reports appear run list_reports().","code":"\n# Compile the second and fourth Rmds in the \"report_sources\" folder\ncompile_reports(reports = c(2, 4))"},{"path":"reportfactory.html","id":"compile-all","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Compile all","text":"can compile R Markdown reports “report_sources” folder setting reports = argument TRUE.","code":""},{"path":"reportfactory.html","id":"compile-from-sub-folder","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Compile from sub-folder","text":"can add sub-folders “report_sources” folder. run R Markdown report subfolder, simply provide name folder subfolder =. example code compile Rmd report lives sub_folder “report_sources”.can compile Rmd reports within subfolder providing subfolder name reports =, slash end, .","code":"\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\ncompile_reports(reports = \"for_partners/\")"},{"path":"reportfactory.html","id":"parameterization","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Parameterization","text":"noted page [Reports R Markdown], can run reports specified parameters. can pass parameters list compile_reports() via params = argument. example, fictional report three parameters provided R Markdown reports.","code":"\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)"},{"path":"reportfactory.html","id":"using-a-run-file","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Using a “run-file”","text":"multiple reports run, consider creating R script contains compile_reports() commands. user can simply run commands R script reports compile. can save “run-file” “scripts” folder.","code":""},{"path":"reportfactory.html","id":"outputs-1","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41.5 Outputs","text":"compiled reports times, “outputs” folder might look like (highlights added clarity):Within “outputs”, sub-folders created Rmd reportWithin , sub-folders created unique compiling\ndate- time-stamped (“2021-04-23_T11-07-36” means 23rd April 2021 11:07:36)\ncan edit date/time-stamp format. See ?compile_reports\ndate- time-stamped (“2021-04-23_T11-07-36” means 23rd April 2021 11:07:36)can edit date/time-stamp format. See ?compile_reportsWithin date/time compiled folder, report output stored (e.g. HTML, PDF, Word) along Rmd script (version control!) exported files (e.g. table.csv, epidemic_curve.png)view inside one date/time-stamped folders, “daily_sitrep” report. file path highlighted yellow emphasis.Finally, screenshot HTML report output.can use list_outputs() review list outputs.","code":""},{"path":"reportfactory.html","id":"miscellaneous-1","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41.6 Miscellaneous","text":"","code":""},{"path":"reportfactory.html","id":"knit","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Knit","text":"can still “knit” one R Markdown reports pressing “Knit” button, want. , default, outputs appear folder Rmd saved - “report_sources” folder. prior versions reportfactory, non-Rmd files “report_sources” prevent compiling, longer case. can run compile_reports() error occur.","code":""},{"path":"reportfactory.html","id":"scripts-1","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Scripts","text":"encourage utilize “scripts” folder store “runfiles” .R scripts sourced .Rmd scripts. See page [R Markdown][Reports R Markdown] tips structure code across several files.","code":""},{"path":"reportfactory.html","id":"extras","chapter":"41 Tổ chức báo cáo định kỳ","heading":"Extras","text":"reportfactory, can use function list_deps() list packages required across reports entire factory.reportfactory, can use function list_deps() list packages required across reports entire factory.accompanying package development called rfextras offers helper functions assist building reports, :\nload_scripts() - sources/loads .R scripts given folder (“scripts” folder default)\nfind_latest() - finds latest version file (e.g. latest dataset)\naccompanying package development called rfextras offers helper functions assist building reports, :load_scripts() - sources/loads .R scripts given folder (“scripts” folder default)find_latest() - finds latest version file (e.g. latest dataset)","code":""},{"path":"reportfactory.html","id":"resources-24","chapter":"41 Tổ chức báo cáo định kỳ","heading":"41.7 Resources","text":"See reportfactory package’s Github pageSee rfextras package’s Github page","code":""},{"path":"flexdashboard.html","id":"flexdashboard","chapter":"42 Dashboards với R Markdown","heading":"42 Dashboards với R Markdown","text":"page cover basic use flexdashboard package. package allows easily format R Markdown output dashboard panels pages. dashboard content can text, static figures/tables interactive graphics.Advantages flexdashboard:requires minimal non-standard R coding - little practice can quickly create dashboardThe dashboard can usually emailed colleagues self-contained HTML file - server requiredYou can combine flexdashboard shiny, ggplotly, “html widgets” add interactivityDisadvantages flexdashboard:Less customization compared using shiny alone create dashboardVery comprehensive tutorials using flexdashboard informed page can found Resources section. describe core features give example building dashboard explore outbreak, using case linelist data.","code":""},{"path":"flexdashboard.html","id":"preparation-25","chapter":"42 Dashboards với R Markdown","heading":"42.1 Preparation","text":"","code":""},{"path":"flexdashboard.html","id":"load-packages-24","chapter":"42 Dashboards với R Markdown","heading":"Load packages","text":"handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,             # data import/export     \n  here,            # locate files\n  tidyverse,       # data management and visualization\n  flexdashboard,   # dashboard versions of R Markdown reports\n  shiny,           # interactive figures\n  plotly           # interactive figures\n)"},{"path":"flexdashboard.html","id":"import-data-18","chapter":"42 Dashboards với R Markdown","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want follow along, click download “clean” linelist (.rds file). Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"flexdashboard.html","id":"create-new-r-markdown","chapter":"42 Dashboards với R Markdown","heading":"42.2 Create new R Markdown","text":"installed package, create new R Markdown file clicking File > New file > R Markdown.window opens, select “Template” select “Flex Dashboard” template. prompted name document. page’s example, name R Markdown “outbreak_dashboard.Rmd”.","code":""},{"path":"flexdashboard.html","id":"the-script","chapter":"42 Dashboards với R Markdown","heading":"42.3 The script","text":"script R Markdown script, components organization described page [Reports R Markdown]. briefly re-visit highlight differences R Markdown output formats.","code":""},{"path":"flexdashboard.html","id":"yaml","chapter":"42 Dashboards với R Markdown","heading":"YAML","text":"top script “YAML” header. must begin three dashes --- must close three dashes ---. YAML parameters comes key:value pairs. indentation placement colons YAML important - key:value pairs separated colons (equals signs!).YAML begin metadata document. order primary YAML parameters (indented) matter. example:can use R code YAML values putting like -line code (preceeded r within backticks) also within quotes (see Date).required YAML parameter output:, specifies type file produced (e.g. html_document, pdf_document, word_document, powerpoint_presentation). flexdashboard parameter value bit confusing - must set output:flexdashboard::flex_dashboard. Note single double colons, underscore. YAML output parameter often followed additional colon indented sub-parameters (see orientation: vertical_layout: parameters ).shown , indentations (2 spaces) used sub-parameters. case, forget put additional colon primary, like key:value:.appropriate, logical values given YAML lowercase (true, false, null). colon part value (e.g. title) put value quotes. See examples sections .","code":"\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\ntitle: \"My dashboard\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll"},{"path":"flexdashboard.html","id":"code-chunks","chapter":"42 Dashboards với R Markdown","heading":"Code chunks","text":"R Markdown script can contain multiple code “chunks” - areas script can write multiple-line R code function just like mini R scripts.Code chunks created three back-ticks curly brackets lowercase “r” within. chunk closed three backticks. can create new chunk typing , using keyboard shortcut “Ctrl + Alt + ” (Cmd + Shift + r Mac), clicking green ‘insert new code chunk’ icon top script editor. Many examples given .","code":""},{"path":"flexdashboard.html","id":"narrative-text","chapter":"42 Dashboards với R Markdown","heading":"Narrative text","text":"Outside R code “chunk”, can write narrative text. described page [Reports R Markdown], can italicize text surrounding one asterisk (*), bold surrounding two asterisks (**). Recall bullets numbering schemes sensitive newlines, indentation, finishing line two spaces.can also insert -line R code text described [Reports R Markdown] page, surrounding code backticks starting command “r”: ` 1+1`(see example date ).","code":""},{"path":"flexdashboard.html","id":"headings","chapter":"42 Dashboards với R Markdown","heading":"Headings","text":"Different heading levels established different numbers hash symbols, described [Reports R Markdown] page.flexdashboard, primary heading (#) creates “page” dashboard. Second-level headings (##) create column row depending orientation: parameter (see details ). Third-level headings (###) create panels plots, charts, tables, text, etc.","code":"# First-level heading (page)\n\n## Second level heading (row or column)  \n\n### Third-level heading (pane for plot, chart, etc.)"},{"path":"flexdashboard.html","id":"section-attributes","chapter":"42 Dashboards với R Markdown","heading":"42.4 Section attributes","text":"normal R markdown, can specify attributes apply parts dashboard including key=value options heading, within curly brackets { }. example, typical HTML R Markdown report might organize sub-headings tabs ## heading {.tabset}.Note attributes written heading text portion script. different knitr options inserted within top R code chunks, .height =.Section attributes specific flexdashboard include:{data-orientation=} Set either rows columns. dashboard multiple pages, add attribute page indicate orientation (explained layout section).{data-width=} {data-height=} set relative size charts, columns, rows laid dimension (horizontal vertical). Absolute sizes adjusted best fill space display device thanks flexbox engine.\nHeight charts also depends whether set YAML parameter vertical_layout: fill vertical_layout: scroll. set scroll, figure height reflect traditional fig.height = option R code chunk.\nSee complete size documentation flexdashboard website\nHeight charts also depends whether set YAML parameter vertical_layout: fill vertical_layout: scroll. set scroll, figure height reflect traditional fig.height = option R code chunk.See complete size documentation flexdashboard website{.hidden} Use exclude specific page navigation bar{data-navbar=} Use page-level heading nest within navigation bar drop-menu. Provide name (quotes) drop-menu. See example .","code":""},{"path":"flexdashboard.html","id":"layout","chapter":"42 Dashboards với R Markdown","heading":"42.5 Layout","text":"Adjust layout dashboard following ways:Add pages, columns/rows, charts R Markdown headings (e.g. #, ##, ###)Adjust YAML parameter orientation: either rows columnsSpecify whether layout fills browser allows scrollingAdd tabs particular section heading","code":""},{"path":"flexdashboard.html","id":"pages","chapter":"42 Dashboards với R Markdown","heading":"Pages","text":"First-level headings (#) R Markdown represent “pages” dashboard. default, pages appear navigation bar along top dashboard.can group pages “menu” within top navigation bar adding attribute {data-navmenu=} page heading. careful - include spaces around equals sign otherwise work!script produces:can also convert page column “sidebar” left side dashboard adding {.sidebar} attribute. can hold text (viewable page), integrated shiny interactivity can useful hold user-input controls sliders drop-menus.script produces:","code":""},{"path":"flexdashboard.html","id":"orientation","chapter":"42 Dashboards với R Markdown","heading":"Orientation","text":"Set orientation: yaml parameter indicate second-level (##) R Markdown headings interpreted - either orientation: columns orientation: rows.Second-level headings (##) interpreted new columns rows based orientation setting.set orientation: columns, second-level headers create new columns dashboard. dashboard one page, containing two columns, total three panels. can adjust relative width columns {data-width=} shown .script produces:set orientation: rows, second-level headers create new rows instead columns. script , orientation: rows second-level headings produce rows instead columns. can adjust relative height rows {data-height=} shown .script produces:dashboard multiple pages, can designate orientation specific page adding {data-orientation=} attribute header page (specify either rows columns without quotes).","code":""},{"path":"flexdashboard.html","id":"tabs","chapter":"42 Dashboards với R Markdown","heading":"Tabs","text":"can divide content tabs {.tabset} attribute, HTML R Markdown outputs.Simply add attribute desired heading. Sub-headings heading displayed tabs. example, example script column 2 right (##) modified epidemic curve table panes (###) displayed tabs.can rows orientation rows.script produces:","code":""},{"path":"flexdashboard.html","id":"adding-content","chapter":"42 Dashboards với R Markdown","heading":"42.6 Adding content","text":"Let’s begin build dashboard. simple dashboard 1 page, 2 columns, 4 panels. build panels piece--piece demonstration.can easily include standard R outputs text, ggplots, tables (see [Tables presentation] page). Simply code within R code chunk R Markdown script.Note: can download finished Rmd script HTML dashboard output - see [Download handbook data] page.","code":""},{"path":"flexdashboard.html","id":"text","chapter":"42 Dashboards với R Markdown","heading":"Text","text":"can type Markdown text include -line code R Markdown output. See [Reports R Markdown] page details.dashboard include summary text panel includes dynamic text showing latest hospitalisation date number cases reported outbreak.","code":""},{"path":"flexdashboard.html","id":"tables","chapter":"42 Dashboards với R Markdown","heading":"Tables","text":"can include R code chunks print outputs tables. output look best respond window size use kable() function knitr display tables. flextable functions may produce tables shortened / cut-.example, feed linelist() count() command produce summary table cases hospital. Ultimately, table piped knitr::kable() result scroll bar right. can read customizing table kable() kableExtra .script produces:want show dynamic table allows user filter, sort, /click “pages” data frame, use package DT ’s function datatable(), code .example code , data frame linelist printed. can set rownames = FALSE conserve horizontal space, filter = \"top\" filters top every column. list specifications can provided options =. , set pageLength = 5 rows appear scrollX = user can use scroll bar bottom scroll horizontally. argument class = 'white-space: nowrap' ensures row one line (multiple lines). can read possible arguments values entering ?datatable","code":"\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = list(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )"},{"path":"flexdashboard.html","id":"plots","chapter":"42 Dashboards với R Markdown","heading":"Plots","text":"can print plots dashboard pane R script. example, use incidence2 package create “epicurve” age group two simple commands (see [Epidemic curves] page). However, use ggplot() print plot manner.script produces:","code":""},{"path":"flexdashboard.html","id":"interactive-plots-1","chapter":"42 Dashboards với R Markdown","heading":"Interactive plots","text":"can also pass standard ggplot plot object ggplotly() plotly package (see Interactive plots page). make plot interactive, allow reader “zoom ”, show--hover value every data point (scenario number cases per week age group curve).looks like dashboard (gif). interactive functionality still work even email dashboard static file (online server).","code":"\nage_outbreak <- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %>% \n  plotly::ggplotly()"},{"path":"flexdashboard.html","id":"html-widgets","chapter":"42 Dashboards với R Markdown","heading":"HTML widgets","text":"HTML widgets R special class R packages increases interactivity utilizing JavaScript libraries. can embed R Markdown outputs (flexdashboard) Shiny dashboards.common examples widgets include:Plotly (used handbook page [Interative plots] page)visNetwork (used [Transmission Chains] page handbook)Leaflet (used [GIS Basics] page handbook)dygraphs (useful interactively showing time series data)DT (datatable()) (used show dynamic tables filter, sort, etc.)demonstrate adding epidemic transmission chain uses visNetwork dashboard. script shows new code added “Column 2” section R Markdown script. can find code [Transmission chains] page handbook.script produces:","code":""},{"path":"flexdashboard.html","id":"code-organization","chapter":"42 Dashboards với R Markdown","heading":"42.7 Code organization","text":"may elect code within R Markdown flexdashboard script. Alternatively, clean concise dashboard script may choose call upon code/figures hosted created external R scripts. described greater detail [Reports R Markdown] page.","code":""},{"path":"flexdashboard.html","id":"shiny-1","chapter":"42 Dashboards với R Markdown","heading":"42.8 Shiny","text":"Integrating R package shiny can make dashboards even reactive user input. example, user select jurisdiction, date range, panels react choice (e.g. filter data displayed). embed shiny reactivity flexdashboard, need make changes flexdashboard R Markdown script.can use shiny produce apps/dashboards without flexdashboard . handbook page [Dashboards Shiny] gives overview approach, including primers shiny syntax, app file structure, options sharing/publishing (including free server options). syntax general tips translate flexdashboard context well.Embedding shiny flexdashboard however, fundamental change flexdashboard. longer produce HTML output can send email anyone open view. Instead, “app”. “Knit” button top script replaced “Run document” icon, open instance interactive dashboard locally computer.Sharing dashboard now require either:Send Rmd script viewer, open R computer, run app, orThe app/dashboard hosted server accessible viewerThus, benefits integrating shiny, also complications. easy sharing email priority don’t need shiny reactive capabilities, consider reduced interactivity offered ggplotly() demonstrated .give simple example using “outbreak_dashboard.Rmd” . Extensive documentation integrating Shiny flexdashboard available online .","code":""},{"path":"flexdashboard.html","id":"settings","chapter":"42 Dashboards với R Markdown","heading":"Settings","text":"Enable shiny flexdashboard adding YAML parameter runtime: shiny indentation level output:, :also convenient enable “side bar” hold shiny input widgets collect information user. explained , create column indicate {.sidebar} option create side bar left side. can add text R chunks containing shiny input commands within column.app/dashboard hosted server may multiple simultaneous users, name first R code chunk global. Include commands import/load data chunk. special named chunk treated differently, data imported within imported (continuously) available users. improves start-speed app.","code":"---\ntitle: \"Outbreak dashboard (Shiny demo)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---"},{"path":"flexdashboard.html","id":"worked-example","chapter":"42 Dashboards với R Markdown","heading":"Worked example","text":"adapt flexdashboard script “outbreak_dashboard.Rmd” include shiny. add capability user select hospital drop-menu, epidemic curve reflect cases hospital, dynamic plot title. following:Add runtime: shiny YAMLRe-name setup chunk globalCreate sidebar containing:\nCode create vector unique hospital names\nselectInput() command (shiny drop-menu) choice hospital names. selection saved hospital_choice, can referenced later code input$hospital_choice\nCode create vector unique hospital namesA selectInput() command (shiny drop-menu) choice hospital names. selection saved hospital_choice, can referenced later code input$hospital_choiceThe epidemic curve code (column 2) wrapped within renderPlot({ }), including:\nfilter dataset restricting column hospital current value input$hospital_choice\ndynamic plot title incorporates input$hospital_choice\nfilter dataset restricting column hospital current value input$hospital_choiceA dynamic plot title incorporates input$hospital_choiceNote code referencing input$ value must within render({}) function (reactive).top script, including YAML, global chunk, sidebar:Column 2, reactive epicurve plot:dashboard:","code":""},{"path":"flexdashboard.html","id":"other-examples","chapter":"42 Dashboards với R Markdown","heading":"Other examples","text":"read health-related example Shiny-flexdashboard using shiny interactivity leaflet mapping widget, see chapter online book Geospatial Health Data: Modeling Visualization R-INLA Shiny.","code":""},{"path":"flexdashboard.html","id":"sharing","chapter":"42 Dashboards với R Markdown","heading":"42.9 Sharing","text":"Dashboards contain Shiny elements output HTML file (.html), can emailed (size permits). useful, can send “dashboard” report set server host website.embedded shiny, able send output email, can send script R user, host dashboard server explained .","code":""},{"path":"flexdashboard.html","id":"resources-25","chapter":"42 Dashboards với R Markdown","heading":"42.10 Resources","text":"Excellent tutorials informed page can found . review , likely within hour can dashboard.https://bookdown.org/yihui/rmarkdown/dashboards.htmlhttps://rmarkdown.rstudio.com/flexdashboard/https://rmarkdown.rstudio.com/flexdashboard/using.htmlhttps://rmarkdown.rstudio.com/flexdashboard/examples.html","code":""},{"path":"shiny-basics.html","id":"shiny-basics","chapter":"43 Dashboards với Shiny","heading":"43 Dashboards với Shiny","text":"Dashboards often great way share results analyses others. Producing dashboard shiny requires relatively advanced knowledge R language, offers incredible customization possibilities.recommended someone learning dashboards shiny good knowledge data transformation visualisation, comfortable debugging code, writing functions. Working dashboards intuitive ’re starting, difficult understand times, great skill learn gets much easier practice!page give short overview make dashboards shiny extensions.\nalternative method making dashboards faster, easier, perhaps less customizeable, see page flextable ([Dashboards R Markdown]).","code":""},{"path":"shiny-basics.html","id":"preparation-26","chapter":"43 Dashboards với Shiny","heading":"43.1 Preparation","text":"","code":""},{"path":"shiny-basics.html","id":"load-packages-25","chapter":"43 Dashboards với Shiny","heading":"Load packages","text":"handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.begin installing shiny R package:","code":"\npacman::p_load(\"shiny\")"},{"path":"shiny-basics.html","id":"import-data-19","chapter":"43 Dashboards với Shiny","heading":"Import data","text":"like follow-along page, see section Download handbook data. links download R scripts data files produce final Shiny app.try re-construct app using files, please aware R project folder structure created course demonstration (e.g. folders “data” “funcs”).","code":""},{"path":"shiny-basics.html","id":"the-structure-of-a-shiny-app","chapter":"43 Dashboards với Shiny","heading":"43.2 The structure of a shiny app","text":"","code":""},{"path":"shiny-basics.html","id":"basic-file-structures","chapter":"43 Dashboards với Shiny","heading":"Basic file structures","text":"understand shiny, first need understand file structure app works! make brand new directory start. can actually made easier choosing New project Rstudio, choosing Shiny Web Application. create basic structure shiny app .opening project, ’ll notice .R file already present called app.R. essential one two basic file structures:One file called app.R, orTwo files, one called ui.R server.RIn page, use first approach one file called app.R. example script:open file, ’ll notice two objects defined - one called ui another called server. objects must defined every shiny app central structure app ! fact, difference two file structures described structure 1, ui server defined one file, whereas structure 2 defined separate files. Note: can also (larger app) .R files structure can source() app.","code":"\n# an example of app.R\n\nlibrary(shiny)\n\nui <- fluidPage(\n\n    # Application title\n    titlePanel(\"My app\"),\n\n    # Sidebar with a slider input widget\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # Show a plot \n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver <- function(input, output) {\n     \n     plot_1 <- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot <- renderPlot({\n       plot_1()\n    })\n}\n\n\n# Run the application \nshinyApp(ui = ui, server = server)"},{"path":"shiny-basics.html","id":"the-server-and-the-ui","chapter":"43 Dashboards với Shiny","heading":"The server and the ui","text":"next need understand server ui objects actually . Put simply, two objects interacting whenever user interacts shiny app.UI element shiny app , basic level, R code creates HTML interface. means everything displayed UI app. generally includes:“Widgets” - dropdown menus, check boxes, sliders, etc can interacted userPlots, tables, etc - outputs generated R codeNavigation aspects app - tabs, panes, etc.Generic text, hyperlinks, etcHTML CSS elements (addressed later)important thing understand UI receives inputs user displays outputs server. active code running ui time - changes seen UI passed server (less). make plots, downloads, etc serverThe server shiny app code run app starts . way works little confusing. server function effectively react user interfacing UI, run chunks code response. things change server, passed back ui, changes can seen. Importantly, code server executed non-consecutively (’s best think way). Basically, whenever ui input affects chunk code server, run automatically, output produced displayed.probably sounds abstract now, ’ll dive examples get clear idea actually works.","code":""},{"path":"shiny-basics.html","id":"before-you-start-to-build-an-app","chapter":"43 Dashboards với Shiny","heading":"Before you start to build an app","text":"begin build app, immensely helpful know want build. Since UI written code, can’t really visualise ’re building unless aiming something specific. reason, immensely helpful look lots examples shiny apps get idea can make - even better can look source code behind apps! great resources :Rstudio app galleryOnce get idea possible, ’s also helpful map want look like - can paper drawing software (PowerPoint, MS paint, etc.). ’s helpful start simple first app! ’s also shame using code find online nice app template work - much easier building something scratch!","code":""},{"path":"shiny-basics.html","id":"building-a-ui","chapter":"43 Dashboards với Shiny","heading":"43.3 Building a UI","text":"building app, easier work UI first can see ’re making, risk app failing server errors. mentioned previously, often good use template working UI. number standard layouts can used shiny available base shiny package, ’s worth noting also number package extensions shinydashboard. ’ll use example base shiny start .shiny UI generally defined series nested functions, following orderA function defining general layout (basic fluidPage(), available)Panels within layout :\nsidebar (sidebarPanel())\n“main” panel (mainPanel())\ntab (tabPanel())\ngeneric “column” (column())\nsidebar (sidebarPanel())“main” panel (mainPanel())tab (tabPanel())generic “column” (column())Widgets outputs - can confer inputs server (widgets) outputs server (outputs)\nWidgets generally styled xxxInput() e.g. selectInput()\nOutputs generally styled xxxOutput() e.g. plotOutput()\nWidgets generally styled xxxInput() e.g. selectInput()Outputs generally styled xxxOutput() e.g. plotOutput()’s worth stating can’t visualised easily abstract way, ’s best look example! Lets consider making basic app visualises malaria facility count data district. data lot differnet parameters, great end user apply filters see data age group/district see fit! can use simple shiny layout start - sidebar layout. layout widgets placed sidebar left, plot placed right.Lets plan app - can start selector lets us choose district want visualise data, another let us visualise age group interested . ’ll aim use filters show epicurve reflects parameters. need:Two dropdown menus let us choose district want, age group ’re interested .area can show resulting epicurve.might look something like :app.R run UI code (active code server portion app.R) layout appears looking like - note plot server render , inputs working!good opportunity discuss widgets work - note widget accepting inputId, label, series options specific widget type. inputId extremely important - IDs used pass information UI server. reason, must unique. make effort name something sensible, specific interacting cases larger apps.read documentation carefully full details widgets . Widgets pass specific types data server depending widget type, needs fully understood. example, selectInput() pass character type server:select Spring first widget , pass character object \"Spring\" server.select two items dropdown menu, come character vector (e.g. c(\"Spring\", \"Bolo\")).widgets pass different types object server! example:numericInput() pass numeric type object servercheckboxInput() pass logical type object server (TRUE FALSE)’s also worth noting named vector used age data . many widgets, using named vector choices display names vector display choices, pass selected value vector server. .e. someone can select “15+” drop-menu, UI pass \"malaria_rdt_15\" server - happens name column ’re interested !loads widgets can use lots things app. Widgets also allow upload files app, download outputs. also excellent shiny extensions give access widgets base shiny - shinyWidgets package great example . look examples can look following links:base shiny widget galleryshinyWidgets gallery","code":"\nlibrary(shiny)\n\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)"},{"path":"shiny-basics.html","id":"loading-data-into-our-app","chapter":"43 Dashboards với Shiny","heading":"43.4 Loading data into our app","text":"next step app development getting server running. however, need get data app, figure calculations ’re going . shiny app straightforward debug, ’s often clear errors coming , ’s ideal get data processing visualisation code working start making server .given want make app shows epi curves change based user input, think code need run normal R script. ’ll need :Load packagesLoad dataTransform dataDevelop function visualise data based user inputsThis list pretty straightforward, shouldn’t hard . ’s now important think parts process need done parts need run response user inputs. shiny apps generally run code running, performed . help app’s performance much code can moved section. example, need load data/packages basic transformations , can put code outside server. means thing ’ll need server code visualise data. Lets develop componenets script first. However, since ’re visualising data function, can also put code function outside server function environment app runs!First lets load data. Since ’re working new project, want make clean, can create new directory called data, add malaria data . can run code testing script eventually delete clean structure app.easier work data use tidy data standards, also transform longer data format, age group column, cases another column. can easily using ’ve learned [Pivoting data] page.’ve finished preparing data! crosses items 1, 2, 3 list things develop “testing R script”. last, difficult task building function produce epicurve based user defined parameters. mentioned previously, ’s highly recommended anyone learning shiny first look section functional programming ([Writing functions]) understand works!defining function, might hard think parameters want include. functional programming shiny, every relevent parameter generally widget associated , thinking usually quite easy! example current app, want able filter district, widget , can add district parameter reflect . don’t app functionality filter facility (now), don’t need add parameter. Lets start making function three parameters:core datasetThe district choiceThe age group choiceWe won’t go great detail function, ’s relatively simple works. One thing note however, handle errors returning NULL otherwise give error. shiny server produces NULL object instead plot object, nothing shown ui! important, otherwise errors often cause app stop working.Another thing note use %% operator evaluating district input. mentioned , arrive character vector multiple values, using %% flexible say, ==.Let’s test function!function working, now understand going fit shiny app. mentioned concept startup code , lets look can actually incorporate structure app. two ways can !Put code app.R file start script (UI), orCreate new file app’s directory called global.R, put startup code file.’s worth noting point ’s generally easier, especially bigger apps, use second file structure, lets separate file structure simple way. Lets fully develop global.R script now. look like:Easy! One great feature shiny understand files named app.R, server.R, ui.R, global.R , need connect via code. just code global.R directory run start app!.also note improve app’s organisation moved plotting function file - especially helpful apps become larger. , make another directory called funcs, put function file called plot_epicurve.R. read function via following command global.RNote always specify local = TRUE shiny apps, since affect sourcing /app published server.","code":"\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# read data\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\nprint(malaria_data)## # A tibble: 3,038 x 10\n##    location_name data_date  submitted_date Province District `malaria_rdt_0-4`\n##    <chr>         <date>     <date>         <chr>    <chr>                <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring                  11\n##  2 Facility 2    2020-08-11 2020-08-12     North    Bolo                    11\n##  3 Facility 3    2020-08-11 2020-08-12     North    Dingo                    8\n##  4 Facility 4    2020-08-11 2020-08-12     North    Bolo                    16\n##  5 Facility 5    2020-08-11 2020-08-12     North    Bolo                     9\n##  6 Facility 6    2020-08-11 2020-08-12     North    Dingo                    3\n##  7 Facility 6    2020-08-10 2020-08-12     North    Dingo                    4\n##  8 Facility 5    2020-08-10 2020-08-12     North    Bolo                    15\n##  9 Facility 5    2020-08-09 2020-08-12     North    Bolo                    11\n## 10 Facility 5    2020-08-08 2020-08-12     North    Bolo                    19\n## # ... with 3,028 more rows, and 4 more variables: malaria_rdt_5-14 <int>,\n## #   malaria_rdt_15 <int>, malaria_tot <int>, newid <int>\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)## # A tibble: 12,152 x 7\n##    location_name data_date  submitted_date Province District age_group      cases_reported\n##    <chr>         <date>     <date>         <chr>    <chr>    <chr>                   <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_0~             11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_5~             12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_15             23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot                46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_0~             11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_5~             10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_15              5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot                26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_0~              8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_5~              5\n## # ... with 12,142 more rows\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n# global.R script\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n# read data\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\n# clean data and pivot longer\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# define plotting function\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # create plot title\n  if (!(\"All\" %in% district)) {            \n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # filter to age group\n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)"},{"path":"shiny-basics.html","id":"developing-an-app-server","chapter":"43 Dashboards với Shiny","heading":"43.5 Developing an app server","text":"Now code, just develop server. final piece app, probably hardest understand. server large R function, helpful think series smaller functions, tasks app can perform. ’s important understand functions executed linear order. order , ’s fully necessary understand starting shiny. basic level, tasks functions activate change user inputs affects , unless developer set behave differently. , quite abstract, lets first go three basic types shiny objectsReactive sources - another term user inputs. shiny server access outputs UI widgets ’ve programmed. Every time values changed, passed server.Reactive sources - another term user inputs. shiny server access outputs UI widgets ’ve programmed. Every time values changed, passed server.Reactive conductors - objects exist inside shiny server. don’t actually need simple apps, produce objects can seen inside server, used operations. generally depend reactive sources.Reactive conductors - objects exist inside shiny server. don’t actually need simple apps, produce objects can seen inside server, used operations. generally depend reactive sources.Endpoints - outputs passed server UI. example, epi curve producing.Endpoints - outputs passed server UI. example, epi curve producing.mind lets construct server step--step. ’ll show UI code just reference:code UI :Two inputs:\nDistrict selector (inputId select_district)\nAge group selector (inputId select_agegroup)\nDistrict selector (inputId select_district)Age group selector (inputId select_agegroup)One output:\nepicurve (outputId malaria_epicurve)\nepicurve (outputId malaria_epicurve)stated previously, unique names assigned inputs outputs crucial. must unique used pass information ui server. server, access inputs via syntax input$inputID outputs passed ui syntax output$output_name Lets look example, hard understand otherwise!server simple app like actually quite straightforward! ’ll notice server function three parameters - input, output, session - isn’t important understand now, important stick setup! server one task - renders plot based function made earlier, inputs server. Notice names input output objects correspond exactly ui.understand basics server reacts user inputs, note output know (underlying package) inputs change, rerun function create plot every time change. Note also use renderPlot() function - one family class-specific functions pass objects ui output. number functions behave similarly, need ensure function used matches class object ’re passing ui! example:renderText() - send text uirenderDataTable - send interactive table ui.Remember also need match output function used ui - renderPlot() paired plotOutput(), renderText() matched textOutput().’ve finally made functioning app! can run pressing Run App button top right script window Rstudio. note can choose run app default browser (rather Rstudio) accurately reflect app look like users.fun note R console, app “listening”! Talk reactivity!","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}"},{"path":"shiny-basics.html","id":"adding-more-functionality","chapter":"43 Dashboards với Shiny","heading":"43.6 Adding more functionality","text":"point ’ve finally got running app, little functionality. also haven’t really scratched surface shiny can , ’s lot learn ! Lets continue build existing app adding extra features. things nice add :explanatory textA download button plot - provide user high quality version image ’re generating appA selector specific facilitiesAnother dashboard page - show table data.lot add, can use learn bunch different shiny featues way. much learn shiny (can get advanced, hopefully case users better idea use can become comfortable using external learning sources well).","code":""},{"path":"shiny-basics.html","id":"adding-static-text","chapter":"43 Dashboards với Shiny","heading":"Adding static text","text":"Lets first discuss adding static text shiny app. Adding text app extremely easy, basic grasp . Since static text doesn’t change shiny app (’d like change, can use text rendering functions server!), shiny’s static text generally added ui app. wont go great detail, can add number different elements ui (even custom ones) interfacing R HTML css.HTML css languages explicitly involved user interface design. don’t need understand well, HTML creates objects UI (like text box, table), css generally used change style aesthetics objects. Shiny access large array HTML tags - present objects behave specific way, headers, paragraphs text, line breaks, tables, etc. can use examples like :h1() - header tag, make enclosed text automatically larger, change defaults pertain font face, colour etc (depending overall theme app). can access smaller smaller sub-heading h2() h6() well. Usage looks like:\nh1(\"header - section 1\")\nh1() - header tag, make enclosed text automatically larger, change defaults pertain font face, colour etc (depending overall theme app). can access smaller smaller sub-heading h2() h6() well. Usage looks like:h1(\"header - section 1\")p() - paragraph tag, make enclosed text similar text body text. text automatically wrap, relatively small size (footers smaller example.) Think text body word document. Usage looks like:\np(\"larger body text explaining function app\")\np() - paragraph tag, make enclosed text similar text body text. text automatically wrap, relatively small size (footers smaller example.) Think text body word document. Usage looks like:p(\"larger body text explaining function app\")tags$b() tags$() - used create bold tags$b() italicised tags$() whichever text enclosed!tags$b() tags$() - used create bold tags$b() italicised tags$() whichever text enclosed!tags$ul(), tags$ol() tags$li() - tags used creating lists. used within syntax , allow user create either ordered list (tags$ol(); .e. numbered) unordered list (tags$ul(), .e. bullet points). tags$li() used denote items list, regardless type list used. e.g.:tags$ul(), tags$ol() tags$li() - tags used creating lists. used within syntax , allow user create either ordered list (tags$ol(); .e. numbered) unordered list (tags$ul(), .e. bullet points). tags$li() used denote items list, regardless type list used. e.g.:br() hr() - tags create linebreaks horizontal lines (linebreak) respectively. Use separate sections app text! need pass items tags (parentheses can remain empty).br() hr() - tags create linebreaks horizontal lines (linebreak) respectively. Use separate sections app text! need pass items tags (parentheses can remain empty).div() - generic tag can contain anything, can named anything. progress ui design, can use compartmentalize ui, give specific sections specific styles, create interactions server UI elements. won’t go detail, ’re worth aware !div() - generic tag can contain anything, can named anything. progress ui design, can use compartmentalize ui, give specific sections specific styles, create interactions server UI elements. won’t go detail, ’re worth aware !Note every one objects can accessed tags$... , just function. effectively synonymous, may help use tags$... style ’d rather explicit overwrite functions accidentally. also means exhaustive list tags available. full list tags available shiny even can used inserting HTML directly ui!’re feeling confident, can also add css styling elements HTML tags style argument . won’t go works detail, one tip testing aesthetic changes UI using HTML inspector mode chrome (shiny app running browser), editing style objects !Lets add text app","code":"\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)"},{"path":"shiny-basics.html","id":"adding-a-link","chapter":"43 Dashboards với Shiny","heading":"Adding a link","text":"add link website, use tags$() link display text shown . standalone paragraph, put within p(). words sentence linked, break sentence parts use tags$() hyperlinked part. ensure link opens new browser window, add target = \"_blank\" argument.","code":"\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")"},{"path":"shiny-basics.html","id":"adding-a-download-button","chapter":"43 Dashboards với Shiny","heading":"Adding a download button","text":"Lets move second three features. download button fairly common thing add app fairly easy make. need add another Widget ui, need add another output server attach . can also introduce reactive conductors example!Lets update ui first - easy shiny comes widget called downloadButton() - lets give inputId label.Note ’ve also added hr() tag - adds horizontal line separating control widgets download widgets. another one HTML tags discussed previously.Now ui ready, need add server component. Downloads done server downloadHandler() function. Similar plot, need attach output inputId download button. function takes two arguments - filename content - functions. might able guess, filename used specify name downloaded file, content used specify downloaded. content contain function use save data locally - downloading csv file use rio::export(). Since ’re downloading plot, ’ll use ggplot2::ggsave(). Lets look program (won’t add server yet).Note content function always takes file argument, put output file name specified. might also notice ’re repeating code - using plot_epicurve() function twice server, download image displayed app. wont massively affect performance, means code generate plot run user changes widgets specifying district age group, want download plot. larger apps, suboptimal decisions like one slow things , ’s good learn make app efficient sense. make sense way run epicurve code districts/age groups changes, let used renderPlot() downloadHandler() functions. reactive conductors come !Reactive conductors objects created shiny server reactive way, outputted - can just used parts server. number different kinds reactive conductors, ’ll go basic two.1.reactive() - basic reactive conductor - react whenever inputs used inside change (district/age group widgets)\n2. eventReactive()- rective conductor works reactive(), except user can specify inputs cause rerun. useful reactive conductor takes long time process, explained later.Lets look two examples:use eventReactive() setup, can specify inputs cause chunk code run - isn’t useful us moment, can leave now. Note can include multiple inputs c()Lets look can integrate server code:can see ’re just calling output reactive ’ve defined download plot rendering functions. One thing note often trips people use outputs reactives functions - must add empty brackets end (.e. malaria_plot() correct, malaria_plot ). Now ’ve added solution app little tidyer, faster, easier change since code runs epicurve function one place.","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\nmalaria_plot_r <- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# only runs when the district selector changes!\nmalaria_plot_er <- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}"},{"path":"shiny-basics.html","id":"adding-a-facility-selector","chapter":"43 Dashboards với Shiny","heading":"Adding a facility selector","text":"Lets move next feature - selector specific facilities. ’ll implement another parameter function can pass argument code. Lets look first - just operates principles parameters ’ve set . Lets update test function.Let’s test :facilites data, isn’t clear facilities correspond districts - end user won’t know either. might make using app quite unintuitive. reason, make facility options UI change dynamically user changes district - one filters ! Since many variables ’re using options, might also want generate options ui global.R file data. example, can add code chunk global.R ’ve read data :Let’s look :can pass new variables ui without issue, since globally visible server ui! Lets update UI:Notice ’re now passing variables choices instead hard coding ui! might make code compact well! Lastly, ’ll update server. easy update function incorporate new input (just pass argument new parameter), remember also want ui update dynamically user changes selected district. important understand can change parameters behaviour widgets app running, needs done server. need understand new way output server learn .functions need understand known observer functions, similar reactive functions behave. one key difference though:Reactive functions directly affect outputs, produce objects can seen locations serverObserver functions can affect server outputs, via side effects functions. (can also things, main function practice)Similar reactive functions, two flavours observer functions, divided logic divides reactive functions:observe() - function runs whenever inputs used inside changeobserveEvent() - function runs user-specified input changesWe also need understand shiny-provided functions update widgets. fairly straightforward run - first take session object server function (doesn’t need understood now), inputId function changed. pass new versions parameters already taken selectInput() - automatically updated widget.Lets look isolated example use server. user changes district, want filter tibble facilities district, update choices reflect available district (option facilities)’s ! can add server, behaviour now work. ’s new server look like:","code":"\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data <- data %>%\n      filter(location_name == facility)\n    \n    plot_title_facility <- facility\n    \n  } else {\n    \n    plot_title_facility <- \"all facilities\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\nall_districts <- c(\"All\", unique(malaria_data$District))\n\n# data frame of location names by district\nfacility_list <- malaria_data %>%\n  group_by(location_name, District) %>%\n  summarise() %>% \n  ungroup()\nall_districts## [1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\nfacility_list## # A tibble: 65 x 2\n##    location_name District\n##    <chr>         <chr>   \n##  1 Facility 1    Spring  \n##  2 Facility 10   Bolo    \n##  3 Facility 11   Spring  \n##  4 Facility 12   Dingo   \n##  5 Facility 13   Bolo    \n##  6 Facility 14   Dingo   \n##  7 Facility 15   Barnard \n##  8 Facility 16   Barnard \n##  9 Facility 17   Barnard \n## 10 Facility 18   Bolo    \n## # ... with 55 more rows\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for facility\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices <- facility_list$location_name\n  } else {\n    new_choices <- facility_list %>%\n      filter(District == input$select_district) %>%\n      pull(location_name)\n  }\n  \n  new_choices <- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}"},{"path":"shiny-basics.html","id":"adding-another-tab-with-a-table","chapter":"43 Dashboards với Shiny","heading":"Adding another tab with a table","text":"Now ’ll move last component want add app. ’ll want separate ui two tabs, one interactive table user can see data making epidemic curve . , can use packaged ui elements come shiny relevant tabs. basic level, can enclose main panel general structure:Lets apply ui. also want use DT package - great package making interactive tables pre-existing data. can see used DT::datatableOutput() example.Now app arranged tabs! Lets make necessary edits server well. Since dont need manipulate dataset render actually simple - just render malaria_data dataset via DT::renderDT() ui!","code":"\n# ... the rest of ui\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\nui <- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # selector for district\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for age group\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for facility\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # horizontal line\n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # render data table to ui\n  output$raw_data <- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}"},{"path":"shiny-basics.html","id":"sharing-shiny-apps","chapter":"43 Dashboards với Shiny","heading":"43.7 Sharing shiny apps","text":"Now ’ve developed app, probably want share others - main advantage shiny ! can sharing code directly, publish server. share code, others able see ’ve done build , negate one main advantages shiny - can eliminate need end-users maintain R installation. reason, ’re sharing app users comfortable R, much easier share app published server.’d rather share code, make .zip file app, better yet, publish app github add collaborators. can refer section github information .However, ’re publishing app online, need little work. Ultimately, want app able accessed via web URL others can get quick easy access . Unfortunately, publish app server, need access server publish ! number hosting options comes :shinyapps.io: easiest place publish shiny apps, smallest amount configuration work needed, free, limited licenses.shinyapps.io: easiest place publish shiny apps, smallest amount configuration work needed, free, limited licenses.RStudio Connect: far powerful version R server, can perform many operations, including publishing shiny apps. however, harder use, less recommended first-time users.RStudio Connect: far powerful version R server, can perform many operations, including publishing shiny apps. however, harder use, less recommended first-time users.purposes document, use shinyapps.io, since easier first time users. can make free account start - also different price plans server licesnses needed. users expect , expensive price plan may , keep consideration. ’re looking create something small set individuals use, free license may perfectly suitable, public facing app may need licenses.First make sure app suitable publishing server. app, restart R session, ensure runs without running extra code. important, app requires package loading, data reading defined app code won’t run server. Also note can’t explicit file paths app - invalid server setting - using package solves issue well. Finally, ’re reading data source requires user-authentication, organisation’s servers, generally work server. need liase department figure whitelist shiny server .signing accountOnce account, can navigate tokens page Accounts. want add new token - used deploy app., note url account reflect name app - app called my_app, url appended xxx.io/my_app/. Choose app name wisely! Now ready, click deploy - successful run app web url chose!something making apps documents?","code":""},{"path":"shiny-basics.html","id":"further-reading","chapter":"43 Dashboards với Shiny","heading":"43.8 Further reading","text":"far, ’ve covered lot aspects shiny, barely scratched surface offer shiny. guide serves introduction, loads learn fully understand shiny. start making apps gradually add functionality","code":""},{"path":"shiny-basics.html","id":"recommended-extension-packages","chapter":"43 Dashboards với Shiny","heading":"43.9 Recommended extension packages","text":"following represents selection high quality shiny extensions can help get lot shiny. particular order:shinyWidgets - package gives many many widgets can used app. Run shinyWidgets::shinyWidgetsGallery() see selection available widgets package. See examples hereshinyWidgets - package gives many many widgets can used app. Run shinyWidgets::shinyWidgetsGallery() see selection available widgets package. See examples hereshinyjs - excellent package gives user ability greatly extend shiny’s utility via series javascript. applications package range simple highly advanced, might want first use manipulate ui simple ways, like hiding/showing elements, enabling/disabling buttons. Find hereshinyjs - excellent package gives user ability greatly extend shiny’s utility via series javascript. applications package range simple highly advanced, might want first use manipulate ui simple ways, like hiding/showing elements, enabling/disabling buttons. Find hereshinydashboard - package massively expands available ui can used shiny, specifically letting user create complex dashboard variety complex layouts. See hereshinydashboard - package massively expands available ui can used shiny, specifically letting user create complex dashboard variety complex layouts. See hereshinydashboardPlus - get even features shinydashboard framework! See hereshinydashboardPlus - get even features shinydashboard framework! See hereshinythemes - change default css theme shiny app wide range preset templates! See hereshinythemes - change default css theme shiny app wide range preset templates! See hereThere also number packages can used create interactive outputs shiny compatible.DT semi-incorporated base-shiny, provides great set functions create interactive tables.DT semi-incorporated base-shiny, provides great set functions create interactive tables.plotly package creating interactive plots user can manipulate app. can also convert plot interactive versions via plotly::ggplotly()! alternatives, dygraphs highcharter also excellent.plotly package creating interactive plots user can manipulate app. can also convert plot interactive versions via plotly::ggplotly()! alternatives, dygraphs highcharter also excellent.","code":""},{"path":"shiny-basics.html","id":"recommended-resources","chapter":"43 Dashboards với Shiny","heading":"43.10 Recommended resources","text":"","code":""},{"path":"writing-functions.html","id":"writing-functions","chapter":"44 Viết hàm","heading":"44 Viết hàm","text":"","code":""},{"path":"writing-functions.html","id":"preparation-27","chapter":"44 Viết hàm","heading":"44.1 Preparation","text":"","code":""},{"path":"writing-functions.html","id":"load-packages-26","chapter":"44 Viết hàm","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":""},{"path":"writing-functions.html","id":"import-data-20","chapter":"44 Viết hàm","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions [Download book data] page. dataset imported using import() function rio package. See page [Import export] various ways import data.also use last part page data H7N9 flu 2013.","code":""},{"path":"writing-functions.html","id":"functions-1","chapter":"44 Viết hàm","heading":"44.2 Functions","text":"Functions helpful programming since allow make codes easier understand, somehow shorter less prone errors (given errors function ).come far handbook, means came across endless functions since R, every operation function call\n+, , , [, $, { …. example x + y '+'(x, y)R one languages offers possibility work functions give enough tools user easily write . think functions fixed top end programming chain, R offers possibility use vectors even use inside functions, lists…Lot advanced resources functional programming exist give insight help start functional programming short practical examples. encouraged visit links references read .","code":""},{"path":"writing-functions.html","id":"why-would-you-use-a-function","chapter":"44 Viết hàm","heading":"44.3 Why would you use a function?","text":"answering question, important note already tips get write first R functions page [Iteration, loops, lists] handbook. fact, use “/else” loops often core part many functions since easily help either broaden application code allowing multiple conditions iterate codes repeating tasks.repeating multiple times block code apply different variable data?repeating multiple times block code apply different variable data?Getting rid substantially shorten overall code make run quicker?Getting rid substantially shorten overall code make run quicker?possible code written used different value many places code?possible code written used different value many places code?answer one previous questions “YES”, probably need write function","code":""},{"path":"writing-functions.html","id":"how-does-r-build-functions","chapter":"44 Viết hàm","heading":"44.4 How does R build functions?","text":"Functions R three main components:formals() list arguments controls can call functionthe formals() list arguments controls can call functionthe body() code inside function .e. within brackets following parenthesis depending write itthe body() code inside function .e. within brackets following parenthesis depending write itand,environment() help locate function’s variables determines function finds value.created function, can verify components calling function associated.","code":""},{"path":"writing-functions.html","id":"basic-syntax-and-structure","chapter":"44 Viết hàm","heading":"44.5 Basic syntax and structure","text":"function need named properly job easily understandable soon read name. Actually already case majority base R architecture. Functions like mean(), print(), summary() names straightforwardA function need named properly job easily understandable soon read name. Actually already case majority base R architecture. Functions like mean(), print(), summary() names straightforwardA function need arguments, data work objects can static values among optionsA function need arguments, data work objects can static values among optionsAnd finally function give output based core task arguments given. Usually use built-functions print(), return()… produce output. output can logical value, number, character, data frame…short kind R object.finally function give output based core task arguments given. Usually use built-functions print(), return()… produce output. output can logical value, number, character, data frame…short kind R object.Basically composition function:can create first function called contain_covid19().can verify components newly created function.Now test function. call written function, use use R functions .e writing function name adding required arguments.can write name argument precautionary reasons. without specifying , code work since R memory positioning argument. long put values arguments correct order, can skip writing arguments names calling functions.let’s look happens one values \"\" \"yes\".provide argument recognized, get error:Error contain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\",  :    find function \"contain_covid19\"NOTE: functions (time short straightforward) may need name can used directly line code inside another function quick task. called anonymous functions .instance first anonymous function keeps character variables dataset.another function selects every second observation dataset (may relevant longitudinal data many records per patient instance ordered date visit).\ncase, proper function writing outside dplyr function (x) (x%%2 == 0) apply vector containing row numbers.possible base R code task :CAUTION: Though true using functions can help us code, can nevertheless time consuming write functions fix one thought thoroughly, written adequately returning errors result. reason often recommended first write R code, make sure intend , transform function three main components listed . ","code":"\nfunction_name <- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\ncontain_covid19 <- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\nformals(contain_covid19)## $barrier_gest\n## \n## \n## $wear_mask\n## \n## \n## $get_vaccine\nbody(contain_covid19)## {\n##     if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n##         \"yes\") \n##         return(\"success\")\n##     else (\"please make sure all are yes, this pandemic has to end!\")\n## }\nenvironment(contain_covid19)## <environment: R_GlobalEnv>\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")## [1] \"success\"\ncontain_covid19(\"yes\", \"yes\", \"yes\")## [1] \"success\"\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")## [1] \"please make sure all are yes, this pandemic has to end!\"\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\nlinelist %>% \n  dplyr::slice_head(n=10) %>%  #equivalent to R base \"head\" function and that return first n observation of the  dataset\n  select(function(x) is.character(x)) \nlinelist %>%   \n   slice_head(n=20) %>% \n   tibble::rownames_to_column() %>% # add indices of each obs as rownames to clearly see the final selection\n   filter(row_number() %%2 == 0)\nlinelist_firstobs <- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]"},{"path":"writing-functions.html","id":"examples-1","chapter":"44 Viết hàm","heading":"44.6 Examples","text":"","code":""},{"path":"writing-functions.html","id":"return-proportion-tables-for-several-columns","chapter":"44 Viết hàm","heading":"Return proportion tables for several columns","text":"Yes, already nice functions many packages allowing summarize information easy nice way. still try make , first steps getting used writing functions.example want show writing simple function avoid copy-pasting code multiple times.TIP: shown , important comment functions general programming. Bear mind function’s aim make code ready read, shorter efficient. one able understand function just reading name details reading comments.second option use function another one via loop make process :simpler way using base R “apply” instead “loop” expressed :TIP: R often defined functional programming language almost anytime run line code using built-functions. good habit comfortable writing functions often internal look basic functions using daily built. shortcut selecting function name clicking onCtrl+F2 fn+F2 Cmd+F2 (depending computer) .","code":"\nproptab_multiple <- function(my_data, var_to_tab){\n  \n  #print the name of each variable of interest before doing the tabulation\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( #bind the results of the two following function by row\n        #tabulate the variable of interest: gives only numbers\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #calculate the proportions for each variable of interest and round the value to 2 decimals\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")## [1] \"gender\"##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\nproptab_multiple(linelist, \"age_cat\")## [1] \"age_cat\"##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\nproptab_multiple(linelist, \"outcome\")## [1] \"outcome\"##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44\nfor(var_to_tab in c(\"gender\",\"age_cat\",  \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}## [1] \"gender\"\n##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\n## [1] \"age_cat\"\n##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n## [1] \"outcome\"\n##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44"},{"path":"writing-functions.html","id":"using-purrr-writing-functions-that-can-be-iteratively-applied","chapter":"44 Viết hàm","heading":"44.7 Using purrr: writing functions that can be iteratively applied","text":"","code":""},{"path":"writing-functions.html","id":"modify-class-of-multiple-columns-in-a-dataset","chapter":"44 Viết hàm","heading":"Modify class of multiple columns in a dataset","text":"Let’s say many character variables original linelist data need changes “factor” analysis plotting purposes. Instead repeating step several times, can just use lapply() transformation variables concerned single line code.CAUTION: lapply() returns list, thus use may require additional modification last step.step can done using map_if() function purrr package","code":"\nlinelist_factor2 <- linelist %>%\n  purrr::map_if(is.character, as.factor)\n\n\nlinelist_factor2 %>%\n        glimpse()## List of 30\n##  $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n##  $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n##  $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA ...\n##  $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" ...\n##  $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" ...\n##  $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" ...\n##  $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n##  $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n##  $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n##  $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n##  $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n##  $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n##  $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n##  $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n##  $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n##  $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n##  $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n##  $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n##  $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n##  $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n##  $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n##  $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n##  $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n##  $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n##  $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ..."},{"path":"writing-functions.html","id":"iteratively-produce-graphs-for-different-levels-of-a-variable","chapter":"44 Viết hàm","heading":"Iteratively produce graphs for different levels of a variable","text":"produce pie chart look distribution patient’s outcome China H7N9 outbreak province. Instead repeating code , just apply function create.","code":"\n#precising options for the use of highchart\noptions(highcharter.theme =   highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n#create a function called \"chart_outcome_province\" that takes as argument the dataset and the name of the province for which to plot the distribution of the outcome.\n\nchart_outcome_province <- function(data_used, prov){\n  \n  tab_prov <- data_used %>% \n    filter(province == prov,\n           !is.na(outcome))%>% \n    group_by(outcome) %>% \n    count() %>%\n    adorn_totals(where = \"row\") %>% \n    adorn_percentages(denominator = \"col\", )%>%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %>%\n    filter(outcome != \"Total\") %>% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distibution of the outcome in:\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\nchart_outcome_province(flu_china,\"Zhejiang\")\nchart_outcome_province(flu_china,\"Jiangsu\")"},{"path":"writing-functions.html","id":"iteratively-produce-tables-for-different-levels-of-a-variable","chapter":"44 Viết hàm","heading":"Iteratively produce tables for different levels of a variable","text":"create three indicators summarize table like produce table provinces. indicators delay onset hospitalization, percentage recovery median age cases.Indicateurs pour la province de: ShanghaiIndicateursEstimationMean delay onset-hosp4.00Percentage recovery46.67Median age cases67.00Indicateurs pour la province de: JiangsuIndicateursEstimationMean delay onset-hosp6.00Percentage recovery71.43Median age cases55.00","code":"\nindic_1 <- flu_china %>% \n  group_by(province) %>% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %>%\n  select(province, mean_delay_onset_hosp)  %>% \n  distinct()\n     \n\nindic_2 <-  flu_china %>% \n            filter(!is.na(outcome)) %>% \n            group_by(province, outcome) %>% \n            count() %>%\n            pivot_wider(names_from = outcome, values_from = n) %>% \n    adorn_totals(where = \"col\") %>% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%>% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 <-  flu_china %>% \n            group_by(province) %>% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %>% \n  select(province, median_age_cases)  %>% \n  distinct()## Warning in median(as.numeric(age), na.rm = TRUE): NAs introduced by coercion\n#join the three indicator datasets\n\ntable_indic_all <- indic_1 %>% \n  dplyr::left_join(indic_2, by = \"province\") %>% \n        left_join(indic_3, by = \"province\")\n\n\n#print the indicators in a flextable\n\n\nprint_indic_prov <-  function(table_used, prov){\n  \n  #first transform a bit the dataframe for printing ease\n  indic_prov <- table_used %>%\n    filter(province==prov) %>%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %>% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\",\"perc_recovery\",\"median_age_cases\"),\n   labels=c(\"Mean delay onset-hosp\",\"Percentage of recovery\", \"Median age of the cases\"))\n   ) %>% \n    ungroup(province) %>% \n    select(indic_label, value)\n  \n\n    tab_print <- flextable(indic_prov)  %>%\n    theme_vanilla() %>% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print <- tab_print %>% \n                  autofit()   %>%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %>%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %>%\n    flextable::bold(part = \"header\") %>%\n    flextable::color(color = \"white\", part = \"header\") %>% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de: \", prov)) %>% \nbold(part = \"header\")\n \n tab_print <- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\nprint_indic_prov(table_indic_all, \"Jiangsu\")"},{"path":"writing-functions.html","id":"tips-and-best-practices-for-well-functioning-functions","chapter":"44 Viết hàm","heading":"44.8 Tips and best Practices for well functioning functions","text":"Functional programming meant ease code facilitates reading. produce contrary. tips help clean code easy read code.","code":""},{"path":"writing-functions.html","id":"naming-and-syntax","chapter":"44 Viết hàm","heading":"Naming and syntax","text":"Avoid using character easily already taken functions already existing environmentAvoid using character easily already taken functions already existing environmentIt recommended function name short straightforward understand another readerIt recommended function name short straightforward understand another readerIt preferred use verbs function name nouns argument names.preferred use verbs function name nouns argument names.","code":""},{"path":"writing-functions.html","id":"column-names-and-tidy-evaluation","chapter":"44 Viết hàm","heading":"Column names and tidy evaluation","text":"want know reference column names provided code arguments, read tidyverse programming guidance. Among topics covered tidy evaluation use embrace {{ }} “double braces”example, quick skeleton template code page tutorial mentioned just :","code":"\nvar_summary <- function(data, var) {\n  data %>%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))\n}\nmtcars %>% \n  group_by(cyl) %>% \n  var_summary(mpg)"},{"path":"writing-functions.html","id":"testing-and-error-handling","chapter":"44 Viết hàm","heading":"Testing and Error handling","text":"complicated function’s task higher possibility errors. Thus sometimes necessary add verification within funtion help quickly understand error find way t fix .can recommended introduce check missingness one argument using missing(argument). simple check can return “TRUE” “FALSE” value.Use stop() detectable errors.see run built-functions, messages warnings can pop-certain conditions. can integrate written functions using functions message() warning().see run built-functions, messages warnings can pop-certain conditions. can integrate written functions using functions message() warning().can handle errors also using safely() takes one function argument executes safe way. fact function execute without stopping encounters error. safely() returns output list two objects results error “skipped”.can handle errors also using safely() takes one function argument executes safe way. fact function execute without stopping encounters error. safely() returns output list two objects results error “skipped”.can verify first running mean() function, run safely().said previously, well commenting codes already good way documentation work.","code":"\ncontain_covid19_missing <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask ==\"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")## [1] \"please provide arg1\"\n## [1] \"please provide arg2\"## Error in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\ncontain_covid19_stop <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\"))\n  \n  if (barrier_gest == \"yes\" & wear_mask ==\"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")## Error in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\nmap(linelist, mean)## $case_id\n## [1] NA\n## \n## $generation\n## [1] 16.56165\n## \n## $date_infection\n## [1] NA\n## \n## $date_onset\n## [1] NA\n## \n## $date_hospitalisation\n## [1] \"2014-11-03\"\n## \n## $date_outcome\n## [1] NA\n## \n## $outcome\n## [1] NA\n## \n## $gender\n## [1] NA\n## \n## $age\n## [1] NA\n## \n## $age_unit\n## [1] NA\n## \n## $age_years\n## [1] NA\n## \n## $age_cat\n## [1] NA\n## \n## $age_cat5\n## [1] NA\n## \n## $hospital\n## [1] NA\n## \n## $lon\n## [1] -13.23381\n## \n## $lat\n## [1] 8.469638\n## \n## $infector\n## [1] NA\n## \n## $source\n## [1] NA\n## \n## $wt_kg\n## [1] 52.64487\n## \n## $ht_cm\n## [1] 124.9633\n## \n## $ct_blood\n## [1] 21.20686\n## \n## $fever\n## [1] NA\n## \n## $chills\n## [1] NA\n## \n## $cough\n## [1] NA\n## \n## $aches\n## [1] NA\n## \n## $vomit\n## [1] NA\n## \n## $temp\n## [1] NA\n## \n## $time_admission\n## [1] NA\n## \n## $bmi\n## [1] 46.89023\n## \n## $days_onset_hosp\n## [1] NA\nsafe_mean <- safely(mean)\nlinelist %>% \n  map(safe_mean)## $case_id\n## $case_id$result\n## [1] NA\n## \n## $case_id$error\n## NULL\n## \n## \n## $generation\n## $generation$result\n## [1] 16.56165\n## \n## $generation$error\n## NULL\n## \n## \n## $date_infection\n## $date_infection$result\n## [1] NA\n## \n## $date_infection$error\n## NULL\n## \n## \n## $date_onset\n## $date_onset$result\n## [1] NA\n## \n## $date_onset$error\n## NULL\n## \n## \n## $date_hospitalisation\n## $date_hospitalisation$result\n## [1] \"2014-11-03\"\n## \n## $date_hospitalisation$error\n## NULL\n## \n## \n## $date_outcome\n## $date_outcome$result\n## [1] NA\n## \n## $date_outcome$error\n## NULL\n## \n## \n## $outcome\n## $outcome$result\n## [1] NA\n## \n## $outcome$error\n## NULL\n## \n## \n## $gender\n## $gender$result\n## [1] NA\n## \n## $gender$error\n## NULL\n## \n## \n## $age\n## $age$result\n## [1] NA\n## \n## $age$error\n## NULL\n## \n## \n## $age_unit\n## $age_unit$result\n## [1] NA\n## \n## $age_unit$error\n## NULL\n## \n## \n## $age_years\n## $age_years$result\n## [1] NA\n## \n## $age_years$error\n## NULL\n## \n## \n## $age_cat\n## $age_cat$result\n## [1] NA\n## \n## $age_cat$error\n## NULL\n## \n## \n## $age_cat5\n## $age_cat5$result\n## [1] NA\n## \n## $age_cat5$error\n## NULL\n## \n## \n## $hospital\n## $hospital$result\n## [1] NA\n## \n## $hospital$error\n## NULL\n## \n## \n## $lon\n## $lon$result\n## [1] -13.23381\n## \n## $lon$error\n## NULL\n## \n## \n## $lat\n## $lat$result\n## [1] 8.469638\n## \n## $lat$error\n## NULL\n## \n## \n## $infector\n## $infector$result\n## [1] NA\n## \n## $infector$error\n## NULL\n## \n## \n## $source\n## $source$result\n## [1] NA\n## \n## $source$error\n## NULL\n## \n## \n## $wt_kg\n## $wt_kg$result\n## [1] 52.64487\n## \n## $wt_kg$error\n## NULL\n## \n## \n## $ht_cm\n## $ht_cm$result\n## [1] 124.9633\n## \n## $ht_cm$error\n## NULL\n## \n## \n## $ct_blood\n## $ct_blood$result\n## [1] 21.20686\n## \n## $ct_blood$error\n## NULL\n## \n## \n## $fever\n## $fever$result\n## [1] NA\n## \n## $fever$error\n## NULL\n## \n## \n## $chills\n## $chills$result\n## [1] NA\n## \n## $chills$error\n## NULL\n## \n## \n## $cough\n## $cough$result\n## [1] NA\n## \n## $cough$error\n## NULL\n## \n## \n## $aches\n## $aches$result\n## [1] NA\n## \n## $aches$error\n## NULL\n## \n## \n## $vomit\n## $vomit$result\n## [1] NA\n## \n## $vomit$error\n## NULL\n## \n## \n## $temp\n## $temp$result\n## [1] NA\n## \n## $temp$error\n## NULL\n## \n## \n## $time_admission\n## $time_admission$result\n## [1] NA\n## \n## $time_admission$error\n## NULL\n## \n## \n## $bmi\n## $bmi$result\n## [1] 46.89023\n## \n## $bmi$error\n## NULL\n## \n## \n## $days_onset_hosp\n## $days_onset_hosp$result\n## [1] NA\n## \n## $days_onset_hosp$error\n## NULL"},{"path":"writing-functions.html","id":"resources-26","chapter":"44 Viết hàm","heading":"44.9 Resources","text":"R Data Science linkCheatsheet advance R programmingCheatsheet purr PackageVideo-ACM talk Hadley Wickham: joy functional programming (map_dbl work)","code":""},{"path":"directories.html","id":"directories","chapter":"45 Tương tác với thư mục làm việc","heading":"45 Tương tác với thư mục làm việc","text":"page cover common scenarios create, interact , save, import directories (folders).","code":""},{"path":"directories.html","id":"preparation-28","chapter":"45 Tương tác với thư mục làm việc","heading":"45.1 Preparation","text":"","code":""},{"path":"directories.html","id":"fs-package","chapter":"45 Tương tác với thư mục làm việc","heading":"fs package","text":"fs package tidyverse package facilitate directory interactions, improving base R functions. sections often use functions fs.","code":"\npacman::p_load(\n  fs,             # file/directory interactions\n  rio,            # import/export\n  here,           # relative file pathways\n  tidyverse)      # data management and visualization"},{"path":"directories.html","id":"print-directory-as-a-dendrogram-tree","chapter":"45 Tương tác với thư mục làm việc","heading":"Print directory as a dendrogram tree","text":"Use function dir_tree() fs.Provide folder filepath path = decide whether want show one level (recurse = FALSE) files sub-levels (recurse = TRUE). use () shorthand R project specify sub-folder “data”, contains data used R handbook. set display files within “data” sub-folders (e.g. “cache”, “epidemic models”, “population”, “shp”, “weather”).","code":"\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)## D:/Book Writing/4. EpiR Book/epiRhandbook_vn/data\n## +-- cache\n## |   \\-- epidemic_models\n## |       +-- 2015-04-30\n## |       |   +-- estimated_reported_cases_samples.rds\n## |       |   +-- estimate_samples.rds\n## |       |   +-- latest_date.rds\n## |       |   +-- reported_cases.rds\n## |       |   +-- summarised_estimated_reported_cases.rds\n## |       |   +-- summarised_estimates.rds\n## |       |   \\-- summary.rds\n## |       +-- epinow_res.rds\n## |       +-- epinow_res_small.rds\n## |       +-- generation_time.rds\n## |       \\-- incubation_period.rds\n## +-- case_linelists\n## |   +-- cleaning_dict.csv\n## |   +-- fluH7N9_China_2013.csv\n## |   +-- linelist_cleaned.rds\n## |   +-- linelist_cleaned.xlsx\n## |   \\-- linelist_raw.xlsx\n## +-- example\n## |   +-- Central Hospital.csv\n## |   +-- district_weekly_count_data.xlsx\n## |   +-- fluH7N9_China_2013.csv\n## |   +-- hospital_linelists.xlsx\n## |   +-- linelists\n## |   |   +-- 20201007linelist.csv\n## |   |   +-- case_linelist20201006.csv\n## |   |   +-- case_linelist_2020-10-02.csv\n## |   |   +-- case_linelist_2020-10-03.csv\n## |   |   +-- case_linelist_2020-10-04.csv\n## |   |   +-- case_linelist_2020-10-05.csv\n## |   |   \\-- case_linelist_2020-10-08.xlsx\n## |   +-- Military Hospital.csv\n## |   +-- Missing.csv\n## |   +-- Other.csv\n## |   +-- Port Hospital.csv\n## |   \\-- St. Mark's Maternity Hospital (SMMH).csv\n## +-- flexdashboard\n## |   +-- outbreak_dashboard.html\n## |   +-- outbreak_dashboard.Rmd\n## |   +-- outbreak_dashboard_shiny.Rmd\n## |   +-- outbreak_dashboard_test.html\n## |   \\-- outbreak_dashboard_test.Rmd\n## +-- gis\n## |   +-- africa_countries.geo.json\n## |   +-- covid_incidence.csv\n## |   +-- covid_incidence_map.R\n## |   +-- linelist_cleaned_with_adm3.rds\n## |   +-- population\n## |   |   +-- sle_admpop_adm3_2020.csv\n## |   |   \\-- sle_population_statistics_sierraleone_2020.xlsx\n## |   \\-- shp\n## |       +-- README.txt\n## |       +-- sle_adm3.CPG\n## |       +-- sle_adm3.dbf\n## |       +-- sle_adm3.prj\n## |       +-- sle_adm3.sbn\n## |       +-- sle_adm3.sbx\n## |       +-- sle_adm3.shp\n## |       +-- sle_adm3.shp.xml\n## |       +-- sle_adm3.shx\n## |       +-- sle_hf.CPG\n## |       +-- sle_hf.dbf\n## |       +-- sle_hf.prj\n## |       +-- sle_hf.sbn\n## |       +-- sle_hf.sbx\n## |       +-- sle_hf.shp\n## |       \\-- sle_hf.shx\n## +-- godata\n## |   +-- cases_clean.rds\n## |   +-- contacts_clean.rds\n## |   +-- followups_clean.rds\n## |   \\-- relationships_clean.rds\n## +-- likert_data.csv\n## +-- linelist_cleaned.xlsx\n## +-- make_evd_dataset.R\n## +-- malaria_app\n## |   +-- app.R\n## |   +-- data\n## |   |   \\-- facility_count_data.rds\n## |   +-- funcs\n## |   |   \\-- plot_epicurve.R\n## |   +-- global.R\n## |   +-- malaria_app.Rproj\n## |   +-- server.R\n## |   \\-- ui.R\n## +-- malaria_facility_count_data.rds\n## +-- phylo\n## |   +-- sample_data_Shigella_tree.csv\n## |   +-- Shigella_subtree_2.nwk\n## |   +-- Shigella_subtree_2.txt\n## |   \\-- Shigella_tree.txt\n## +-- rmarkdown\n## |   +-- outbreak_report.docx\n## |   +-- outbreak_report.html\n## |   +-- outbreak_report.pdf\n## |   +-- outbreak_report.pptx\n## |   +-- outbreak_report.Rmd\n## |   +-- report_tabbed_example.html\n## |   \\-- report_tabbed_example.Rmd\n## +-- standardization\n## |   +-- country_demographics.csv\n## |   +-- country_demographics_2.csv\n## |   +-- deaths_countryA.csv\n## |   +-- deaths_countryB.csv\n## |   \\-- world_standard_population_by_sex.csv\n## +-- surveys\n## |   +-- population.xlsx\n## |   +-- survey_data.xlsx\n## |   \\-- survey_dict.xlsx\n## \\-- time_series\n##     +-- campylobacter_germany.xlsx\n##     \\-- weather\n##         +-- germany_weather2002.nc\n##         +-- germany_weather2003.nc\n##         +-- germany_weather2004.nc\n##         +-- germany_weather2005.nc\n##         +-- germany_weather2006.nc\n##         +-- germany_weather2007.nc\n##         +-- germany_weather2008.nc\n##         +-- germany_weather2009.nc\n##         +-- germany_weather2010.nc\n##         \\-- germany_weather2011.nc"},{"path":"directories.html","id":"list-files-in-a-directory","chapter":"45 Tương tác với thư mục làm việc","heading":"45.2 List files in a directory","text":"list just file names directory can use dir() base R. example, command lists file names files “population” subfolder “data” folder R project. relative filepath provided using () (can read [Import export] page).list full file paths directory’s files, can use can use dir_ls() fs. base R alternative list.files().get metadata information file directory, (e.g. path, modification date, etc.) can use dir_info() fs.can particularly useful want extract last modification time file, example want import recent version file. example , see [Import export] page.data frame returned. Scroll right see columns.","code":"\n# file names\ndir(here(\"data\", \"gis\", \"population\"))## [1] \"sle_admpop_adm3_2020.csv\"                       \n## [2] \"sle_population_statistics_sierraleone_2020.xlsx\"\n# file paths\ndir_ls(here(\"data\", \"gis\", \"population\"))## D:/Book Writing/4. EpiR Book/epiRhandbook_vn/data/gis/population/sle_admpop_adm3_2020.csv\n## D:/Book Writing/4. EpiR Book/epiRhandbook_vn/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n# file info\ndir_info(here(\"data\", \"gis\", \"population\"))"},{"path":"directories.html","id":"file-information","chapter":"45 Tương tác với thư mục làm việc","heading":"45.3 File information","text":"extract metadata information specific file, can use file_info() fs (file.info() base R).use $ index result return modification_time value.","code":"\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time## [1] \"2021-07-12 21:35:27 CEST\""},{"path":"directories.html","id":"check-if-exists","chapter":"45 Tương tác với thư mục làm việc","heading":"45.4 Check if exists","text":"","code":""},{"path":"directories.html","id":"r-objects","chapter":"45 Tương tác với thư mục làm việc","heading":"R objects","text":"can use exists() base R check whether R object exists within R (supply object name quotes).Note base R packages use generic object names like “data” behind scenes, appear TRUE unless inherit = FALSE specified. one reason name dataset “data”.writing function, use missing() base R check argument present , instead exists().","code":"\nexists(\"linelist\")## [1] TRUE\nexists(\"data\")## [1] TRUE\nexists(\"data\", inherit = FALSE)## [1] FALSE"},{"path":"directories.html","id":"directories-1","chapter":"45 Tương tác với thư mục làm việc","heading":"Directories","text":"check whether directory exists, provide file path (file name) is_dir() fs. Scroll right see TRUE printed.alternative file.exists() base R.","code":"\nis_dir(here(\"data\"))## D:/Book Writing/4. EpiR Book/epiRhandbook_vn/data \n##                                              TRUE"},{"path":"directories.html","id":"files","chapter":"45 Tương tác với thư mục làm việc","heading":"Files","text":"check specific file exists, use is_file() fs. Scroll right see TRUE printed.base R alternative file.exists().","code":"\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))## D:/Book Writing/4. EpiR Book/epiRhandbook_vn/data/case_linelists/linelist_cleaned.rds \n##                                                                                  TRUE"},{"path":"directories.html","id":"create","chapter":"45 Tương tác với thư mục làm việc","heading":"45.5 Create","text":"","code":""},{"path":"directories.html","id":"directories-2","chapter":"45 Tương tác với thư mục làm việc","heading":"Directories","text":"create new directory (folder) can use dir_create() fs. directory already exists, overwritten error returned.alternative dir.create() base R, show error directory already exists. contrast, dir_create() scenario silent.","code":"\ndir_create(here(\"data\", \"test\"))"},{"path":"directories.html","id":"files-1","chapter":"45 Tương tác với thư mục làm việc","heading":"Files","text":"can create (empty) file file_create() fs. file already exists, -written changed.base R alternative file.create(). file already exists, option truncate . use file_create() file left unchanged.","code":"\nfile_create(here(\"data\", \"test.rds\"))"},{"path":"directories.html","id":"create-if-does-not-exists","chapter":"45 Tương tác với thư mục làm việc","heading":"Create if does not exists","text":"CONSTRUCTION","code":""},{"path":"directories.html","id":"delete","chapter":"45 Tương tác với thư mục làm việc","heading":"45.6 Delete","text":"","code":""},{"path":"directories.html","id":"r-objects-1","chapter":"45 Tương tác với thư mục làm việc","heading":"R objects","text":"Use rm() base R remove R object.","code":""},{"path":"directories.html","id":"directories-3","chapter":"45 Tương tác với thư mục làm việc","heading":"Directories","text":"Use dir_delete() fs.","code":""},{"path":"directories.html","id":"files-2","chapter":"45 Tương tác với thư mục làm việc","heading":"Files","text":"can delete files file_delete() fs.","code":""},{"path":"directories.html","id":"running-other-files","chapter":"45 Tương tác với thư mục làm việc","heading":"45.7 Running other files","text":"","code":""},{"path":"directories.html","id":"source","chapter":"45 Tương tác với thư mục làm việc","heading":"source()","text":"run one R script another R script, can use source() command (base R).equivalent viewing R script clicking “Source” button upper-right script. execute script silently (output R console) unless specifically intended. See page [Interactive console] examples using source() interact user via R console question--answer mode.","code":"\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))"},{"path":"directories.html","id":"render","chapter":"45 Tương tác với thư mục làm việc","heading":"render()","text":"render() variation source() often used R markdown scripts. provide input = R markdown file, also output_format = (typically either “html_document”, “pdf_document”, “word_document”, \"\")See page [Reports R Markdown] details. Also see documentation render() entering ?render.","code":""},{"path":"directories.html","id":"run-files-in-a-directory","chapter":"45 Tương tác với thư mục làm việc","heading":"Run files in a directory","text":"can create loop use source() every file directory, identified dir().want run certain scripts, can identify name like :comparison fs base R functions.","code":"\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) {   # for each script name in the R Project's \"scripts\" folder (with .R extension)\n  source(here(\"scripts\", script))                        # source the file with the matching name that exists in the scripts folder\n}\nscripts_to_run <- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}"},{"path":"directories.html","id":"import-files-in-a-directory","chapter":"45 Tương tác với thư mục làm việc","heading":"Import files in a directory","text":"See page [Import export] importing exporting individual files.Also see [Import export] page methods automatically import recent file, based date file name looking file meta-data.See page [Iteration, loops, lists] example package purrr demonstrating:Splitting data frame saving multiple CSV filesSplitting data frame saving part separate sheet within one Excel workbookImporting multiple CSV files combining one dataframeImporting Excel workbook multiple sheets combining one dataframe","code":""},{"path":"directories.html","id":"base-r-3","chapter":"45 Tương tác với thư mục làm việc","heading":"45.8 base R","text":"See functions list.files() dir(), perform operation listing files within specified directory. can specify ignore.case = specific pattern look .file currently “open”, display folder tilde front, like “~$hospital_linelists.xlsx”.","code":"\nlist.files(path = here(\"data\"))\n\nlist.files(path = here(\"data\"), pattern = \".csv\")\n# dir(path = here(\"data\"), pattern = \".csv\")\n\nlist.files(path = here(\"data\"), pattern = \"evd\", ignore.case = TRUE)"},{"path":"directories.html","id":"resources-27","chapter":"45 Tương tác với thư mục làm việc","heading":"45.9 Resources","text":"https://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html","code":""},{"path":"collaboration.html","id":"collaboration","chapter":"46 Version control với Git và Github","heading":"46 Version control với Git và Github","text":"chapter presents overview using Git collaborate others.\nextensive tutorials can \nfound bottom Resources section.","code":""},{"path":"collaboration.html","id":"what-is-git","chapter":"46 Version control với Git và Github","heading":"46.1 What is Git?","text":"Git version control software allows tracking changes \nfolder. can used like “track change” option Word, LibreOffice \nGoogle docs, types files. one powerful\nused options version control.never heard ? - people developer\nbackground routinely learn use version control software (Git,\nMercurial, Subversion others), us \nquantitative disciplines taught skills. Consequently, epidemiologists never\nhear studies, learn fly.Wait, heard Github, ? - exactly, \noften use together, show . short:Git version control system, piece software. can use \nlocally computer synchronize folder \nhost website. default, one uses terminal give Git\ninstructions command-line.Git version control system, piece software. can use \nlocally computer synchronize folder \nhost website. default, one uses terminal give Git\ninstructions command-line.can use Git client/interface avoid command-line \nperform actions (least simple, super common\nones).can use Git client/interface avoid command-line \nperform actions (least simple, super common\nones).want store folder host website \ncollaborate others, may create account Github,\nGitlab, Bitbucket others.want store folder host website \ncollaborate others, may create account Github,\nGitlab, Bitbucket others.use client/interface Github Desktop, uses\nGit background manage files, locally \ncomputer, remotely Github server.","code":""},{"path":"collaboration.html","id":"why-use-the-combo-git-and-github","chapter":"46 Version control với Git và Github","heading":"46.2 Why use the combo Git and Github?","text":"Using Git facilitates:Archiving documented versions incremental changes \ncan easily revert backwards previous stateHaving parallel branches, .e. developing/“working” versions \nstructured ways integrate changes reviewThis can done locally computer, even don’t collaborate\npeople. ever:regretted deleted section code, realize two\nmonths later actually needed ?regretted deleted section code, realize two\nmonths later actually needed ?come back project pause attempted \nremember whether made tricky modification one \nmodels?come back project pause attempted \nremember whether made tricky modification one \nmodels?file model_1.R another file model_1_test.R file\nmodel_1_not_working.R try things ?file model_1.R another file model_1_test.R file\nmodel_1_not_working.R try things ?file report.Rmd, file report_full.Rmd, file\nreport_true_final.Rmd, file report_final_20210304.Rmd, file\nreport_final_20210402.Rmd cursed archiving skills?file report.Rmd, file report_full.Rmd, file\nreport_true_final.Rmd, file report_final_20210304.Rmd, file\nreport_final_20210402.Rmd cursed archiving skills?Git help , worth learn alone.However, becomes even powerful used online repository\nGithub support collaborative projects. facilitates:Collaboration: others can review, comment , \naccept/decline changesCollaboration: others can review, comment , \naccept/decline changesSharing code, data, outputs, invite feedback\npublic (privately, team)Sharing code, data, outputs, invite feedback\npublic (privately, team)avoids:“Oops, forgot send last version now need \nredo two days worth work new file”“Oops, forgot send last version now need \nredo two days worth work new file”Mina, Henry Oumar worked time one script \nneed manually merge changesMina, Henry Oumar worked time one script \nneed manually merge changesTwo people try modify file Dropbox Sharepoint\ncreates synchronization error.Two people try modify file Dropbox Sharepoint\ncreates synchronization error.","code":""},{"path":"collaboration.html","id":"this-sounds-complicated-i-am-not-a-programmer","chapter":"46 Version control với Git và Github","heading":"This sounds complicated, I am not a programmer","text":"can . Examples advanced uses can quite scary. However, much\nlike R, even Excel, don’t need become expert reap \nbenefits tool. Learning small number functions notions\nlets track changes, synchronize files online\nrepository collaborate colleagues short amount\ntime.Due learning curve, emergency context may best time\nlearn tools. learning can achieved steps. acquire\ncouple notions, workflow can quite efficient fast.\nworking project collaborating people\nGit necessity, actually good time get\nconfident using solo diving collaboration.","code":""},{"path":"collaboration.html","id":"setup","chapter":"46 Version control với Git và Github","heading":"46.3 Setup","text":"","code":""},{"path":"collaboration.html","id":"install-git","chapter":"46 Version control với Git và Github","heading":"Install Git","text":"Git engine behind scenes computer, tracks\nchanges, branches (versions), merges, reverting. must first\ninstall Git https://git-scm.com/downloads.","code":""},{"path":"collaboration.html","id":"install-an-interface-optional-but-recommended","chapter":"46 Version control với Git và Github","heading":"Install an interface (optional but recommended)","text":"Git language commands, can typed command\nline terminal. However, many clients/interfaces non-developpers, \nday--day use, rarely need interact Git directly \ninterface usually provide nice visualisation tools file modifications branches.Many options exist, OS, beginner friendly complex ones.\nGood options beginners include RStudio Git pane \nGithub Desktop, showcase \nchapter.\nIntermediate (powerfull, complex) options include Source Tree,\nGitkracken, Smart Git others.Quick explanation Git clients.Note: since interfaces actually use Git internally, can try several \n, switch one another given project, use console punctually\naction interface support, even perform number \nactions online Github.noted , may occasionally write Git commands \nterminal RStudio terminal pane (tab adjacent R\nConsole) Git Bash terminal.","code":""},{"path":"collaboration.html","id":"github-account","chapter":"46 Version control với Git và Github","heading":"Github account","text":"Sign-free account github.com.may offered set-two-factor authentication app \nphone. Read Github help\ndocuments.use Github Desktop, can enter Gitub credentials \ninstallation following \nsteps.\ndon’t know, credentials asked later try \nclone project Github.","code":""},{"path":"collaboration.html","id":"vocabulary-concepts-and-basic-functions","chapter":"46 Version control với Git và Github","heading":"46.4 Vocabulary, concepts and basic functions","text":"learning R, bit vocabulary remember \nunderstand Git. basics get \ngoing\n/ interactive tutorial. next\nsections, show use interfaces, good\nvocabulary concepts mind, build mental model,\n’ll need using interfaces anyway.","code":""},{"path":"collaboration.html","id":"repository","chapter":"46 Version control với Git và Github","heading":"Repository","text":"Git repository (“repo”) folder contains \nsub-folders files project (data, code, images, etc.) \nrevision histories. begin tracking changes \nrepository , Git create hidden folder contains\ntracking information. typical Git repository \nR Project folder (see handbook page [R projects]).show create (initialize) Git repository\nGithub, Github Desktop Rstudio next\nsections.","code":""},{"path":"collaboration.html","id":"commits","chapter":"46 Version control với Git và Github","heading":"Commits","text":"commit snapshot project given time.\nmake change project, make new commit\ntrack changes (delta) made \nfiles. example, perhaps edited lines code updated \nrelated dataset. changes saved, can bundle \nchanges together one “commit”.commit unique ID (hash). version control purposes,\ncan revert project back time based commits, best\nkeep relatively small coherent. also attach brief\ndescription changes called “commit message”.Staged changes? stage changes add staging area\npreparation next commit. idea can finely\ndecide changes include given commit. example, \nworked model specification one script, later figure \nanother script, make sense two different commits (easier\ncase wanted revert changes figure model).","code":""},{"path":"collaboration.html","id":"branches","chapter":"46 Version control với Git và Github","heading":"Branches","text":"branch represents independent line changes repo, \nparallel, alternate version project files.Branches useful test changes incorporated \nmain branch, usually primary/final/“live” version \nproject. done experimenting branch, can bring\nchanges main branch, merging , delete , \nchanges successful.Note: collaborate people use branches,\nneed remote online repository.","code":""},{"path":"collaboration.html","id":"local-and-remote-repositories","chapter":"46 Version control với Git và Github","heading":"Local and remote repositories","text":"clone create copy Git repository another place.example, can clone online repository Github locally \ncomputer, begin local repository clone\nonline Github.cloned repository, project files exist \ntwo places:LOCAL repository physical computer. \nmake actual changes files/code.LOCAL repository physical computer. \nmake actual changes files/code.REMOTE, online repository: versions project files\nGithub repository (web\nhost).REMOTE, online repository: versions project files\nGithub repository (web\nhost).synchronize repositories, use functions. Indeed,\nunlike Sharepoint, Dropbox synchronizing software, Git \nautomatically update local repository based ’s online,\nvice-versa. get choose synchronize.git fetch downloads new changes remote repository \nchange local repository. Think checking state remote repository.git fetch downloads new changes remote repository \nchange local repository. Think checking state remote repository.git pull downloads new changes remote repositories\nupdate local repository.git pull downloads new changes remote repositories\nupdate local repository.made one several commits locally, can\ngit push commits remote repository. sends \nchanges Github people can see pull \nwant .made one several commits locally, can\ngit push commits remote repository. sends \nchanges Github people can see pull \nwant .","code":""},{"path":"collaboration.html","id":"get-started-create-a-new-repository","chapter":"46 Version control với Git và Github","heading":"46.5 Get started: create a new repository","text":"many ways create new repositories. can \nconsole, Github, interface.Two general approaches set-:Create new R Project existing new Github repository\n(preferred beginners), orCreate Github repository existing R project","code":""},{"path":"collaboration.html","id":"start-up-files","chapter":"46 Version control với Git và Github","heading":"Start-up files","text":"create new repository, can optionally create\nfiles, can add repository later stage.\ntypically live “root” folder repository.README file file someone can read understand \nproject exists else know use . \nempty first, complete later.README file file someone can read understand \nproject exists else know use . \nempty first, complete later..gitignore file text file line contain\nfolders files Git ignore (track changes). Read\nsee examples\n..gitignore file text file line contain\nfolders files Git ignore (track changes). Read\nsee examples\n.can choose license work, people\nknow conditions can use reproduce work. \ninformation, see Creative Commons\nlicenses.can choose license work, people\nknow conditions can use reproduce work. \ninformation, see Creative Commons\nlicenses.","code":""},{"path":"collaboration.html","id":"create-a-new-repository-in-github","chapter":"46 Version control với Git và Github","heading":"Create a new repository in Github","text":"create new repository, log Github look green\nbutton create new repository. now empty repository can \ncloned locally computer (see next section).must choose want repository public (visible \neveryone internet) private (visible \npermission). important implications data sensitive.\nrepository private encounter quotas advanced\nspecial circumstances, using Github actions \nautomatically run code cloud.","code":""},{"path":"collaboration.html","id":"clone-from-a-github-repository","chapter":"46 Version control với Git và Github","heading":"Clone from a Github repository","text":"can clone existing Github repository create\nnew local R project computer.Github repository one already exists contains\ncontent, empty repository just created. \nlatter case essentially creating Github repo local R\nproject time (see instructions ).Note: contributing rights Github repository,\npossible first fork repository profile, \nproceed actions. Forking explained end \nchapter, recommend read sections first.Step 1: Navigate Github repository, click green “Code”\nbutton copy HTTPS clone URL (see image )next step can performed interface. illustrate \nRstudio Github desktop.","code":""},{"path":"collaboration.html","id":"in-rstudio","chapter":"46 Version control với Git và Github","heading":"In Rstudio","text":"RStudio, start new R project clicking File > New Project >\nVersion Control > GitWhen prompted “Repository URL”, paste HTTPS URL \nGithubAssign R project short, informative nameChoose new R Project saved locallyCheck “Open new session” click “Create project”now new, local, RStudio project clone \nGithub repository. local project Github repository now\nlinked.","code":""},{"path":"collaboration.html","id":"in-github-desktop","chapter":"46 Version control với Git và Github","heading":"In Github Desktop","text":"Click File > Clone repositoryClick File > Clone repositorySelect URL tabSelect URL tabPaste HTTPS URL Github first boxPaste HTTPS URL Github first boxSelect folder want local repositorySelect folder want local repositoryClick “CLONE”Click “CLONE”","code":""},{"path":"collaboration.html","id":"new-github-repo-from-existing-r-project","chapter":"46 Version control với Git và Github","heading":"New Github repo from existing R project","text":"alternative setup scenario existing R project\ncontent, want create Github repository .Create new, empty Github repository project (see\ninstructions )Clone repository locally (see HTTPS instructions )Copy content pre-existing R\nproject (codes, data, etc.) new empty, local, repository (e.g. use copy paste).Open new project RStudio, go Git pane. new files \nregister file changes, now tracked Git. Therefore, can\nbundle changes commit push Github.\npushed, repository Github reflect files.See Github workflow section details process.","code":""},{"path":"collaboration.html","id":"what-does-it-look-like-now","chapter":"46 Version control với Git và Github","heading":"What does it look like now?","text":"","code":""},{"path":"collaboration.html","id":"in-rstudio-1","chapter":"46 Version control với Git và Github","heading":"In RStudio","text":"cloned Github repository new R project,\nnow see RStudio “Git” tab. tab appears RStudio pane\nR Environment:Please note buttons circled image , \nreferenced later (left right):Button commit saved file changes local\nbranch (open new window)Blue arrow pull (update local version branch \nchanges made remote/Github version branch)Green arrow push (send commits/changes local\nversion branch remote/Github version branch)Git tab RStudioButton create NEW branch using whichever local branch shown\nright base. almost always want branch \nmain branch (first pull update main branch)branch currently working inChanges made code files appear ","code":""},{"path":"collaboration.html","id":"in-github-desktop-1","chapter":"46 Version control với Git và Github","heading":"In Github Desktop","text":"Github Desktop independent application allows manage\nrepositories. open , interface allows \nchoose repository want work , perform basic Git\nactions .","code":""},{"path":"collaboration.html","id":"git-github-workflow","chapter":"46 Version control với Git và Github","heading":"46.6 Git + Github workflow","text":"","code":""},{"path":"collaboration.html","id":"process-overview","chapter":"46 Version control với Git và Github","heading":"Process overview","text":"completed setup (described ), \nGithub repo connected (cloned) local R project. \nmain branch (created default) -called “live” version \nfiles. want make modifications, good\npractice create new branch main branch (like “Make \nCopy”). typical workflow Git creating branch \neasy fast.typical workflow follow:Make sure local repository --date, update \nnotMake sure local repository --date, update \nnotGo branch working previously, create new\nbranch try thingsGo branch working previously, create new\nbranch try thingsWork files locally computer, make one several\ncommits branchWork files locally computer, make one several\ncommits branchUpdate remote version branch changes (push)Update remote version branch changes (push)satisfied branch, can merge online\nversion working branch online “main” branch \ntransfer changesWhen satisfied branch, can merge online\nversion working branch online “main” branch \ntransfer changesOther team members may thing branches,\nperhaps contributing commits working branch well.go process step--step detail .\nschematic ’ve developed - ’s format two-way\ntable help epidemiologists understand.’s another diagram.Note: recently, term “master” branch used, now\nreferred “main” branch.Image\nsource","code":""},{"path":"collaboration.html","id":"create-a-new-branch","chapter":"46 Version control với Git và Github","heading":"46.7 Create a new branch","text":"select branch work , Git resets working directory\nway last time branch.","code":""},{"path":"collaboration.html","id":"in-rstudio-git-pane","chapter":"46 Version control với Git và Github","heading":"In Rstudio Git pane","text":"Ensure “main” branch, click purple icon \ncreate new branch (see image ).prompted name branch one-word descriptive\nname (can use underscores needed).see locally, still R project, \nlonger working “main” branch.created, new branch also appear Github website\nbranch.can visualize branches Git Pane Rstudio clicking “History”","code":""},{"path":"collaboration.html","id":"in-github-desktop-2","chapter":"46 Version control với Git và Github","heading":"In Github Desktop","text":"process much similar, prompted give branch\nname. , prompted “Publish branch Github” \nmake new branch appear remote repo well.","code":""},{"path":"collaboration.html","id":"in-console","chapter":"46 Version control với Git và Github","heading":"In console","text":"actually happening behind scenes create new\nbranch git branch, go branch \ngit checkout (.e. tell Git next commits occur ).\ngit repository:information using console, see section \nGit commands end.","code":"git branch my-new-branch  # Create the new branch branch\ngit checkout my-new-branch # Go to the branch\ngit checkout -b my-new-branch # Both at once (shortcut)"},{"path":"collaboration.html","id":"commit-changes","chapter":"46 Version control với Git và Github","heading":"46.8 Commit changes","text":"Now can edit code, add new files, update datasets, etc.Every one changes tracked, respective file \nsaved. Changed files appear RStudio Git tab, Github\nDesktop, using command git status terminal (see ).Whenever make substantial changes (e.g. adding updating section \ncode), pause commit changes. Think commit “batch”\nchanges related common purpose. can always continue \nrevise file committed changes .Advice commits: generally, better make small commits, \ncan easily reverted problem arises, commit together\nmodifications related common purpose. achieve , \nfind commit often. beginning, ’ll probably\nforget commit often, habit kicks .","code":""},{"path":"collaboration.html","id":"in-rstudio-2","chapter":"46 Version control với Git và Github","heading":"In Rstudio","text":"example shows , since last commit, R Markdown script “collaboration.Rmd” changed,\nseveral PNG images added.might wondering yellow, blue, green, red squares next \nfile names represent. snapshot RStudio\ncheatsheet\nexplains meaning. Note changes yellow “?” can still\nstaged, committed, pushed.Press “Commit” button Git tab, open new\nwindow (shown )Press “Commit” button Git tab, open new\nwindow (shown )Click file name upper-left boxClick file name upper-left boxReview changes made file (highlighted green\nred)Review changes made file (highlighted green\nred)“Stage” file, include changes commit. \nchecking box next file name. Alternatively, \ncan highlight multiple file names click “Stage”“Stage” file, include changes commit. \nchecking box next file name. Alternatively, \ncan highlight multiple file names click “Stage”Write commit message short descriptive (required)Write commit message short descriptive (required)Press “Commit” button. pop-box appear showing success\nerror message.Press “Commit” button. pop-box appear showing success\nerror message.Now can make changes commits, many times like","code":""},{"path":"collaboration.html","id":"in-github-desktop-3","chapter":"46 Version control với Git và Github","heading":"In Github Desktop","text":"can see list files changed left. \nselect text file, see summary modifications made\nright pane (view work complex files like .docs .xlsx).stage changes, just tick little box near file names. \nselected files want add commit, give commit\nname, optionally description click commit\nbutton.","code":""},{"path":"collaboration.html","id":"in-console-1","chapter":"46 Version control với Git và Github","heading":"In console","text":"two functions used behind scenes git add select/stage\nfiles git commit actually commit.","code":"git status # see the changes \n\ngit add new_pages/collaboration.Rmd  # select files to commit (= stage the changes)\n\ngit commit -m \"Describe commit from Github Desktop\" # commit the changes with a message\n\ngit log  # view information on past commits"},{"path":"collaboration.html","id":"amend-a-previous-commit","chapter":"46 Version control với Git và Github","heading":"Amend a previous commit","text":"happens commit changes, carry working, realize\nmade changes “belong” past commit (opinion).\nFear ! can append changes previous commit.Rstudio, pretty obvious “Amend previous commit”\nbox line COMMIT button.unclear reason, functionality implemented\nGithub Desktop, (conceptually awkward easy)\nway around. committed pushed changes yet,\n“UNDO” button appears just COMMIT button. Click \nrevert commit (keep staged files commit message).\nSave changes, add new files commit necessary commit .console:Note: think modifying commits already public shared collaborators.","code":"git add [YOUR FILES] # Stage your new changes\n\ngit commit --amend  # Amend the previous commit\n\ngit commit --amend -m \"An updated commit message\"  # Amend the previous commit AND update the commit message"},{"path":"collaboration.html","id":"pull-and-push-changes-up-to-github","chapter":"46 Version control với Git và Github","heading":"46.9 Pull and push changes up to Github","text":"“First PULL, PUSH”good practice fetch pull begin working \nproject, update branch version local computer \nchanges made remote/Github version.PULL often. Don’t hesitate. Always pull pushing.changes made committed happy \nstate project, can push commits \nremote/Github version branch.Rince repeat working repository.Note: much easier revert changes committed \npushed (.e. still local) revert changes pushed \nremote repository (perhaps already pulled someone else), better\npush done introducing changes task \nworking .","code":""},{"path":"collaboration.html","id":"in-rstudio-3","chapter":"46 Version control với Git và Github","heading":"In Rstudio","text":"PULL - First, click “Pull” icon (downward arrow) fetches \npulls time.PUSH - Clicking green “Pull” icon (upward arrow). may asked\nenter Github username password. first time \nasked, may need enter two Git command lines Terminal:git config –global user.email\n“@example.com” (Github\nemail address), andgit config –global user.name “Github username”learn enter commands, see section \nGit commands.TIP: Asked provide password often? See chapters\n10 & 11 \ntutorial\nconnect repository using SSH key (\ncomplicated)","code":""},{"path":"collaboration.html","id":"in-github-desktop-4","chapter":"46 Version control với Git và Github","heading":"In Github Desktop","text":"Click “Fetch origin” button check new commits \nremote repository.Git finds new commits remote repository, button \nchange “Pull” button. button used push \npull, push changes don’t pull .can go “History” tab (near “Changes” tab) see \ncommits (others). nice way acquainting \ncollaborators . can read commit message, \ndescription one, compare code two files using\ndiff pane.remote changes pulled, least one local change\ncommitted, can push clicking button.","code":""},{"path":"collaboration.html","id":"console","chapter":"46 Version control với Git và Github","heading":"Console","text":"Without surprise, commands fetch, pull push.","code":"git fetch  # are there new commits in the remote directory?\ngit pull   # Bring remote commits into your local branch\ngit push   # Puch local commits of this branch to the remote branch"},{"path":"collaboration.html","id":"i-want-to-pull-but-i-have-local-work","chapter":"46 Version control với Git và Github","heading":"I want to pull but I have local work","text":"can happen sometimes:\nmade changes local repository, remote\nrepository commits didn’t pull.Git refuse pull might overwrite changes.\nseveral strategies keep changes,\nwell described Happy Git R,\namong two main ones :\n- commit changes, fetch remote changes, pull , resolve conflicts\nneeded (see section ), push everything online\n- stash changes, sort stores aside, pull, unstash\n(restore), commit, solve conflicts, push.files concerned remote changes files concerned\nlocal changes overlap, Git may solve conflicts automatically.Github Desktop, can done buttons. stash, go Branch > Stash changes.","code":""},{"path":"collaboration.html","id":"merge-branch-into-main","chapter":"46 Version control với Git và Github","heading":"46.10 Merge branch into Main","text":"finished making changes, can begin process \nmerging changes main branch. Depending situation,\nmay fast, may deliberate review approval\nsteps involving teammates.","code":""},{"path":"collaboration.html","id":"locally-in-github-desktop","chapter":"46 Version control với Git và Github","heading":"Locally in Github Desktop","text":"One can merge branches locally using Github Desktop. First, go \n(checkout) branch recipient commits, words, \nbranch want update. go menu Branch > Merge \ncurrent branch click. box allow select branch \nwant import .","code":""},{"path":"collaboration.html","id":"in-console-2","chapter":"46 Version control với Git và Github","heading":"In console","text":"First move back branch recipient changes.\nusually master, another branch. merge \nworking branch master.\npage\nshows advanced example branching explains bit \nhappening behind scenes.","code":"git checkout master  # Go back to master (or to the branch you want to move your )\ngit merge this_fancy_new_branch"},{"path":"collaboration.html","id":"in-github-submitting-pull-requests","chapter":"46 Version control với Git và Github","heading":"In Github: submitting pull requests","text":"totally possible merge two branches locally, without\ninforming anybody, merge may discussed investigated several\npeople integrated master branch. help \nprocess, Github offers discussion features around merge: \npull request.pull request (“PR”) request merge one branch another\n(words, request working branch pulled “main” branch).\npull request typically involves multiple commits. pull request usually begins conversation review\nprocess accepted branch merged. example,\ncan read pull request discussions dplyr’s\ngithub.can submit pull request (PR) directly form website (\nillustrated bellow) Github Desktop.Go Github repository (online)View tab “Pull Requests” click “New pull request” buttonSelect drop-menu merge branch mainWrite detailed Pull Request comment click “Create Pull\nRequest”.image , branch “forests” selected merged\n“main”:Now able see pull request (example image ):Review tab “Files changed” see “main” branch \nchange branch merged.right, can request review members team \ntagging Github ID. like, can set repository\nsettings require one approving review order merge \nmain.pull request approved, button \n“Merge pull request” become active. Click .completed, delete branch explained .","code":""},{"path":"collaboration.html","id":"resolving-conflicts","chapter":"46 Version control với Git và Github","heading":"Resolving conflicts","text":"two people modified line(s) time, \nmerge conflict arises. Indeed, Git refuses make decision \nversion keep, helps find \nconflict . PANIC. time, pretty straightforward\nresolve.example, Github:merge raised conflict, open file favorite editor.\nconflict indicated series characters:text <<<<<<< HEAD ======= comes \nlocal repository, one ======= >>>>>>> \nbranch (may origin, master branch \nchoice).need decide version code prefer (even write \nthird, including changes sides pertinent), delete rest\nremove marks Git added (<<<<<<< HEAD, =======,\n>>>>>>> origin/master/your_branch_name)., save file, stage commit : commit\nmakes merged version “official”. forget push afterwards.often collaborators pull push, smaller \nconflicts .Note: feel ease console, advanced\nmerging\noptions\n(e.g. ignoring whitespace, giving collaborator priority etc.).","code":""},{"path":"collaboration.html","id":"delete-your-branch","chapter":"46 Version control với Git và Github","heading":"Delete your branch","text":"branch merged master longer needed, can\ndelete .","code":""},{"path":"collaboration.html","id":"github-rstudio","chapter":"46 Version control với Git và Github","heading":"46.10.0.1 Github + Rstudio","text":"Go repository Github click button view \nbranches (next drop-select branches). Now find \nbranch click trash icon next . Read detail deleting\nbranch\n.sure also delete branch locally computer. \nhappen automatically.RStudio, make sure Main branchSwitch typing Git commands RStudio “Terminal” (tab\nadjacent R console), type: git branch -d\nbranch_name, “branch_name” name branch \ndeletedRefresh Git tab branch gone","code":""},{"path":"collaboration.html","id":"in-github-desktop-5","chapter":"46 Version control với Git và Github","heading":"46.10.0.2 In Github Desktop","text":"Just checkout branch want delete, go menu\nBranch > Delete.","code":""},{"path":"collaboration.html","id":"forking","chapter":"46 Version control với Git và Github","heading":"Forking","text":"can fork project like contribute \nrights , just\nwant modify personal use. \nshort description forking can found .Github, click “Fork” button:clone original repository, profile. now,\ntwo versions repository Github: original one,\nmodify, cloned version profile., can proceed clone version online repository locally\ncomputer, using methods described previous sections.\n, can create new branch, make changes, commit push \nremote repository.happy result can create Pull Request\nGithub Github Desktop begin conversation \nowners/maintainers original repository.need newer commits official repository?Imagine someone makes critical modification official repository,\nwant include cloned version.\npossible synchronize fork official repository.\ninvolves using terminal, complicated.\nmostly need remember :\n- upstream = official repository, one modify\n- origin = version repository Github profileYou can read tutorial follow along :First, type Git terminal (inside repo):yet configured upstream repository \nsee two lines, beginning origin. show remote repo\nfetch push point . Remember, origin conventional\nnickname version repository Github. example:Now, add new remote repository:address address Github generates clone\nrepository (see section cloning). Now four remote pointers:Now setup done, whenever want get changes \noriginal (upstream) repository, just go (checkout) \nbranch want update type:conflicts, solve , explained\nResolving conflicts section.Summary: forking cloning, Github server side.\nrest actions typical collaboration workflow actions\n(clone, push, pull, commit, merge, submit pull requests…).Note: forking concept, Git command, also exist Web hosts, like Bitbucket.","code":"git remote -vgit remote add upstream https://github.com/epirhandbook/Epi_R_handbook.gitgit fetch upstream # Get the new commits from the remote repository\ngit checkout the_branch_you_want_to_update\ngit merge upstream/the_branch_you_want_to_update  # Merge the upstream branch into your branch.\ngit push # Update your own version of the remote repo"},{"path":"collaboration.html","id":"what-we-learned","chapter":"46 Version control với Git và Github","heading":"46.11 What we learned","text":"learned :setup Git track modifications folders,connect local repository remote online repository,commit changes,synchronize local remote repositories.get going enough needs \nepidemiologists. usually advanced usage developers.However, know want (need) go , Git offers power simplify\ncommit histories, revert one several commits, cherry-pick commits, etc.\nmay sound like pure wizardry, now basics,\neasier build .Note Git pane Rstudio Github Desktop good \nbeginners / day--day usage line work, offer \ninterface intermediate / advanced Git functions.\ncomplete interfaces allows point--click\n(usually cost complex layout).Remember since can use tool point track repository,\ncan easily install interface try sometimes,\nperform less common complex task occasionally,\npreferring simplified interface rest time (e.g. using\nGithub Desktop time, switching SourceTree Gitbash specific tasks).","code":""},{"path":"collaboration.html","id":"git","chapter":"46 Version control với Git và Github","heading":"46.12 Git commands","text":"","code":""},{"path":"collaboration.html","id":"recommended-learning","chapter":"46 Version control với Git và Github","heading":"Recommended learning","text":"learn Git commands interactive tutorial, see \nwebsite.","code":""},{"path":"collaboration.html","id":"where-to-enter-commands","chapter":"46 Version control với Git và Github","heading":"Where to enter commands","text":"enter commands Git shell.Option 1 can open new Terminal RStudio. tab next \nR Console. type text , click \ndrop-menu “Terminal” select “New terminal”. Type \ncommands blinking space front dollar sign “$”.Option 2 can also open shell (terminal enter commands) \nclicking blue “gears” icon Git tab (near RStudio\nEnvironment). Select “Shell” drop-menu. new window \nopen can type commands dollar sign “$”.Option 3 Right click open “Git Bash ” open \nsort terminal, open Git Bash form application list.\nbeginner-friendly informations Git Bash,\nfind bash commands need.","code":""},{"path":"collaboration.html","id":"sample-commands","chapter":"46 Version control với Git và Github","heading":"Sample commands","text":"present common git commands. use , keep mind\nbranch active (checked-), change action!commands ,  represents branch name.\n represents hash ID specific\ncommit.  represents number. type \n< > symbols.","code":""},{"path":"collaboration.html","id":"resources-28","chapter":"46 Version control với Git và Github","heading":"46.13 Resources","text":"Much page informed “Happy Git R”\nwebsite Jenny Bryan. helpful\nsection website helps troubleshoot common Git \nR-related errors.Github.com documentation start\nguide.RStudio “IDE”\ncheatsheet\nincludes tips Git RStudio.https://ohi-science.org/news/github-going-back--timeGit commands beginnersAn interactive\ntutorial learn\nGit commands.https://www.freecodecamp.org/news/-introduction--git--absolute-beginners-86fa1d32ff71/:\ngood learning absolute basics track changes one folder \ncomputer.Nice schematics understand branches:\nhttps://speakerdeck.com/alicebartlett/git--humansTutorials covering basic advanced subjectshttps://tutorialzine.com/2016/06/learn-git--30-minuteshttps://dzone.com/articles/git-tutorial-commands--operations--git\nhttps://swcarpentry.github.io/git-novice/ (short course)\nhttps://rsjakob.gitbooks.io/git/content/chapter1.htmlThe Pro Git book considered official reference.\nchapters ok, usually bit technical. probably good resource\nused Git bit want learn bit precisely\nhappens go .","code":""},{"path":"errors.html","id":"errors","chapter":"47 Các lỗi thường gặp","heading":"47 Các lỗi thường gặp","text":"Chương này bao gồm một danh sách các lỗi phổ biến và các giải pháp đề xuất để khắc phục chúng.","code":""},{"path":"errors.html","id":"phiên-giải-thông-báo-lỗi","chapter":"47 Các lỗi thường gặp","heading":"47.1 Phiên giải thông báo lỗi","text":"Các lỗi trong R đôi khi có thể khó hiểu, vì vậy Google là bạn của bạn. Tìm kiếm thông báo lỗi với “R” và tìm các bài đăng gần đây trong StackExchange.com, stackoverflow.com, community.rstudio.com, twitter (#rstats), và các diễn đàn khác được lập trình viên sử dụng để gửi câu hỏi và câu trả lời. Hãy cố gắng tìm các bài đăng gần đây đã giải quyết các vấn đề tương tự.Nếu sau nhiều lần tìm kiếm, bạn không thể tìm thấy câu trả lời cho vấn đề của mình, hãy cân nhắc tạo một ví dụ có thể tái tạo (“reprex”) và tự đăng câu hỏi. Xem chương Nhờ sự trợ giúp để biết các mẹo về cách tạo và đăng một ví dụ có thể tái tạo lên diễn đàn.","code":""},{"path":"errors.html","id":"các-lỗi-thường-gặp","chapter":"47 Các lỗi thường gặp","heading":"47.2 Các lỗi thường gặp","text":"Dưới đây, chúng tôi liệt kê một số lỗi phổ biến và các giải thích/giải pháp tiềm năng. Một số trong số này được mượn từ Noam Ross, người đã phân tích các bài đăng phổ biến nhất trên diễn đàn Stack Overflow về các thông báo lỗi trên R (xem bài phân tích tại đây)","code":""},{"path":"errors.html","id":"lỗi-đánh-máy","chapter":"47 Các lỗi thường gặp","heading":"Lỗi đánh máy","text":"Nếu bạn thấy lỗi “unexpected symbol”, kiểm tra xem có thiếu dấu phẩy không","code":"Error: unexpected symbol in:\n\"  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\""},{"path":"errors.html","id":"các-lỗi-liên-quan-đến-package","chapter":"47 Các lỗi thường gặp","heading":"Các lỗi liên quan đến Package","text":"Điều này có thể có nghĩa là bạn đã nhập sai tên hàm hoặc quên cài đặt hoặc gọi một package.Bạn nghĩ rằng bạn đang sử dụng dplyr::select() nhưng thực tế là hàm select() đã bị đè bởi hàm MASS::select() - hãy ghi rõ dplyr:: hoặc sắp xếp lại thứ tự các package được gọi để dplyr đứng sau tất cả các package khác.Các lỗi hàm bị đè phổ biến khác bắt nguồn từ: plyr::summarise() và stats::filter(). Cân nhắc sử dụng conflicted package.Nếu bạn gặp lỗi thông báo rằng bạn cần xóa tệp “00LOCK”, go “R” library computer directory (e.g. R/win-library/) look folder called “00LOCK”. Delete manually, try installing package . previous install process probably interrupted, led .","code":"could not find function \"x\"...Error in select(data, var) : unused argument (var)Error in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’ for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’"},{"path":"errors.html","id":"các-lỗi-liên-quan-tới-đối-tượng","chapter":"47 Các lỗi thường gặp","heading":"Các lỗi liên quan tới đối tượng","text":"Nếu bạn gặp lỗi như thế này khi cố gắng xuất hoặc nhập: Hãy kiểm tra lỗi chính tả của tệp và đường dẫn tệp và nếu đường dẫn chứa dấu gạch chéo, hãy đảm bảo rằng bạn đang dùng dấu gạch chéo xuôi / chứ không phải dấu gạch chéo ngược \\. Ngoài ra, hãy đảm bảo rằng bạn đã sử dụng đúng phần mở rộng tệp (ví dụ: .csv, .xlsx).Điều này có nghĩa là một đối tượng bạn đang tham chiếu không tồn tại. Có lẽ code trên đã không chạy đúng cách?Điều này có nghĩa là bạn đã cố gắng truy cập vào thứ gì đó (một phần tử của vectơ hoặc danh sách) không có ở đó.","code":"No such file or directory:object 'x' not found Error in 'x': subscript out of bounds"},{"path":"errors.html","id":"các-lỗi-liên-quan-tới-cú-pháp-hàm","chapter":"47 Các lỗi thường gặp","heading":"Các lỗi liên quan tới cú pháp hàm","text":"Lỗi bên trên (argument .x missing, default) thường gặp với hàm mutate() nếu bạn đang cung cấp một hàm như recode() hoặc replace_na() trong đó nó yêu cầu bạn cung cấp tên cột làm đối số đầu tiên. Điều này rất dễ quên.","code":"# ran recode without re-stating the x variable in mutate(x = recode(x, OLD = NEW)\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`."},{"path":"errors.html","id":"các-lỗi-logic","chapter":"47 Các lỗi thường gặp","heading":"Các lỗi logic","text":"Điều này có thể có nghĩa là một mệnh đề đã được áp dụng cho một cái gì đó không phải là TRUE hoặc FALSE.","code":"Error in if"},{"path":"errors.html","id":"các-lỗi-liên-quan-tới-factor","chapter":"47 Các lỗi thường gặp","heading":"Các lỗi liên quan tới Factor","text":"Nếu bạn nhìn thấy lỗi liên quan tới thứ bậc kiểu factor không hợp lệ, có thể bạn đang có một cột kiểu Factor(chứa các thứ bậc đã được xác định) và bạn đang cố gắng thêm một giá trị mới vào nó. Chuyển nó thành kiểu ký tự trước khi thêm giá trị mới.","code":"#Tried to add a value (\"Missing\") to a factor (with replace_na operating on a factor)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated"},{"path":"errors.html","id":"lỗi-khi-vẽ-biểu-đồ","chapter":"47 Các lỗi thường gặp","heading":"Lỗi khi vẽ biểu đồ","text":"Error: Insufficient values manual scale. 3 needed 2 provided.\nĐây có thể là lỗi khi bạn vẽ biểu đồ bằng ggplot, sử dụng scale_fill_manual() values = c(“orange”, “purple”), trong đó bạn chưa cung cấp đủ số lượng màu cho hàm. Nếu cột này dạng factor, hãy cân nhắc liệu NA có phải là một bậc của factor hay không.Bạn có thể thừa dấu + ở cuối lệnh ggplot mà bạn cần xóa.","code":"Can't add x object"},{"path":"errors.html","id":"lỗi-r-markdown","chapter":"47 Các lỗi thường gặp","heading":"Lỗi R Markdown","text":"Nếu thông báo lỗi là Error options[[sprintf(\"fig.%s\", )]], kiểm tra xem các tùy chọn của knitr ở đầu mỗi đoạn code có sử dụng chính xác .width = hoặc .height = và không phải fig.width= và fig.height= hay không.","code":""},{"path":"errors.html","id":"tổng-hợp","chapter":"47 Các lỗi thường gặp","heading":"Tổng hợp","text":"Cân nhắc liệu bạn có đã sắp xếp lại các động từ dplyr đã được pipe và đã không thay thế một pipe ở giữa, hoặc đã không xóa một pipe ở cuối sau khi sắp xếp lại.","code":""},{"path":"errors.html","id":"nguồn-7","chapter":"47 Các lỗi thường gặp","heading":"47.3 Nguồn","text":"Đây là một bài đăng trên blog khác liệt kê Các lỗi lập trình R phổ biến mà người mới bắt đầu gặp phải","code":""},{"path":"help.html","id":"help","chapter":"48 Nhờ sự trợ giúp","heading":"48 Nhờ sự trợ giúp","text":"page covers get help posting Github issue posting reproducible example (“reprex”) online forum.","code":""},{"path":"help.html","id":"github-issues","chapter":"48 Nhờ sự trợ giúp","heading":"48.1 Github issues","text":"Many R packages projects code hosted website Github.com. can communicate directly authors via website posting “Issue”.Read store work Github page [Collaboration Github].Github, project contained within repository. repository contains code, data, outputs, help documentation, etc. also vehicle communicate authors called “Issues”.See Github page incidence2 package (used make epidemic curves). can see “Issues” tab highlighted yellow. can see 5 open issues.Issues tab, can see open issues. Review ensure problem already addressed. can open new issue clicking green button right. need Github account .issue, follow instructions provide minimal, reproducible example. please courteous! people developing R packages projects spare time (like handbook!).read advanced materials handling issues Github repository, check Github documentation Issues.","code":""},{"path":"help.html","id":"reproducible-example","chapter":"48 Nhờ sự trợ giúp","heading":"48.2 Reproducible example","text":"Providing reproducible example (“reprex”) key getting help posting forum Github issue. People want help , give example can work computer. example :Demonstrate problem encounteredBe minimal, includes data code required reproduce problemBe reproducible, objects (e.g. data), package calls (e.g. library() p_load()) includedAlso, sure post sensitive data reprex! can create example data frames, use one data frames built R (enter data() open list datasets).","code":""},{"path":"help.html","id":"the-reprex-package","chapter":"48 Nhờ sự trợ giúp","heading":"The reprex package","text":"reprex package can assist making reproducible example:reprex installed tidyverse, load either packageBegin R script creates problem, step--step, starting loading packages data.Copy code clipboard, run following command:see HTML output appear RStudio Viewer pane. contain code warnings, errors, plot outputs. output also copied clipboard, can post directly Github issue forum post.set session_info = TRUE output sessioninfo::session_info() R R package versions includedYou can provide working directory wd =can read arguments possible variations documentation entering ?reprexIn example , ggplot() command run arguemnt date_format = correct - date_labels =.","code":"\n# install/load tidyverse (which includes reprex)\npacman::p_load(tidyverse)\n# load packages\npacman::p_load(\n     tidyverse,  # data mgmt and vizualization\n     outbreaks)  # example outbreak datasets\n\n# flu epidemic case linelist\noutbreak_raw <- outbreaks::fluH7N9_china_2013  # retrieve dataset from outbreaks package\n\n# Clean dataset\noutbreak <- outbreak_raw %>% \n     mutate(across(contains(\"date\"), as.Date))\n\n# Plot epidemic\n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\nreprex::reprex()"},{"path":"help.html","id":"minimal-data","chapter":"48 Nhờ sự trợ giúp","heading":"Minimal data","text":"helpers need able use data - ideally need able create code.create minumal dataset, consider anonymising using subset observations.CONSTRUCTION - can also use function dput() create minimal dataset.","code":""},{"path":"help.html","id":"posting-to-a-forum","chapter":"48 Nhờ sự trợ giúp","heading":"48.3 Posting to a forum","text":"Read lots forum posts. Get understanding posts well-written, ones .First, decide whether ask question . thoroughly reviewed forum website, trying various search terms, see question already asked?First, decide whether ask question . thoroughly reviewed forum website, trying various search terms, see question already asked?Give question informative title (“Help! isn’t working”).Give question informative title (“Help! isn’t working”).Write question:Write question:Introduce situation problemLink posts similar issues explain answer questionInclude relevant information help someone know context workGive minimal reproducible example R session informationUse proper spelling, grammar, punctuation, break question paragraphs easier readMonitor question posted respond requests clarification. courteous gracious - often people answering volunteering time help . follow-question consider whether separate posted question.Monitor question posted respond requests clarification. courteous gracious - often people answering volunteering time help . follow-question consider whether separate posted question.Mark question answered, get answer meets original request. helps others later quickly recognize solution.Mark question answered, get answer meets original request. helps others later quickly recognize solution.Read posts ask good question Stack overflow code conduct.","code":""},{"path":"help.html","id":"resources-29","chapter":"48 Nhờ sự trợ giúp","heading":"48.4 Resources","text":"Tidyverse page get help!Tips producing minimal datasetDocumentation dput function","code":""},{"path":"network-drives.html","id":"network-drives","chapter":"49 R trên ổ cứng mạng","heading":"49 R trên ổ cứng mạng","text":"","code":""},{"path":"network-drives.html","id":"overview-8","chapter":"49 R trên ổ cứng mạng","heading":"49.1 Overview","text":"Using R network “company” shared drives can present additional challenges. page contains approaches, common errors, suggestions troubleshooting gained experience working issues. include tips particularly delicate situations involving R Markdown.Using R Network Drives: Overarching principlesYou must get administrator access computer. Setup RStudio specifically run administrator.Save packages library lettered drive (e.g. “C:”) possible. Use package library whose path begins \"\\\" little possible.rmarkdown package must \"\\\" package library, can’t connect TinyTex Pandoc.","code":""},{"path":"network-drives.html","id":"rstudio-as-administrator","chapter":"49 R trên ổ cứng mạng","heading":"49.2 RStudio as administrator","text":"click RStudio icon open RStudio, right-click. Depending machine, may see option “Run Administrator”. Otherwise, may see option select Properties (appear window option “Compatibility”, can select checkbox “Run Administrator”).","code":""},{"path":"network-drives.html","id":"useful-commands","chapter":"49 R trên ổ cứng mạng","heading":"49.3 Useful commands","text":"useful commands trying troubleshoot issues using R network drives.can return path(s) package libraries R using. listed order R using install/load/search packages. Thus, want R use different default library, can switch order paths (see ).may want switch order package libraries used R. example R picking library location begins “\\\" one begins letter e.g. ”D:\". can adjust order .libPaths() following code.difficulties R Markdown connecting Pandoc, begin code find RStudio thinks Pandoc installation .want see library package loading , try code:","code":"\n# Find libraries\n.libPaths()                   # Your library paths, listed in order that R installs/searches. \n                              # Note: all libraries will be listed, but to install to some (e.g. C:) you \n                              # may need to be running RStudio as an administrator (it won't appear in the \n                              # install packages library drop-down menu) \n# Switch order of libraries\n# this can effect the priority of R finding a package. E.g. you may want your C: library to be listed first\nmyPaths <- .libPaths() # get the paths\nmyPaths <- c(myPaths[2], myPaths[1]) # switch them\n.libPaths(myPaths) # reassign them\n# Find Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\")  # Find where RStudio thinks your Pandoc installation is\n# Find a package\n# gives first location of package (note order of your libraries)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\")) "},{"path":"network-drives.html","id":"troubleshooting-common-errors","chapter":"49 R trên ổ cứng mạng","heading":"49.4 Troubleshooting common errors","text":"“Failed compile…tex rmarkdown”Check installation TinyTex, install TinyTex C: location. See [R basics] page install TinyTex.Internet routines loadedFor example, Error tools::startDynamicHelp() : internet routines loadedTry selecting 32-bit version RStudio via Tools/Global Options.\nnote: 32-bit version appear menu, make sure using RStudio v1.2.\nnote: 32-bit version appear menu, make sure using RStudio v1.2.Alternatively, try uninstalling R re-installing different bit version (32 instead 64)C: library appear option try install packages manuallyRun RStudio administrator, option appear.set-RStudio always run administrator (advantageous using Rproject don’t click RStudio icon open)… right-click Rstudio iconThe image shows can manually select library install package . window appears open Packages RStudio pane click “Install”.Pandoc 1 errorIf getting “pandoc error 1” knitting R Markdowns scripts network drives:multiple library locations, one lettered drive listed first (see codes )solution worked knitting local drive networked internet connectionSee tips : https://ciser.cornell.edu/rmarkdown-knit--html-word-pdf/Pandoc Error 83The error look something like : find file...rmarkdown...lua.... means unable find file.See https://stackoverflow.com/questions/58830927/rmarkdown-unable--locate-lua-filter--knitting--wordPossibilities:Rmarkdown package installedRmarkdown package findableAn admin rights issue.possible R able find rmarkdown package file, check library rmarkdown package lives (see code ). package installed library inaccessible (e.g. starts \"\\\") consider manually moving C: named drive library. aware rmarkdown package able connect TinyTex installation, can live library network drive.Pandoc Error 61For example: Error: pandoc document conversion failed error 61 fetch...Try running RStudio administrator (right click icon, select run admin, see instructions)Also see specific package unable reached can moved C: library.LaTex error (see )error like: ! Package pdftex.def Error: File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' found: using draft setting. Error: LaTeX failed compile file_name.tex.See https://yihui.org/tinytex/r/#debugging debugging tips.See file_name.log info.Pandoc Error 127This RAM (space) issue. Re-start R session try .Mapping network drivesMapping network drive can risky. Consult department attempting .tip borrowed forum discussion:one open file “mapped network drive”?First, ’ll need know network location ’re trying access.Next, Windows file manager, need right click “PC” right hand pane, select “Map network drive”.Go dialogue define network location earlier lettered drive.Now two ways get file ’re opening. Using drive-letter path work.Error install.packages()get error includes mention “lock” directory, example: Error install.packages : ERROR: failed lock directory...Look package library see folder whose name begins “00LOCK”. Try following tips:Manually delete “00LOCK” folder directory package library. Try installing package .can also try command pacman::p_unlock() (can also put command Rprofile runs every time project opens.). try installing package . may take several tries.Try running RStudio Administrator mode, try installing packages one--one.else fails, install package another library folder (e.g. Temp) manually copy package’s folder desired library.","code":"\n# check/install tinytex, to C: location\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # should return TRUE (note three colons)"},{"path":"data-table.html","id":"data-table","chapter":"50 Data Table","heading":"50 Data Table","text":"handbook focusses dplyr “verb” functions magrittr pipe operator %>% method clean group data, data.table package offers alternative method may encounter R career.","code":""},{"path":"data-table.html","id":"intro-to-data-tables","chapter":"50 Data Table","heading":"50.1 Intro to data tables","text":"data table 2-dimensional data structure like data frame allows complex grouping operations performed. data.table syntax structured operations can performed rows, columns groups.structure DT[, j, ], separated 3 parts; , j arguments. argument allows subsetting required rows, j argument allows operate columns argument allows operate columns groups.page address following topics:Importing data use fread() fwrite()Selecting filtering rows using argumentUsing helper functions %like%, %chin%, %%Selecting computing columns using j argumentComputing groups using argumentAdding updating data data tables using :=","code":""},{"path":"data-table.html","id":"load-packages-and-import-data","chapter":"50 Data Table","heading":"50.2 Load packages and import data","text":"","code":""},{"path":"data-table.html","id":"load-packages-27","chapter":"50 Data Table","heading":"Load packages","text":"Using p_load() function pacman, load (install necessary) packages required analysis.","code":"\npacman::p_load(\n  rio,        # to import data\n  data.table, # to group and clean data\n  tidyverse,  # allows use of pipe (%>%) function in this chapter\n  here \n  ) "},{"path":"data-table.html","id":"import-data-21","chapter":"50 Data Table","heading":"Import data","text":"page explore core functions data.table using case linelist referenced throughout handbook.import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions [Download book data] page. dataset imported using import() function rio package. See page [Import export] various ways import data. use data.table() convert data frame data table.fread() function used directly import regular delimited files, .csv files, directly data table format. function, counterpart, fwrite(), used writing data.tables regular delimited files fast computationally efficient options large databases.first 20 rows linelist:Base R commands dim() used data frames can also used data tables","code":"\nlinelist <- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %>% data.table()\ndim(linelist) #gives the number of rows and columns in the data table## [1] 5888   30"},{"path":"data-table.html","id":"the-i-argument-selecting-and-filtering-rows","chapter":"50 Data Table","heading":"50.3 The i argument: selecting and filtering rows","text":"Recalling DT[, j, ] structure, can filter rows using either row numbers logical expressions. argument first; therefore, syntax DT[] DT[,] can used.first example retrieves first 5 rows data table, second example subsets cases 18 years , third example subsets cases 18 years old diagnosed Central Hospital:Using .N argument represents total number rows data table. can used subset row numbers:","code":"\nlinelist[1:5] #returns the 1st to 5th row\nlinelist[age >= 18] #subsets cases are equal to or over 18 years\nlinelist[age >= 18 & hospital != \"Central Hospital\"] #subsets cases equal to or over 18 years old but not diagnosed at the Central Hospital\nlinelist[.N] #returns the last row\nlinelist[15:.N] #returns the 15th to the last row"},{"path":"data-table.html","id":"using-helper-functions-for-filtering","chapter":"50 Data Table","heading":"Using helper functions for filtering","text":"Data table uses helper functions make subsetting rows easy. %like% function used match pattern column, %chin% used match specific character, %% helper function used match numeric columns within prespecified range.following examples :\n* filter rows hospital variable contains “Hospital”\n* filter rows outcome “Recover” “Death”\n* filter rows age range 40-60","code":"\nlinelist[hospital %like% \"Hospital\"] #filter rows where the hospital variable contains “Hospital”\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] #filter rows where the outcome is “Recover” or “Death”\nlinelist[age %between% c(40, 60)] #filter rows in the age range 40-60\n\n#%between% must take a vector of length 2, whereas %chin% can take vectors of length >= 1"},{"path":"data-table.html","id":"the-j-argument-selecting-and-computing-on-columns","chapter":"50 Data Table","heading":"50.4 The j argument: selecting and computing on columns","text":"Using DT[, j, ] structure, can select columns using numbers names. j argument second; therefore, syntax DT[, j] used. facilitate computations j argument, column wrapped using either list() .().","code":""},{"path":"data-table.html","id":"selecting-columns","chapter":"50 Data Table","heading":"Selecting columns","text":"first example retrieves first, third fifth columns data table, second example selects columns except height, weight gender columns. third example uses .() wrap select case_id outcome columns.","code":"\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] works just as well"},{"path":"data-table.html","id":"computing-on-columns","chapter":"50 Data Table","heading":"Computing on columns","text":"combining j arguments possible filter rows compute columns. Using .N j argument also represents total number rows data table can useful return number rows row filtering.following examples :\n* Count number cases stayed 7 days hospital\n* Calculate mean age cases died military hospital\n* Calculate standard deviation, median, mean age cases recovered central hospitalRemember using .() wrap j argument facilitates computation, returns data table allows column naming.","code":"\nlinelist[days_onset_hosp > 7 , .N]## [1] 189\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] #na.rm = T removes N/A values##         V1\n## 1: 15.9084\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] #this syntax does not use the helper functions but works just as well##    mean_age median_age   sd_age\n## 1: 16.85185         14 12.93857"},{"path":"data-table.html","id":"the-by-argument-computing-by-groups","chapter":"50 Data Table","heading":"50.5 The by argument: computing by groups","text":"argument third argument DT[, j, ] structure. argument accepts character vector list() .() syntax. Using .() syntax argument allows column renaming fly.following examples :\n* group number cases hospital\n* cases 18 years old , calculate mean height weight cases according gender whether recovered died\n* admissions lasted 7 days, count number cases according month admitted hospital admitted toData.table also allows chaining expressions follows:examples following assumption row data table equal new case, can use .N represent number rows data table. Another useful function represent number unique cases uniqueN(), returns number unique values given input. illustrated :answer 3, unique values gender column m, f N/. Compare base R function unique(), returns unique values given input:find number unique cases given month write following:","code":"\nlinelist[, .N, .(hospital)] #the number of cases by hospital##                                hospital    N\n## 1:                                Other  885\n## 2:                              Missing 1469\n## 3: St. Mark's Maternity Hospital (SMMH)  422\n## 4:                        Port Hospital 1762\n## 5:                    Military Hospital  896\n## 6:                     Central Hospital  454\nlinelist[age > 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NAs represent the categories where the data is missing##    gender outcome  mean_wt  mean_ht\n## 1:      m Recover 71.90227 178.1977\n## 2:      f   Death 63.27273 159.9448\n## 3:      m   Death 71.61770 175.4726\n## 4:      f    <NA> 64.49375 162.7875\n## 5:      m    <NA> 72.65505 176.9686\n## 6:      f Recover 62.86498 159.2996\n## 7:   <NA> Recover 67.21429 175.2143\n## 8:   <NA>   Death 69.16667 170.7917\n## 9:   <NA>    <NA> 70.25000 175.5000\nlinelist[days_onset_hosp > 7, .N, .(month = month(date_hospitalisation), hospital)]##     month                             hospital  N\n##  1:     5                    Military Hospital  3\n##  2:     6                        Port Hospital  4\n##  3:     7                        Port Hospital  8\n##  4:     8 St. Mark's Maternity Hospital (SMMH)  5\n##  5:     8                    Military Hospital  9\n##  6:     8                                Other 10\n##  7:     8                        Port Hospital 10\n##  8:     9                        Port Hospital 28\n##  9:     9                              Missing 27\n## 10:     9                     Central Hospital 10\n## 11:     9 St. Mark's Maternity Hospital (SMMH)  6\n## 12:    10                              Missing  2\n## 13:    10                    Military Hospital  3\n## 14:     3                        Port Hospital  1\n## 15:     4                    Military Hospital  1\n## 16:     5                                Other  2\n## 17:     5                     Central Hospital  1\n## 18:     5                              Missing  1\n## 19:     6                              Missing  7\n## 20:     6 St. Mark's Maternity Hospital (SMMH)  2\n## 21:     6                    Military Hospital  1\n## 22:     7                    Military Hospital  3\n## 23:     7                                Other  1\n## 24:     7                              Missing  2\n## 25:     7 St. Mark's Maternity Hospital (SMMH)  1\n## 26:     8                     Central Hospital  2\n## 27:     8                              Missing  6\n## 28:     9                                Other  9\n## 29:     9                    Military Hospital 11\n## 30:    10                        Port Hospital  3\n## 31:    10                                Other  4\n## 32:    10 St. Mark's Maternity Hospital (SMMH)  1\n## 33:    10                     Central Hospital  1\n## 34:    11                              Missing  2\n## 35:    11                        Port Hospital  1\n## 36:    12                        Port Hospital  1\n##     month                             hospital  N\nlinelist[, .N, .(hospital)][order(-N)][1:3] #1st selects all cases by hospital, 2nd orders the cases in descending order, 3rd subsets the 3 hospitals with the largest caseload##             hospital    N\n## 1:     Port Hospital 1762\n## 2:           Missing 1469\n## 3: Military Hospital  896\nlinelist[, .(uniqueN(gender))] #remember .() in the j argument returns a data table##    V1\n## 1:  3\nlinelist[, .(unique(gender))]##      V1\n## 1:    m\n## 2:    f\n## 3: <NA>\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]##     month   V1\n##  1:     5   62\n##  2:     6  100\n##  3:     7  198\n##  4:     8  509\n##  5:     9 1170\n##  6:    10 1228\n##  7:    11  813\n##  8:    12  576\n##  9:     1  434\n## 10:     2  310\n## 11:     3  290\n## 12:     4  198"},{"path":"data-table.html","id":"adding-and-updating-to-data-tables","chapter":"50 Data Table","heading":"50.6 Adding and updating to data tables","text":":= operator used add update data data table. Adding columns data table can done following ways:complex aggregations beyond scope introductory chapter, idea provide popular viable alternative dplyr grouping cleaning data. data.table package great package allows neat readable code.","code":"\nlinelist[, adult := age >= 18] #adds one column\nlinelist[, c(\"child\", \"wt_lbs\") := .(age < 18, wt_kg*2.204)] #to add multiple columns requires c(\"\") and list() or .() syntax\nlinelist[, `:=` (bmi_in_range = (bmi > 16 & bmi < 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] #this method uses := as a functional operator `:=`\nlinelist[, adult := NULL] #deletes the column"},{"path":"data-table.html","id":"resources-30","chapter":"50 Data Table","heading":"50.7 Resources","text":"useful resources information:\n* https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\n* https://github.com/Rdatatable/data.table\n* https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf\n* https://www.machinelearningplus.com/data-manipulation/datatable--r-complete-guide/\n* https://www.datacamp.com/community/tutorials/data-table-r-tutorialYou can perform summary function grouped data; see Cheat Sheet info:\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf","code":""}]
